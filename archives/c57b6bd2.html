<!DOCTYPE HTML>
<html lang="en">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="应用软件开发基础论文报告, ">
    <meta name="description" content=" ">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>应用软件开发基础论文报告 | </title>
    <link rel="icon" type="image/png" href="/favicon.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">

    <script src="/libs/jquery/jquery.min.js"></script>

<meta name="generator" content="Hexo 5.4.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head>




<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span"></span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>Home</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>Tags</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>Categories</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>Archives</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>About</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>Contact</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>Friends</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="Search" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name"></div>
        <div class="logo-desc">
            
             
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			Home
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			Tags
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			Categories
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			Archives
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			About
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			Contact
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			Friends
		</a>
          
        </li>
        
        
    </ul>
</div>


        </div>

        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/0.png')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">应用软件开发基础论文报告</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        padding: 35px 0 15px 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        padding-bottom: 30px;
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;

        position: absolute;
        right: 23.5vw;
        display: block;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/%E6%9C%9F%E6%9C%AB%E4%BD%9C%E4%B8%9A/">
                                <span class="chip bg-color">期末作业</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/%E7%94%9F%E6%B4%BB/" class="post-category">
                                生活
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>Publish Date:&nbsp;&nbsp;
                    2021-10-08
                </div>
                

                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>Word Count:&nbsp;&nbsp;
                    8.8k
                </div>
                

                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>Read Count:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        
        <!-- 是否加载使用自带的 prismjs. -->
        <link rel="stylesheet" href="/libs/prism/prism.css">
        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <h1 id="应用软件开发基础论文报告"><a href="#应用软件开发基础论文报告" class="headerlink" title="应用软件开发基础论文报告"></a>应用软件开发基础论文报告</h1><h3 id="——Python-numpy实习报告-以前馈神经网络为例"><a href="#——Python-numpy实习报告-以前馈神经网络为例" class="headerlink" title="——Python numpy实习报告 (以前馈神经网络为例)"></a>——Python numpy实习报告 (以前馈神经网络为例)</h3><h2 id="选题背景"><a href="#选题背景" class="headerlink" title="选题背景"></a>选题背景</h2><p><strong>深度前馈网络（deep feed-forward network）</strong>也叫作<strong>前馈神经网络（feed-forward neural network）</strong>或者<strong>多层感知机（multilayer perceptron, MLP）</strong>，是典型的深度学习模型。前馈网络的目标是近似某个函数。例如，对于分类器，$y = f (x)$ 将输入 x 映射到一个类别 y。前馈网络定义了一个映射 $y = f(x; θ)$，并且学习参数 θ 的值，使它能够得到最佳的函数近似。</p>
<p>这种模型被称为前向（feed-forward）的，是因为信息流过 x 的函数，流经用于 定义 f 的中间计算过程，最终到达输出 y。在模型的输出和模型本身之间没有反馈连接接。</p>
<p>前馈神经网络被称作<strong>全连接网络（fully connected network）</strong>是因为它们通常用许多不同函数复合在一起来表示。该模型与一个有向无环图相关联，而图描述了函数是如何复合在一起的。例如，我们有三个函数 $f_1, f_2, f_3$ 连接在一个链上以形成 </p>
<script type="math/tex; mode=display">
f(x) = f_3(f_2(f_1(x)))</script><p>这些链式结构是神经网络中最常用的结构。链的全长称为模型的<strong>深度（depth）</strong>。正是因为这个术语才出现了 ‘‘深度学习’’ 这个名字。</p>
<p>前馈神经网络在深度学习中扮演者非常重要的角色，是深度学习发展的基石。现在人们已经发展出了一些强大的深度学习框架，例如 TensorFlow, Pytorch 等等，在这些框架之上，能够方便地搭建各种各样的复杂网络，加速了深度学习的发展。前馈神经网络在这些框架之中也封装得非常好，可以用几行代码就可以轻松实现，本报告的主要目的在于使用 python 第三方库 numpy 来实现全连接网络的建立、优化等等，自下而上地深入地了解前馈神经网络的搭建过程及其工作原理。</p>
<h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p>全连接网络可以分为三个部分：输入层、隐藏层、输出层。网络中的每个隐藏层通常都是向量值的。这些隐藏层的维数决定了模型的<strong>宽度 （width）</strong>。向量的每个元素都可以被视为起到类似一个神经元的作用。除了将层想象成向量到向量的单个函数，我们也可以把层想象成由许多并行操作的<strong>单元（unit）</strong> 组成，每个单元表示一个向量到标量的函数。</p>
<p>现代的神经网络研究受到更多的是来自许多数学和工程学科的指引，并且神经网络的目 标并不是完美地给大脑建模。<strong>我们最好将前馈神经网络想成是为了实现统计泛化而设计出的函数近似机，它偶尔从我们了解的大脑中提取灵感，但并不是大脑功能的模型</strong>。</p>
<p><img src="/archives/c57b6bd2/image-20210624151217027.png" alt="image-20210624151217027" style="zoom: 33%;"></p>
<p>由于线性模型有明显的缺陷，即模型的能力被局限在线性函数里，所以它无法理解任何两个输入变量间的相互作用。为了扩展线性模型来表示 x 的非线性函数，我们可以不把线性模型用于 x 本身， 而是用在一个变换后的输入 ϕ(x) 上，这里 <strong>ϕ 是一个非线性变换</strong>。我们可以认为 ϕ 提供了一组描述 x 的特征，或者认为它提供了 x 的一个新的表示。</p>
<p>深度学习的策略是去学习 ϕ。在这种方法中，我们有一个模型 y = f(x; θ, w) = ϕ(x; θ) ⊤w。我们现在有两种参数：用于从一大类函数中学习 ϕ 的参数 θ，以及用于将 ϕ(x) 映射到所需的输出的参数 w。这是深度前馈网络的一个例子，<strong>其中 ϕ 定义了一个隐藏层</strong>。这是种方法放弃了训练问题的凸性的， 但是利大于弊。</p>
<p>神经网络的非线性导致大多数我们感兴趣的代价函数都变得非凸，这意味着神经网络的训练通常使用迭代的、基于梯度的优化，仅仅使得代价函数达到一个非常小的值。和其他的机器学习模型一样，为了使用基于梯度的学习方法我们必须选择一个代价函数，并且我们必须选择如何表示模型的输出。</p>
<h2 id="历史和分类"><a href="#历史和分类" class="headerlink" title="历史和分类"></a>历史和分类</h2><p>深度学习（Deep Learning）一词最初在 <strong>1986</strong> 被引入机器学习（Machine Learning），后来在 2000 年时被用于<strong>人工神经网络（ANN</strong>）。深度神经网络由多个隐层组成，以学习具有多个抽象层次的数据特征。深度学习方法允许计算机通过相对简单的概念来学习复杂的概念。对于人工神经网络（ANN），深度学习（DL）（也称为分层学习（Hierarchical Learning）），为了学习复杂的功能，深层的架构被用于多个抽象层次，即非线性操作。用准确的话总结就是，<strong>深度学习是机器学习的一个子领域，它使用了多层次的非线性信息处理和抽象，用于有监督、无监督、半监督、自监督、弱监督等的特征学习、表示、分类、回归和模式识别等</strong>。</p>
<p><strong>第一代</strong>人工神经网络由简单的感知器神经层组成（也就是感知器），只能进行有限的简单计算。<strong>第二代</strong>使用反向传播，反向传播算法的核心算法是用链式求导法则，即目标函数对于输出层的导数（或梯度），通过该层向前一层求导实现，如此递延一直传递到第一层（输入层）。最后将特征传递给一个非线性激活函数，可以得到分类的结果。为了克服反向传播中出现的梯度消失和梯度爆炸等局限性，人们提出了受限玻尔兹曼机（RBM），使学习更容易。此时其他技术和神经网络也出现了，如前馈神经网络 (FNN)、卷积神经网络 (CNN)、循环神经网络 (RNN) 等，以及深层信念网络、自编码器、GAN等。从那时起，为实现各种用途，ANN 在不同方面得到了改进和设计。</p>
<h2 id="案例实战"><a href="#案例实战" class="headerlink" title="案例实战"></a>案例实战</h2><h3 id="main-py"><a href="#main-py" class="headerlink" title="main.py"></a>main.py</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token triple-quoted-string string">""" Fully-Connected Neural Network """</span>
<span class="token keyword">import</span> time
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">from</span> FCN<span class="token punctuation">.</span>classifiers<span class="token punctuation">.</span>fc_net <span class="token keyword">import</span> <span class="token operator">*</span>
<span class="token keyword">from</span> FCN<span class="token punctuation">.</span>data_utils <span class="token keyword">import</span> get_CIFAR10_data
<span class="token keyword">from</span> FCN<span class="token punctuation">.</span>gradient_check <span class="token keyword">import</span> eval_numerical_gradient<span class="token punctuation">,</span> eval_numerical_gradient_array
<span class="token keyword">from</span> FCN<span class="token punctuation">.</span>solver <span class="token keyword">import</span> Solver

plt<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">'figure.figsize'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">10.0</span><span class="token punctuation">,</span> <span class="token number">8.0</span><span class="token punctuation">)</span>  <span class="token comment"># set default size of plots</span>
plt<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">'image.interpolation'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'nearest'</span>
plt<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">'image.cmap'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'gray'</span>


<span class="token keyword">def</span> <span class="token function">rel_error</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">""" returns relative error """</span>
    <span class="token keyword">return</span> np<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span><span class="token builtin">abs</span><span class="token punctuation">(</span>x <span class="token operator">-</span> y<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span>np<span class="token punctuation">.</span>maximum<span class="token punctuation">(</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">8</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span><span class="token builtin">abs</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token operator">+</span> np<span class="token punctuation">.</span><span class="token builtin">abs</span><span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>


<span class="token comment"># load CIFAR10 data</span>
data <span class="token operator">=</span> get_CIFAR10_data<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> <span class="token builtin">list</span><span class="token punctuation">(</span>data<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">'%s: '</span> <span class="token operator">%</span> k<span class="token punctuation">,</span> v<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>


<span class="token comment"># Affine layer forward</span>

num_inputs <span class="token operator">=</span> <span class="token number">2</span>
input_shape <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span>
output_dim <span class="token operator">=</span> <span class="token number">3</span>

input_size <span class="token operator">=</span> num_inputs <span class="token operator">*</span> np<span class="token punctuation">.</span>prod<span class="token punctuation">(</span>input_shape<span class="token punctuation">)</span>
weight_size <span class="token operator">=</span> output_dim <span class="token operator">*</span> np<span class="token punctuation">.</span>prod<span class="token punctuation">(</span>input_shape<span class="token punctuation">)</span>

x <span class="token operator">=</span> np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> num<span class="token operator">=</span>input_size<span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>num_inputs<span class="token punctuation">,</span> <span class="token operator">*</span>input_shape<span class="token punctuation">)</span>
w <span class="token operator">=</span> np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">0.2</span><span class="token punctuation">,</span> <span class="token number">0.3</span><span class="token punctuation">,</span> num<span class="token operator">=</span>weight_size<span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>np<span class="token punctuation">.</span>prod<span class="token punctuation">(</span>input_shape<span class="token punctuation">)</span><span class="token punctuation">,</span> output_dim<span class="token punctuation">)</span>
b <span class="token operator">=</span> np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">0.3</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">,</span> num<span class="token operator">=</span>output_dim<span class="token punctuation">)</span>

out<span class="token punctuation">,</span> _ <span class="token operator">=</span> affine_forward<span class="token punctuation">(</span>x<span class="token punctuation">,</span> w<span class="token punctuation">,</span> b<span class="token punctuation">)</span>
correct_out <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">1.49834967</span><span class="token punctuation">,</span>  <span class="token number">1.70660132</span><span class="token punctuation">,</span>  <span class="token number">1.91485297</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                        <span class="token punctuation">[</span> <span class="token number">3.25553199</span><span class="token punctuation">,</span>  <span class="token number">3.5141327</span><span class="token punctuation">,</span>   <span class="token number">3.77273342</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># Compare your output with ours. The error should be around 1e-9.</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Testing affine_forward function:'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'difference: '</span><span class="token punctuation">,</span> rel_error<span class="token punctuation">(</span>out<span class="token punctuation">,</span> correct_out<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"--------------------------------------------------------"</span><span class="token punctuation">)</span>

<span class="token comment"># Affine layer backward</span>
x <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
w <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>
b <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span>
dout <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>

dx_num <span class="token operator">=</span> eval_numerical_gradient_array<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> affine_forward<span class="token punctuation">(</span>x<span class="token punctuation">,</span> w<span class="token punctuation">,</span> b<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> x<span class="token punctuation">,</span> dout<span class="token punctuation">)</span>
dw_num <span class="token operator">=</span> eval_numerical_gradient_array<span class="token punctuation">(</span><span class="token keyword">lambda</span> w<span class="token punctuation">:</span> affine_forward<span class="token punctuation">(</span>x<span class="token punctuation">,</span> w<span class="token punctuation">,</span> b<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> w<span class="token punctuation">,</span> dout<span class="token punctuation">)</span>
db_num <span class="token operator">=</span> eval_numerical_gradient_array<span class="token punctuation">(</span><span class="token keyword">lambda</span> b<span class="token punctuation">:</span> affine_forward<span class="token punctuation">(</span>x<span class="token punctuation">,</span> w<span class="token punctuation">,</span> b<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> b<span class="token punctuation">,</span> dout<span class="token punctuation">)</span>

_<span class="token punctuation">,</span> cache <span class="token operator">=</span> affine_forward<span class="token punctuation">(</span>x<span class="token punctuation">,</span> w<span class="token punctuation">,</span> b<span class="token punctuation">)</span>
dx<span class="token punctuation">,</span> dw<span class="token punctuation">,</span> db <span class="token operator">=</span> affine_backward<span class="token punctuation">(</span>dout<span class="token punctuation">,</span> cache<span class="token punctuation">)</span>

<span class="token comment"># The error should be around 1e-10</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Testing affine_backward function:'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'dx error: '</span><span class="token punctuation">,</span> rel_error<span class="token punctuation">(</span>dx_num<span class="token punctuation">,</span> dx<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'dw error: '</span><span class="token punctuation">,</span> rel_error<span class="token punctuation">(</span>dw_num<span class="token punctuation">,</span> dw<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'db error: '</span><span class="token punctuation">,</span> rel_error<span class="token punctuation">(</span>db_num<span class="token punctuation">,</span> db<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"--------------------------------------------------------"</span><span class="token punctuation">)</span>

<span class="token comment"># Test the relu_forward/backward function</span>

x <span class="token operator">=</span> np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> num<span class="token operator">=</span><span class="token number">12</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>

out<span class="token punctuation">,</span> _ <span class="token operator">=</span> relu_forward<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
correct_out <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span>          <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span>          <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span>          <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span>        <span class="token punctuation">]</span><span class="token punctuation">,</span>
                        <span class="token punctuation">[</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span>          <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span>          <span class="token number">0.04545455</span><span class="token punctuation">,</span>  <span class="token number">0.13636364</span><span class="token punctuation">,</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                        <span class="token punctuation">[</span> <span class="token number">0.22727273</span><span class="token punctuation">,</span>  <span class="token number">0.31818182</span><span class="token punctuation">,</span>  <span class="token number">0.40909091</span><span class="token punctuation">,</span>  <span class="token number">0.5</span><span class="token punctuation">,</span>       <span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># Compare your output with ours. The error should be around 1e-8</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Testing relu_forward function:'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'difference: '</span><span class="token punctuation">,</span> rel_error<span class="token punctuation">(</span>out<span class="token punctuation">,</span> correct_out<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"--------------------------------------------------------"</span><span class="token punctuation">)</span>
x <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>
dout <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token operator">*</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>

dx_num <span class="token operator">=</span> eval_numerical_gradient_array<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> relu_forward<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> x<span class="token punctuation">,</span> dout<span class="token punctuation">)</span>

_<span class="token punctuation">,</span> cache <span class="token operator">=</span> relu_forward<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
dx <span class="token operator">=</span> relu_backward<span class="token punctuation">(</span>dout<span class="token punctuation">,</span> cache<span class="token punctuation">)</span>

<span class="token comment"># The error should be around 1e-12</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Testing relu_backward function:'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'dx error: '</span><span class="token punctuation">,</span> rel_error<span class="token punctuation">(</span>dx_num<span class="token punctuation">,</span> dx<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"--------------------------------------------------------"</span><span class="token punctuation">)</span>

<span class="token comment"># "Sandwich" layers: affine-relu-forward</span>
<span class="token keyword">from</span> FCN<span class="token punctuation">.</span>layer_utils <span class="token keyword">import</span> affine_relu_forward<span class="token punctuation">,</span> affine_relu_backward

x <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>
w <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>
b <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span>
dout <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>

out<span class="token punctuation">,</span> cache <span class="token operator">=</span> affine_relu_forward<span class="token punctuation">(</span>x<span class="token punctuation">,</span> w<span class="token punctuation">,</span> b<span class="token punctuation">)</span>
dx<span class="token punctuation">,</span> dw<span class="token punctuation">,</span> db <span class="token operator">=</span> affine_relu_backward<span class="token punctuation">(</span>dout<span class="token punctuation">,</span> cache<span class="token punctuation">)</span>

dx_num <span class="token operator">=</span> eval_numerical_gradient_array<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> affine_relu_forward<span class="token punctuation">(</span>x<span class="token punctuation">,</span> w<span class="token punctuation">,</span> b<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> x<span class="token punctuation">,</span> dout<span class="token punctuation">)</span>
dw_num <span class="token operator">=</span> eval_numerical_gradient_array<span class="token punctuation">(</span><span class="token keyword">lambda</span> w<span class="token punctuation">:</span> affine_relu_forward<span class="token punctuation">(</span>x<span class="token punctuation">,</span> w<span class="token punctuation">,</span> b<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> w<span class="token punctuation">,</span> dout<span class="token punctuation">)</span>
db_num <span class="token operator">=</span> eval_numerical_gradient_array<span class="token punctuation">(</span><span class="token keyword">lambda</span> b<span class="token punctuation">:</span> affine_relu_forward<span class="token punctuation">(</span>x<span class="token punctuation">,</span> w<span class="token punctuation">,</span> b<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> b<span class="token punctuation">,</span> dout<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Testing affine_relu_forward:'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'dx error: '</span><span class="token punctuation">,</span> rel_error<span class="token punctuation">(</span>dx_num<span class="token punctuation">,</span> dx<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'dw error: '</span><span class="token punctuation">,</span> rel_error<span class="token punctuation">(</span>dw_num<span class="token punctuation">,</span> dw<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'db error: '</span><span class="token punctuation">,</span> rel_error<span class="token punctuation">(</span>db_num<span class="token punctuation">,</span> db<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"--------------------------------------------------------"</span><span class="token punctuation">)</span>

<span class="token comment"># softmax loss</span>
num_classes<span class="token punctuation">,</span> num_inputs <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">50</span>
x <span class="token operator">=</span> <span class="token number">0.001</span> <span class="token operator">*</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>num_inputs<span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span>
y <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span>num_classes<span class="token punctuation">,</span> size<span class="token operator">=</span>num_inputs<span class="token punctuation">)</span>
dx_num <span class="token operator">=</span> eval_numerical_gradient<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> softmax_loss<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> x<span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
loss<span class="token punctuation">,</span> dx <span class="token operator">=</span> softmax_loss<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span>

<span class="token comment"># Test softmax_loss function. Loss should be 2.3 and dx error should be 1e-8</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Testing softmax_loss:'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'loss: '</span><span class="token punctuation">,</span> loss<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'dx error: '</span><span class="token punctuation">,</span> rel_error<span class="token punctuation">(</span>dx_num<span class="token punctuation">,</span> dx<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"--------------------------------------------------------"</span><span class="token punctuation">)</span>

<span class="token comment"># Initial Loss and Gradient Check</span>
np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">231</span><span class="token punctuation">)</span>
N<span class="token punctuation">,</span> D<span class="token punctuation">,</span> H1<span class="token punctuation">,</span> H2<span class="token punctuation">,</span> C <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">,</span> <span class="token number">10</span>
X <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>N<span class="token punctuation">,</span> D<span class="token punctuation">)</span>
y <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span>C<span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token punctuation">(</span>N<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> reg <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3.14</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Running check with reg = "</span><span class="token punctuation">,</span> reg<span class="token punctuation">)</span>
    model <span class="token operator">=</span> FullyConnectedNet<span class="token punctuation">(</span>
        <span class="token punctuation">[</span>H1<span class="token punctuation">,</span> H2<span class="token punctuation">]</span><span class="token punctuation">,</span>
        input_dim<span class="token operator">=</span>D<span class="token punctuation">,</span>
        num_classes<span class="token operator">=</span>C<span class="token punctuation">,</span>
        reg<span class="token operator">=</span>reg<span class="token punctuation">,</span>
        weight_scale<span class="token operator">=</span><span class="token number">5e</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span>
        dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float64
    <span class="token punctuation">)</span>

    loss<span class="token punctuation">,</span> grads <span class="token operator">=</span> model<span class="token punctuation">.</span>loss<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Initial loss: "</span><span class="token punctuation">,</span> loss<span class="token punctuation">)</span>

    <span class="token comment"># Most of the errors should be on the order of e-7 or smaller.</span>
    <span class="token comment"># NOTE: It is fine however to see an error for W2 on the order of e-5</span>
    <span class="token comment"># for the check when reg = 0.0</span>
    <span class="token keyword">for</span> name <span class="token keyword">in</span> <span class="token builtin">sorted</span><span class="token punctuation">(</span>grads<span class="token punctuation">)</span><span class="token punctuation">:</span>
        f <span class="token operator">=</span> <span class="token keyword">lambda</span> _<span class="token punctuation">:</span> model<span class="token punctuation">.</span>loss<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        grad_num <span class="token operator">=</span> eval_numerical_gradient<span class="token punctuation">(</span>f<span class="token punctuation">,</span> model<span class="token punctuation">.</span>params<span class="token punctuation">[</span>name<span class="token punctuation">]</span><span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> h<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">{</span>name<span class="token punctuation">}</span></span><span class="token string"> relative error: </span><span class="token interpolation"><span class="token punctuation">{</span>rel_error<span class="token punctuation">(</span>grad_num<span class="token punctuation">,</span> grads<span class="token punctuation">[</span>name<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"--------------------------------------------------------"</span><span class="token punctuation">)</span>

<span class="token comment"># Use a three-layer Net to overfit 50 training examples</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Overfit 50 training examples'</span><span class="token punctuation">)</span>
num_train <span class="token operator">=</span> <span class="token number">50</span>
small_data <span class="token operator">=</span> <span class="token punctuation">{</span>
  <span class="token string">"X_train"</span><span class="token punctuation">:</span> data<span class="token punctuation">[</span><span class="token string">"X_train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span>num_train<span class="token punctuation">]</span><span class="token punctuation">,</span>
  <span class="token string">"y_train"</span><span class="token punctuation">:</span> data<span class="token punctuation">[</span><span class="token string">"y_train"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span>num_train<span class="token punctuation">]</span><span class="token punctuation">,</span>
  <span class="token string">"X_val"</span><span class="token punctuation">:</span> data<span class="token punctuation">[</span><span class="token string">"X_val"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
  <span class="token string">"y_val"</span><span class="token punctuation">:</span> data<span class="token punctuation">[</span><span class="token string">"y_val"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
<span class="token punctuation">}</span>

weight_scale <span class="token operator">=</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">2</span>   <span class="token comment"># Experiment with this!</span>
learning_rate <span class="token operator">=</span> <span class="token number">8e</span><span class="token operator">-</span><span class="token number">3</span>  <span class="token comment"># Experiment with this!</span>
model <span class="token operator">=</span> FullyConnectedNet<span class="token punctuation">(</span>
    <span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    weight_scale<span class="token operator">=</span>weight_scale<span class="token punctuation">,</span>
    dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float64
<span class="token punctuation">)</span>
solver <span class="token operator">=</span> Solver<span class="token punctuation">(</span>
    model<span class="token punctuation">,</span>
    small_data<span class="token punctuation">,</span>
    print_every<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>
    num_epochs<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">,</span>
    batch_size<span class="token operator">=</span><span class="token number">25</span><span class="token punctuation">,</span>
    update_rule<span class="token operator">=</span><span class="token string">"sgd"</span><span class="token punctuation">,</span>
    optim_config<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">"learning_rate"</span><span class="token punctuation">:</span> learning_rate<span class="token punctuation">}</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>
solver<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>solver<span class="token punctuation">.</span>loss_history<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"Training loss history"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">"Iteration"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">"Training loss"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>grid<span class="token punctuation">(</span>linestyle<span class="token operator">=</span><span class="token string">'--'</span><span class="token punctuation">,</span> linewidth<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"--------------------------------------------------------"</span><span class="token punctuation">)</span>

<span class="token comment"># Train a Model</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Train a 6 layer model'</span><span class="token punctuation">)</span>
learning_rate <span class="token operator">=</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">4</span>
weight_scale <span class="token operator">=</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">2</span>
model <span class="token operator">=</span> FullyConnectedNet<span class="token punctuation">(</span>
    <span class="token punctuation">[</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    weight_scale<span class="token operator">=</span>weight_scale<span class="token punctuation">,</span>
    dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float64
<span class="token punctuation">)</span>
solver <span class="token operator">=</span> Solver<span class="token punctuation">(</span>
    model<span class="token punctuation">,</span>
    data<span class="token punctuation">,</span>
    print_every<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">,</span>
    num_epochs<span class="token operator">=</span><span class="token number">30</span><span class="token punctuation">,</span>
    batch_size<span class="token operator">=</span><span class="token number">25</span><span class="token punctuation">,</span>
    update_rule<span class="token operator">=</span><span class="token string">'adam'</span><span class="token punctuation">,</span>
    optim_config<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">'learning_rate'</span><span class="token punctuation">:</span> learning_rate<span class="token punctuation">}</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>
solver<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>solver<span class="token punctuation">.</span>loss_history<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Training loss history'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'Iteration'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'Training loss'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>grid<span class="token punctuation">(</span>linestyle<span class="token operator">=</span><span class="token string">'--'</span><span class="token punctuation">,</span> linewidth<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="fc-net-py"><a href="#fc-net-py" class="headerlink" title="fc_net.py"></a>fc_net.py</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> builtins <span class="token keyword">import</span> <span class="token builtin">range</span>
<span class="token keyword">from</span> builtins <span class="token keyword">import</span> <span class="token builtin">object</span>
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">from</span> <span class="token punctuation">.</span><span class="token punctuation">.</span>layers <span class="token keyword">import</span> <span class="token operator">*</span>
<span class="token keyword">from</span> <span class="token punctuation">.</span><span class="token punctuation">.</span>layer_utils <span class="token keyword">import</span> <span class="token operator">*</span>


<span class="token keyword">class</span> <span class="token class-name">FullyConnectedNet</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Class for a multi-layer fully connected neural network.

    Network contains an arbitrary number of hidden layers, ReLU nonlinearities,
    and a softmax loss function. This will also implement dropout and batch/layer
    normalization as options. For a network with L layers, the architecture will be

    {affine - [batch/layer norm] - relu - [dropout]} x (L - 1) - affine - softmax

    where batch/layer normalization and dropout are optional and the {...} block is
    repeated L - 1 times.

    Learnable parameters are stored in the self.params dictionary and will be learned
    using the Solver class.
    """</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>
        self<span class="token punctuation">,</span>
        hidden_dims<span class="token punctuation">,</span>
        input_dim<span class="token operator">=</span><span class="token number">3</span> <span class="token operator">*</span> <span class="token number">32</span> <span class="token operator">*</span> <span class="token number">32</span><span class="token punctuation">,</span>
        num_classes<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>
        dropout_keep_ratio<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>
        normalization<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>
        reg<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">,</span>
        weight_scale<span class="token operator">=</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span>
        dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">,</span>
        seed<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""Initialize a new FullyConnectedNet.

        Inputs:
        - hidden_dims: A list of integers giving the size of each hidden layer.
        - input_dim: An integer giving the size of the input.
        - num_classes: An integer giving the number of classes to classify.
        - dropout_keep_ratio: Scalar between 0 and 1 giving dropout strength.
            If dropout_keep_ratio=1 then the network should not use dropout at all.
        - normalization: What type of normalization the network should use. Valid values
            are "batchnorm", "layernorm", or None for no normalization (the default).
        - reg: Scalar giving L2 regularization strength.
        - weight_scale: Scalar giving the standard deviation for random
            initialization of the weights.
        - dtype: A numpy datatype object; all computations will be performed using
            this datatype. float32 is faster but less accurate, so you should use
            float64 for numeric gradient checking.
        - seed: If not None, then pass this random seed to the dropout layers.
            This will make the dropout layers deteriminstic so we can gradient check the model.
        """</span>
        self<span class="token punctuation">.</span>normalization <span class="token operator">=</span> normalization
        self<span class="token punctuation">.</span>use_dropout <span class="token operator">=</span> dropout_keep_ratio <span class="token operator">!=</span> <span class="token number">1</span>
        self<span class="token punctuation">.</span>reg <span class="token operator">=</span> reg
        self<span class="token punctuation">.</span>num_layers <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">+</span> <span class="token builtin">len</span><span class="token punctuation">(</span>hidden_dims<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>dtype <span class="token operator">=</span> dtype
        self<span class="token punctuation">.</span>params <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
        layer_input_dim <span class="token operator">=</span> input_dim
        <span class="token keyword">for</span> i<span class="token punctuation">,</span> hd <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>hidden_dims<span class="token punctuation">)</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W%d'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> weight_scale <span class="token operator">*</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>layer_input_dim<span class="token punctuation">,</span> hd<span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b%d'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> weight_scale <span class="token operator">*</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>hd<span class="token punctuation">)</span>
            layer_input_dim <span class="token operator">=</span> hd
        <span class="token comment"># output layer</span>
        self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W%d'</span> <span class="token operator">%</span> self<span class="token punctuation">.</span>num_layers<span class="token punctuation">]</span> <span class="token operator">=</span> weight_scale <span class="token operator">*</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>layer_input_dim<span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b%d'</span> <span class="token operator">%</span> self<span class="token punctuation">.</span>num_layers<span class="token punctuation">]</span> <span class="token operator">=</span> weight_scale <span class="token operator">*</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>num_classes<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>dropout_param <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>use_dropout<span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>dropout_param <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">"mode"</span><span class="token punctuation">:</span> <span class="token string">"train"</span><span class="token punctuation">,</span> <span class="token string">"p"</span><span class="token punctuation">:</span> dropout_keep_ratio<span class="token punctuation">}</span>
            <span class="token keyword">if</span> seed <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
                self<span class="token punctuation">.</span>dropout_param<span class="token punctuation">[</span><span class="token string">"seed"</span><span class="token punctuation">]</span> <span class="token operator">=</span> seed
        self<span class="token punctuation">.</span>bn_params <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>normalization <span class="token operator">==</span> <span class="token string">"batchnorm"</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>bn_params <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token string">"mode"</span><span class="token punctuation">:</span> <span class="token string">"train"</span><span class="token punctuation">}</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_layers <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>normalization <span class="token operator">==</span> <span class="token string">"layernorm"</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>bn_params <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">{</span><span class="token punctuation">}</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_layers <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span>

        <span class="token comment"># Cast all parameters to the correct datatype.</span>
        <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> self<span class="token punctuation">.</span>params<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>params<span class="token punctuation">[</span>k<span class="token punctuation">]</span> <span class="token operator">=</span> v<span class="token punctuation">.</span>astype<span class="token punctuation">(</span>dtype<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">loss</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">,</span> y<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""Compute loss and gradient for the fully connected net.
        
        Inputs:
        - X: Array of input data of shape (N, d_1, ..., d_k)
        - y: Array of labels, of shape (N,). y[i] gives the label for X[i].

        Returns:
        If y is None, then run a test-time forward pass of the model and return:
        - scores: Array of shape (N, C) giving classification scores, where
            scores[i, c] is the classification score for X[i] and class c.

        If y is not None, then run a training-time forward and backward pass and
        return a tuple of:
        - loss: Scalar value giving the loss
        - grads: Dictionary with the same keys as self.params, mapping parameter
            names to gradients of the loss with respect to those parameters.
        """</span>
        X <span class="token operator">=</span> X<span class="token punctuation">.</span>astype<span class="token punctuation">(</span>self<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span>
        mode <span class="token operator">=</span> <span class="token string">"test"</span> <span class="token keyword">if</span> y <span class="token keyword">is</span> <span class="token boolean">None</span> <span class="token keyword">else</span> <span class="token string">"train"</span>

        <span class="token comment"># Set train/test mode for batch_norm params and dropout param since they</span>
        <span class="token comment"># behave differently during training and testing.</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>use_dropout<span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>dropout_param<span class="token punctuation">[</span><span class="token string">"mode"</span><span class="token punctuation">]</span> <span class="token operator">=</span> mode
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>normalization <span class="token operator">==</span> <span class="token string">"batchnorm"</span><span class="token punctuation">:</span>
            <span class="token keyword">for</span> bn_param <span class="token keyword">in</span> self<span class="token punctuation">.</span>bn_params<span class="token punctuation">:</span>
                bn_param<span class="token punctuation">[</span><span class="token string">"mode"</span><span class="token punctuation">]</span> <span class="token operator">=</span> mode
        scores <span class="token operator">=</span> <span class="token boolean">None</span>
        layer_input <span class="token operator">=</span> X
        affine_relu_cache <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_layers <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            index <span class="token operator">=</span> i <span class="token operator">+</span> <span class="token number">1</span>
            w <span class="token operator">=</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W%d'</span> <span class="token operator">%</span> index<span class="token punctuation">]</span>
            b <span class="token operator">=</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b%d'</span> <span class="token operator">%</span> index<span class="token punctuation">]</span>
            layer_input<span class="token punctuation">,</span> affine_relu_cache<span class="token punctuation">[</span>index<span class="token punctuation">]</span> <span class="token operator">=</span> affine_relu_forward<span class="token punctuation">(</span>layer_input<span class="token punctuation">,</span> w<span class="token punctuation">,</span> b<span class="token punctuation">)</span>
        w <span class="token operator">=</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W%d'</span> <span class="token operator">%</span> self<span class="token punctuation">.</span>num_layers<span class="token punctuation">]</span>
        b <span class="token operator">=</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b%d'</span> <span class="token operator">%</span> self<span class="token punctuation">.</span>num_layers<span class="token punctuation">]</span>
        scores<span class="token punctuation">,</span> affine_relu_cache<span class="token punctuation">[</span>self<span class="token punctuation">.</span>num_layers<span class="token punctuation">]</span> <span class="token operator">=</span> affine_forward<span class="token punctuation">(</span>layer_input<span class="token punctuation">,</span> w<span class="token punctuation">,</span> b<span class="token punctuation">)</span>
        <span class="token comment"># If test mode return early.</span>
        <span class="token keyword">if</span> mode <span class="token operator">==</span> <span class="token string">"test"</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span> scores
        loss<span class="token punctuation">,</span> grads <span class="token operator">=</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
        loss<span class="token punctuation">,</span> dx <span class="token operator">=</span> softmax_loss<span class="token punctuation">(</span>scores<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> loss <span class="token operator">+</span> <span class="token number">0.5</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>reg <span class="token operator">*</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W%d'</span> <span class="token operator">%</span> self<span class="token punctuation">.</span>num_layers<span class="token punctuation">]</span> <span class="token operator">*</span>
                                              self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W%d'</span> <span class="token operator">%</span> self<span class="token punctuation">.</span>num_layers<span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token comment"># last affine layer back prop</span>
        dx<span class="token punctuation">,</span> dw<span class="token punctuation">,</span> db <span class="token operator">=</span> affine_backward<span class="token punctuation">(</span>dx<span class="token punctuation">,</span> affine_relu_cache<span class="token punctuation">[</span>self<span class="token punctuation">.</span>num_layers<span class="token punctuation">]</span><span class="token punctuation">)</span>
        grads<span class="token punctuation">[</span><span class="token string">'W%d'</span> <span class="token operator">%</span> self<span class="token punctuation">.</span>num_layers<span class="token punctuation">]</span> <span class="token operator">=</span> dw <span class="token operator">+</span> self<span class="token punctuation">.</span>reg <span class="token operator">*</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W%d'</span> <span class="token operator">%</span> self<span class="token punctuation">.</span>num_layers<span class="token punctuation">]</span>
        grads<span class="token punctuation">[</span><span class="token string">'b%d'</span> <span class="token operator">%</span> self<span class="token punctuation">.</span>num_layers<span class="token punctuation">]</span> <span class="token operator">=</span> db
        <span class="token comment"># hidden layers back prop</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_layers <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            index <span class="token operator">=</span> self<span class="token punctuation">.</span>num_layers <span class="token operator">-</span> <span class="token number">1</span> <span class="token operator">-</span> i
            loss <span class="token operator">=</span> loss <span class="token operator">+</span> <span class="token number">0.5</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>reg <span class="token operator">*</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W%d'</span> <span class="token operator">%</span> index<span class="token punctuation">]</span> <span class="token operator">*</span>
                                                  self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W%d'</span> <span class="token operator">%</span> index<span class="token punctuation">]</span><span class="token punctuation">)</span>
            dx<span class="token punctuation">,</span> dw<span class="token punctuation">,</span> db <span class="token operator">=</span> affine_relu_backward<span class="token punctuation">(</span>dx<span class="token punctuation">,</span> affine_relu_cache<span class="token punctuation">[</span>index<span class="token punctuation">]</span><span class="token punctuation">)</span>
            grads<span class="token punctuation">[</span><span class="token string">'W%d'</span> <span class="token operator">%</span> index<span class="token punctuation">]</span> <span class="token operator">=</span> dw <span class="token operator">+</span> self<span class="token punctuation">.</span>reg <span class="token operator">*</span> self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'W%d'</span> <span class="token operator">%</span> index<span class="token punctuation">]</span>
            grads<span class="token punctuation">[</span><span class="token string">'b%d'</span> <span class="token operator">%</span> index<span class="token punctuation">]</span> <span class="token operator">=</span> db
        <span class="token keyword">return</span> loss<span class="token punctuation">,</span> grads
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="layers-py"><a href="#layers-py" class="headerlink" title="layers.py"></a>layers.py</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> builtins <span class="token keyword">import</span> <span class="token builtin">range</span>
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np


<span class="token keyword">def</span> <span class="token function">affine_forward</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> w<span class="token punctuation">,</span> b<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Computes the forward pass for an affine (fully connected) layer.

    The input x has shape (N, d_1, ..., d_k) and contains a minibatch of N
    examples, where each example x[i] has shape (d_1, ..., d_k). We will
    reshape each input into a vector of dimension D = d_1 * ... * d_k, and
    then transform it to an output vector of dimension M.

    Inputs:
    - x: A numpy array containing input data, of shape (N, d_1, ..., d_k)
    - w: A numpy array of weights, of shape (D, M)
    - b: A numpy array of biases, of shape (M,)

    Returns a tuple of:
    - out: output, of shape (N, M)
    - cache: (x, w, b)
    """</span>
    out <span class="token operator">=</span> <span class="token boolean">None</span>
    n_samples <span class="token operator">=</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    x_ <span class="token operator">=</span> x<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>n_samples<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
    out <span class="token operator">=</span> x_<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>w<span class="token punctuation">)</span> <span class="token operator">+</span> b
    cache <span class="token operator">=</span> <span class="token punctuation">(</span>x<span class="token punctuation">,</span> w<span class="token punctuation">,</span> b<span class="token punctuation">)</span>
    cache <span class="token operator">=</span> <span class="token punctuation">(</span>x<span class="token punctuation">,</span> w<span class="token punctuation">,</span> b<span class="token punctuation">)</span>
    <span class="token keyword">return</span> out<span class="token punctuation">,</span> cache


<span class="token keyword">def</span> <span class="token function">affine_backward</span><span class="token punctuation">(</span>dout<span class="token punctuation">,</span> cache<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Computes the backward pass for an affine (fully connected) layer.

    Inputs:
    - dout: Upstream derivative, of shape (N, M)
    - cache: Tuple of:
      - x: Input data, of shape (N, d_1, ... d_k)
      - w: Weights, of shape (D, M)
      - b: Biases, of shape (M,)

    Returns a tuple of:
    - dx: Gradient with respect to x, of shape (N, d1, ..., d_k)
    - dw: Gradient with respect to w, of shape (D, M)
    - db: Gradient with respect to b, of shape (M,)
    """</span>
    x<span class="token punctuation">,</span> w<span class="token punctuation">,</span> b <span class="token operator">=</span> cache
    dx<span class="token punctuation">,</span> dw<span class="token punctuation">,</span> db <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token boolean">None</span>
    n_samples <span class="token operator">=</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    x_ <span class="token operator">=</span> x<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>n_samples<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
    dx <span class="token operator">=</span> <span class="token punctuation">(</span>dout<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>w<span class="token punctuation">.</span>T<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
    dw <span class="token operator">=</span> x_<span class="token punctuation">.</span>T<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>dout<span class="token punctuation">)</span>
    db <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dout<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> dx<span class="token punctuation">,</span> dw<span class="token punctuation">,</span> db


<span class="token keyword">def</span> <span class="token function">relu_forward</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Computes the forward pass for a layer of rectified linear units (ReLUs).

    Input:
    - x: Inputs, of any shape

    Returns a tuple of:
    - out: Output, of the same shape as x
    - cache: x
    """</span>
    out <span class="token operator">=</span> <span class="token boolean">None</span>
    out <span class="token operator">=</span> np<span class="token punctuation">.</span>maximum<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>
    cache <span class="token operator">=</span> x
    <span class="token keyword">return</span> out<span class="token punctuation">,</span> cache


<span class="token keyword">def</span> <span class="token function">relu_backward</span><span class="token punctuation">(</span>dout<span class="token punctuation">,</span> cache<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Computes the backward pass for a layer of rectified linear units (ReLUs).

    Input:
    - dout: Upstream derivatives, of any shape
    - cache: Input x, of same shape as dout

    Returns:
    - dx: Gradient with respect to x
    """</span>
    dx<span class="token punctuation">,</span> x <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span> cache
    index <span class="token operator">=</span> x <span class="token operator">&gt;</span> <span class="token number">0</span>
    dx <span class="token operator">=</span> dout <span class="token operator">*</span> index
    <span class="token keyword">return</span> dx


<span class="token keyword">def</span> <span class="token function">softmax_loss</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Computes the loss and gradient for softmax classification.

    Inputs:
    - x: Input data, of shape (N, C) where x[i, j] is the score for the jth
      class for the ith input.
    - y: Vector of labels, of shape (N,) where y[i] is the label for x[i] and
      0 &lt;= y[i] &lt; C

    Returns a tuple of:
    - loss: Scalar giving the loss
    - dx: Gradient of the loss with respect to x
    """</span>
    loss<span class="token punctuation">,</span> dx <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token boolean">None</span>
    probs <span class="token operator">=</span> np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>x <span class="token operator">-</span> np<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> keepdims<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    probs <span class="token operator">/=</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>probs<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> keepdims<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    N <span class="token operator">=</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    loss <span class="token operator">=</span> <span class="token operator">-</span>np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>log<span class="token punctuation">(</span>probs<span class="token punctuation">[</span>np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>N<span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">/</span> N
    dx <span class="token operator">=</span> probs<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>
    dx<span class="token punctuation">[</span>np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>N<span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">]</span> <span class="token operator">-=</span> <span class="token number">1</span>
    dx <span class="token operator">/=</span> N
    <span class="token keyword">return</span> loss<span class="token punctuation">,</span> dx


<span class="token keyword">def</span> <span class="token function">batchnorm_forward</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> gamma<span class="token punctuation">,</span> beta<span class="token punctuation">,</span> bn_param<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Forward pass for batch normalization.

    During training the sample mean and (uncorrected) sample variance are
    computed from minibatch statistics and used to normalize the incoming data.
    During training we also keep an exponentially decaying running mean of the
    mean and variance of each feature, and these averages are used to normalize
    data at test-time.

    At each timestep we update the running averages for mean and variance using
    an exponential decay based on the momentum parameter:

    running_mean = momentum * running_mean + (1 - momentum) * sample_mean
    running_var = momentum * running_var + (1 - momentum) * sample_var

    Note that the batch normalization paper suggests a different test-time
    behavior: they compute sample mean and variance for each feature using a
    large number of training images rather than using a running average. For
    this implementation we have chosen to use running averages instead since
    they do not require an additional estimation step; the torch7
    implementation of batch normalization also uses running averages.

    Input:
    - x: Data of shape (N, D)
    - gamma: Scale parameter of shape (D,)
    - beta: Shift paremeter of shape (D,)
    - bn_param: Dictionary with the following keys:
      - mode: 'train' or 'test'; required
      - eps: Constant for numeric stability
      - momentum: Constant for running mean / variance.
      - running_mean: Array of shape (D,) giving running mean of features
      - running_var Array of shape (D,) giving running variance of features

    Returns a tuple of:
    - out: of shape (N, D)
    - cache: A tuple of values needed in the backward pass
    """</span>
    mode <span class="token operator">=</span> bn_param<span class="token punctuation">[</span><span class="token string">"mode"</span><span class="token punctuation">]</span>
    eps <span class="token operator">=</span> bn_param<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"eps"</span><span class="token punctuation">,</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">)</span>
    momentum <span class="token operator">=</span> bn_param<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"momentum"</span><span class="token punctuation">,</span> <span class="token number">0.9</span><span class="token punctuation">)</span>

    N<span class="token punctuation">,</span> D <span class="token operator">=</span> x<span class="token punctuation">.</span>shape
    running_mean <span class="token operator">=</span> bn_param<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"running_mean"</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>D<span class="token punctuation">,</span> dtype<span class="token operator">=</span>x<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span><span class="token punctuation">)</span>
    running_var <span class="token operator">=</span> bn_param<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"running_var"</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>D<span class="token punctuation">,</span> dtype<span class="token operator">=</span>x<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span><span class="token punctuation">)</span>

    out<span class="token punctuation">,</span> cache <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token boolean">None</span>
    <span class="token keyword">if</span> mode <span class="token operator">==</span> <span class="token string">"train"</span><span class="token punctuation">:</span>
        <span class="token keyword">pass</span>
    <span class="token keyword">elif</span> mode <span class="token operator">==</span> <span class="token string">"test"</span><span class="token punctuation">:</span>
        <span class="token keyword">pass</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">'Invalid forward batchnorm mode "%s"'</span> <span class="token operator">%</span> mode<span class="token punctuation">)</span>
    <span class="token comment"># Store the updated running means back into bn_param</span>
    bn_param<span class="token punctuation">[</span><span class="token string">"running_mean"</span><span class="token punctuation">]</span> <span class="token operator">=</span> running_mean
    bn_param<span class="token punctuation">[</span><span class="token string">"running_var"</span><span class="token punctuation">]</span> <span class="token operator">=</span> running_var
    <span class="token keyword">return</span> out<span class="token punctuation">,</span> cache


<span class="token keyword">def</span> <span class="token function">batchnorm_backward</span><span class="token punctuation">(</span>dout<span class="token punctuation">,</span> cache<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Backward pass for batch normalization.

    For this implementation, you should write out a computation graph for
    batch normalization on paper and propagate gradients backward through
    intermediate nodes.

    Inputs:
    - dout: Upstream derivatives, of shape (N, D)
    - cache: Variable of intermediates from batchnorm_forward.

    Returns a tuple of:
    - dx: Gradient with respect to inputs x, of shape (N, D)
    - dgamma: Gradient with respect to scale parameter gamma, of shape (D,)
    - dbeta: Gradient with respect to shift parameter beta, of shape (D,)
    """</span>
    dx<span class="token punctuation">,</span> dgamma<span class="token punctuation">,</span> dbeta <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token boolean">None</span>
    <span class="token keyword">pass</span>
    <span class="token keyword">return</span> dx<span class="token punctuation">,</span> dgamma<span class="token punctuation">,</span> dbeta


<span class="token keyword">def</span> <span class="token function">batchnorm_backward_alt</span><span class="token punctuation">(</span>dout<span class="token punctuation">,</span> cache<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Alternative backward pass for batch normalization.

    For this implementation you should work out the derivatives for the batch
    normalizaton backward pass on paper and simplify as much as possible. You
    should be able to derive a simple expression for the backward pass.
    See the jupyter notebook for more hints.

    Note: This implementation should expect to receive the same cache variable
    as batchnorm_backward, but might not use all of the values in the cache.

    Inputs / outputs: Same as batchnorm_backward
    """</span>
    dx<span class="token punctuation">,</span> dgamma<span class="token punctuation">,</span> dbeta <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token boolean">None</span>
    <span class="token keyword">pass</span>
    <span class="token keyword">return</span> dx<span class="token punctuation">,</span> dgamma<span class="token punctuation">,</span> dbeta


<span class="token keyword">def</span> <span class="token function">layernorm_forward</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> gamma<span class="token punctuation">,</span> beta<span class="token punctuation">,</span> ln_param<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Forward pass for layer normalization.

    During both training and test-time, the incoming data is normalized per data-point,
    before being scaled by gamma and beta parameters identical to that of batch normalization.

    Note that in contrast to batch normalization, the behavior during train and test-time for
    layer normalization are identical, and we do not need to keep track of running averages
    of any sort.

    Input:
    - x: Data of shape (N, D)
    - gamma: Scale parameter of shape (D,)
    - beta: Shift paremeter of shape (D,)
    - ln_param: Dictionary with the following keys:
        - eps: Constant for numeric stability

    Returns a tuple of:
    - out: of shape (N, D)
    - cache: A tuple of values needed in the backward pass
    """</span>
    out<span class="token punctuation">,</span> cache <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token boolean">None</span>
    eps <span class="token operator">=</span> ln_param<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"eps"</span><span class="token punctuation">,</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">)</span>
    <span class="token keyword">pass</span>
    <span class="token keyword">return</span> out<span class="token punctuation">,</span> cache


<span class="token keyword">def</span> <span class="token function">layernorm_backward</span><span class="token punctuation">(</span>dout<span class="token punctuation">,</span> cache<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Backward pass for layer normalization.

    For this implementation, you can heavily rely on the work you've done already
    for batch normalization.

    Inputs:
    - dout: Upstream derivatives, of shape (N, D)
    - cache: Variable of intermediates from layernorm_forward.

    Returns a tuple of:
    - dx: Gradient with respect to inputs x, of shape (N, D)
    - dgamma: Gradient with respect to scale parameter gamma, of shape (D,)
    - dbeta: Gradient with respect to shift parameter beta, of shape (D,)
    """</span>
    dx<span class="token punctuation">,</span> dgamma<span class="token punctuation">,</span> dbeta <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token boolean">None</span>
    <span class="token keyword">pass</span>
    <span class="token keyword">return</span> dx<span class="token punctuation">,</span> dgamma<span class="token punctuation">,</span> dbeta


<span class="token keyword">def</span> <span class="token function">dropout_forward</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> dropout_param<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Forward pass for inverted dropout.

    Note that this is different from the vanilla version of dropout.
    Here, p is the probability of keeping a neuron output, as opposed to
    the probability of dropping a neuron output.
    See http://cs231n.github.io/neural-networks-2/#reg for more details.

    Inputs:
    - x: Input data, of any shape
    - dropout_param: A dictionary with the following keys:
      - p: Dropout parameter. We keep each neuron output with probability p.
      - mode: 'test' or 'train'. If the mode is train, then perform dropout;
        if the mode is test, then just return the input.
      - seed: Seed for the random number generator. Passing seed makes this
        function deterministic, which is needed for gradient checking but not
        in real networks.

    Outputs:
    - out: Array of the same shape as x.
    - cache: tuple (dropout_param, mask). In training mode, mask is the dropout
      mask that was used to multiply the input; in test mode, mask is None.
    """</span>
    p<span class="token punctuation">,</span> mode <span class="token operator">=</span> dropout_param<span class="token punctuation">[</span><span class="token string">"p"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dropout_param<span class="token punctuation">[</span><span class="token string">"mode"</span><span class="token punctuation">]</span>
    <span class="token keyword">if</span> <span class="token string">"seed"</span> <span class="token keyword">in</span> dropout_param<span class="token punctuation">:</span>
        np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span>dropout_param<span class="token punctuation">[</span><span class="token string">"seed"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

    mask <span class="token operator">=</span> <span class="token boolean">None</span>
    out <span class="token operator">=</span> <span class="token boolean">None</span>

    <span class="token keyword">if</span> mode <span class="token operator">==</span> <span class="token string">"train"</span><span class="token punctuation">:</span>
        <span class="token keyword">pass</span>
    <span class="token keyword">elif</span> mode <span class="token operator">==</span> <span class="token string">"test"</span><span class="token punctuation">:</span>
        <span class="token keyword">pass</span>
    cache <span class="token operator">=</span> <span class="token punctuation">(</span>dropout_param<span class="token punctuation">,</span> mask<span class="token punctuation">)</span>
    out <span class="token operator">=</span> out<span class="token punctuation">.</span>astype<span class="token punctuation">(</span>x<span class="token punctuation">.</span>dtype<span class="token punctuation">,</span> copy<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> out<span class="token punctuation">,</span> cache


<span class="token keyword">def</span> <span class="token function">dropout_backward</span><span class="token punctuation">(</span>dout<span class="token punctuation">,</span> cache<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Backward pass for inverted dropout.

    Inputs:
    - dout: Upstream derivatives, of any shape
    - cache: (dropout_param, mask) from dropout_forward.
    """</span>
    dropout_param<span class="token punctuation">,</span> mask <span class="token operator">=</span> cache
    mode <span class="token operator">=</span> dropout_param<span class="token punctuation">[</span><span class="token string">"mode"</span><span class="token punctuation">]</span>

    dx <span class="token operator">=</span> <span class="token boolean">None</span>
    <span class="token keyword">if</span> mode <span class="token operator">==</span> <span class="token string">"train"</span><span class="token punctuation">:</span>
        <span class="token keyword">pass</span>
    <span class="token keyword">elif</span> mode <span class="token operator">==</span> <span class="token string">"test"</span><span class="token punctuation">:</span>
        dx <span class="token operator">=</span> dout
    <span class="token keyword">return</span> dx


<span class="token keyword">def</span> <span class="token function">conv_forward_naive</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> w<span class="token punctuation">,</span> b<span class="token punctuation">,</span> conv_param<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""A naive implementation of the forward pass for a convolutional layer.

    The input consists of N data points, each with C channels, height H and
    width W. We convolve each input with F different filters, where each filter
    spans all C channels and has height HH and width WW.

    Input:
    - x: Input data of shape (N, C, H, W)
    - w: Filter weights of shape (F, C, HH, WW)
    - b: Biases, of shape (F,)
    - conv_param: A dictionary with the following keys:
      - 'stride': The number of pixels between adjacent receptive fields in the
        horizontal and vertical directions.
      - 'pad': The number of pixels that will be used to zero-pad the input.

    During padding, 'pad' zeros should be placed symmetrically (i.e equally on both sides)
    along the height and width axes of the input. Be careful not to modfiy the original
    input x directly.

    Returns a tuple of:
    - out: Output data, of shape (N, F, H', W') where H' and W' are given by
      H' = 1 + (H + 2 * pad - HH) / stride
      W' = 1 + (W + 2 * pad - WW) / stride
    - cache: (x, w, b, conv_param)
    """</span>
    out <span class="token operator">=</span> <span class="token boolean">None</span>
    <span class="token keyword">pass</span>
    cache <span class="token operator">=</span> <span class="token punctuation">(</span>x<span class="token punctuation">,</span> w<span class="token punctuation">,</span> b<span class="token punctuation">,</span> conv_param<span class="token punctuation">)</span>
    <span class="token keyword">return</span> out<span class="token punctuation">,</span> cache


<span class="token keyword">def</span> <span class="token function">conv_backward_naive</span><span class="token punctuation">(</span>dout<span class="token punctuation">,</span> cache<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""A naive implementation of the backward pass for a convolutional layer.

    Inputs:
    - dout: Upstream derivatives.
    - cache: A tuple of (x, w, b, conv_param) as in conv_forward_naive

    Returns a tuple of:
    - dx: Gradient with respect to x
    - dw: Gradient with respect to w
    - db: Gradient with respect to b
    """</span>
    dx<span class="token punctuation">,</span> dw<span class="token punctuation">,</span> db <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token boolean">None</span>
    <span class="token keyword">pass</span>
    <span class="token keyword">return</span> dx<span class="token punctuation">,</span> dw<span class="token punctuation">,</span> db


<span class="token keyword">def</span> <span class="token function">max_pool_forward_naive</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> pool_param<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""A naive implementation of the forward pass for a max-pooling layer.

    Inputs:
    - x: Input data, of shape (N, C, H, W)
    - pool_param: dictionary with the following keys:
      - 'pool_height': The height of each pooling region
      - 'pool_width': The width of each pooling region
      - 'stride': The distance between adjacent pooling regions

    No padding is necessary here, eg you can assume:
      - (H - pool_height) % stride == 0
      - (W - pool_width) % stride == 0

    Returns a tuple of:
    - out: Output data, of shape (N, C, H', W') where H' and W' are given by
      H' = 1 + (H - pool_height) / stride
      W' = 1 + (W - pool_width) / stride
    - cache: (x, pool_param)
    """</span>
    out <span class="token operator">=</span> <span class="token boolean">None</span>
    <span class="token keyword">pass</span>
    cache <span class="token operator">=</span> <span class="token punctuation">(</span>x<span class="token punctuation">,</span> pool_param<span class="token punctuation">)</span>
    <span class="token keyword">return</span> out<span class="token punctuation">,</span> cache


<span class="token keyword">def</span> <span class="token function">max_pool_backward_naive</span><span class="token punctuation">(</span>dout<span class="token punctuation">,</span> cache<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""A naive implementation of the backward pass for a max-pooling layer.

    Inputs:
    - dout: Upstream derivatives
    - cache: A tuple of (x, pool_param) as in the forward pass.

    Returns:
    - dx: Gradient with respect to x
    """</span>
    dx <span class="token operator">=</span> <span class="token boolean">None</span>
    <span class="token keyword">pass</span>
    <span class="token keyword">return</span> dx


<span class="token keyword">def</span> <span class="token function">spatial_batchnorm_forward</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> gamma<span class="token punctuation">,</span> beta<span class="token punctuation">,</span> bn_param<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Computes the forward pass for spatial batch normalization.

    Inputs:
    - x: Input data of shape (N, C, H, W)
    - gamma: Scale parameter, of shape (C,)
    - beta: Shift parameter, of shape (C,)
    - bn_param: Dictionary with the following keys:
      - mode: 'train' or 'test'; required
      - eps: Constant for numeric stability
      - momentum: Constant for running mean / variance. momentum=0 means that
        old information is discarded completely at every time step, while
        momentum=1 means that new information is never incorporated. The
        default of momentum=0.9 should work well in most situations.
      - running_mean: Array of shape (D,) giving running mean of features
      - running_var Array of shape (D,) giving running variance of features

    Returns a tuple of:
    - out: Output data, of shape (N, C, H, W)
    - cache: Values needed for the backward pass
    """</span>
    out<span class="token punctuation">,</span> cache <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token boolean">None</span>
    <span class="token keyword">pass</span>
    <span class="token keyword">return</span> out<span class="token punctuation">,</span> cache


<span class="token keyword">def</span> <span class="token function">spatial_batchnorm_backward</span><span class="token punctuation">(</span>dout<span class="token punctuation">,</span> cache<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Computes the backward pass for spatial batch normalization.

    Inputs:
    - dout: Upstream derivatives, of shape (N, C, H, W)
    - cache: Values from the forward pass

    Returns a tuple of:
    - dx: Gradient with respect to inputs, of shape (N, C, H, W)
    - dgamma: Gradient with respect to scale parameter, of shape (C,)
    - dbeta: Gradient with respect to shift parameter, of shape (C,)
    """</span>
    dx<span class="token punctuation">,</span> dgamma<span class="token punctuation">,</span> dbeta <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token boolean">None</span>
    <span class="token keyword">pass</span>
    <span class="token keyword">return</span> dx<span class="token punctuation">,</span> dgamma<span class="token punctuation">,</span> dbeta


<span class="token keyword">def</span> <span class="token function">spatial_groupnorm_forward</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> gamma<span class="token punctuation">,</span> beta<span class="token punctuation">,</span> G<span class="token punctuation">,</span> gn_param<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Computes the forward pass for spatial group normalization.
    
    In contrast to layer normalization, group normalization splits each entry in the data into G
    contiguous pieces, which it then normalizes independently. Per-feature shifting and scaling
    are then applied to the data, in a manner identical to that of batch normalization and layer
    normalization.

    Inputs:
    - x: Input data of shape (N, C, H, W)
    - gamma: Scale parameter, of shape (1, C, 1, 1)
    - beta: Shift parameter, of shape (1, C, 1, 1)
    - G: Integer mumber of groups to split into, should be a divisor of C
    - gn_param: Dictionary with the following keys:
      - eps: Constant for numeric stability

    Returns a tuple of:
    - out: Output data, of shape (N, C, H, W)
    - cache: Values needed for the backward pass
    """</span>
    out<span class="token punctuation">,</span> cache <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token boolean">None</span>
    eps <span class="token operator">=</span> gn_param<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"eps"</span><span class="token punctuation">,</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">)</span>
    <span class="token keyword">pass</span>
    <span class="token keyword">return</span> out<span class="token punctuation">,</span> cache


<span class="token keyword">def</span> <span class="token function">spatial_groupnorm_backward</span><span class="token punctuation">(</span>dout<span class="token punctuation">,</span> cache<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Computes the backward pass for spatial group normalization.

    Inputs:
    - dout: Upstream derivatives, of shape (N, C, H, W)
    - cache: Values from the forward pass

    Returns a tuple of:
    - dx: Gradient with respect to inputs, of shape (N, C, H, W)
    - dgamma: Gradient with respect to scale parameter, of shape (1, C, 1, 1)
    - dbeta: Gradient with respect to shift parameter, of shape (1, C, 1, 1)
    """</span>
    dx<span class="token punctuation">,</span> dgamma<span class="token punctuation">,</span> dbeta <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token boolean">None</span>
    <span class="token keyword">pass</span>
    <span class="token keyword">return</span> dx<span class="token punctuation">,</span> dgamma<span class="token punctuation">,</span> dbeta<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="solver-py"><a href="#solver-py" class="headerlink" title="solver.py"></a>solver.py</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> __future__ <span class="token keyword">import</span> print_function<span class="token punctuation">,</span> division
<span class="token keyword">from</span> future <span class="token keyword">import</span> standard_library

standard_library<span class="token punctuation">.</span>install_aliases<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">from</span> builtins <span class="token keyword">import</span> <span class="token builtin">range</span>
<span class="token keyword">from</span> builtins <span class="token keyword">import</span> <span class="token builtin">object</span>
<span class="token keyword">import</span> os
<span class="token keyword">import</span> pickle <span class="token keyword">as</span> pickle

<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

<span class="token keyword">from</span> FCN <span class="token keyword">import</span> optim


<span class="token keyword">class</span> <span class="token class-name">Solver</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    A Solver encapsulates all the logic necessary for training classification
    models. The Solver performs stochastic gradient descent using different
    update rules defined in optim.py.

    The solver accepts both training and validataion data and labels so it can
    periodically check classification accuracy on both training and validation
    data to watch out for overfitting.

    To train a model, you will first construct a Solver instance, passing the
    model, dataset, and various options (learning rate, batch size, etc) to the
    constructor. You will then call the train() method to run the optimization
    procedure and train the model.

    After the train() method returns, model.params will contain the parameters
    that performed best on the validation set over the course of training.
    In addition, the instance variable solver.loss_history will contain a list
    of all losses encountered during training and the instance variables
    solver.train_acc_history and solver.val_acc_history will be lists of the
    accuracies of the model on the training and validation set at each epoch.

    Example usage might look something like this:

    data = {
      'X_train': # training data
      'y_train': # training labels
      'X_val': # validation data
      'y_val': # validation labels
    }
    model = MyAwesomeModel(hidden_size=100, reg=10)
    solver = Solver(model, data,
                    update_rule='sgd',
                    optim_config={
                      'learning_rate': 1e-4,
                    },
                    lr_decay=0.95,
                    num_epochs=5, batch_size=200,
                    print_every=100)
    solver.train()


    A Solver works on a model object that must conform to the following API:

    - model.params must be a dictionary mapping string parameter names to numpy
      arrays containing parameter values.

    - model.loss(X, y) must be a function that computes training-time loss and
      gradients, and test-time classification scores, with the following inputs
      and outputs:

      Inputs:
      - X: Array giving a minibatch of input data of shape (N, d_1, ..., d_k)
      - y: Array of labels, of shape (N,) giving labels for X where y[i] is the
        label for X[i].

      Returns:
      If y is None, run a test-time forward pass and return:
      - scores: Array of shape (N, C) giving classification scores for X where
        scores[i, c] gives the score of class c for X[i].

      If y is not None, run a training time forward and backward pass and
      return a tuple of:
      - loss: Scalar giving the loss
      - grads: Dictionary with the same keys as self.params mapping parameter
        names to gradients of the loss with respect to those parameters.
    """</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> model<span class="token punctuation">,</span> data<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        Construct a new Solver instance.

        Required arguments:
        - model: A model object conforming to the API described above
        - data: A dictionary of training and validation data containing:
          'X_train': Array, shape (N_train, d_1, ..., d_k) of training images
          'X_val': Array, shape (N_val, d_1, ..., d_k) of validation images
          'y_train': Array, shape (N_train,) of labels for training images
          'y_val': Array, shape (N_val,) of labels for validation images

        Optional arguments:
        - update_rule: A string giving the name of an update rule in optim.py.
          Default is 'sgd'.
        - optim_config: A dictionary containing hyperparameters that will be
          passed to the chosen update rule. Each update rule requires different
          hyperparameters (see optim.py) but all update rules require a
          'learning_rate' parameter so that should always be present.
        - lr_decay: A scalar for learning rate decay; after each epoch the
          learning rate is multiplied by this value.
        - batch_size: Size of minibatches used to compute loss and gradient
          during training.
        - num_epochs: The number of epochs to run for during training.
        - print_every: Integer; training losses will be printed every
          print_every iterations.
        - verbose: Boolean; if set to false then no output will be printed
          during training.
        - num_train_samples: Number of training samples used to check training
          accuracy; default is 1000; set to None to use entire training set.
        - num_val_samples: Number of validation samples to use to check val
          accuracy; default is None, which uses the entire validation set.
        - checkpoint_name: If not None, then save model checkpoints here every
          epoch.
        """</span>
        self<span class="token punctuation">.</span>model <span class="token operator">=</span> model
        self<span class="token punctuation">.</span>X_train <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token string">"X_train"</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>y_train <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token string">"y_train"</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>X_val <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token string">"X_val"</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>y_val <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token string">"y_val"</span><span class="token punctuation">]</span>

        <span class="token comment"># Unpack keyword arguments</span>
        self<span class="token punctuation">.</span>update_rule <span class="token operator">=</span> kwargs<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token string">"update_rule"</span><span class="token punctuation">,</span> <span class="token string">"sgd"</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>optim_config <span class="token operator">=</span> kwargs<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token string">"optim_config"</span><span class="token punctuation">,</span> <span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>lr_decay <span class="token operator">=</span> kwargs<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token string">"lr_decay"</span><span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>batch_size <span class="token operator">=</span> kwargs<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token string">"batch_size"</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>num_epochs <span class="token operator">=</span> kwargs<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token string">"num_epochs"</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>num_train_samples <span class="token operator">=</span> kwargs<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token string">"num_train_samples"</span><span class="token punctuation">,</span> <span class="token number">1000</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>num_val_samples <span class="token operator">=</span> kwargs<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token string">"num_val_samples"</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>checkpoint_name <span class="token operator">=</span> kwargs<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token string">"checkpoint_name"</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>print_every <span class="token operator">=</span> kwargs<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token string">"print_every"</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>verbose <span class="token operator">=</span> kwargs<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token string">"verbose"</span><span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">)</span>

        <span class="token comment"># Throw an error if there are extra keyword arguments</span>
        <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>kwargs<span class="token punctuation">)</span> <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">:</span>
            extra <span class="token operator">=</span> <span class="token string">", "</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string">'"%s"'</span> <span class="token operator">%</span> k <span class="token keyword">for</span> k <span class="token keyword">in</span> <span class="token builtin">list</span><span class="token punctuation">(</span>kwargs<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">"Unrecognized arguments %s"</span> <span class="token operator">%</span> extra<span class="token punctuation">)</span>

        <span class="token comment"># Make sure the update rule exists, then replace the string</span>
        <span class="token comment"># name with the actual function</span>
        <span class="token keyword">if</span> <span class="token keyword">not</span> <span class="token builtin">hasattr</span><span class="token punctuation">(</span>optim<span class="token punctuation">,</span> self<span class="token punctuation">.</span>update_rule<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">'Invalid update_rule "%s"'</span> <span class="token operator">%</span> self<span class="token punctuation">.</span>update_rule<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>update_rule <span class="token operator">=</span> <span class="token builtin">getattr</span><span class="token punctuation">(</span>optim<span class="token punctuation">,</span> self<span class="token punctuation">.</span>update_rule<span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>_reset<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">_reset</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        Set up some book-keeping variables for optimization. Don't call this
        manually.
        """</span>
        <span class="token comment"># Set up some variables for book-keeping</span>
        self<span class="token punctuation">.</span>epoch <span class="token operator">=</span> <span class="token number">0</span>
        self<span class="token punctuation">.</span>best_val_acc <span class="token operator">=</span> <span class="token number">0</span>
        self<span class="token punctuation">.</span>best_params <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
        self<span class="token punctuation">.</span>loss_history <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>train_acc_history <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>val_acc_history <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

        <span class="token comment"># Make a deep copy of the optim_config for each parameter</span>
        self<span class="token punctuation">.</span>optim_configs <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
        <span class="token keyword">for</span> p <span class="token keyword">in</span> self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>params<span class="token punctuation">:</span>
            d <span class="token operator">=</span> <span class="token punctuation">{</span>k<span class="token punctuation">:</span> v <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> self<span class="token punctuation">.</span>optim_config<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
            self<span class="token punctuation">.</span>optim_configs<span class="token punctuation">[</span>p<span class="token punctuation">]</span> <span class="token operator">=</span> d

    <span class="token keyword">def</span> <span class="token function">_step</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        Make a single gradient update. This is called by train() and should not
        be called manually.
        """</span>
        <span class="token comment"># Make a minibatch of training data</span>
        num_train <span class="token operator">=</span> self<span class="token punctuation">.</span>X_train<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        batch_mask <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>num_train<span class="token punctuation">,</span> self<span class="token punctuation">.</span>batch_size<span class="token punctuation">)</span>
        X_batch <span class="token operator">=</span> self<span class="token punctuation">.</span>X_train<span class="token punctuation">[</span>batch_mask<span class="token punctuation">]</span>
        y_batch <span class="token operator">=</span> self<span class="token punctuation">.</span>y_train<span class="token punctuation">[</span>batch_mask<span class="token punctuation">]</span>

        <span class="token comment"># Compute loss and gradient</span>
        loss<span class="token punctuation">,</span> grads <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>loss<span class="token punctuation">(</span>X_batch<span class="token punctuation">,</span> y_batch<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>loss_history<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>

        <span class="token comment"># Perform a parameter update</span>
        <span class="token keyword">for</span> p<span class="token punctuation">,</span> w <span class="token keyword">in</span> self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>params<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            dw <span class="token operator">=</span> grads<span class="token punctuation">[</span>p<span class="token punctuation">]</span>
            config <span class="token operator">=</span> self<span class="token punctuation">.</span>optim_configs<span class="token punctuation">[</span>p<span class="token punctuation">]</span>
            next_w<span class="token punctuation">,</span> next_config <span class="token operator">=</span> self<span class="token punctuation">.</span>update_rule<span class="token punctuation">(</span>w<span class="token punctuation">,</span> dw<span class="token punctuation">,</span> config<span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>params<span class="token punctuation">[</span>p<span class="token punctuation">]</span> <span class="token operator">=</span> next_w
            self<span class="token punctuation">.</span>optim_configs<span class="token punctuation">[</span>p<span class="token punctuation">]</span> <span class="token operator">=</span> next_config

    <span class="token keyword">def</span> <span class="token function">_save_checkpoint</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>checkpoint_name <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span>
        checkpoint <span class="token operator">=</span> <span class="token punctuation">{</span>
            <span class="token string">"model"</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>model<span class="token punctuation">,</span>
            <span class="token string">"update_rule"</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>update_rule<span class="token punctuation">,</span>
            <span class="token string">"lr_decay"</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>lr_decay<span class="token punctuation">,</span>
            <span class="token string">"optim_config"</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>optim_config<span class="token punctuation">,</span>
            <span class="token string">"batch_size"</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>batch_size<span class="token punctuation">,</span>
            <span class="token string">"num_train_samples"</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>num_train_samples<span class="token punctuation">,</span>
            <span class="token string">"num_val_samples"</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>num_val_samples<span class="token punctuation">,</span>
            <span class="token string">"epoch"</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>epoch<span class="token punctuation">,</span>
            <span class="token string">"loss_history"</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>loss_history<span class="token punctuation">,</span>
            <span class="token string">"train_acc_history"</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>train_acc_history<span class="token punctuation">,</span>
            <span class="token string">"val_acc_history"</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>val_acc_history<span class="token punctuation">,</span>
        <span class="token punctuation">}</span>
        filename <span class="token operator">=</span> <span class="token string">"%s_epoch_%d.pkl"</span> <span class="token operator">%</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>checkpoint_name<span class="token punctuation">,</span> self<span class="token punctuation">.</span>epoch<span class="token punctuation">)</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>verbose<span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Saving checkpoint to "%s"'</span> <span class="token operator">%</span> filename<span class="token punctuation">)</span>
        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>filename<span class="token punctuation">,</span> <span class="token string">"wb"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
            pickle<span class="token punctuation">.</span>dump<span class="token punctuation">(</span>checkpoint<span class="token punctuation">,</span> f<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">check_accuracy</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> num_samples<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        Check accuracy of the model on the provided data.

        Inputs:
        - X: Array of data, of shape (N, d_1, ..., d_k)
        - y: Array of labels, of shape (N,)
        - num_samples: If not None, subsample the data and only test the model
          on num_samples datapoints.
        - batch_size: Split X and y into batches of this size to avoid using
          too much memory.

        Returns:
        - acc: Scalar giving the fraction of instances that were correctly
          classified by the model.
        """</span>

        <span class="token comment"># Maybe subsample the data</span>
        N <span class="token operator">=</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        <span class="token keyword">if</span> num_samples <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span> <span class="token keyword">and</span> N <span class="token operator">&gt;</span> num_samples<span class="token punctuation">:</span>
            mask <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>N<span class="token punctuation">,</span> num_samples<span class="token punctuation">)</span>
            N <span class="token operator">=</span> num_samples
            X <span class="token operator">=</span> X<span class="token punctuation">[</span>mask<span class="token punctuation">]</span>
            y <span class="token operator">=</span> y<span class="token punctuation">[</span>mask<span class="token punctuation">]</span>

        <span class="token comment"># Compute predictions in batches</span>
        num_batches <span class="token operator">=</span> N <span class="token operator">//</span> batch_size
        <span class="token keyword">if</span> N <span class="token operator">%</span> batch_size <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">:</span>
            num_batches <span class="token operator">+=</span> <span class="token number">1</span>
        y_pred <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_batches<span class="token punctuation">)</span><span class="token punctuation">:</span>
            start <span class="token operator">=</span> i <span class="token operator">*</span> batch_size
            end <span class="token operator">=</span> <span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">*</span> batch_size
            scores <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>loss<span class="token punctuation">(</span>X<span class="token punctuation">[</span>start<span class="token punctuation">:</span>end<span class="token punctuation">]</span><span class="token punctuation">)</span>
            y_pred<span class="token punctuation">.</span>append<span class="token punctuation">(</span>np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>scores<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        y_pred <span class="token operator">=</span> np<span class="token punctuation">.</span>hstack<span class="token punctuation">(</span>y_pred<span class="token punctuation">)</span>
        acc <span class="token operator">=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>y_pred <span class="token operator">==</span> y<span class="token punctuation">)</span>

        <span class="token keyword">return</span> acc

    <span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        Run optimization to train the model.
        """</span>
        num_train <span class="token operator">=</span> self<span class="token punctuation">.</span>X_train<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        iterations_per_epoch <span class="token operator">=</span> <span class="token builtin">max</span><span class="token punctuation">(</span>num_train <span class="token operator">//</span> self<span class="token punctuation">.</span>batch_size<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        num_iterations <span class="token operator">=</span> self<span class="token punctuation">.</span>num_epochs <span class="token operator">*</span> iterations_per_epoch

        <span class="token keyword">for</span> t <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_iterations<span class="token punctuation">)</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>_step<span class="token punctuation">(</span><span class="token punctuation">)</span>

            <span class="token comment"># Maybe print training loss</span>
            <span class="token keyword">if</span> self<span class="token punctuation">.</span>verbose <span class="token keyword">and</span> t <span class="token operator">%</span> self<span class="token punctuation">.</span>print_every <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
                <span class="token keyword">print</span><span class="token punctuation">(</span>
                    <span class="token string">"(Iteration %d / %d) loss: %f"</span>
                    <span class="token operator">%</span> <span class="token punctuation">(</span>t <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> num_iterations<span class="token punctuation">,</span> self<span class="token punctuation">.</span>loss_history<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
                <span class="token punctuation">)</span>

            <span class="token comment"># At the end of every epoch, increment the epoch counter and decay</span>
            <span class="token comment"># the learning rate.</span>
            epoch_end <span class="token operator">=</span> <span class="token punctuation">(</span>t <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span> iterations_per_epoch <span class="token operator">==</span> <span class="token number">0</span>
            <span class="token keyword">if</span> epoch_end<span class="token punctuation">:</span>
                self<span class="token punctuation">.</span>epoch <span class="token operator">+=</span> <span class="token number">1</span>
                <span class="token keyword">for</span> k <span class="token keyword">in</span> self<span class="token punctuation">.</span>optim_configs<span class="token punctuation">:</span>
                    self<span class="token punctuation">.</span>optim_configs<span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"learning_rate"</span><span class="token punctuation">]</span> <span class="token operator">*=</span> self<span class="token punctuation">.</span>lr_decay

            <span class="token comment"># Check train and val accuracy on the first iteration, the last</span>
            <span class="token comment"># iteration, and at the end of each epoch.</span>
            first_it <span class="token operator">=</span> t <span class="token operator">==</span> <span class="token number">0</span>
            last_it <span class="token operator">=</span> t <span class="token operator">==</span> num_iterations <span class="token operator">-</span> <span class="token number">1</span>
            <span class="token keyword">if</span> first_it <span class="token keyword">or</span> last_it <span class="token keyword">or</span> epoch_end<span class="token punctuation">:</span>
                train_acc <span class="token operator">=</span> self<span class="token punctuation">.</span>check_accuracy<span class="token punctuation">(</span>
                    self<span class="token punctuation">.</span>X_train<span class="token punctuation">,</span> self<span class="token punctuation">.</span>y_train<span class="token punctuation">,</span> num_samples<span class="token operator">=</span>self<span class="token punctuation">.</span>num_train_samples
                <span class="token punctuation">)</span>
                val_acc <span class="token operator">=</span> self<span class="token punctuation">.</span>check_accuracy<span class="token punctuation">(</span>
                    self<span class="token punctuation">.</span>X_val<span class="token punctuation">,</span> self<span class="token punctuation">.</span>y_val<span class="token punctuation">,</span> num_samples<span class="token operator">=</span>self<span class="token punctuation">.</span>num_val_samples
                <span class="token punctuation">)</span>
                self<span class="token punctuation">.</span>train_acc_history<span class="token punctuation">.</span>append<span class="token punctuation">(</span>train_acc<span class="token punctuation">)</span>
                self<span class="token punctuation">.</span>val_acc_history<span class="token punctuation">.</span>append<span class="token punctuation">(</span>val_acc<span class="token punctuation">)</span>
                self<span class="token punctuation">.</span>_save_checkpoint<span class="token punctuation">(</span><span class="token punctuation">)</span>

                <span class="token keyword">if</span> self<span class="token punctuation">.</span>verbose<span class="token punctuation">:</span>
                    <span class="token keyword">print</span><span class="token punctuation">(</span>
                        <span class="token string">"(Epoch %d / %d) train acc: %f; val_acc: %f"</span>
                        <span class="token operator">%</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>epoch<span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_epochs<span class="token punctuation">,</span> train_acc<span class="token punctuation">,</span> val_acc<span class="token punctuation">)</span>
                    <span class="token punctuation">)</span>

                <span class="token comment"># Keep track of the best model</span>
                <span class="token keyword">if</span> val_acc <span class="token operator">&gt;</span> self<span class="token punctuation">.</span>best_val_acc<span class="token punctuation">:</span>
                    self<span class="token punctuation">.</span>best_val_acc <span class="token operator">=</span> val_acc
                    self<span class="token punctuation">.</span>best_params <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
                    <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>params<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                        self<span class="token punctuation">.</span>best_params<span class="token punctuation">[</span>k<span class="token punctuation">]</span> <span class="token operator">=</span> v<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token comment"># At the end of training swap the best params into the model</span>
        self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>params <span class="token operator">=</span> self<span class="token punctuation">.</span>best_params<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><h3 id="CIFAR-10数据集"><a href="#CIFAR-10数据集" class="headerlink" title="CIFAR-10数据集"></a>CIFAR-10数据集</h3><p>本次实验采用 CIFAR-10 数据集。CIFAR-10是一个更接近普适物体的彩色图像数据集。CIFAR-10 是由Hinton 的学生Alex Krizhevsky 和Ilya Sutskever 整理的一个用于识别普适物体的小型数据集。一共包含10 个类别的 RGB 彩色图片：飞机（ airplane ）、汽车（ automobile ）、鸟类（ bird ）、猫（ cat ）、鹿（ deer ）、狗（ dog ）、蛙类（ frog ）、马（ horse ）、船（ ship ）和卡车（ truck ）。每个图片的尺寸为32 × 32 ，每个类别有6000个图像，数据集中一共有50000 张训练图片和10000 张测试图片。</p>
<h3 id="实验步骤"><a href="#实验步骤" class="headerlink" title="实验步骤"></a>实验步骤</h3><ol>
<li><p>载入 CIFAR-10 数据集。</p>
</li>
<li><p>测试前馈神经网络各个网络层：</p>
<p>(1) Affine layer forward/backward</p>
<p>(2) ReLU layer forward/backward</p>
<p>(3) “Sandwich” layers</p>
<p>(4) Softmax loss</p>
<p>测试内容为检查公式计算的梯度和数值计算的梯度是否一致</p>
</li>
<li><p>网络初始化检查。将网络初始化，检查各个网络层的参数是否和数值计算的参数一致</p>
</li>
<li><p>网络过拟合测试。采取50个样本，让网络在20个 epoch 中在训练集上的预测准确率达到100%，training loss history 如下图</p>
<p><img src="/archives/c57b6bd2/Figure_2.png" alt="overfit training loss"></p>
</li>
<li><p>训练一个6层前馈神经网络。网络参数在 main.py 中，Training loss history 如下图</p>
</li>
</ol>
<p><img src="/archives/c57b6bd2/Figure_1.png" alt="training loss"></p>
<h3 id="输出结果"><a href="#输出结果" class="headerlink" title="输出结果"></a>输出结果</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token operator">/</span>home<span class="token operator">/</span>declan<span class="token operator">/</span>anaconda3<span class="token operator">/</span><span class="token builtin">bin</span><span class="token operator">/</span>python <span class="token operator">/</span>home<span class="token operator">/</span>declan<span class="token operator">/</span>PycharmProjects<span class="token operator">/</span>assignment<span class="token operator">/</span>main<span class="token punctuation">.</span>py
<span class="token punctuation">(</span><span class="token string">'X_train: '</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">49000</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token punctuation">(</span><span class="token string">'y_train: '</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">49000</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token punctuation">(</span><span class="token string">'X_val: '</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token punctuation">(</span><span class="token string">'y_val: '</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token punctuation">(</span><span class="token string">'X_test: '</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token punctuation">(</span><span class="token string">'y_test: '</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
Testing affine_forward function<span class="token punctuation">:</span>
difference<span class="token punctuation">:</span>  <span class="token number">9.769847728806635e-10</span>
<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
Testing affine_backward function<span class="token punctuation">:</span>
dx error<span class="token punctuation">:</span>  <span class="token number">3.9797761177321483e-10</span>
dw error<span class="token punctuation">:</span>  <span class="token number">2.086880679588048e-10</span>
db error<span class="token punctuation">:</span>  <span class="token number">1.175381784105478e-11</span>
<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
Testing relu_forward function<span class="token punctuation">:</span>
difference<span class="token punctuation">:</span>  <span class="token number">4.999999798022158e-08</span>
<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
Testing relu_backward function<span class="token punctuation">:</span>
dx error<span class="token punctuation">:</span>  <span class="token number">3.275627447256477e-12</span>
<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
Testing affine_relu_forward<span class="token punctuation">:</span>
dx error<span class="token punctuation">:</span>  <span class="token number">2.4731883908969436e-11</span>
dw error<span class="token punctuation">:</span>  <span class="token number">1.130423646865338e-10</span>
db error<span class="token punctuation">:</span>  <span class="token number">7.826624913878236e-12</span>
<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
Testing softmax_loss<span class="token punctuation">:</span>
loss<span class="token punctuation">:</span>  <span class="token number">2.302678654946736</span>
dx error<span class="token punctuation">:</span>  <span class="token number">8.692830474189084e-09</span>
<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
Running check <span class="token keyword">with</span> reg <span class="token operator">=</span>  <span class="token number">0</span>
Initial loss<span class="token punctuation">:</span>  <span class="token number">2.300479089768492</span>
W1 relative error<span class="token punctuation">:</span> <span class="token number">1.0252674471656573e-07</span>
W2 relative error<span class="token punctuation">:</span> <span class="token number">2.212047930816777e-05</span>
W3 relative error<span class="token punctuation">:</span> <span class="token number">4.5623278145362223e-07</span>
b1 relative error<span class="token punctuation">:</span> <span class="token number">4.660094372886962e-09</span>
b2 relative error<span class="token punctuation">:</span> <span class="token number">2.085654124402131e-09</span>
b3 relative error<span class="token punctuation">:</span> <span class="token number">1.689724888469736e-10</span>
Running check <span class="token keyword">with</span> reg <span class="token operator">=</span>  <span class="token number">3.14</span>
Initial loss<span class="token punctuation">:</span>  <span class="token number">7.052114776533016</span>
W1 relative error<span class="token punctuation">:</span> <span class="token number">1.409028728052923e-08</span>
W2 relative error<span class="token punctuation">:</span> <span class="token number">6.86942277940646e-08</span>
W3 relative error<span class="token punctuation">:</span> <span class="token number">2.1311298702113723e-08</span>
b1 relative error<span class="token punctuation">:</span> <span class="token number">1.475242751587128e-08</span>
b2 relative error<span class="token punctuation">:</span> <span class="token number">1.7223751746766738e-09</span>
b3 relative error<span class="token punctuation">:</span> <span class="token number">2.378772438198909e-10</span>
<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
Overfit <span class="token number">50</span> training examples
<span class="token punctuation">(</span>Iteration <span class="token number">1</span> <span class="token operator">/</span> <span class="token number">40</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">2.363364</span>
<span class="token punctuation">(</span>Epoch <span class="token number">0</span> <span class="token operator">/</span> <span class="token number">20</span><span class="token punctuation">)</span> train acc<span class="token punctuation">:</span> <span class="token number">0.200000</span><span class="token punctuation">;</span> val_acc<span class="token punctuation">:</span> <span class="token number">0.100000</span>
<span class="token punctuation">(</span>Epoch <span class="token number">1</span> <span class="token operator">/</span> <span class="token number">20</span><span class="token punctuation">)</span> train acc<span class="token punctuation">:</span> <span class="token number">0.300000</span><span class="token punctuation">;</span> val_acc<span class="token punctuation">:</span> <span class="token number">0.123000</span>
<span class="token punctuation">(</span>Epoch <span class="token number">2</span> <span class="token operator">/</span> <span class="token number">20</span><span class="token punctuation">)</span> train acc<span class="token punctuation">:</span> <span class="token number">0.420000</span><span class="token punctuation">;</span> val_acc<span class="token punctuation">:</span> <span class="token number">0.164000</span>
<span class="token punctuation">(</span>Epoch <span class="token number">3</span> <span class="token operator">/</span> <span class="token number">20</span><span class="token punctuation">)</span> train acc<span class="token punctuation">:</span> <span class="token number">0.480000</span><span class="token punctuation">;</span> val_acc<span class="token punctuation">:</span> <span class="token number">0.182000</span>
<span class="token punctuation">(</span>Epoch <span class="token number">4</span> <span class="token operator">/</span> <span class="token number">20</span><span class="token punctuation">)</span> train acc<span class="token punctuation">:</span> <span class="token number">0.480000</span><span class="token punctuation">;</span> val_acc<span class="token punctuation">:</span> <span class="token number">0.180000</span>
<span class="token punctuation">(</span>Epoch <span class="token number">5</span> <span class="token operator">/</span> <span class="token number">20</span><span class="token punctuation">)</span> train acc<span class="token punctuation">:</span> <span class="token number">0.680000</span><span class="token punctuation">;</span> val_acc<span class="token punctuation">:</span> <span class="token number">0.183000</span>
<span class="token punctuation">(</span>Iteration <span class="token number">11</span> <span class="token operator">/</span> <span class="token number">40</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">1.012326</span>
<span class="token punctuation">(</span>Epoch <span class="token number">6</span> <span class="token operator">/</span> <span class="token number">20</span><span class="token punctuation">)</span> train acc<span class="token punctuation">:</span> <span class="token number">0.740000</span><span class="token punctuation">;</span> val_acc<span class="token punctuation">:</span> <span class="token number">0.195000</span>
<span class="token punctuation">(</span>Epoch <span class="token number">7</span> <span class="token operator">/</span> <span class="token number">20</span><span class="token punctuation">)</span> train acc<span class="token punctuation">:</span> <span class="token number">0.700000</span><span class="token punctuation">;</span> val_acc<span class="token punctuation">:</span> <span class="token number">0.187000</span>
<span class="token punctuation">(</span>Epoch <span class="token number">8</span> <span class="token operator">/</span> <span class="token number">20</span><span class="token punctuation">)</span> train acc<span class="token punctuation">:</span> <span class="token number">0.780000</span><span class="token punctuation">;</span> val_acc<span class="token punctuation">:</span> <span class="token number">0.185000</span>
<span class="token punctuation">(</span>Epoch <span class="token number">9</span> <span class="token operator">/</span> <span class="token number">20</span><span class="token punctuation">)</span> train acc<span class="token punctuation">:</span> <span class="token number">0.860000</span><span class="token punctuation">;</span> val_acc<span class="token punctuation">:</span> <span class="token number">0.201000</span>
<span class="token punctuation">(</span>Epoch <span class="token number">10</span> <span class="token operator">/</span> <span class="token number">20</span><span class="token punctuation">)</span> train acc<span class="token punctuation">:</span> <span class="token number">0.880000</span><span class="token punctuation">;</span> val_acc<span class="token punctuation">:</span> <span class="token number">0.196000</span>
<span class="token punctuation">(</span>Iteration <span class="token number">21</span> <span class="token operator">/</span> <span class="token number">40</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">0.499348</span>
<span class="token punctuation">(</span>Epoch <span class="token number">11</span> <span class="token operator">/</span> <span class="token number">20</span><span class="token punctuation">)</span> train acc<span class="token punctuation">:</span> <span class="token number">0.920000</span><span class="token punctuation">;</span> val_acc<span class="token punctuation">:</span> <span class="token number">0.199000</span>
<span class="token punctuation">(</span>Epoch <span class="token number">12</span> <span class="token operator">/</span> <span class="token number">20</span><span class="token punctuation">)</span> train acc<span class="token punctuation">:</span> <span class="token number">0.900000</span><span class="token punctuation">;</span> val_acc<span class="token punctuation">:</span> <span class="token number">0.187000</span>
<span class="token punctuation">(</span>Epoch <span class="token number">13</span> <span class="token operator">/</span> <span class="token number">20</span><span class="token punctuation">)</span> train acc<span class="token punctuation">:</span> <span class="token number">0.940000</span><span class="token punctuation">;</span> val_acc<span class="token punctuation">:</span> <span class="token number">0.204000</span>
<span class="token punctuation">(</span>Epoch <span class="token number">14</span> <span class="token operator">/</span> <span class="token number">20</span><span class="token punctuation">)</span> train acc<span class="token punctuation">:</span> <span class="token number">1.000000</span><span class="token punctuation">;</span> val_acc<span class="token punctuation">:</span> <span class="token number">0.199000</span>
<span class="token punctuation">(</span>Epoch <span class="token number">15</span> <span class="token operator">/</span> <span class="token number">20</span><span class="token punctuation">)</span> train acc<span class="token punctuation">:</span> <span class="token number">0.960000</span><span class="token punctuation">;</span> val_acc<span class="token punctuation">:</span> <span class="token number">0.193000</span>
<span class="token punctuation">(</span>Iteration <span class="token number">31</span> <span class="token operator">/</span> <span class="token number">40</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">0.209285</span>
<span class="token punctuation">(</span>Epoch <span class="token number">16</span> <span class="token operator">/</span> <span class="token number">20</span><span class="token punctuation">)</span> train acc<span class="token punctuation">:</span> <span class="token number">1.000000</span><span class="token punctuation">;</span> val_acc<span class="token punctuation">:</span> <span class="token number">0.195000</span>
<span class="token punctuation">(</span>Epoch <span class="token number">17</span> <span class="token operator">/</span> <span class="token number">20</span><span class="token punctuation">)</span> train acc<span class="token punctuation">:</span> <span class="token number">1.000000</span><span class="token punctuation">;</span> val_acc<span class="token punctuation">:</span> <span class="token number">0.214000</span>
<span class="token punctuation">(</span>Epoch <span class="token number">18</span> <span class="token operator">/</span> <span class="token number">20</span><span class="token punctuation">)</span> train acc<span class="token punctuation">:</span> <span class="token number">1.000000</span><span class="token punctuation">;</span> val_acc<span class="token punctuation">:</span> <span class="token number">0.213000</span>
<span class="token punctuation">(</span>Epoch <span class="token number">19</span> <span class="token operator">/</span> <span class="token number">20</span><span class="token punctuation">)</span> train acc<span class="token punctuation">:</span> <span class="token number">1.000000</span><span class="token punctuation">;</span> val_acc<span class="token punctuation">:</span> <span class="token number">0.197000</span>
<span class="token punctuation">(</span>Epoch <span class="token number">20</span> <span class="token operator">/</span> <span class="token number">20</span><span class="token punctuation">)</span> train acc<span class="token punctuation">:</span> <span class="token number">1.000000</span><span class="token punctuation">;</span> val_acc<span class="token punctuation">:</span> <span class="token number">0.198000</span>
<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
Train a <span class="token number">6</span> layer model
<span class="token punctuation">(</span>Iteration <span class="token number">1</span> <span class="token operator">/</span> <span class="token number">58800</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">2.302535</span>
<span class="token punctuation">(</span>Epoch <span class="token number">0</span> <span class="token operator">/</span> <span class="token number">30</span><span class="token punctuation">)</span> train acc<span class="token punctuation">:</span> <span class="token number">0.142000</span><span class="token punctuation">;</span> val_acc<span class="token punctuation">:</span> <span class="token number">0.126000</span>
<span class="token punctuation">(</span>Iteration <span class="token number">1001</span> <span class="token operator">/</span> <span class="token number">58800</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">1.900293</span>
<span class="token punctuation">(</span>Epoch <span class="token number">1</span> <span class="token operator">/</span> <span class="token number">30</span><span class="token punctuation">)</span> train acc<span class="token punctuation">:</span> <span class="token number">0.413000</span><span class="token punctuation">;</span> val_acc<span class="token punctuation">:</span> <span class="token number">0.393000</span>
<span class="token punctuation">(</span>Iteration <span class="token number">2001</span> <span class="token operator">/</span> <span class="token number">58800</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">1.578841</span>
<span class="token punctuation">(</span>Iteration <span class="token number">3001</span> <span class="token operator">/</span> <span class="token number">58800</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">1.339331</span>
<span class="token punctuation">(</span>Epoch <span class="token number">2</span> <span class="token operator">/</span> <span class="token number">30</span><span class="token punctuation">)</span> train acc<span class="token punctuation">:</span> <span class="token number">0.433000</span><span class="token punctuation">;</span> val_acc<span class="token punctuation">:</span> <span class="token number">0.457000</span>
<span class="token punctuation">(</span>Iteration <span class="token number">4001</span> <span class="token operator">/</span> <span class="token number">58800</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">1.641333</span>
<span class="token punctuation">(</span>Iteration <span class="token number">5001</span> <span class="token operator">/</span> <span class="token number">58800</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">1.232348</span>
<span class="token punctuation">(</span>Epoch <span class="token number">3</span> <span class="token operator">/</span> <span class="token number">30</span><span class="token punctuation">)</span> train acc<span class="token punctuation">:</span> <span class="token number">0.497000</span><span class="token punctuation">;</span> val_acc<span class="token punctuation">:</span> <span class="token number">0.489000</span>
<span class="token punctuation">(</span>Iteration <span class="token number">6001</span> <span class="token operator">/</span> <span class="token number">58800</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">1.060361</span>
<span class="token punctuation">(</span>Iteration <span class="token number">7001</span> <span class="token operator">/</span> <span class="token number">58800</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">1.445194</span>
<span class="token punctuation">(</span>Epoch <span class="token number">4</span> <span class="token operator">/</span> <span class="token number">30</span><span class="token punctuation">)</span> train acc<span class="token punctuation">:</span> <span class="token number">0.501000</span><span class="token punctuation">;</span> val_acc<span class="token punctuation">:</span> <span class="token number">0.497000</span>
<span class="token punctuation">(</span>Iteration <span class="token number">8001</span> <span class="token operator">/</span> <span class="token number">58800</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">1.261873</span>
<span class="token punctuation">(</span>Iteration <span class="token number">9001</span> <span class="token operator">/</span> <span class="token number">58800</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">1.476637</span>
<span class="token punctuation">(</span>Epoch <span class="token number">5</span> <span class="token operator">/</span> <span class="token number">30</span><span class="token punctuation">)</span> train acc<span class="token punctuation">:</span> <span class="token number">0.543000</span><span class="token punctuation">;</span> val_acc<span class="token punctuation">:</span> <span class="token number">0.516000</span>
<span class="token punctuation">(</span>Iteration <span class="token number">10001</span> <span class="token operator">/</span> <span class="token number">58800</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">1.425499</span>
<span class="token punctuation">(</span>Iteration <span class="token number">11001</span> <span class="token operator">/</span> <span class="token number">58800</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">0.995042</span>
<span class="token punctuation">(</span>Epoch <span class="token number">6</span> <span class="token operator">/</span> <span class="token number">30</span><span class="token punctuation">)</span> train acc<span class="token punctuation">:</span> <span class="token number">0.585000</span><span class="token punctuation">;</span> val_acc<span class="token punctuation">:</span> <span class="token number">0.516000</span>
<span class="token punctuation">(</span>Iteration <span class="token number">12001</span> <span class="token operator">/</span> <span class="token number">58800</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">1.172578</span>
<span class="token punctuation">(</span>Iteration <span class="token number">13001</span> <span class="token operator">/</span> <span class="token number">58800</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">1.220867</span>
<span class="token punctuation">(</span>Epoch <span class="token number">7</span> <span class="token operator">/</span> <span class="token number">30</span><span class="token punctuation">)</span> train acc<span class="token punctuation">:</span> <span class="token number">0.604000</span><span class="token punctuation">;</span> val_acc<span class="token punctuation">:</span> <span class="token number">0.535000</span>
<span class="token punctuation">(</span>Iteration <span class="token number">14001</span> <span class="token operator">/</span> <span class="token number">58800</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">1.126022</span>
<span class="token punctuation">(</span>Iteration <span class="token number">15001</span> <span class="token operator">/</span> <span class="token number">58800</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">1.189169</span>
<span class="token punctuation">(</span>Epoch <span class="token number">8</span> <span class="token operator">/</span> <span class="token number">30</span><span class="token punctuation">)</span> train acc<span class="token punctuation">:</span> <span class="token number">0.607000</span><span class="token punctuation">;</span> val_acc<span class="token punctuation">:</span> <span class="token number">0.515000</span>
<span class="token punctuation">(</span>Iteration <span class="token number">16001</span> <span class="token operator">/</span> <span class="token number">58800</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">0.911871</span>
<span class="token punctuation">(</span>Iteration <span class="token number">17001</span> <span class="token operator">/</span> <span class="token number">58800</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">1.321649</span>
<span class="token punctuation">(</span>Epoch <span class="token number">9</span> <span class="token operator">/</span> <span class="token number">30</span><span class="token punctuation">)</span> train acc<span class="token punctuation">:</span> <span class="token number">0.651000</span><span class="token punctuation">;</span> val_acc<span class="token punctuation">:</span> <span class="token number">0.540000</span>
<span class="token punctuation">(</span>Iteration <span class="token number">18001</span> <span class="token operator">/</span> <span class="token number">58800</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">0.853801</span>
<span class="token punctuation">(</span>Iteration <span class="token number">19001</span> <span class="token operator">/</span> <span class="token number">58800</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">1.168619</span>
<span class="token punctuation">(</span>Epoch <span class="token number">10</span> <span class="token operator">/</span> <span class="token number">30</span><span class="token punctuation">)</span> train acc<span class="token punctuation">:</span> <span class="token number">0.636000</span><span class="token punctuation">;</span> val_acc<span class="token punctuation">:</span> <span class="token number">0.538000</span>
<span class="token punctuation">(</span>Iteration <span class="token number">20001</span> <span class="token operator">/</span> <span class="token number">58800</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">0.645601</span>
<span class="token punctuation">(</span>Iteration <span class="token number">21001</span> <span class="token operator">/</span> <span class="token number">58800</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">1.041803</span>
<span class="token punctuation">(</span>Epoch <span class="token number">11</span> <span class="token operator">/</span> <span class="token number">30</span><span class="token punctuation">)</span> train acc<span class="token punctuation">:</span> <span class="token number">0.657000</span><span class="token punctuation">;</span> val_acc<span class="token punctuation">:</span> <span class="token number">0.548000</span>
<span class="token punctuation">(</span>Iteration <span class="token number">22001</span> <span class="token operator">/</span> <span class="token number">58800</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">0.866582</span>
<span class="token punctuation">(</span>Iteration <span class="token number">23001</span> <span class="token operator">/</span> <span class="token number">58800</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">0.939673</span>
<span class="token punctuation">(</span>Epoch <span class="token number">12</span> <span class="token operator">/</span> <span class="token number">30</span><span class="token punctuation">)</span> train acc<span class="token punctuation">:</span> <span class="token number">0.716000</span><span class="token punctuation">;</span> val_acc<span class="token punctuation">:</span> <span class="token number">0.523000</span>
<span class="token punctuation">(</span>Iteration <span class="token number">24001</span> <span class="token operator">/</span> <span class="token number">58800</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">0.539047</span>
<span class="token punctuation">(</span>Iteration <span class="token number">25001</span> <span class="token operator">/</span> <span class="token number">58800</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">0.935193</span>
<span class="token punctuation">(</span>Epoch <span class="token number">13</span> <span class="token operator">/</span> <span class="token number">30</span><span class="token punctuation">)</span> train acc<span class="token punctuation">:</span> <span class="token number">0.723000</span><span class="token punctuation">;</span> val_acc<span class="token punctuation">:</span> <span class="token number">0.545000</span>
<span class="token punctuation">(</span>Iteration <span class="token number">26001</span> <span class="token operator">/</span> <span class="token number">58800</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">1.321233</span>
<span class="token punctuation">(</span>Iteration <span class="token number">27001</span> <span class="token operator">/</span> <span class="token number">58800</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">0.807344</span>
<span class="token punctuation">(</span>Epoch <span class="token number">14</span> <span class="token operator">/</span> <span class="token number">30</span><span class="token punctuation">)</span> train acc<span class="token punctuation">:</span> <span class="token number">0.706000</span><span class="token punctuation">;</span> val_acc<span class="token punctuation">:</span> <span class="token number">0.534000</span>
<span class="token punctuation">(</span>Iteration <span class="token number">28001</span> <span class="token operator">/</span> <span class="token number">58800</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">0.629804</span>
<span class="token punctuation">(</span>Iteration <span class="token number">29001</span> <span class="token operator">/</span> <span class="token number">58800</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">0.730200</span>
<span class="token punctuation">(</span>Epoch <span class="token number">15</span> <span class="token operator">/</span> <span class="token number">30</span><span class="token punctuation">)</span> train acc<span class="token punctuation">:</span> <span class="token number">0.769000</span><span class="token punctuation">;</span> val_acc<span class="token punctuation">:</span> <span class="token number">0.537000</span>
<span class="token punctuation">(</span>Iteration <span class="token number">30001</span> <span class="token operator">/</span> <span class="token number">58800</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">0.503031</span>
<span class="token punctuation">(</span>Iteration <span class="token number">31001</span> <span class="token operator">/</span> <span class="token number">58800</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">0.439191</span>
<span class="token punctuation">(</span>Epoch <span class="token number">16</span> <span class="token operator">/</span> <span class="token number">30</span><span class="token punctuation">)</span> train acc<span class="token punctuation">:</span> <span class="token number">0.760000</span><span class="token punctuation">;</span> val_acc<span class="token punctuation">:</span> <span class="token number">0.520000</span>
<span class="token punctuation">(</span>Iteration <span class="token number">32001</span> <span class="token operator">/</span> <span class="token number">58800</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">1.236385</span>
<span class="token punctuation">(</span>Iteration <span class="token number">33001</span> <span class="token operator">/</span> <span class="token number">58800</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">0.533880</span>
<span class="token punctuation">(</span>Epoch <span class="token number">17</span> <span class="token operator">/</span> <span class="token number">30</span><span class="token punctuation">)</span> train acc<span class="token punctuation">:</span> <span class="token number">0.778000</span><span class="token punctuation">;</span> val_acc<span class="token punctuation">:</span> <span class="token number">0.534000</span>
<span class="token punctuation">(</span>Iteration <span class="token number">34001</span> <span class="token operator">/</span> <span class="token number">58800</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">0.404297</span>
<span class="token punctuation">(</span>Iteration <span class="token number">35001</span> <span class="token operator">/</span> <span class="token number">58800</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">0.292954</span>
<span class="token punctuation">(</span>Epoch <span class="token number">18</span> <span class="token operator">/</span> <span class="token number">30</span><span class="token punctuation">)</span> train acc<span class="token punctuation">:</span> <span class="token number">0.765000</span><span class="token punctuation">;</span> val_acc<span class="token punctuation">:</span> <span class="token number">0.534000</span>
<span class="token punctuation">(</span>Iteration <span class="token number">36001</span> <span class="token operator">/</span> <span class="token number">58800</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">0.499621</span>
<span class="token punctuation">(</span>Iteration <span class="token number">37001</span> <span class="token operator">/</span> <span class="token number">58800</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">0.534113</span>
<span class="token punctuation">(</span>Epoch <span class="token number">19</span> <span class="token operator">/</span> <span class="token number">30</span><span class="token punctuation">)</span> train acc<span class="token punctuation">:</span> <span class="token number">0.805000</span><span class="token punctuation">;</span> val_acc<span class="token punctuation">:</span> <span class="token number">0.541000</span>
<span class="token punctuation">(</span>Iteration <span class="token number">38001</span> <span class="token operator">/</span> <span class="token number">58800</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">0.758606</span>
<span class="token punctuation">(</span>Iteration <span class="token number">39001</span> <span class="token operator">/</span> <span class="token number">58800</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">0.668027</span>
<span class="token punctuation">(</span>Epoch <span class="token number">20</span> <span class="token operator">/</span> <span class="token number">30</span><span class="token punctuation">)</span> train acc<span class="token punctuation">:</span> <span class="token number">0.814000</span><span class="token punctuation">;</span> val_acc<span class="token punctuation">:</span> <span class="token number">0.541000</span>
<span class="token punctuation">(</span>Iteration <span class="token number">40001</span> <span class="token operator">/</span> <span class="token number">58800</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">0.510081</span>
<span class="token punctuation">(</span>Iteration <span class="token number">41001</span> <span class="token operator">/</span> <span class="token number">58800</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">0.718000</span>
<span class="token punctuation">(</span>Epoch <span class="token number">21</span> <span class="token operator">/</span> <span class="token number">30</span><span class="token punctuation">)</span> train acc<span class="token punctuation">:</span> <span class="token number">0.804000</span><span class="token punctuation">;</span> val_acc<span class="token punctuation">:</span> <span class="token number">0.538000</span>
<span class="token punctuation">(</span>Iteration <span class="token number">42001</span> <span class="token operator">/</span> <span class="token number">58800</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">0.451329</span>
<span class="token punctuation">(</span>Iteration <span class="token number">43001</span> <span class="token operator">/</span> <span class="token number">58800</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">0.312300</span>
<span class="token punctuation">(</span>Epoch <span class="token number">22</span> <span class="token operator">/</span> <span class="token number">30</span><span class="token punctuation">)</span> train acc<span class="token punctuation">:</span> <span class="token number">0.831000</span><span class="token punctuation">;</span> val_acc<span class="token punctuation">:</span> <span class="token number">0.516000</span>
<span class="token punctuation">(</span>Iteration <span class="token number">44001</span> <span class="token operator">/</span> <span class="token number">58800</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">0.385578</span>
<span class="token punctuation">(</span>Iteration <span class="token number">45001</span> <span class="token operator">/</span> <span class="token number">58800</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">0.357169</span>
<span class="token punctuation">(</span>Epoch <span class="token number">23</span> <span class="token operator">/</span> <span class="token number">30</span><span class="token punctuation">)</span> train acc<span class="token punctuation">:</span> <span class="token number">0.842000</span><span class="token punctuation">;</span> val_acc<span class="token punctuation">:</span> <span class="token number">0.544000</span>
<span class="token punctuation">(</span>Iteration <span class="token number">46001</span> <span class="token operator">/</span> <span class="token number">58800</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">0.337137</span>
<span class="token punctuation">(</span>Iteration <span class="token number">47001</span> <span class="token operator">/</span> <span class="token number">58800</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">0.609988</span>
<span class="token punctuation">(</span>Epoch <span class="token number">24</span> <span class="token operator">/</span> <span class="token number">30</span><span class="token punctuation">)</span> train acc<span class="token punctuation">:</span> <span class="token number">0.842000</span><span class="token punctuation">;</span> val_acc<span class="token punctuation">:</span> <span class="token number">0.544000</span>
<span class="token punctuation">(</span>Iteration <span class="token number">48001</span> <span class="token operator">/</span> <span class="token number">58800</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">0.578434</span>
<span class="token punctuation">(</span>Epoch <span class="token number">25</span> <span class="token operator">/</span> <span class="token number">30</span><span class="token punctuation">)</span> train acc<span class="token punctuation">:</span> <span class="token number">0.853000</span><span class="token punctuation">;</span> val_acc<span class="token punctuation">:</span> <span class="token number">0.537000</span>
<span class="token punctuation">(</span>Iteration <span class="token number">49001</span> <span class="token operator">/</span> <span class="token number">58800</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">0.436553</span>
<span class="token punctuation">(</span>Iteration <span class="token number">50001</span> <span class="token operator">/</span> <span class="token number">58800</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">0.250274</span>
<span class="token punctuation">(</span>Epoch <span class="token number">26</span> <span class="token operator">/</span> <span class="token number">30</span><span class="token punctuation">)</span> train acc<span class="token punctuation">:</span> <span class="token number">0.851000</span><span class="token punctuation">;</span> val_acc<span class="token punctuation">:</span> <span class="token number">0.543000</span>
<span class="token punctuation">(</span>Iteration <span class="token number">51001</span> <span class="token operator">/</span> <span class="token number">58800</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">0.502778</span>
<span class="token punctuation">(</span>Iteration <span class="token number">52001</span> <span class="token operator">/</span> <span class="token number">58800</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">0.603514</span>
<span class="token punctuation">(</span>Epoch <span class="token number">27</span> <span class="token operator">/</span> <span class="token number">30</span><span class="token punctuation">)</span> train acc<span class="token punctuation">:</span> <span class="token number">0.858000</span><span class="token punctuation">;</span> val_acc<span class="token punctuation">:</span> <span class="token number">0.526000</span>
<span class="token punctuation">(</span>Iteration <span class="token number">53001</span> <span class="token operator">/</span> <span class="token number">58800</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">0.434914</span>
<span class="token punctuation">(</span>Iteration <span class="token number">54001</span> <span class="token operator">/</span> <span class="token number">58800</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">0.463235</span>
<span class="token punctuation">(</span>Epoch <span class="token number">28</span> <span class="token operator">/</span> <span class="token number">30</span><span class="token punctuation">)</span> train acc<span class="token punctuation">:</span> <span class="token number">0.858000</span><span class="token punctuation">;</span> val_acc<span class="token punctuation">:</span> <span class="token number">0.546000</span>
<span class="token punctuation">(</span>Iteration <span class="token number">55001</span> <span class="token operator">/</span> <span class="token number">58800</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">0.248021</span>
<span class="token punctuation">(</span>Iteration <span class="token number">56001</span> <span class="token operator">/</span> <span class="token number">58800</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">0.244172</span>
<span class="token punctuation">(</span>Epoch <span class="token number">29</span> <span class="token operator">/</span> <span class="token number">30</span><span class="token punctuation">)</span> train acc<span class="token punctuation">:</span> <span class="token number">0.882000</span><span class="token punctuation">;</span> val_acc<span class="token punctuation">:</span> <span class="token number">0.526000</span>
<span class="token punctuation">(</span>Iteration <span class="token number">57001</span> <span class="token operator">/</span> <span class="token number">58800</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">0.242352</span>
<span class="token punctuation">(</span>Iteration <span class="token number">58001</span> <span class="token operator">/</span> <span class="token number">58800</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">0.201015</span>
<span class="token punctuation">(</span>Epoch <span class="token number">30</span> <span class="token operator">/</span> <span class="token number">30</span><span class="token punctuation">)</span> train acc<span class="token punctuation">:</span> <span class="token number">0.893000</span><span class="token punctuation">;</span> val_acc<span class="token punctuation">:</span> <span class="token number">0.533000</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本实验使用了 python 第三方数据库 numpy，从底层实现了前馈神经网络的搭建与优化，使用 CIFAR-10 数据集进行测试，在验证集上达到了50%以上的准确率。</p>
<h3 id="改进思路"><a href="#改进思路" class="headerlink" title="改进思路"></a>改进思路</h3><ol>
<li><p>在训练6层前馈神经网络时，依然出现了过拟合的问题。对于过拟合可以考虑使用正则化项。如果使用 L2 正则化，部分实验结果如下</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token punctuation">(</span>Epoch <span class="token number">18</span> <span class="token operator">/</span> <span class="token number">30</span><span class="token punctuation">)</span> train acc<span class="token punctuation">:</span> <span class="token number">0.750000</span><span class="token punctuation">;</span> val_acc<span class="token punctuation">:</span> <span class="token number">0.533000</span>
   <span class="token punctuation">(</span>Iteration <span class="token number">36001</span> <span class="token operator">/</span> <span class="token number">58800</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">0.614462</span>
   <span class="token punctuation">(</span>Iteration <span class="token number">37001</span> <span class="token operator">/</span> <span class="token number">58800</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">0.643702</span>
   <span class="token punctuation">(</span>Epoch <span class="token number">19</span> <span class="token operator">/</span> <span class="token number">30</span><span class="token punctuation">)</span> train acc<span class="token punctuation">:</span> <span class="token number">0.752000</span><span class="token punctuation">;</span> val_acc<span class="token punctuation">:</span> <span class="token number">0.527000</span>
   <span class="token punctuation">(</span>Iteration <span class="token number">38001</span> <span class="token operator">/</span> <span class="token number">58800</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">0.774556</span>
   <span class="token punctuation">(</span>Iteration <span class="token number">39001</span> <span class="token operator">/</span> <span class="token number">58800</span><span class="token punctuation">)</span> loss<span class="token punctuation">:</span> <span class="token number">0.964057</span>
   <span class="token punctuation">(</span>Epoch <span class="token number">20</span> <span class="token operator">/</span> <span class="token number">30</span><span class="token punctuation">)</span> train acc<span class="token punctuation">:</span> <span class="token number">0.758000</span><span class="token punctuation">;</span> val_acc<span class="token punctuation">:</span> <span class="token number">0.537000</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>正则化参数 $\lambda= 10^{-3}$，最终结果并没有明显提升，也许使用不同的正则化参数会有更好的效果。</p>
</li>
<li><p>可以使用卷积神经网络。卷积神经网络 CNN 在计算机视觉领域的应用越来越广泛，相比简单的全连接网络设计更适合于计算机视觉任务。</p>
</li>
<li><p>可以尝试其他超参数，例如网络的深度，隐藏层节点个数等等。</p>
</li>
</ol>

                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        Author:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">Declan</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        Link:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://hongkun.space/archives/c57b6bd2.html">https://hongkun.space/archives/c57b6bd2.html</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        Reprint policy:
                    </i>
                </span>
                <span class="reprint-info">
                    All articles in this blog are used except for special statements
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    reprint polocy. If reproduced, please indicate source
                    <a href="/about" target="_blank">Declan</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>Copied successfully, please follow the reprint policy of this article</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">more</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/%E6%9C%9F%E6%9C%AB%E4%BD%9C%E4%B8%9A/">
                                    <span class="chip bg-color">期末作业</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.4rem;
        line-height: 38px;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

        <div class="card">
	    <script src="https://utteranc.es/client.js"
	    repo="DeclK/declk.github.io"
	    issue-term="pathname"
	    theme="github-light"
	    crossorigin="anonymous"
	    async>
	    </script>
            

            

            

            

            
			
			

            

        </div>

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;Previous</div>
            <div class="card">
                <a href="/archives/7cb0d5f5.html">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/0.png" class="responsive-img" alt="SE-SSD (dev)">
                        
                        <span class="card-title">SE-SSD (dev)</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2021-10-08
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/papers/" class="post-category">
                                    papers
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Point-Cloud/">
                        <span class="chip bg-color">Point Cloud</span>
                    </a>
                    
                    <a href="/tags/SE-SSD/">
                        <span class="chip bg-color">SE-SSD</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                Next&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/archives/acef3112.html">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/0.png" class="responsive-img" alt="MMDetection 项目">
                        
                        <span class="card-title">MMDetection 项目</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2021-09-28
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E7%BC%96%E7%A8%8B/" class="post-category">
                                    编程
                                </a>
                            
                            <a href="/categories/%E7%BC%96%E7%A8%8B/OpenMMLab/" class="post-category">
                                    OpenMMLab
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/MMDetection/">
                        <span class="chip bg-color">MMDetection</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;TOC</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>


<script src="https://cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
    MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$', '$'], ['\\(', '\\)']]}
    });
</script>



    <footer class="page-footer bg-color">
    
    <div class="container row center-align" style="margin-bottom: 0px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2021</span>
            
            <a href="/about" target="_blank">Declan</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            <br>
            
            &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                class="white-color">81k</span>&nbsp;字
            
            <span id="sitetime"></span>
            
            
            
            
            
            <span id="busuanzi_container_site_pv">
                |&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv"
                    class="white-color"></span>&nbsp;次
            </span>
            
            
            <span id="busuanzi_container_site_uv">
                |&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv"
                    class="white-color"></span>&nbsp;人
            </span>
            
            <br>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/DeclK" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:hongkun20sme@smail.nju.edu.cn" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>















    <a href="https://space.bilibili.com/385931953" class="tooltipped" target="_blank" data-tooltip="访问我的bilibili" data-position="top" data-delay="50">
        <i class="fas fa-bold"></i>
    </a>

</div>
    </div>
</footer>

<div class="progress-bar"></div>


<script language=javascript>
    function siteTime() {
        window.setTimeout("siteTime()", 1000);
        var seconds = 1000;
        var minutes = seconds * 60;
        var hours = minutes * 60;
        var days = hours * 24;
        var years = days * 365;
        var today = new Date();
        var todayYear = today.getFullYear();
        var todayMonth = today.getMonth() + 1;
        var todayDate = today.getDate();
        var todayHour = today.getHours();
        var todayMinute = today.getMinutes();
        var todaySecond = today.getSeconds();
        var t1 = Date.UTC(2021, 06, 30, 00, 00, 00); //起始北京时间
        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
        var diff = t2 - t1;
        var diffYears = Math.floor(diff / years);
        var diffDays = Math.floor((diff / days) - diffYears * 365);
        var diffHours = Math.floor((diff - (diffYears * 365 + diffDays) * days) / hours);
        var diffMinutes = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours) / minutes);
        var diffSeconds = Math.floor((diff - (diffYears * 365 + diffDays) * days - diffHours * hours - diffMinutes * minutes) / seconds);
        document.getElementById("sitetime").innerHTML = "本站已运行 " +diffYears+" 年 "+diffDays + " 天 " + diffHours + " 小时 " + diffMinutes + " 分钟 " + diffSeconds + " 秒";
    }/*因为建站时间还没有一年，就将之注释掉了。需要的可以取消*/
    siteTime();
</script>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;Search</span>
            <input type="search" id="searchInput" name="s" placeholder="Please enter a search keyword"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

	
    

    

    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
