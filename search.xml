<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Leetcode-diary 3 Array &amp; Binary Search</title>
      <link href="/archives/6921f8d1.html"/>
      <url>/archives/6921f8d1.html</url>
      
        <content type="html"><![CDATA[<h1 id="Leetcode-diary-3-Array-amp-Binary-Search"><a href="#Leetcode-diary-3-Array-amp-Binary-Search" class="headerlink" title="Leetcode-diary 3 Array &amp; Binary Search"></a>Leetcode-diary 3 Array &amp; Binary Search</h1><h2 id="Binary-Search"><a href="#Binary-Search" class="headerlink" title="Binary Search"></a>Binary Search</h2><h4 id="528-按权重随机选择"><a href="#528-按权重随机选择" class="headerlink" title="528. 按权重随机选择"></a><a href="https://leetcode-cn.com/problems/random-pick-with-weight/">528. 按权重随机选择</a></h4><p>我先使用了 numpy 解决了这个问题，显然这一题需要使用二分查找。具体思路是将随机问题转化为一个在区间之内选择数字的问题</p><h4 id="162-寻找峰值"><a href="#162-寻找峰值" class="headerlink" title="162. 寻找峰值"></a><a href="https://leetcode-cn.com/problems/find-peak-element/">162. 寻找峰值</a></h4><p>这一题的二分查找需要对逻辑非常清晰，也就是为什么当 mid 值小于任一邻值时，邻居方向必定有解。并且对于边界的情况需要好好思考，也就是左右不存在邻值。一个优雅的解法是定义一个辅助函数，来返回 -1 和 n 边界的值</p><h4 id="410-分割数组的最大值"><a href="#410-分割数组的最大值" class="headerlink" title="410. 分割数组的最大值"></a><a href="https://leetcode-cn.com/problems/split-array-largest-sum/">410. 分割数组的最大值</a></h4><p>使用动态规划会超出时间限制，而且这一题的动态规划也挺绕的，主要是初始化如何进行：关键点为要关注有减号的地方，当这些地方超过了数组的范围，就需要进行初始化或者特殊处理，如果能在循环之外进行初始化就是最好不过的了，二维通常要多1个长度</p><p>这一题的最佳解法是二分搜索+贪心算法：假设一个值 x, 判断整个数组能不能分成 m 份, 每一份都小于等于 x，通过二分查找很快就能判定这个值的大小</p><h4 id="658-找到-K-个最接近的元素"><a href="#658-找到-K-个最接近的元素" class="headerlink" title="658. 找到 K 个最接近的元素"></a><a href="https://leetcode-cn.com/problems/find-k-closest-elements/">658. 找到 K 个最接近的元素</a></h4><p>先用二分查找到位置，然后使用双指针判断邻居</p><h4 id="1011-在-D-天内送达包裹的能力"><a href="#1011-在-D-天内送达包裹的能力" class="headerlink" title="1011. 在 D 天内送达包裹的能力"></a><a href="https://leetcode-cn.com/problems/capacity-to-ship-packages-within-d-days/">1011. 在 D 天内送达包裹的能力</a></h4><p>和410的题目是完全一样的</p><h4 id="315-计算右侧小于当前元素的个数"><a href="#315-计算右侧小于当前元素的个数" class="headerlink" title="315. 计算右侧小于当前元素的个数"></a><a href="https://leetcode-cn.com/problems/count-of-smaller-numbers-after-self/">315. 计算右侧小于当前元素的个数</a></h4><p>不理解…明明写的两种算法时间复杂度应该都是一样的，但写的第一种就是会超时，原因在于每次搜寻的都是最长的数组</p><h2 id="Array"><a href="#Array" class="headerlink" title="Array"></a>Array</h2><p>现在重点突击 array &amp; dp，感觉这两个才是大头的考点</p><h4 id="442-数组中重复的数据"><a href="#442-数组中重复的数据" class="headerlink" title="442. 数组中重复的数据"></a><a href="https://leetcode-cn.com/problems/find-all-duplicates-in-an-array/">442. 数组中重复的数据</a></h4><p>使用数组的下标做标记…第一次碰到，这就是原地哈希。充分利用了数组的范围在 [1, n] 之间这个信息。我的第一个想法还是位运算，在题解里找到一个位运算的解析，其实有一点点 bug，因为 python 的数值是可以无限大的，使用位来记录也有点作弊，但事实上由于计算机的限制，我们依然可以把这里看作 O(1) 空间</p><h4 id="581-最短无序连续子数组"><a href="#581-最短无序连续子数组" class="headerlink" title="581. 最短无序连续子数组"></a><a href="https://leetcode-cn.com/problems/shortest-unsorted-continuous-subarray/">581. 最短无序连续子数组</a></h4><p>很容易就想到方法，但是想要弄到 O(N) 需要另外的方法，我首先想到的依然是单调栈，一旦遇到降序的数字就需要维护单调栈，并记录 pop  掉的位置</p><h4 id="189-轮转数组"><a href="#189-轮转数组" class="headerlink" title="189. 轮转数组"></a><a href="https://leetcode-cn.com/problems/rotate-array/">189. 轮转数组</a></h4><p>主要是对空间复杂度的要求，可以使用两次翻转数组完成。以后应该养成快速解题的习惯，而不应该拘泥于这些细节，如果感觉这些 trick 没什么帮助，就应赶紧跳过</p><h4 id="41-缺失的第一个正数"><a href="#41-缺失的第一个正数" class="headerlink" title="41. 缺失的第一个正数"></a><a href="https://leetcode-cn.com/problems/first-missing-positive/">41. 缺失的第一个正数</a></h4><p>这一题又遇到了原地哈希的概念，在 442 中也是一样的。原地哈希算法主要应用在范围为 [0, len(nums)] 的数组解法中，将数组元素本身作为 <code>nums</code> 的下标，即 <code>nums[nums[i]]</code>，这将解决空间不足的问题。这一题虽然数字的范围很广，但稍加推测可以知道，答案的解必定在 1~n+1 之间，所以使用原地哈希也是比较自然的。常用的方法是对原始数组进行正负标定，来表征是否在集合中，于此同时在遍历数组的时候，需要使用 abs() 绝对值操作，来获取原始信息</p><p>我可以先把负数转换成一个很大的正数，这将不影响答案</p><h4 id="845-数组中的最长山脉"><a href="#845-数组中的最长山脉" class="headerlink" title="845. 数组中的最长山脉"></a><a href="https://leetcode-cn.com/problems/longest-mountain-in-array/">845. 数组中的最长山脉</a></h4><p>先尝试了动态规划，但是超时了，用了 N 方复杂度，然后考虑使用栈，花费了比较长的时间，因为思路需要更细致。看了题解：使用两次动态规划，计算数字左侧可扩展的数字和右侧可扩展的数字！又是一题使用多个动态规划结果来解决的，这种题做的比较少</p><h4 id="274-H-指数"><a href="#274-H-指数" class="headerlink" title="274. H 指数"></a><a href="https://leetcode-cn.com/problems/h-index/">274. H 指数</a></h4><p>很明显的就想到了二分查找的思想。但要实现 O(N) 复杂度就需要直接解题，这一题有一个特点，就是 H 指数一定不会超过 N，那么我们就可以使用一个 N + 1 数组进行存储，使用一个数组存储 store[i + 1] 代表值为 i 的次数，其中 store[N] 表示值 &gt;=N 的次数</p><h4 id="275-H-指数-II"><a href="#275-H-指数-II" class="headerlink" title="275. H 指数 II"></a><a href="https://leetcode-cn.com/problems/h-index-ii/">275. H 指数 II</a></h4><p>一个二分查找的题目，看第 k 个数字与其存储值 citations[k] 的大小</p><h4 id="220-存在重复元素-III"><a href="#220-存在重复元素-III" class="headerlink" title="220. 存在重复元素 III"></a><a href="https://leetcode-cn.com/problems/contains-duplicate-iii/">220. 存在重复元素 III</a></h4><p>这一题也不太常规，虽然我使用了暴力解法。第一种思路是使用红黑树维护有序数组，但是原生 Python 里没有这样的数据结构，需要使用 <a href="https://grantjenks.com/docs/sortedcontainers/">sortedcontainiers</a> 这个库…这个库其实用于维护有序数组非常有用，但考虑到笔试面试的时候可能用不上这个库，所以了解一下第二种思路：桶排序。最多使用 k 个桶，每个桶的编号为 m，这个编号代表了数值在 $m \times (t + 1) \sim (m + 1)\times (t + 1) - 1$ 之间的数，使用字典 <code>bucket</code> 创建桶，具体思路如下：</p><ol><li>从第一个元素开始遍历，假设当前元素为 <code>num[i]</code>，计算其所属桶的编号 <code>m = num[i] // (t + 1)</code></li><li>查询当前是否存在有桶的编号，如果存在则返回 true，如果不存在则查找相邻编号 <code>m + 1 or m - 1</code> 的桶是否存在，如果存在查看桶中元素是否符合 <code>abs(bucket[m + 1 or m - 1] - num[i]) &lt;= t</code>，如果存在也返回 true，如果依然不存在则建立新的桶。此时如果桶的个数超过了 k 个，则删除最早建立的桶 <code>bucker(num[i - k] // (t + 1))</code>。通过字典能够快速实现新建桶和删除桶</li></ol><h4 id="307-区域和检索-数组可修改"><a href="#307-区域和检索-数组可修改" class="headerlink" title="307. 区域和检索 - 数组可修改"></a><a href="https://leetcode-cn.com/problems/range-sum-query-mutable/">307. 区域和检索 - 数组可修改</a></h4><p>线段树…直接放弃，如果真的需要徒手实现这样的数据结构还是算了吧</p><h4 id="121-买卖股票的最佳时机"><a href="#121-买卖股票的最佳时机" class="headerlink" title="121. 买卖股票的最佳时机"></a><a href="https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock/">121. 买卖股票的最佳时机</a></h4><p>这一题是一个系列，一起干掉！这一题真正展示了动态规划的本质：一个问题使用动态规划的终极标准就是该问题能否由<strong>一些</strong>子问题（状态）方便解决，而这些子问题又能够通过<strong>递归</strong>方便解决，子问题可以是与原问题不同的问题。通过递归解决子问题（状态）可以有两种方式：1. 状态自身的简单递归；2. 不同状态之间的递归</p><p>这一题直接记录最多交易 k 次的情况。我起始思路其实是从思考 k -1 次的情况开始：如果知道到截止到第 j 天的 k - 1 次的情况，通过 n 次循环就能很快得出此问题的答案。然而事实是解决这两个子问题会变得比较复杂，也就是说我们要解决两个问题：</p><ol><li><code>dp_1[i][j]</code> 代表到第 i 天最多交易 j 次的情况</li><li><code>dp_2[i][j]</code> 代表第 i 天到第 j 天最多交易1次的情况</li></ol><p>这似乎不是一个好的状态定义，尤其是第二个子问题直接需要 n 方的时间复杂度。题解的思路为，如果知道每个时间点的所有买卖状态，就能够知道下一个时间点的所有买卖状态。每个时间点买卖状态有 2 * k + 1个：</p><ol><li>第 i 天，最多0次交易，并不持有股票的最大收益</li><li>第 i 天，最多0次交易，并持有1支股票的最大收益</li><li>第 i 天，最多1次交易，并不持有股票的最大收益</li><li>第 i 天，最多1次交易，并持有1支股票的最大收益</li><li>第 i 天，最多2次交易，并不持有股票的最大收益</li><li>…</li></ol><p>该题的难点在于找到合适的状态。由于需要知道前一天是否持有股票才能进行买入卖出，所以需要定义此时买入卖出的状态，这样在更新第 i + 1 天的时候，能够根据昨日的状态更新所有 2 * k + 1 个状态</p><h4 id="11-盛最多水的容器"><a href="#11-盛最多水的容器" class="headerlink" title="11. 盛最多水的容器"></a><a href="https://leetcode-cn.com/problems/container-with-most-water/">11. 盛最多水的容器</a></h4><p>太经典的贪心算法了，使用双指针不断地进行贪心搜索，返回搜索过程中的最大值</p><h4 id="42-接雨水"><a href="#42-接雨水" class="headerlink" title="42. 接雨水"></a><a href="https://leetcode-cn.com/problems/trapping-rain-water/">42. 接雨水</a></h4><p>这一题有多种解法：1. 动态规划；2. 单调栈（维护单调属性）；3. 双指针（动态规划的升级）</p><p>重点提一下双指针：因为我们是不断地移动较小指针，所以即使指针中间出现更大/更小的值，也不会对当前较小指针接的水有所影响</p><h4 id="128-最长连续序列"><a href="#128-最长连续序列" class="headerlink" title="128. 最长连续序列"></a><a href="https://leetcode-cn.com/problems/longest-consecutive-sequence/">128. 最长连续序列</a></h4><p>虽然需要时间复杂度为 O(N)，但我还是要先实现一个暴力解法，迅速解题，并且暴力解法的时间复杂度并不是很高。接着我就想到了连通的思想，使用一个集合，然后不断地寻找其连通的数字</p><h4 id="239-滑动窗口最大值"><a href="#239-滑动窗口最大值" class="headerlink" title="239. 滑动窗口最大值"></a><a href="https://leetcode-cn.com/problems/sliding-window-maximum/">239. 滑动窗口最大值</a></h4><p>这一题在剑指里面刷过，我再自己写一次，关键是在于维护一个有序数组。首先实现了堆的写法，思路还是比较清晰。但是维护单调性质的数据结构应该首先考虑单调栈，这一题更特殊一点，要维护一个定长的数组，所以需要从栈底删除元素，所以更加自然的就得出了单调队列的方法</p><h4 id="295-数据流的中位数"><a href="#295-数据流的中位数" class="headerlink" title="295. 数据流的中位数"></a><a href="https://leetcode-cn.com/problems/find-median-from-data-stream/">295. 数据流的中位数</a></h4><p>一开始题目就理解错了…需要的是有序列表的中位数！之前还在剑指 offer 做过这一题的！使用最大堆维护左边，最小堆维护右边</p><h4 id="209-长度最小的子数组"><a href="#209-长度最小的子数组" class="headerlink" title="209. 长度最小的子数组"></a><a href="https://leetcode-cn.com/problems/minimum-size-subarray-sum/">209. 长度最小的子数组</a></h4><p>思路非常的清晰，一个是使用双指针进行滑动窗口，另一个是进行二分查找。二分查找效率更差，不过也是一种暴力解，在调试不出来的时候可以进一步尝试</p><h4 id="238-除自身以外数组的乘积"><a href="#238-除自身以外数组的乘积" class="headerlink" title="238. 除自身以外数组的乘积"></a><a href="https://leetcode-cn.com/problems/product-of-array-except-self/">238. 除自身以外数组的乘积</a></h4><p>上下三角形存储所需要的乘积。如果需要使用常数存储空间，那么使用一个流转循环的方式即可</p><h4 id="152-乘积最大子数组"><a href="#152-乘积最大子数组" class="headerlink" title="152. 乘积最大子数组"></a><a href="https://leetcode-cn.com/problems/maximum-product-subarray/">152. 乘积最大子数组</a></h4><p>动态规划，使用两个状态：最大整数，最小负数分析即可</p><h4 id="713-乘积小于K的子数组"><a href="#713-乘积小于K的子数组" class="headerlink" title="713. 乘积小于K的子数组"></a><a href="https://leetcode-cn.com/problems/subarray-product-less-than-k/">713. 乘积小于K的子数组</a></h4><p>这里总结了一下双指针的套路：双指针常常与连续/顺序有关, 并且能够通过指针移动方便地更新区间的性质。通常，双指针可以使用两个循环甚至一个循环完成，<strong>先将某个指针移动</strong>，然后进行条件判断(并移动指针)，直到满足/不满足某个条件，进入下一次循环</p><p>大多数的循环都应该是如此：需要收尾相接，也就是循环结束的末尾需要和开头对应，初始情况需要特殊处理。换句话说循环的开头需要能够处理初始状况和满足条件的状况！</p><p>本题的双指针不太一样，右指针需要按照顺序移动, 左指针将灵活移动</p><h4 id="974-和可被-K-整除的子数组"><a href="#974-和可被-K-整除的子数组" class="headerlink" title="974. 和可被 K 整除的子数组"></a><a href="https://leetcode-cn.com/problems/subarray-sums-divisible-by-k/">974. 和可被 K 整除的子数组</a></h4><p>直接求前缀和，统计其余数相同的位置，只要余数相等那么他们的差必定是 k 的倍数，并且特殊处理前缀和为0的情况</p><h4 id="945-使数组唯一的最小增量"><a href="#945-使数组唯一的最小增量" class="headerlink" title="945. 使数组唯一的最小增量"></a><a href="https://leetcode-cn.com/problems/minimum-increment-to-make-array-unique/">945. 使数组唯一的最小增量</a></h4><p>我想用 empty 记录一个空缺位置。更好理解的是：直接先排序，然后遇到与前一个数字相等就将其变为前一个数字加一</p><h4 id="321-拼接最大数"><a href="#321-拼接最大数" class="headerlink" title="321. 拼接最大数"></a><a href="https://leetcode-cn.com/problems/create-maximum-number/">321. 拼接最大数</a></h4><p>这一题很明显是两道中等题目拼接而来，需要对中等题目有比较高的熟练程度！我很快就解出了一个子问题，但是第二个子问题将两个数字进行拼接这一步解决得不太顺畅。首先让我想到了 offer 45，但实际上二者并没有特别类似，虽然有朦朦胧胧的想法，但是并不精确，题解中直接比较两个字符串的字典序大小，非常好用</p><h4 id="402-移掉-K-位数字"><a href="#402-移掉-K-位数字" class="headerlink" title="402. 移掉 K 位数字"></a><a href="https://leetcode-cn.com/problems/remove-k-digits/">402. 移掉 K 位数字</a></h4><p>这是解决上一题的子问题。学习点：<strong>可以使用 strip/lstrip/rstrip 来对字符串前后进行裁切</strong></p><h4 id="403-青蛙过河"><a href="#403-青蛙过河" class="headerlink" title="403. 青蛙过河"></a><a href="https://leetcode-cn.com/problems/frog-jump/">403. 青蛙过河</a></h4><p>动态规划，这一题就是纯粹地从简单推广到复杂，记录到达当前石头的步长，尝试从当前石头向前出发，更新其他石头的状态和步长。再一次清晰了动态规划的核心：建立当前所得状态与未知状态之间的转移方程</p><h4 id="1029-两地调度"><a href="#1029-两地调度" class="headerlink" title="1029. 两地调度"></a><a href="https://leetcode-cn.com/problems/two-city-scheduling/">1029. 两地调度</a></h4><p>假设他们都去了同一个地方，看如果他们去另一个地方需要花费多少</p><h4 id="986-区间列表的交集"><a href="#986-区间列表的交集" class="headerlink" title="986. 区间列表的交集"></a><a href="https://leetcode-cn.com/problems/interval-list-intersections/">986. 区间列表的交集</a></h4><p>纯纯的递归写法，仅需要不断地判断第一个区间是否相交即可，然后 pop 出尾端较小的首部，继续递归</p><h4 id="939-最小面积矩形"><a href="#939-最小面积矩形" class="headerlink" title="939. 最小面积矩形"></a><a href="https://leetcode-cn.com/problems/minimum-area-rectangle/">939. 最小面积矩形</a></h4><p>使用哈希表进行查询，需要使用暴力解法</p><h4 id="957-N-天后的牢房"><a href="#957-N-天后的牢房" class="headerlink" title="957. N 天后的牢房"></a><a href="https://leetcode-cn.com/problems/prison-cells-after-n-days/">957. N 天后的牢房</a></h4><p>这一题比较有意思。因为牢房的数量是恒定的，所以状态是可以穷举的。我只需要知道到哪一个状态过后又回到初始状态，就可以进入循环求解了。这里还运用了字典是按照顺序创建的特性</p><h4 id="4-寻找两个正序数组的中位数"><a href="#4-寻找两个正序数组的中位数" class="headerlink" title="4. 寻找两个正序数组的中位数"></a><a href="https://leetcode-cn.com/problems/median-of-two-sorted-arrays/">4. 寻找两个正序数组的中位数</a></h4><p>这一题的二分查找挺奇诡哎的…不太好理解，并不是一般的每次排除掉一半的搜索范围，感觉是每次排除 1/4 的搜索范围，不过这样也能够达成指数级的下降。同时还需要处理边界条件 k = 1 or 0 的情况，<strong>代码我没有尝试写过，之后要写一下</strong></p><h4 id="56-合并区间"><a href="#56-合并区间" class="headerlink" title="56. 合并区间"></a><a href="https://leetcode-cn.com/problems/merge-intervals/">56. 合并区间</a></h4><p>和之前的重叠区间是类似的，把握好了重叠条件即可</p><h4 id="376-摆动序列"><a href="#376-摆动序列" class="headerlink" title="376. 摆动序列"></a><a href="https://leetcode-cn.com/problems/wiggle-subsequence/">376. 摆动序列</a></h4><h2 id="Hard"><a href="#Hard" class="headerlink" title="Hard"></a>Hard</h2><h4 id="25-K-个一组翻转链表"><a href="#25-K-个一组翻转链表" class="headerlink" title="25. K 个一组翻转链表"></a><a href="https://leetcode-cn.com/problems/reverse-nodes-in-k-group/">25. K 个一组翻转链表</a></h4><p>首先复习了一下反转链表，都是典型的递归处理，这一题是建立在反转链表之上的。不过此题在解决递归时的基础情况需要进行更进一步的判断：链表的长度是否小于 k。判断过后再进行接下来的反转</p><h4 id="85-最大矩形"><a href="#85-最大矩形" class="headerlink" title="85. 最大矩形"></a><a href="https://leetcode-cn.com/problems/maximal-rectangle/">85. 最大矩形</a></h4><p>这一题是 84 题的升级版本，需要 84 题的结果…关键点在于构建 array。这里是使用一个数组进行更新的形式</p><h4 id="84-柱状图中最大的矩形"><a href="#84-柱状图中最大的矩形" class="headerlink" title="84. 柱状图中最大的矩形"></a><a href="https://leetcode-cn.com/problems/largest-rectangle-in-histogram/">84. 柱状图中最大的矩形</a></h4><p>这一题使用单调栈，可以说是单调栈的本质：寻找左侧/右侧第一个小于/大于某个数的数字。这一题还需要使用”哨兵“变量，增强原数组，这样就能够统一处理，而不用特殊处理开头和结尾</p><h4 id="376-摆动序列-1"><a href="#376-摆动序列-1" class="headerlink" title="376. 摆动序列"></a><a href="https://leetcode-cn.com/problems/wiggle-subsequence/">376. 摆动序列</a></h4><p>先使用了动态规划，是 N 方复杂度。接着考虑将多次单调的数值去除，使用 O(N) 复杂度</p><h4 id="324-摆动排序-II"><a href="#324-摆动排序-II" class="headerlink" title="324. 摆动排序 II"></a><a href="https://leetcode-cn.com/problems/wiggle-sort-ii/">324. 摆动排序 II</a></h4><p>一个小一个大的进行排序，但是要倒着来排。这里要求时间复杂度 O(N) 可以使用桶排序，因为数值的范围比较小</p><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><h4 id="200-岛屿数量"><a href="#200-岛屿数量" class="headerlink" title="200. 岛屿数量"></a><a href="https://leetcode-cn.com/problems/number-of-islands/">200. 岛屿数量</a></h4><p>并查集常常可以使用深度搜索进行替代，今后遇到并查集，可以先创建一个连通的结构，然后使用深度搜索解决</p>]]></content>
      
      
      <categories>
          
          <category> 编程 </category>
          
          <category> Leetcode </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Leetcode </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SPG &amp; BtcDet</title>
      <link href="/archives/199de5de.html"/>
      <url>/archives/199de5de.html</url>
      
        <content type="html"><![CDATA[<h1 id="SPG-amp-BtcDet"><a href="#SPG-amp-BtcDet" class="headerlink" title="SPG &amp; BtcDet"></a>SPG &amp; BtcDet</h1><hr><p>Xu, Qiangeng, et al. “SPG: Unsupervised Domain Adaptation for 3D Object Detection via Semantic Point Generation.” <em>ArXiv:2108.06709 [Cs]</em>, Aug. 2021. <em>arXiv.org</em>, <a href="http://arxiv.org/abs/2108.06709">http://arxiv.org/abs/2108.06709</a>.</p><p>Xu, Qiangeng, et al. “Behind the Curtain: Learning Occluded Shapes for 3D Object Detection.” <em>ArXiv:2112.02205 [Cs]</em>, Dec. 2021. <em>arXiv.org</em>, <a href="http://arxiv.org/abs/2112.02205">http://arxiv.org/abs/2112.02205</a>.</p><hr><p>这两篇论文有着非常相似的思路，它们都是从点云的稀疏性出发，尝试在场景当中生成前景点，或者在特征图谱中融合前景点存在的概率</p><h2 id="SPG"><a href="#SPG" class="headerlink" title="SPG"></a>SPG</h2><h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><p>论文首先提出了问题：domain shifts，也就是说数据集之间，样本的分布是有差异的。有的点云样本密度较大，而有的点云采集可能由于天气的原因，密度较小。使用检测器在点云较少的场景中进行预测，表现将会大大降低</p><p>论文提出解决方法：Semantic Point Generation (SPG)，使用轻量级神经网络在相关场景 (generation area) 中生成前景点，以补偿点云消失的部分</p><h3 id="Domian-gap"><a href="#Domian-gap" class="headerlink" title="Domian gap"></a>Domian gap</h3><p>在我理解 domain gap 就是在于数据集分布的差异。在看论文的时候看到了 feature misalign 问题，这里也总结一下：</p><ol><li>多尺度问题。一个特征点对应了多个尺度，该问题可以使用 FPN 解决，有一种分治的思想在里面，小目标使用高分辨率特征，大目标使用低分辨率特征</li><li>anchor &amp; 分类得分不匹配。可以通过 RCNN 的细化解决</li><li>遮挡。无法解决这样的问题</li></ol><p>除了使用特征对齐的方法，还有的论文将数据从一个域转到另一个域，本文也应该受到该方法的启发</p><p>另外还提到了使用对抗生成网络来解决的方法，不过没有深入</p><h3 id="Semantic-Point-Generation"><a href="#Semantic-Point-Generation" class="headerlink" title="Semantic Point Generation"></a>Semantic Point Generation</h3><p>定义原始点云输入</p><script type="math/tex; mode=display">PC_{raw}={p_1,..,p_n} \in \mathbb R^{3+F}</script><p>F，代表其他的原始特征，例如反射强度。将点云场景进行体素化，对于每一个体素，都将生成一个置信度 $\tilde P^f$ 以及一个特征 $\tilde \phi$ ，前者表示该体素有前景点的概率，后者表示该点的特征 $(x, y, z, f)$</p><p>虽然对每一个体素都进行了预测，但并不是所有的体素都参与生成点云。需要满足两个条件：</p><ol><li>在生成区域内的体素 generation area。生成区域定义为原始非空体素附近的区域</li><li>置信度大于阈值的体素</li></ol><h4 id="SPG-trainning-targets"><a href="#SPG-trainning-targets" class="headerlink" title="SPG trainning targets"></a>SPG trainning targets</h4><p>前面对于 SPG 的目的已经介绍了一部分。标签这部分比较简单，就是使用了原始点云中的非空体素以及在选框内的体素作为前景体素标签，进行训练</p><h4 id="Model-structure"><a href="#Model-structure" class="headerlink" title="Model structure"></a>Model structure</h4><p>模型是基于 PointPillars，不过在最后将 Pillars 还原成为了体素，进行了两部分的预测</p><p><img src="/archives/199de5de/image-20220316211604579.png" alt="image-20220316211604579" style="zoom: 50%;"></p><h4 id="Hide-and-predict"><a href="#Hide-and-predict" class="headerlink" title="Hide and predict"></a>Hide and predict</h4><p>这是论文中的一个训练策略：将一部分的体素移除，但是其标签仍然保持。这样天然形成了一些空体素，希望网络去学习生成点</p><p>个人认为，这里仍有改进空间：这并没有明确让网络去学习稀疏 -&gt; 密集这样的一个过程。仅仅是简单的下采样，不能够模拟出点云中的稀疏场景，更难以表达稀疏特征和密集特征之间的关系。当然这样的操作肯定是对网络有益的，增加了 robustness</p><h4 id="Loss-functions"><a href="#Loss-functions" class="headerlink" title="Loss functions"></a>Loss functions</h4><p>对于分类的损失函数，需要特殊处理的有两部分：1. $V_e^f$ empty foreground voxel; 2. hidden voxel 给它们加上了不同的权重即可。其他的 observed voxel &amp; empty background voxel 照常处理</p><script type="math/tex; mode=display">\begin{aligned}L_{c l s} &=\frac{1}{\left|V_{o} \cup V_{e}^{b}\right|} \sum_{V_{o} \cup V_{e}^{b}} L_{\text {focal }} \\&+\frac{\alpha}{\left|V_{e}^{f}\right|} \sum_{V_{e}^{f}} L_{\text {focal }}+\frac{\beta}{\left|V_{\text {hide }}\right|} \sum_{V_{\text {hide }}} L_{\text {focal }}\end{aligned}</script><p>对于回归的损失函数，仅对 observed voxel &amp; hidden voxel 做回归损失</p><script type="math/tex; mode=display">\begin{aligned}L_{r e g} &=\frac{1}{\left|V_{o}^{f}\right|} \sum_{V_{o}^{f}} L_{\text {smooth-L1 }}(\tilde{\psi}, \psi) \\&+\frac{\beta}{\left|V_{h i d e}^{f}\right|} \sum_{V_{\text {hide }}^{f}} L_{\text {smooth }-L 1}(\tilde{\psi}, \psi)\end{aligned}</script><p>其中 $\alpha = 0.5, \beta =2.0$，并且<strong>所有的体素都必须是 generation area 之内的体素</strong></p><h3 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h3><p>训练是在 Waymo Open Dataset 上训练的，并在 Waymo Open Dataset &amp; KirK 上都进行了测试</p><p><img src="/archives/199de5de/image-20220316214602575.png" alt="image-20220316214602575" style="zoom: 50%;"></p><p>在 KITTI 测试集上也进行了实验</p><p><img src="/archives/199de5de/image-20220316214637192.png" alt="image-20220316214637192" style="zoom:50%;"></p><p>KITTI 验证集</p><p><img src="/archives/199de5de/image-20220316214808815.png" alt="image-20220316214808815" style="zoom:50%;"></p><p>SPG 与各种策略的比较</p><p><img src="/archives/199de5de/image-20220316214710727.png" alt="image-20220316214710727" style="zoom:50%;"></p><p>其中 k-frames 是将 k 帧点云进行叠加，也是一个稳定涨点技巧但是需要大量的内存和处理时间。SPG 很轻量，只加入了 8k 个点，并且参数少速度快</p><h2 id="BtcDet"><a href="#BtcDet" class="headerlink" title="BtcDet"></a>BtcDet</h2><p>这篇论文相对于 SPG 感觉更晦涩更细致，但是出发点依然是对于消失点云的补偿。本文更进一步对消失点云以及<strong>消失形状</strong>进行学习</p><h3 id="Causes-of-shape-miss"><a href="#Causes-of-shape-miss" class="headerlink" title="Causes of shape miss"></a>Causes of shape miss</h3><ol><li>Signal miss，信号消失。这里我理解为激光穿过了玻璃类似的物质，或者反射角太大，或者被物质吸收，没办法进行返回</li><li>Occlusion，遮挡。后方物体被前方物体遮挡</li><li>信号发散。这是点云自身特点造成，越远处的地方，点云将越稀疏</li></ol><p>论文指出，在点云密集的地方，现在的 SOTA 检测器能够非常非常精准地识别出来，这也是对点云补偿的出发点</p><h3 id="Learning-shapes-for-3D-object-detection"><a href="#Learning-shapes-for-3D-object-detection" class="headerlink" title="Learning shapes for 3D object detection"></a>Learning shapes for 3D object detection</h3><p>在之前的论文如 SA-SSD &amp; PV-RCNN 已经证明学习结构信息（前景点分割，中心点预测）对于目标检测是有提升的。但是它们忽略了消失形状的影响</p><h3 id="Learning-shapes-in-occlusion"><a href="#Learning-shapes-in-occlusion" class="headerlink" title="Learning shapes in occlusion"></a>Learning shapes in occlusion</h3><h4 id="Approximate-the-complete-shapes"><a href="#Approximate-the-complete-shapes" class="headerlink" title="Approximate the complete shapes"></a>Approximate the complete shapes</h4><p>首先我们得知道完整的形状是什么样的，这样才能更好地学习。论文采取的策略有两个</p><ol><li><p>镜像。因为大多数目标都是镜像对称的，对称将补充部分点云</p></li><li><p>向其他同类 object “借”。论文构造了一个函数 $H(A,B)$ 来评估B 物体是否尽可能补全 A 物体</p><script type="math/tex; mode=display">\begin{aligned}\mathcal{H}(A, B) &=\sum_{x \in P_{A}} \min _{y \in P_{B}}\|x-y\|-\alpha \operatorname{IoU}\left(\mathcal{D}_{A}, \mathcal{D}_{B}\right) \\&+\beta /\left|\left\{x: x \in \operatorname{Vox}\left(P_{B}\right), x \notin \operatorname{Vox}\left(P_{A}\right)\right\}\right|\end{aligned}</script><p>第一项希望 B 的点尽量覆盖 A 的点</p><p>第二项希望二者的 IoU 尽量大</p><p>第三项希望 B 中的 voxel 尽量多的不属于 A</p><p>启发式函数越低越好，代表 B 更能覆盖和填补 A。对 A 物体，选择得分最高的3个物体，并将它们的点云借给 A 作为补充</p></li></ol><h4 id="Identify-R-oc-cup-R-sm-in-spherical-coordinate"><a href="#Identify-R-oc-cup-R-sm-in-spherical-coordinate" class="headerlink" title="Identify $R_{oc} \cup R_{sm}$ in spherical coordinate"></a>Identify $R_{oc} \cup R_{sm}$ in spherical coordinate</h4><p>这个极坐标系也是本文有点难以理解的。对于 occlusion 区域，是指某个非空弧形体素及其之后的弧形体素区域。对于 signal missing 区域需要使用 range view 来理解。理论上来讲 Lidar 的 range view 应该是铺满整个平面的，但由于 signal missing，range view 会缺失。如果 spherical voxel 映射到缺失区域中，就认定该 spherical voxel 属于 signal missing 区域</p><p><img src="/archives/199de5de/image-20220317000714947.png" alt="image-20220317000714947" style="zoom:50%;"></p><h4 id="Training-targets"><a href="#Training-targets" class="headerlink" title="Training targets"></a>Training targets</h4><p>此时 targets 就不是简单的使用原始点云场景了。而是使用经过目标补全的点云场景</p><h4 id="Estimate-the-shape-occupancy"><a href="#Estimate-the-shape-occupancy" class="headerlink" title="Estimate the shape occupancy"></a>Estimate the shape occupancy</h4><p>BtcDet 将预测在遮挡和消失区域的 spherical voxel 含有点云的概率。它不作任何的点云生成，这也是与 SPG 的一个区别。SPG 关注的是在空体素处是否含有前景点（在 bbox 中即可），而本文关注的是在遮挡和信号消失的区域是否含有目标点（更精细）</p><p>损失函数如下，仅关注遮挡和信号消失的区域</p><script type="math/tex; mode=display">\mathcal{L}_{\text {shape }}=\frac{\sum_{v \in \mathcal{R}_{\mathcal{O C}} \cup \mathcal{R}_{\mathcal{S M}}} w_{v} \cdot \mathcal{L}_{\text {focal }}\left(p_{v}\right)}{\left|\mathcal{R}_{\mathcal{O C}} \cup \mathcal{R}_{\mathcal{S M}}\right|} \text {, }\\where\  w_{v}=\left\{\begin{array}{ll}\delta & \text { if } v \in \text { regions of shape miss } \\ 1 & \text { otherwise. }\end{array}\right.</script><p> 对于借来的点以及空的 voxel 都使用权重 δ</p><p>还值得提到是，论文使用的是极坐标系下的 3d 稀疏卷积来提取每一个体素的特征</p><h3 id="Shape-Occupancy-Probability-Integration"><a href="#Shape-Occupancy-Probability-Integration" class="headerlink" title="Shape Occupancy Probability Integration"></a>Shape Occupancy Probability Integration</h3><p>得到了一个 spherical coordinate feature map $P(Occupancy)$，表示了各个弧形体素中是否包含目标点</p><p>先把极坐标系转换到笛卡尔坐标系，这样方便和其他特征图谱进行融合，通过下采样可以得到和其他特征图谱相同分辨率</p><p><img src="/archives/199de5de/image-20220317003143105.png" alt="image-20220317003143105" style="zoom:50%;"></p><h3 id="Experiments-1"><a href="#Experiments-1" class="headerlink" title="Experiments"></a>Experiments</h3><p>在 KITTI 数据集上横扫</p><p><img src="/archives/199de5de/image-20220317003314223.png" alt="image-20220317003314223" style="zoom:50%;"></p><p>在 waymo 数据集上横扫</p><p><img src="/archives/199de5de/image-20220317003337540.png" alt="image-20220317003337540" style="zoom:50%;"></p>]]></content>
      
      
      <categories>
          
          <category> papers </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SPG </tag>
            
            <tag> BtcDet </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pathlib</title>
      <link href="/archives/d99f910b.html"/>
      <url>/archives/d99f910b.html</url>
      
        <content type="html"><![CDATA[<h1 id="Pathlib"><a href="#Pathlib" class="headerlink" title="Pathlib"></a>Pathlib</h1><h2 id="取路径"><a href="#取路径" class="headerlink" title="取路径"></a>取路径</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> pathlib <span class="token keyword">import</span> Path<span class="token comment"># 当前工作目录</span>Path<span class="token punctuation">.</span>cwd<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># 当前文件路径</span>Path<span class="token punctuation">(</span>__file__<span class="token punctuation">)</span><span class="token comment"># 任意字符串路径</span>Path<span class="token punctuation">(</span><span class="token string">'abc/file.py'</span><span class="token punctuation">)</span><span class="token comment"># 获取绝对路径</span>Path<span class="token punctuation">(</span><span class="token string">'abc/file.py'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>resolve<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="获取路径组成部分"><a href="#获取路径组成部分" class="headerlink" title="获取路径组成部分"></a>获取路径组成部分</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token builtin">file</span> <span class="token operator">=</span> Path<span class="token punctuation">(</span><span class="token string">'abc/file.py'</span><span class="token punctuation">)</span><span class="token comment"># 文件名</span><span class="token builtin">file</span><span class="token punctuation">.</span>name<span class="token comment"># 文件名，不含后缀</span><span class="token builtin">file</span><span class="token punctuation">.</span>stem<span class="token comment"># 后缀</span><span class="token builtin">file</span><span class="token punctuation">.</span>suffix<span class="token comment"># 父级目录</span><span class="token builtin">file</span><span class="token punctuation">.</span>parent<span class="token comment"># 获得所有父级目录</span><span class="token builtin">file</span><span class="token punctuation">.</span>parents<span class="token builtin">file</span><span class="token punctuation">.</span>parents<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token comment"># 上级 abc</span><span class="token builtin">file</span><span class="token punctuation">.</span>parents<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token comment"># 上上级 .</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>对 <code>file</code> 获得父级目录时，仅对所输入的字符串进行操作 <code>abc/file.py</code>，如果想要获得绝对路径下的父级目录，请先使用 <code>.resolve()</code> 获得绝对目录</p><h2 id="子路径扫描"><a href="#子路径扫描" class="headerlink" title="子路径扫描"></a>子路径扫描</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python">path <span class="token operator">=</span> Path<span class="token punctuation">(</span><span class="token string">'.'</span><span class="token punctuation">)</span><span class="token comment"># 遍历目录下的所有文件/子目录, 但不会递归遍历子目录</span>files <span class="token operator">=</span> <span class="token punctuation">[</span>f <span class="token keyword">for</span> f <span class="token keyword">in</span> path<span class="token punctuation">.</span>iterdir<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token comment"># 查找目录下的指定文件, 通常查找某后缀名文件</span>files <span class="token operator">=</span> <span class="token punctuation">[</span>f <span class="token keyword">for</span> f <span class="token keyword">in</span> path<span class="token punctuation">.</span>glob<span class="token punctuation">(</span><span class="token string">'*.txt'</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token comment"># 子目录递归查询</span>files <span class="token operator">=</span> <span class="token punctuation">[</span>f <span class="token keyword">for</span> f <span class="token keyword">in</span> path<span class="token punctuation">.</span>rglob<span class="token punctuation">(</span><span class="token string">'*.txt'</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="路径拼接"><a href="#路径拼接" class="headerlink" title="路径拼接"></a>路径拼接</h2><p>重载除法算符，非常好用👍</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">path <span class="token operator">=</span> Path<span class="token punctuation">(</span><span class="token string">'.'</span><span class="token punctuation">)</span>new_file <span class="token operator">=</span> <span class="token builtin">file</span> <span class="token operator">/</span> <span class="token string">'dir'</span> <span class="token operator">/</span> <span class="token string">'file.txt'</span><span class="token keyword">print</span><span class="token punctuation">(</span>new_file<span class="token punctuation">)</span><span class="token comment"># ./dir/file.txt</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h2 id="路径判断"><a href="#路径判断" class="headerlink" title="路径判断"></a>路径判断</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token builtin">file</span> <span class="token operator">=</span> Path<span class="token punctuation">(</span>any_str<span class="token punctuation">)</span><span class="token comment"># 是否为文件</span><span class="token builtin">file</span><span class="token punctuation">.</span>is_file<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># 是否为目录</span><span class="token builtin">file</span><span class="token punctuation">.</span>is_dir<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># 是否存在</span><span class="token builtin">file</span><span class="token punctuation">.</span>exists<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="文件操作"><a href="#文件操作" class="headerlink" title="文件操作"></a>文件操作</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token builtin">file</span> <span class="token operator">=</span> Path<span class="token punctuation">(</span><span class="token string">'hello.txt'</span><span class="token punctuation">)</span><span class="token comment"># 创建文件 touch</span><span class="token builtin">file</span><span class="token punctuation">.</span>touch<span class="token punctuation">(</span>exist_ok<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment"># exist_ok = False 文件不存在时才能创建, 如果文件存在则报错</span><span class="token builtin">file</span><span class="token punctuation">.</span>touch<span class="token punctuation">(</span>exist_ok<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token comment"># 读取与写入文本</span><span class="token comment"># pathlib 对读取和写入进行了简单封装, 不用 open 操作</span><span class="token builtin">file</span><span class="token punctuation">.</span>read_text<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token builtin">file</span><span class="token punctuation">.</span>write_text<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># 打开文件</span><span class="token keyword">with</span> <span class="token builtin">file</span><span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>    <span class="token keyword">pass</span><span class="token comment"># 重命名文件</span><span class="token builtin">file</span><span class="token punctuation">.</span>rename<span class="token punctuation">(</span>new_name<span class="token punctuation">)</span><span class="token comment"># 创建目录</span>path <span class="token operator">=</span> Path<span class="token punctuation">(</span><span class="token string">'dir/'</span><span class="token punctuation">)</span><span class="token comment"># parents = True 可以创建多级目录</span>path<span class="token punctuation">.</span>mkdir<span class="token punctuation">(</span>parents<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> exist_ok<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment"># 删除目录</span><span class="token comment"># 一次只能删除一级目录, 且目录必须为空</span>path<span class="token punctuation">.</span>rmdir<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 编程 </category>
          
          <category> Python </category>
          
          <category> Package </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Pathlib </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SVM</title>
      <link href="/archives/75378e04.html"/>
      <url>/archives/75378e04.html</url>
      
        <content type="html"><![CDATA[<h2 id="SVM"><a href="#SVM" class="headerlink" title="SVM"></a>SVM</h2><p>支撑向量机（SVM）算法在分类问题中有着重要地位，其主要思想是最大化两类之间的间隔</p><p>数据集可分为以下三类：</p><ol><li>线性可分</li><li>线性不可分，但在去掉少量噪声点后线性可分</li><li>线性不可分，完全不可分！</li></ol><p>针对以上三种数据集，发展出来三种 SVM：</p><ol><li>Hard-margin SVM</li><li>Soft-margin SVM</li><li>Kernel method</li></ol><p>SVM 的求解中，大量用到了 Lagrange 乘子法，首先对这种方法进行介绍</p><h2 id="优化问题"><a href="#优化问题" class="headerlink" title="优化问题"></a>优化问题</h2><h3 id="约束优化与无约束优化"><a href="#约束优化与无约束优化" class="headerlink" title="约束优化与无约束优化"></a>约束优化与无约束优化</h3><p>一般地，约束优化问题（原问题）可以写成</p><script type="math/tex; mode=display">\begin{align}&\min_{x\in\mathbb{R^p}}f(x)\\&s.t.\ m_i(x)\le0,i=1,2,\cdots,M\\&\ \ \ \ \ \ \ \ n_j(x)=0,j=1,2,\cdots,N\end{align}</script><p>定义 Lagrange 函数：</p><script type="math/tex; mode=display">L(x,\lambda,\eta)=f(x)+\sum\limits_{i=1}^M\lambda_im_i(x)+\sum\limits_{i=1}^N\eta_in_i(x)</script><p>那么原问题可以等价于无约束形式：</p><script type="math/tex; mode=display">\min_{x\in\mathbb{R}^p}\max_{\lambda,\eta}L(x,\lambda,\eta)\ s.t.\ \lambda_i\ge0</script><p>这二者等价的证明，可以去看一下原视频，讲得非常清楚。如果可以将函数图像画出来，可以发现，当约束条件不满足的时候，下面这个函数将可以趋近于无穷大👇</p><script type="math/tex; mode=display">f'(x) = \max_{\lambda,\eta}L(x,\lambda,\eta)\ s.t.\ \lambda_i\ge0</script><p>再对上面这个函数取最小值时，显然我们不会取到不满足约束条件的 $x$，这就天然过滤了不符合约束条件的 $x$。那么此时可以认为</p><script type="math/tex; mode=display">f'(x) = \max_{\lambda,\eta}L(x,\lambda,\eta)=f(x)\\s.t.\lambda_i\ge0,m(x_i) \le 0</script><p>因为一个数减去一个非负函数肯定小于等于其本身，但是等号是可以取得的，所以其最大值必定等于其本身。再对以上求最小值就得到了原问题了，可以认为以上的推导是双箭头，所以原问题和无约束问题等价</p><h3 id="原问题与对偶问题"><a href="#原问题与对偶问题" class="headerlink" title="原问题与对偶问题"></a>原问题与对偶问题</h3><p>原问题</p><script type="math/tex; mode=display">\min_{x\in\mathbb{R}^p}\max_{\lambda,\eta}L(x,\lambda,\eta)\ s.t.\ \lambda_i\ge0</script><p>对偶问题</p><script type="math/tex; mode=display">\max_{\lambda,\eta}\min_{x\in\mathbb{R}^p}L(x,\lambda,\eta)\ s.t.\ \lambda_i\ge0</script><p>可以看到把 max &amp; min 的位置交换了一下，是不是非常简单！</p><p>可以证明对偶问题的解 ≤ 原问题的解，原视频用了鸡头凤尾形象的比喻，数学语言也很简单</p><blockquote><p>显然有 $\min\limits_{x}L\le L\le\max\limits_{\lambda,\eta}L$，于是显然有 $\max\limits_{\lambda,\eta}\min\limits_{x}L\le L$，且 $\min\limits_{x}\max\limits_{\lambda,\eta}L\ge L$。</p></blockquote><h3 id="强弱对偶性"><a href="#强弱对偶性" class="headerlink" title="强弱对偶性"></a>强弱对偶性</h3><p>定义强弱对偶性如下：</p><ol><li>弱对偶性：对偶问题的解 ≤ 原问题的解</li><li>强对偶性：对偶问题的解 = 原问题的解</li></ol><p>弱对偶性也可以通过一种几何方法表示</p><p><img src="/archives/75378e04/image-20220311215838515.png" alt="image-20220311215838515">对于一个凸优化问题，如果满足 Slater 条件，则强对偶性满足</p><blockquote><p>  Slater 条件为：</p><script type="math/tex; mode=display">  \exist\hat{x}\in Relint\mathcal{D}\ s.t.\ \forall i=1,2,\cdots,M,m_i(x)\lt0</script><p>  其中 Relint 表示相对内部（不包含边界的内部）</p></blockquote><p>对于大多数凸优化问题，Slater 条件都是成立的，但是 Slater 条件也只是一个充分条件。常用的另一个充分条件是 Linearity constraint qualification，即约束等式和不等式都是线性的</p><h3 id="KKT-条件"><a href="#KKT-条件" class="headerlink" title="KKT 条件"></a>KKT 条件</h3><p>在凸优化情况下，强对偶性满足和 KKT 条件成立是等价关系。我们通常使用 KKT 条件进行原问题的数值求解。<a href="https://www.zhihu.com/question/49754458">KKT条件在使用的时候有什么要求吗？是否要求强对偶</a></p><blockquote><p>KKT 条件可分为三个部分</p><ol><li><p>可行域：</p><script type="math/tex; mode=display">\begin{align}m_i(x^*)\le0\\n_j(x^*)=0\\\lambda^*\ge0\end{align}</script></li><li><p>互补松弛 $\lambda^<em>m_i(x^</em>)=0,\forall m_i$，对偶问题的最佳值为 $d^<em>$，原问题为 $p^</em>$</p></li><li><p>梯度为0：$\frac{\partial L(x,\lambda^<em>,\eta^</em>)}{\partial x}|_{x=x^*}=0$</p></li></ol><p>粗糙证明如下：</p><script type="math/tex; mode=display">\begin{align}d^*&=\max_{\lambda,\eta}g(\lambda,\eta)=g(\lambda^*,\eta^*)\nonumber\\&=\min_{x}L(x,\lambda^*,\eta^*)\nonumber\\&\le L(x^*,\lambda^*,\eta^*)\nonumber\\&=f(x^*)+\sum\limits_{i=1}^M\lambda^*m_i(x^*)\nonumber\\&\le f(x^*)=p^*\end{align}</script><p>由强对偶性得，两个不等式必须成立，于是，对于第一个不等于号，可得在 $x^*$ 处有梯度为0成立，对于第二个不等于号需要满足互补松弛条件</p></blockquote><h2 id="Hard-margin-SVM"><a href="#Hard-margin-SVM" class="headerlink" title="Hard-margin SVM"></a>Hard-margin SVM</h2><p>现在正式提出 SVM 模型并计算出最优解！在 SVM 中，我们引入<strong>最大化间隔</strong>这个概念，<strong>间隔指的是数据和直线的距离的最小值</strong></p><p>那么最大化间隔的表达如下</p><script type="math/tex; mode=display">\mathop{argmax}_{w,b}[\min_i\frac{|w^Tx_i+b|}{||w||}]\ s.t.\ y_i(w^Tx_i+b)>0\\\Longrightarrow\mathop{argmax}_{w,b}[\min_i\frac{y_i(w^Tx_i+b)}{||w||}]\ s.t.\ y_i(w^Tx_i+b)>0</script><p>对于约束  $y_i(w^Tx_i+b)&gt;0$，不妨固定其最小值为1，即</p><script type="math/tex; mode=display">\min y_i(w^Tx_i+b)=1>0</script><p>原因在于给超平面 $w^Tx + b = 0$ 乘以一个常数进行缩放是不会改变超平面的。函数的角度来讲，$g(w,b) = \min_i\frac{y_i(w^Tx_i+b)}{||w||}$ 这个函数在超平面缩放过后是没有改变的，所以固定上式的最小值为1并不改变原始问题的最优解。于是约束问题转化为</p><script type="math/tex; mode=display">\mathop{argmin}_{w,b}\frac{1}{2}w^Tw\ s.t.\ \min_iy_i(w^Tx_i+b)=1\\\Rightarrow\mathop{argmin}_{w,b}\frac{1}{2}w^Tw\ s.t.\ y_i(w^Tx_i+b)\ge1,i=1,2,\cdots,N</script><p>这就是一个包含 $N$ 个约束的凸优化问题，有很多求解这种问题的软件。现在我们通过引入 Lagrange 函数并使用 KKT 条件进行求解，原问题等价于</p><script type="math/tex; mode=display">L(w,b,\lambda)=\frac{1}{2}w^Tw+\sum\limits_{i=1}^N\lambda_i(1-y_i(w^Tx_i+b))\\\mathop{argmin}_{w,b}\max_{\lambda}L(w,b,\lambda_i)\ s.t.\ \lambda_i\ge0</script><p>该问题满足强对偶性，所以可以直接求对偶问题的最优解。因为强对偶性和 KKT 条件等价，所以最优解也必定满足 KKT 条件</p><blockquote><script type="math/tex; mode=display">\begin{align}&\frac{\partial L}{\partial w}=0,\frac{\partial L}{\partial b}=0\\&\lambda_k(1-y_k(w^Tx_k+b))=0\\&\lambda_i\ge0\\&1-y_i(w^Tx_i+b)\le0\end{align}</script></blockquote><p>根据以上条件获得最佳参数的表达式</p><script type="math/tex; mode=display">\hat{w}=\sum\limits_{i=1}^N\lambda_iy_ix_i\\\hat{b}=y_k-w^Tx_k=y_k-\sum\limits_{i=1}^N\lambda_iy_ix_i^Tx_k\\\exist k,1-y_k(w^Tx_k+b)=0</script><p>比较难以理解的是参数 $\hat b$ 的表达式。首先要理解为什么必定存在支撑向量 $x_k$（也就是离超平面最近的向量）。这是因为必定存在一个超平面将向量分离，否则原问题就不是线性可分了。所以给定参数 $w$ 必然能够找到其支撑向量，并计算 $b$</p><p>将 KKT 条件得到的表达式代入到对偶问题中有</p><script type="math/tex; mode=display">\max_{\lambda}-\frac{1}{2}\sum\limits_{i=1}^N\sum\limits_{j=1}^N\lambda_i\lambda_jy_iy_jx_i^Tx_j+\sum\limits_{i=1}^N\lambda_i,\ s.t.\ \lambda_i\ge0</script><p>接下来怎么解这个问题，还需要进一步对凸优化进行学习…暂时放在这里，我就是挖坑的神😎</p><p>最后再拔高一下对 SVM 超平面的理解：该超平面就是支撑向量的线性组合</p><h2 id="Soft-margin-SVM"><a href="#Soft-margin-SVM" class="headerlink" title="Soft-margin SVM"></a>Soft-margin SVM</h2><p>当有少量数据不可分的时候应该怎么做呢？我们的基本想法是在损失函数中加入错误分类的惩罚项。线性不可分意味着某些点，不能满足函数间隔大于等于1的约束条件，所以对每个样本点引入一个松弛变量 $\xi_i$，此时将约束变为 $y_i(w^Tx+b)\ge1-\xi_i$。对于每一个松弛变量，将支付一个代价 $\xi_i$，所以原问题变为</p><script type="math/tex; mode=display">\mathop{argmin}_{w,b}\frac{1}{2}w^Tw+C\sum\limits_{i=1}^N\xi_i\\s.t.\ y_i(w^Tx_i+b)\ge1-\xi_i\\\xi_i\ge0,i=1,2,\cdots,N</script><p>原问题依然是一个凸二次规划问题，可以按照之前的方法再进行分析，但 $b$ 可能没有唯一解</p><p>松弛变量可表达为：$\xi_i = 1-y_i(w^Tx_i+b)$，也可以使用 hinge loss function 来表示损失 $loss = max(0, \xi_i)$</p><h2 id="Kernel-Method"><a href="#Kernel-Method" class="headerlink" title="Kernel Method"></a>Kernel Method</h2><p>核方法可以应用在很多问题上，在分类问题中，对于严格不可分问题，我们引入一个特征转换函数将原来的不可分的数据集变为可分的数据集，然后再来应用已有的模型。往往将低维空间的数据集变为高维空间的数据集后，数据会变得可分（数据变得更为稀疏）：</p><blockquote><p>  Cover TH：高维空间比低维空间更易线性可分。</p></blockquote><p>TODO</p><h2 id="TODO-补充：凸优化基础"><a href="#TODO-补充：凸优化基础" class="headerlink" title="TODO 补充：凸优化基础"></a>TODO 补充：凸优化基础</h2><p>建议查看原来做的笔记《最优化原理》约束优化部分</p><ol><li>KKT 条件为什么要加入原始定义域</li><li>KKT 条件是充分条件还是必要条件，还是充要条件</li><li>KKT 条件在解题中充当了什么样的角色？因为使用 KKT 条件并不能完全将最优解得出</li></ol>]]></content>
      
      
      <categories>
          
          <category> 课程 </category>
          
          <category> 白板机器学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SVM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenPCDet loss utils</title>
      <link href="/archives/d4954eb6.html"/>
      <url>/archives/d4954eb6.html</url>
      
        <content type="html"><![CDATA[<h1 id="OpenPCDet-loss-utils"><a href="#OpenPCDet-loss-utils" class="headerlink" title="OpenPCDet loss utils"></a>OpenPCDet loss utils</h1><h2 id="SigmoidFocalClassificationLoss"><a href="#SigmoidFocalClassificationLoss" class="headerlink" title="SigmoidFocalClassificationLoss"></a>SigmoidFocalClassificationLoss</h2><p>这个类实现了 focal loss，关于 focal loss 可以看这篇 <a href="https://zhuanlan.zhihu.com/p/122542747">知乎</a>，白话来说：focal loss 对于 p 趋近于 0 或 1 的预测是与 cross entropy 一样的，但对于 p 处于中间值的时候对于损失函数有着减小的作用，就是这样的减缓作用对于负样本远多于正样本的数据集很有帮助</p><p>先来看 forward 函数的输入输出</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">,</span> target<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">,</span> weights<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""    Args:        input: (B, #anchors, #classes) float tensor.            Predicted logits for each class        target: (B, #anchors, #classes) float tensor.            One-hot encoded classification targets        weights: (B, #anchors) float tensor.            Anchor-wise weights.    Returns:        weighted_loss: (B, #anchors, #classes) float tensor after weighting.    """</span> <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="输入输出"><a href="#输入输出" class="headerlink" title="输入输出"></a>输入输出</h3><p>输入为：</p><ol><li><p>input 是 logits，也就是没有经过 sigmoid 的线性层输出</p></li><li><p>target 是 one-hot 向量</p></li><li><p>weights 是每个 anchor 的权重，通常是一个用于归一化的量，如 1 / num_foreground_anchor</p></li></ol><p>输出为：</p><ol><li>weighted_loss，经过 focal weights 和输入中 weights 加权过后得到的 binary cross entropy loss</li></ol><h3 id="关键函数实现"><a href="#关键函数实现" class="headerlink" title="关键函数实现"></a>关键函数实现</h3><p>首先需要计算每个 anchor 的每个类别预测的 loss，这是由 <code>sigmoid_cross_entropy_with_logits</code> 实现</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">sigmoid_cross_entropy_with_logits</span><span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">,</span> target<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">""" PyTorch Implementation for tf.nn.sigmoid_cross_entropy_with_logits:        max(x, 0) - x * z + log(1 + exp(-abs(x))) in        https://www.tensorflow.org/api_docs/python/tf/nn/sigmoid_cross_entropy_with_logits    Args:        input: (B, #anchors, #classes) float tensor.            Predicted logits for each class        target: (B, #anchors, #classes) float tensor.            One-hot encoded classification targets    Returns:        loss: (B, #anchors, #classes) float tensor.            Sigmoid cross entropy loss without reduction    """</span>    loss <span class="token operator">=</span> torch<span class="token punctuation">.</span>clamp<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> <span class="token builtin">min</span><span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token builtin">input</span> <span class="token operator">*</span> target <span class="token operator">+</span> \           torch<span class="token punctuation">.</span>log1p<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token operator">-</span>torch<span class="token punctuation">.</span><span class="token builtin">abs</span><span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> loss<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在 pytorch 中与之功能几乎一样的是 <code>nn.BCEWithLogitsLoss</code> 或者 <code>F.binary_cross_entropy_with_logits</code>，二者的关系可以用下面的代码表示，<a href="https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html#torch.nn.BCEWithLogitsLoss">pytorch link</a></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">sigmoid_cross_entropy_with_logits<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> target<span class="token punctuation">)</span><span class="token operator">=</span> F<span class="token punctuation">.</span>binary_cross_entropy_with_logits<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> target<span class="token punctuation">,</span> reduction<span class="token operator">=</span><span class="token string">'none'</span><span class="token punctuation">)</span><span class="token comment"># 如果没有 reduction 则默认为 reduction = 'mean'</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="完整实现"><a href="#完整实现" class="headerlink" title="完整实现"></a>完整实现</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">SigmoidFocalClassificationLoss</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""    Sigmoid focal cross entropy loss.    """</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> gamma<span class="token punctuation">:</span> <span class="token builtin">float</span> <span class="token operator">=</span> <span class="token number">2.0</span><span class="token punctuation">,</span> alpha<span class="token punctuation">:</span> <span class="token builtin">float</span> <span class="token operator">=</span> <span class="token number">0.25</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        Args:            gamma: Weighting parameter to balance loss for hard and easy examples.            alpha: Weighting parameter to balance loss for positive and negative examples.        """</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>SigmoidFocalClassificationLoss<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>alpha <span class="token operator">=</span> alpha        self<span class="token punctuation">.</span>gamma <span class="token operator">=</span> gamma    <span class="token decorator annotation punctuation">@staticmethod</span>    <span class="token keyword">def</span> <span class="token function">sigmoid_cross_entropy_with_logits</span><span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">,</span> target<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># 如上一节所示</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">,</span> target<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">,</span> weights<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        Args:            input: (B, #anchors, #classes) float tensor.                Predicted logits for each class            target: (B, #anchors, #classes) float tensor.                One-hot encoded classification targets            weights: (B, #anchors) float tensor.                Anchor-wise weights.        Returns:            weighted_loss: (B, #anchors, #classes) float tensor after weighting.        """</span>         pred_sigmoid <span class="token operator">=</span> torch<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>        alpha_weight <span class="token operator">=</span> target <span class="token operator">*</span> self<span class="token punctuation">.</span>alpha <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> target<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> self<span class="token punctuation">.</span>alpha<span class="token punctuation">)</span>        pt <span class="token operator">=</span> target <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">1.0</span> <span class="token operator">-</span> pred_sigmoid<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">1.0</span> <span class="token operator">-</span> target<span class="token punctuation">)</span> <span class="token operator">*</span> pred_sigmoid        focal_weight <span class="token operator">=</span> alpha_weight <span class="token operator">*</span> torch<span class="token punctuation">.</span><span class="token builtin">pow</span><span class="token punctuation">(</span>pt<span class="token punctuation">,</span> self<span class="token punctuation">.</span>gamma<span class="token punctuation">)</span>        bce_loss <span class="token operator">=</span> self<span class="token punctuation">.</span>sigmoid_cross_entropy_with_logits<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> target<span class="token punctuation">)</span>        loss <span class="token operator">=</span> focal_weight <span class="token operator">*</span> bce_loss        <span class="token comment"># reshape weights to broadcast</span>        <span class="token keyword">if</span> weights<span class="token punctuation">.</span>shape<span class="token punctuation">.</span>__len__<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">2</span> <span class="token keyword">or</span> \                <span class="token punctuation">(</span>weights<span class="token punctuation">.</span>shape<span class="token punctuation">.</span>__len__<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">1</span> <span class="token keyword">and</span> target<span class="token punctuation">.</span>shape<span class="token punctuation">.</span>__len__<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            weights <span class="token operator">=</span> weights<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        <span class="token keyword">assert</span> weights<span class="token punctuation">.</span>shape<span class="token punctuation">.</span>__len__<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> loss<span class="token punctuation">.</span>shape<span class="token punctuation">.</span>__len__<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> loss <span class="token operator">*</span> weights<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="WeightedSmoothL1Loss"><a href="#WeightedSmoothL1Loss" class="headerlink" title="WeightedSmoothL1Loss"></a>WeightedSmoothL1Loss</h2><p>这里做一下精简的理解，把一些提升灵活性和稳定性的代码去掉，仅看 SmoothL1Loss 的核心就会非常简洁</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">WeightedSmoothL1Loss</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""    Code-wise Weighted Smooth L1 Loss modified based on fvcore.nn.smooth_l1_loss    https://github.com/facebookresearch/fvcore/blob/master/fvcore/nn/smooth_l1_loss.py                  | 0.5 * x ** 2 / beta   if abs(x) &lt; beta    smoothl1(x) = |                  | abs(x) - 0.5 * beta   otherwise,    where x = input - target.    """</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> beta<span class="token punctuation">:</span> <span class="token builtin">float</span> <span class="token operator">=</span> <span class="token number">1.0</span> <span class="token operator">/</span> <span class="token number">9.0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>WeightedSmoothL1Loss<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>beta <span class="token operator">=</span> beta    <span class="token decorator annotation punctuation">@staticmethod</span>    <span class="token keyword">def</span> <span class="token function">smooth_l1_loss</span><span class="token punctuation">(</span>diff<span class="token punctuation">,</span> beta<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> beta <span class="token operator">&lt;</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">:</span>            <span class="token comment"># 如果 beta 太小则没有意义，退化为普通 L1 loss</span>            loss <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">abs</span><span class="token punctuation">(</span>diff<span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            n <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">abs</span><span class="token punctuation">(</span>diff<span class="token punctuation">)</span>            loss <span class="token operator">=</span> torch<span class="token punctuation">.</span>where<span class="token punctuation">(</span>n <span class="token operator">&lt;</span> beta<span class="token punctuation">,</span> <span class="token number">0.5</span> <span class="token operator">*</span> n <span class="token operator">**</span> <span class="token number">2</span> <span class="token operator">/</span> beta<span class="token punctuation">,</span> n <span class="token operator">-</span> <span class="token number">0.5</span> <span class="token operator">*</span> beta<span class="token punctuation">)</span>        <span class="token keyword">return</span> loss    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">,</span> target<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">,</span> weights<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Tensor <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        Args:            input: (B, #anchors, #codes) float tensor.                Ecoded predicted locations of objects.            target: (B, #anchors, #codes) float tensor.                Regression targets.            weights: (B, #anchors) float tensor if not None.        Returns:            loss: (B, #anchors) float tensor.                Weighted smooth l1 loss without reduction.        """</span>        diff <span class="token operator">=</span> <span class="token builtin">input</span> <span class="token operator">-</span> target        loss <span class="token operator">=</span> self<span class="token punctuation">.</span>smooth_l1_loss<span class="token punctuation">(</span>diff<span class="token punctuation">,</span> self<span class="token punctuation">.</span>beta<span class="token punctuation">)</span>        <span class="token comment"># anchor-wise weighting</span>        loss <span class="token operator">=</span> loss <span class="token operator">*</span> weights<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> loss<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>所谓的 weighted 也就是对每个 anchor 取权重，在 SigmoidFocalClassificationLoss 中 weights 一般是一个归一化的常量，这是因为正负样本都需要进行损失计算。WeightedSmoothL1Loss 通常用于计算 bbox regression 的损失，通常仅对正样本计算损失，所以这里的 weights 有一点点的区别：negative anchor 的权重为零，positive anchor 的权重为 1 / nums_positive_anchor</p><p><code>torch.where(condition, x, y)</code> 是一个不错的方法，之后可以经常使用：condition 是条件，x 和 y 是同 shape 的矩阵, 针对矩阵中的某个位置的元素, 满足条件就返回 x，不满足就返回 y</p><p>留个坑，之后总结一下 torch 的常用操作</p><h2 id="WeightedCrossEntropyLoss"><a href="#WeightedCrossEntropyLoss" class="headerlink" title="WeightedCrossEntropyLoss"></a>WeightedCrossEntropyLoss</h2><p>这一函数的实现就更加简单了，核心函数三行解决</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">,</span> target<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">,</span> weights<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""    Args:        input: (B, #anchors, #classes) float tensor.            Predited logits for each class.        target: (B, #anchors, #classes) float tensor.            One-hot classification targets.        weights: (B, #anchors) float tensor.            Anchor-wise weights.    Returns:        loss: (B, #anchors) float tensor.            Weighted cross entropy loss without reduction    """</span>    <span class="token builtin">input</span> <span class="token operator">=</span> <span class="token builtin">input</span><span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>    target <span class="token operator">=</span> target<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>    loss <span class="token operator">=</span> F<span class="token punctuation">.</span>cross_entropy<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> target<span class="token punctuation">,</span> reduction<span class="token operator">=</span><span class="token string">'none'</span><span class="token punctuation">)</span> <span class="token operator">*</span> weights    <span class="token keyword">return</span> loss<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="CrossEntropyLoss-amp-BCEWithLogitsLoss"><a href="#CrossEntropyLoss-amp-BCEWithLogitsLoss" class="headerlink" title="CrossEntropyLoss &amp; BCEWithLogitsLoss"></a>CrossEntropyLoss &amp; BCEWithLogitsLoss</h2><p>关于 pytorch 实现的 CrossEntropyLoss: <a href="https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss">pytorch link</a>。这里不禁让我思考这与 BCEWithLogitsLoss 的区别：</p><ol><li><p>二者都是使用 logits 作为输入以维护数值稳定性</p></li><li><p>通常二者的 input &amp; target 形状相同，CE 也可以使用 index 作为 target 用于选取对应的损失</p></li><li><p>CrossEntropyLoss 使用的是 softmax 计算每个类别的概率得分，是归一化的。而 BCEWithLogitsLoss 使用的是 sigmoid 计算得分，并不是归一化的</p></li><li><p><strong>二者表征的损失是不一样的</strong>，当 BCE 拓展到多个类别过后，其损失不仅包括<strong>是</strong>该类别的损失，也包括<strong>不是</strong>该类别的损失，下面是 BCE 的损失函数（可以暂时忽略 $w_n$ 以便理解）</p><p><img src="/archives/d4954eb6/image-20220304171501966.png" alt="image-20220304171501966"></p><p>这是 CE 的损失函数（可以暂时忽略 $w_n$ 以便理解）</p><p><img src="/archives/d4954eb6/image-20220304171428696.png" alt="image-20220304171428696"></p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 编程 </category>
          
          <category> OpenMMLab </category>
          
      </categories>
      
      
        <tags>
            
            <tag> OpenPCDet </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>D2L 11 优化算法</title>
      <link href="/archives/15b3ab53.html"/>
      <url>/archives/15b3ab53.html</url>
      
        <content type="html"><![CDATA[<h1 id="D2L-11-优化算法"><a href="#D2L-11-优化算法" class="headerlink" title="D2L 11 优化算法"></a>D2L 11 优化算法</h1><h2 id="优化和深度学习"><a href="#优化和深度学习" class="headerlink" title="优化和深度学习"></a>优化和深度学习</h2><p>经验风险是训练数据集的平均损失，而风险则是整个数据群的预期损失</p><p>深度学习优化存在许多挑战。其中一些最令人烦恼的是<strong>局部最小值、鞍点和梯度消失</strong></p><p>鞍点（saddle point）是指函数的所有梯度都消失但既不是全局最小值也不是局部最小值的任何位置</p><h2 id="凸性"><a href="#凸性" class="headerlink" title="凸性"></a>凸性</h2><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><ol><li><p>凸集</p><p> 简单地说，如果对于任何 $a，b∈X$，连接 a 和 b 的线段也位于 X 中，则向量空间中的一个集合 X 是凸（convex）的</p></li><li><p>凸函数</p><p>给定一个凸集 X，如果对于所有 $x,x′∈X$ 和所有 $λ∈[0,1$，一个函数 $f:X→R$ 是凸的，我们可以得到</p><script type="math/tex; mode=display">\lambda f(x)+(1-\lambda) f\left(x^{\prime}\right) \geq f\left(\lambda x+(1-\lambda) x^{\prime}\right)</script></li><li><p><strong>琴森不等式（Jensen’s inequality）</strong></p><script type="math/tex; mode=display">\sum_{i} \alpha_{i} f\left(x_{i}\right) \geq f\left(\sum_{i} \alpha_{i} x_{i}\right) \text { and } E_{X}[f(X)] \geq f\left(E_{X}[X]\right)</script><p>换句话说，凸函数的期望不小于期望的凸函数</p></li></ol><h3 id="性质"><a href="#性质" class="headerlink" title="性质"></a>性质</h3><ol><li><p>局部最小值就是全局最小值。证明通过反证法，假设存在更小值，则与局部最小值矛盾</p></li><li><p>水平集与凸函数。对于凸函数定于如下集合</p><script type="math/tex; mode=display">\mathcal{S}_{b}:=\{x \mid x \in \mathcal{X} \text { and } f(x) \leq b\}</script><p>可以证明该集合是凸集，也称其为水平集。证明也很简单，直接按照定义进行证明：集合内任意两点连线上的所有的点都在集合内</p></li><li><p>凸性和二阶导数。Hessian 矩阵半正定与凸函数是等价的，当然还要二阶可微的条件</p></li></ol><h3 id="约束"><a href="#约束" class="headerlink" title="约束"></a>约束</h3><p>这里需要更多凸优化的知识…暂略</p><p>凸约束可以通过拉格朗日函数来添加。在实践中，只需在目标函数中加上一个惩罚就可以了</p><p>投影映射到凸集中最接近原始点的点</p><h2 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h2><h3 id="多元梯度下降"><a href="#多元梯度下降" class="headerlink" title="多元梯度下降"></a>多元梯度下降</h3><p>多元泰勒展开的一阶公式</p><script type="math/tex; mode=display">f(\mathbf{x}+\boldsymbol{\epsilon})=f(\mathbf{x})+\boldsymbol{\epsilon}^{\top} \nabla f(\mathbf{x})+\mathcal{O}\left(\|\boldsymbol{\epsilon}\|^{2}\right)</script><p>使用一阶近似函数，只需要沿着梯度的负方向走合适的步长，就能够使得函数值下降</p><script type="math/tex; mode=display">\mathbf{x} \leftarrow \mathbf{x}-\eta \nabla f(\mathbf{x})</script><h3 id="牛顿法"><a href="#牛顿法" class="headerlink" title="牛顿法"></a>牛顿法</h3><p>多元泰勒展开的二阶公式</p><script type="math/tex; mode=display">f(\mathbf{x}+\boldsymbol{\epsilon})=f(\mathbf{x})+\boldsymbol{\epsilon}^{\top} \nabla f(\mathbf{x})+\frac{1}{2} \boldsymbol{\epsilon}^{\top} \nabla^{2} f(\mathbf{x}) \boldsymbol{\epsilon}+\mathcal{O}\left(\|\boldsymbol{\epsilon}\|^{3}\right)</script><p>其中，定义海森矩阵 Hessian Matrix</p><script type="math/tex; mode=display">\mathbf H = \nabla^{2} f(\mathbf{x})</script><p>对于关于 ε 的二次函数，我们可以直接求得其极值，直接求导为零</p><script type="math/tex; mode=display">\nabla f(\mathbf{x})+\mathbf{H} \boldsymbol{\epsilon}=0 \text { and hence } \boldsymbol{\epsilon}=-\mathbf{H}^{-1} \nabla f(\mathbf{x})</script><p>牛顿法在凸问题中速度很快，但在非凸问题中显得不那么好用</p><p>因为在牛顿法中，我们最终将除以 Hessian。 这意味着如果二阶导数是负的，函数的值可能会趋于增加。 这是这个算法的致命缺陷！</p><h2 id="随机梯度下降"><a href="#随机梯度下降" class="headerlink" title="随机梯度下降"></a>随机梯度下降</h2><p>在深度学习中，目标函数通常是训练数据集中每个样本的损失函数的平均值</p><p>如果使用梯度下降法，则每个自变量迭代的计算代价为 O(n)，它随 n 线性增长。因此，当训练数据集较大时，每次迭代的梯度下降计算代价将较高</p><p>在随机梯度下降的每次迭代中，我们对数据样本随机均匀采样一个索引 i，其中 i∈{1,…,n}，并计算梯度以更新 x</p><h3 id="小批量随机梯度下降"><a href="#小批量随机梯度下降" class="headerlink" title="小批量随机梯度下降"></a>小批量随机梯度下降</h3><p>随机梯度下降的“统计效率”与大批量一次处理数据的“计算效率”之间存在权衡。小批量随机梯度下降提供了两全其美的答案：计算和统计效率</p><p>事实上我们可能会问：假设有足够的硬件条件，batch size 真的越大越好吗？通常来讲 batch size 是训练网络的一个重要超参数，而 batch size 并不是越大越好，<a href="https://blog.csdn.net/ytusdc/article/details/107746786">CSDN</a></p><blockquote><p><strong>较大的 batch size 容易使模型收敛在局部最优点，而使用 mini batch，甚至单个数据训练时，相当于人为给训练加入了噪声，使模型走出局部最优（鞍点），从而在更大的范围内寻找收敛点</strong></p></blockquote><p>这也是为什么使用更大的 batch size 往往会采用更大的学习率的原因之一，帮助走出局部最优</p><h2 id="动量法"><a href="#动量法" class="headerlink" title="动量法"></a>动量法</h2><p>使用动量 Momentum 替代梯度，参数更新方程如下</p><script type="math/tex; mode=display">\begin{array}{l}\mathbf{v}_{t} \leftarrow \beta \mathbf{v}_{t-1}+\mathbf{g}_{t, t-1} \\\mathbf{x}_{t} \leftarrow \mathbf{x}_{t-1}-\eta_{t} \mathbf{v}_{t}\end{array}</script><ul><li>动量法用过去梯度的平均值来替换梯度，这大大加快了收敛速度</li><li>动量法可以防止在随机梯度下降的优化过程停滞的问题</li><li>由于对过去的数据进行了指数降权，有效梯度数为1 / (1 - β)</li></ul><p>如果了解<a href="https://zhuanlan.zhihu.com/p/29895933">指数加权移动平均</a> EWMA，能够很快地理解这个平均的概念，EWA 的更新公式如下</p><script type="math/tex; mode=display">\begin{array}{l}\mathbf{v}_{t} \leftarrow \beta \mathbf{v}_{t-1}+ (1 - \beta)\mathbf{g}_{t, t-1} \\\end{array}</script><p>从 pytorch 中对 <a href="https://pytorch.org/docs/stable/generated/torch.optim.SGD.html">SGD</a> 的介绍来看，是使用的教材中的更新公式，如需要类似 EWA 的功能可设置 dampening 参数</p><p>这里再补充一下对于 EWMA 的理解，来自 <a href="https://www.bilibili.com/video/BV1bP4y1p7Gq">沐神</a> ppt。下面这个展开式就完全告诉我们加权体现在什么地方</p><p><img src="/archives/15b3ab53/image-20220306160047526.png" alt="image-20220306160047526" style="zoom: 33%;"></p><h2 id="AdaGrad"><a href="#AdaGrad" class="headerlink" title="AdaGrad"></a>AdaGrad</h2><p>更新公式如下</p><script type="math/tex; mode=display">\begin{aligned}\mathbf{g}_{t} &=\partial_{\mathbf{w}} l\left(y_{t}, f\left(\mathbf{x}_{t}, \mathbf{w}\right)\right) \\\mathbf{s}_{t} &=\mathbf{s}_{t-1}+\mathbf{g}_{t}^{2} \\\mathbf{w}_{t} &=\mathbf{w}_{t-1}-\frac{\eta}{\sqrt{\mathbf{s}_{t}+\epsilon}} \cdot \mathbf{g}_{t}\end{aligned}</script><p>这里我将采用 cs231n 中做的笔记</p><blockquote><p>Added element-wise <strong>scaling of the gradient</strong> based on the historical sum of squares in each dimension</p></blockquote><p>AdaGrad 能够对梯度的每一维进行缩放，该优化方法能够解决 zigzag 前进问题，我们不希望走陡峭的路径，而是想走到更平滑的全局最优点，对于稀疏特征比较有效。但我们通常不使用该方法，理由：随着不断地更新，累计量 $s_t$ 会越来越大，步长变短可能过于迅速，这对于非凸问题来说是不合适的</p><h2 id="RMSProp"><a href="#RMSProp" class="headerlink" title="RMSProp"></a>RMSProp</h2><p>RootMeanSquareProp 更新公式如下</p><script type="math/tex; mode=display">\begin{array}{l}\mathbf{s}_{t} \leftarrow \gamma \mathbf{s}_{t-1}+(1-\gamma) \mathbf{g}_{t}^{2} \\\mathbf{x}_{t} \leftarrow \mathbf{x}_{t-1}-\frac{\eta}{\sqrt{\mathbf{s}_{t}+\epsilon}} \odot \mathbf{g}_{t}\end{array}</script><p>既然累计量不合适，那么就采取平均量来对梯度的每一维进行缩放。采用 EWA 平均再合适不过了，因为 EWA 平均在实现上非常简单，代码简洁且空间复杂度低</p><h2 id="Adam"><a href="#Adam" class="headerlink" title="Adam"></a>Adam</h2><p>现在我们要将 RMSProp 和 Momentum 结合起来，其实二者一个是对方向的平滑/平均，另一个是对模的平滑/平均</p><script type="math/tex; mode=display">\begin{array}{l}\mathbf{v}_{t} \leftarrow \beta_{1} \mathbf{v}_{t-1}+\left(1-\beta_{1}\right) \mathbf{g}_{t} \\\mathbf{s}_{t} \leftarrow \beta_{2} \mathbf{s}_{t-1}+\left(1-\beta_{2}\right) \mathbf{g}_{t}^{2}\end{array}</script><p>我们同时更新动量/一阶矩 $v_t$ 和二阶矩 $s_t$（随机变量 x 的 n 阶矩为 $E[x^n]$）。当 t 比较小的时候，一阶矩和二阶矩会与其估计出现较大的偏差，在更新通过以下式子进行修正</p><script type="math/tex; mode=display">\hat{\mathbf{v}}_{t}=\frac{\mathbf{v}_{t}}{1-\beta_{1}^{t}} \text { and } \hat{\mathbf{s}}_{t}=\frac{\mathbf{s}_{t}}{1-\beta_{2}^{t}}</script><p>最后更新参数，注意 ε 是在根号外面的，与 RMSProp 不同，在实践中效果略好，深层原因不明…</p><script type="math/tex; mode=display">\mathbf{g}_{t}^{\prime}=\frac{\eta \hat{\mathbf{v}}_{t}}{\sqrt{\hat{\mathbf{s}}_{t}}+\epsilon}\\\mathbf{x}_{t} \leftarrow \mathbf{x}_{t-1}-\eta_{t} \mathbf{g}_{t}^{\prime}</script><p>可以看 pytorch 上的 <a href="https://pytorch.org/docs/stable/generated/torch.optim.Adam.html">Adam</a> 文档，其算法流程也写的很清楚</p><h2 id="学习率调度器"><a href="#学习率调度器" class="headerlink" title="学习率调度器"></a>学习率调度器</h2><p>用与时间相关的学习率 $η(t)$ 取代 $η$ 增加了控制优化算法收敛的复杂性，通常学习率会随着时间衰减，常用以下衰减策略：</p><ol><li><p>分段常数</p></li><li><p>指数衰减</p></li><li><p>多项式衰减</p></li><li><p>余弦衰减</p><script type="math/tex; mode=display">\eta_{t}=\eta_{T}+\frac{\eta_{0}-\eta_{T}}{2}(1+\cos (\pi t / T))</script></li><li><p>先<strong>预热</strong>后衰减，在 OpenPCDet 中遇到的 one cycle policy，参考链接：<a href="https://blog.csdn.net/xys430381_1/article/details/89102866">CSDN-深度学习优化策略—-优化器的学习率调节one cycle policy</a></p></li></ol><p><img src="/archives/15b3ab53/image-20220306161702531.png" alt="image-20220306161702531" style="zoom:50%;"></p><h2 id="补充：信息论基础"><a href="#补充：信息论基础" class="headerlink" title="补充：信息论基础"></a>补充：信息论基础</h2><p>TODO</p>]]></content>
      
      
      <categories>
          
          <category> 课程 </category>
          
          <category> Dive into deep learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Dive into deep learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Leetcode-diary 剑指offer</title>
      <link href="/archives/ff9614a6.html"/>
      <url>/archives/ff9614a6.html</url>
      
        <content type="html"><![CDATA[<h1 id="leetcode-diary-剑指offer"><a href="#leetcode-diary-剑指offer" class="headerlink" title="leetcode-diary 剑指offer"></a>leetcode-diary 剑指offer</h1><p>因为这个题库是大家强推的，所以先刷比较重要的才是更有效率的策略，之后再深入各个板块，<a href="https://leetcode-cn.com/problem-list/xb9nqhhg/">leetcode 剑指offer</a></p><p>现在开始每天复习 offer，旨在能够遇到原题时快速写出最优的答案。会在题目之后 mark 做了几次</p><h4 id="Offer-07-重建二叉树-m2"><a href="#Offer-07-重建二叉树-m2" class="headerlink" title="Offer 07. 重建二叉树 m2"></a><a href="https://leetcode-cn.com/problems/zhong-jian-er-cha-shu-lcof/">Offer 07. 重建二叉树</a> m2</h4><p>前序/后序 + 中序能构建二叉树，但前序 + 后续不能够构建二叉树，仅能明确父子关系。这一题使用递归的方法进行：由前序确定根节点，左子树前序，右子树前序；由中序确定根节点，左子树中序，右子树中序，由此就能够构建递归算法。基础情况就是仅有一个节点的情况（如果使用 index 就直接考虑 index 不满足时的情况）</p><h4 id="Offer-09-用两个栈实现队列"><a href="#Offer-09-用两个栈实现队列" class="headerlink" title="Offer 09. 用两个栈实现队列"></a><a href="https://leetcode-cn.com/problems/yong-liang-ge-zhan-shi-xian-dui-lie-lcof/">Offer 09. 用两个栈实现队列</a></h4><p>使用两个栈，一个用于进，一个用于出</p><p>在 <code>append</code> 的时候操作和栈是一模一样的，在 <code>pop</code> 的时候要分两种情况讨论：1. 当出栈不为空，则 <code>pop</code> 出栈；2. 当出栈为空，则把进栈的数字放入出栈，再 <code>pop</code>；3. 当两个栈都为空，则返回 -1</p><h4 id="Offer-10-I-斐波那契数列"><a href="#Offer-10-I-斐波那契数列" class="headerlink" title="Offer 10- I. 斐波那契数列"></a><a href="https://leetcode-cn.com/problems/fei-bo-na-qi-shu-lie-lcof/">Offer 10- I. 斐波那契数列</a></h4><p>有多种解法：1. 递归；2. 公式法；3. 迭代/动态规划；4. 矩阵快速幂</p><p>简单说一下所谓快速幂的思想：求一个数 a 的 N 次方，相当于用两个 a 的 N/2 次方相乘。使用递归的方法求解即可，当遇到 N 为奇数的时候，拆分为 a 乘以 a 的 N - 1 次方即可</p><h4 id="Offer-11-旋转数组的最小数字"><a href="#Offer-11-旋转数组的最小数字" class="headerlink" title="Offer 11. 旋转数组的最小数字"></a><a href="https://leetcode-cn.com/problems/xuan-zhuan-shu-zu-de-zui-xiao-shu-zi-lcof/">Offer 11. 旋转数组的最小数字</a></h4><p>这是之前做的一个困难题，这里又巩固了一下。又重新理解了一下二分查找，mid 值并不是用于搜索目标的，而是一个确定范围的“探针”，能够迅速让搜索范围缩小一半，但需要特别注意的是边界问题，需要保证三点：</p><ol><li>在边界的情况，左指针一定要不断向前，或者右指针一定要不断向后，这样才能使得 left &gt; right，避免死循环</li><li>最优解一定要在左右指针的范围之内。即：在二分搜索的时候 left = mid + 1 or right = mid - 1 中的 1 有时是需要考虑的</li><li>对特殊情况的讨论，如：对解不再搜索范围之内的情况，应该返回什么</li></ol><h4 id="Offer-12-矩阵中的路径"><a href="#Offer-12-矩阵中的路径" class="headerlink" title="Offer 12. 矩阵中的路径"></a><a href="https://leetcode-cn.com/problems/ju-zhen-zhong-de-lu-jing-lcof/">Offer 12. 矩阵中的路径</a></h4><p>一开始想使用动态规划，简单算了一下其复杂度，应该会比较离谱，所以改为深度搜索，即对每个位置进行深度搜索，这样的复杂度会更加合理。这里也要使用回溯的技巧，显然我已经掌握了</p><h4 id="Offer-14-I-剪绳子"><a href="#Offer-14-I-剪绳子" class="headerlink" title="Offer 14- I. 剪绳子"></a><a href="https://leetcode-cn.com/problems/jian-sheng-zi-lcof/">Offer 14- I. 剪绳子</a></h4><p>这一题直接套用数学上的直觉，当分得越均匀越好。更直接的答案是，拆分成尽量多的长度3，如果余数为1则要拆分成两个2  </p><h4 id="Offer-15-二进制中1的个数"><a href="#Offer-15-二进制中1的个数" class="headerlink" title="Offer 15. 二进制中1的个数"></a><a href="https://leetcode-cn.com/problems/er-jin-zhi-zhong-1de-ge-shu-lcof/">Offer 15. 二进制中1的个数</a></h4><p>这一题有两个方法，比较好理解的是对每一位进行检查。另一个是 n &amp; (n - 1) 直到 n 为0</p><p>对于2的运算可以转化为位运算：</p><ol><li><p>向下整除2等价于右移一位 n &gt;&gt; 1。同样的乘以2等价于向左移动一位，这样还可以更方便地计算2的 N 次方</p></li><li><p>取2的余数等价于判断二进制最右一位值 n &amp; 1</p></li></ol><h4 id="Offer-18-删除链表的节点"><a href="#Offer-18-删除链表的节点" class="headerlink" title="Offer 18. 删除链表的节点"></a><a href="https://leetcode-cn.com/problems/shan-chu-lian-biao-de-jie-dian-lcof/">Offer 18. 删除链表的节点</a></h4><p>使用双指针比较合理一些，必须要记录前一个指针所指的对象。这样的话还需要对 head 情况进行特殊处理</p><h4 id="Offer-20-表示数值的字符串"><a href="#Offer-20-表示数值的字符串" class="headerlink" title="Offer 20. 表示数值的字符串"></a><a href="https://leetcode-cn.com/problems/biao-shi-shu-zhi-de-zi-fu-chuan-lcof/">Offer 20. 表示数值的字符串</a></h4><p>这一题的自动机还是第一次见到，具体情况请直接看题解</p><h4 id="Offer-21-调整数组顺序使奇数位于偶数前面"><a href="#Offer-21-调整数组顺序使奇数位于偶数前面" class="headerlink" title="Offer 21. 调整数组顺序使奇数位于偶数前面"></a><a href="https://leetcode-cn.com/problems/diao-zheng-shu-zu-shun-xu-shi-qi-shu-wei-yu-ou-shu-qian-mian-lcof/">Offer 21. 调整数组顺序使奇数位于偶数前面</a></h4><p>使用双指针进行原地修改</p><h4 id="Offer-24-反转链表"><a href="#Offer-24-反转链表" class="headerlink" title="Offer 24. 反转链表"></a><a href="https://leetcode-cn.com/problems/fan-zhuan-lian-biao-lcof/">Offer 24. 反转链表</a></h4><p>用了两种方法，一个是原地修改（迭代），另一个是取出来再创建，再有一个就是递归，最好尝试一下写一个新的递归函数返回头尾    </p><h4 id="Offer-25-合并两个排序的链表"><a href="#Offer-25-合并两个排序的链表" class="headerlink" title="Offer 25. 合并两个排序的链表"></a><a href="https://leetcode-cn.com/problems/he-bing-liang-ge-pai-xu-de-lian-biao-lcof/">Offer 25. 合并两个排序的链表</a></h4><p>首先想到的当然就是递归。另一个方法就是使用一个空节点作为开头，使用迭代的方法将两个链表穿起来，这样就能够避免一些边界情况处理，比如 head 节点。另一个学习点是 None 可以用作 False 进行判断</p><h4 id="Offer-26-树的子结构"><a href="#Offer-26-树的子结构" class="headerlink" title="Offer 26. 树的子结构"></a><a href="https://leetcode-cn.com/problems/shu-de-zi-jie-gou-lcof/">Offer 26. 树的子结构</a></h4><p>显然需要递归进行判断是否是子结构，并递归进行遍历每一个子节点</p><h4 id="Offer-27-二叉树的镜像"><a href="#Offer-27-二叉树的镜像" class="headerlink" title="Offer 27. 二叉树的镜像"></a><a href="https://leetcode-cn.com/problems/er-cha-shu-de-jing-xiang-lcof/">Offer 27. 二叉树的镜像</a></h4><p>方法一使用递归，这是最明显的，也可以使用队列来进行层序遍历</p><h4 id="Offer-28-对称的二叉树"><a href="#Offer-28-对称的二叉树" class="headerlink" title="Offer 28. 对称的二叉树"></a><a href="https://leetcode-cn.com/problems/dui-cheng-de-er-cha-shu-lcof/">Offer 28. 对称的二叉树</a></h4><p>方法一使用递归，判断左右两个子树是否对称；方法二使用判断每一层是否是中心对称（这个感觉比较麻烦）</p><h4 id="Offer-29-顺时针打印矩阵"><a href="#Offer-29-顺时针打印矩阵" class="headerlink" title="Offer 29. 顺时针打印矩阵"></a><a href="https://leetcode-cn.com/problems/shun-shi-zhen-da-yin-ju-zhen-lcof/">Offer 29. 顺时针打印矩阵</a></h4><p>这一题太迷了…很明显不应该是简单题，因为不能使用简单的代码进行迭代，而需要对每一次运动进行细节判定，所以代码就难看了</p><h4 id="Offer-30-包含min函数的栈"><a href="#Offer-30-包含min函数的栈" class="headerlink" title="Offer 30. 包含min函数的栈"></a><a href="https://leetcode-cn.com/problems/bao-han-minhan-shu-de-zhan-lcof/">Offer 30. 包含min函数的栈</a></h4><p>跟随栈的 pop and push 维护一个最小栈即可</p><h4 id="Offer-31-栈的压入、弹出序列"><a href="#Offer-31-栈的压入、弹出序列" class="headerlink" title="Offer 31. 栈的压入、弹出序列"></a><a href="https://leetcode-cn.com/problems/zhan-de-ya-ru-dan-chu-xu-lie-lcof/">Offer 31. 栈的压入、弹出序列</a></h4><p>这里采用模拟出入栈的方式进行：创建一个模拟栈，然后先入栈，然后看能不能出栈，直到不能出栈；接着进入下一次入栈的循环。要注意的是在判断能不能出栈时有两种情况：</p><ol><li>栈不为空，且栈最后一位正好是我们要出栈的元素</li><li>栈为空 or 最后一位不是我们要出栈的元素</li></ol><h4 id="Offer-32-II-从上到下打印二叉树-II"><a href="#Offer-32-II-从上到下打印二叉树-II" class="headerlink" title="Offer 32 - II. 从上到下打印二叉树 II"></a><a href="https://leetcode-cn.com/problems/cong-shang-dao-xia-da-yin-er-cha-shu-ii-lcof/">Offer 32 - II. 从上到下打印二叉树 II</a></h4><p>层序遍历，使用队列。由于循环终止的条件是队列为空，所以需要先加入一个根节点，然后再开始循环</p><h4 id="Offer-33-二叉搜索树的后序遍历序列"><a href="#Offer-33-二叉搜索树的后序遍历序列" class="headerlink" title="Offer 33. 二叉搜索树的后序遍历序列"></a><a href="https://leetcode-cn.com/problems/er-cha-sou-suo-shu-de-hou-xu-bian-li-xu-lie-lcof/">Offer 33. 二叉搜索树的后序遍历序列</a></h4><p>判断后续遍历输出是否是某<strong>二叉搜索树</strong>的输出。一般后序遍历是不能确定一棵树的，但如果是二叉搜索树那就可以！同理，前序遍历也能够确定一个二叉搜索树，但中序遍历似乎不行…因为中序遍历无法确定根节点的位置</p><p>这一题的数据变化正好有单调的感觉，所以可以考虑使用单调栈，建议看一下题解，逻辑还是比较复杂，需要倒序来看。比较当前节点和栈顶节点的大小：</p><ol><li>如果当前节点大于栈顶节点，则当前节点为栈顶节点的右节点</li><li>如果当前节点小于栈顶节点，则当前节点为栈中<strong>某一节点</strong>的左节点，该节点是距离当前节点最近的点</li></ol><p>这是两个基本性质，通过这两个基本性质单调栈的使用方法就出来了。现在我们需要判定二叉搜索树，这主要看第一条性质。因为当前节点的大小可以很大，有可能大出了根节点的大小，例如某倒序为 <code>[5, 2, 3, 6 ,1]</code>，这样就不是二叉搜索树了，所以整个过程中我们还需要知道当前栈的根节点是谁</p><h4 id="Offer-34-二叉树中和为某一值的路径"><a href="#Offer-34-二叉树中和为某一值的路径" class="headerlink" title="Offer 34. 二叉树中和为某一值的路径"></a><a href="https://leetcode-cn.com/problems/er-cha-shu-zhong-he-wei-mou-yi-zhi-de-lu-jing-lcof/">Offer 34. 二叉树中和为某一值的路径</a></h4><p>深度搜索预定，一开始读题的时候又审错了。是要找从<strong>根节点到叶节点</strong>的情况！这样对于剪枝的情况只能是到达根节点后再进行判断，同时进行搜索时也要判断一下左右节点是否为空</p><h4 id="Offer-35-复杂链表的复制"><a href="#Offer-35-复杂链表的复制" class="headerlink" title="Offer 35. 复杂链表的复制"></a><a href="https://leetcode-cn.com/problems/fu-za-lian-biao-de-fu-zhi-lcof/">Offer 35. 复杂链表的复制</a></h4><p>这一题有两种解法，一种是使用旧表节点作为 key，其 value 为复制的新节点，然后对旧表进行循环，通过对哈希表的查询把新表连接起来。另一种是拼接和拆分，感觉比较晦涩</p><h4 id="Offer-36-二叉搜索树与双向链表"><a href="#Offer-36-二叉搜索树与双向链表" class="headerlink" title="Offer 36. 二叉搜索树与双向链表"></a><a href="https://leetcode-cn.com/problems/er-cha-sou-suo-shu-yu-shuang-xiang-lian-biao-lcof/">Offer 36. 二叉搜索树与双向链表</a></h4><p><strong>中序遍历能够顺序输出二叉搜索树</strong>中的值，所以这一题应当优先考虑中序遍历（然而我一开始并不知道这一点，直接莽了递归，调试太痛苦了，指针的变化很难弄清楚，最好使用 tempt 变量存储节点，然后再进行指针连接）</p><p>一些关键的技巧为：使用一个变量 <code>pre, head</code> 来记录每一个节点前节点和最终输出的头节点，在每次中序遍历的时候将该节点与前节点进行连接，然后更新前节点。在遍历结束后再将头节点和尾节点连接</p><h4 id="Offer-37-序列化二叉树"><a href="#Offer-37-序列化二叉树" class="headerlink" title="Offer 37. 序列化二叉树"></a><a href="https://leetcode-cn.com/problems/xu-lie-hua-er-cha-shu-lcof/">Offer 37. 序列化二叉树</a></h4><p>层序遍历的流程：1. 需要先在队列中放入一个元素；2. 循环中，先 pop 再 pop 出的节点的子节点，然后 appen 其子节点</p><p>需要注意的是 deque 的 popleft 速度比列表的 pop(0) 要快得多</p><h4 id="Offer-38-字符串的排列"><a href="#Offer-38-字符串的排列" class="headerlink" title="Offer 38. 字符串的排列"></a><a href="https://leetcode-cn.com/problems/zi-fu-chuan-de-pai-lie-lcof/">Offer 38. 字符串的排列</a></h4><p>一开始想到的是直接解决，找出所有的可能排列，还想了一下逐渐增加字符的递归方法。然而这些思路不够简洁，对于排列最好还是使用深度搜索的方法，但是为了解决重复性的问题，需要进行剪枝，即某个位置的字符不会重复搜索</p><p>如果日常中需要偷懒的话就直接使用 Python 库 <code>itertools.permutations()</code></p><h4 id="Offer-39-数组中出现次数超过一半的数字"><a href="#Offer-39-数组中出现次数超过一半的数字" class="headerlink" title="Offer 39. 数组中出现次数超过一半的数字"></a><a href="https://leetcode-cn.com/problems/shu-zu-zhong-chu-xian-ci-shu-chao-guo-yi-ban-de-shu-zi-lcof/">Offer 39. 数组中出现次数超过一半的数字</a></h4><p>这一题虽然简单，但是有多种不同的方法：1. 使用 Counter or hash table 找到最多的数字并进行判断；2. 将数组进行排序，只要第一位和中位数是一样的即可；3. 投票法：假设票数为零则当前数作为众数，并与接下来的数进行比较，遇到与该数相等的则票数加一，遇到不相等的票数减一，如此进行循环。其原理是：当票数为零时，之后的计算得到的众数就是全局的众数，最后还可以判断一下，如果 count 大于一般则为真众数，否则众数不存在</p><h4 id="Offer-40-最小的k个数"><a href="#Offer-40-最小的k个数" class="headerlink" title="Offer 40. 最小的k个数"></a><a href="https://leetcode-cn.com/problems/zui-xiao-de-kge-shu-lcof/">Offer 40. 最小的k个数</a></h4><p>三个思路：1. 排序；2. 堆；3. 快排思想：寻找第 k 小 or 第 k + 1 小的数，找到过后把其左边的数一同输出即为答案，期望时间为 O(N)</p><p>又学习到了一个新方法：python 的交换值语法可以用一行写完，不需要 tempt 值。同时这一题让我对快排的代码完全了解了，实现了原地修改和非原地修改两种版本</p><h4 id="Offer-41-数据流中的中位数"><a href="#Offer-41-数据流中的中位数" class="headerlink" title="Offer 41. 数据流中的中位数"></a><a href="https://leetcode-cn.com/problems/shu-ju-liu-zhong-de-zhong-wei-shu-lcof/">Offer 41. 数据流中的中位数</a></h4><p>这里介绍 python 有关堆的库 heapq 堆队列，需要了解的有几点：</p><ol><li>建堆是 O(N) 时间复杂度；</li><li>堆是一个完全二叉树，但是完全可以使用一个数组来实现，因为完全二叉树的根节点和子节点之间的 index 关系是确定的：<code>left = root * 2 + 1</code> &amp; <code>right = root * 2 + 2</code></li><li>insert &amp; pop 的时间复杂度都是 O(logN)</li></ol><p>python 里面只实现了最小堆，最大堆可以通过把值取负数实现。建堆可以使用 <code>heapify(list)</code> or 直接向一个列表插入即可自动建堆 <code>heappush(list, num)</code>，删除堆顶操作为 <code>heappop</code>，获得堆顶直接取切片 <code>list[0]</code></p><p>这一题通过建立两个堆，一个最大堆和一个最小堆。其中最大堆 B 保留较小的数，最小堆 A 保留较大的数，这将使得 A &gt;= B 以两个堆的数量是否相等为判断：</p><ol><li>当两个堆数量相等时，把数字插入最大堆 B，然后 pop 出 B 堆中的最大值，将其插入 A 中</li><li>当两个堆数量不等时（准确来说当 A 堆比 B 堆多一个数时），把数字插入最小堆 B，然后 pop 出 A 堆中的最小值，将其插入 B 中</li></ol><p>以上的两个方法将维护这两个堆，保持输入的数组均匀分成两份</p><h4 id="Offer-42-连续子数组的最大和"><a href="#Offer-42-连续子数组的最大和" class="headerlink" title="Offer 42. 连续子数组的最大和"></a><a href="https://leetcode-cn.com/problems/lian-xu-zi-shu-zu-de-zui-da-he-lcof/">Offer 42. 连续子数组的最大和</a></h4><p>很明显的动态规划题目，以第 i 个数为结尾的连续子数组的最大和为状态进行构建</p><h4 id="Offer-43-1～n-整数中-1-出现的次数"><a href="#Offer-43-1～n-整数中-1-出现的次数" class="headerlink" title="Offer 43. 1～n 整数中 1 出现的次数"></a><a href="https://leetcode-cn.com/problems/1nzheng-shu-zhong-1chu-xian-de-ci-shu-lcof/">Offer 43. 1～n 整数中 1 出现的次数</a></h4><p>这是一个困难题，这一题没有什么套路可言。完全是通过逻辑的推演得出的解题思路，其主思路是计算每一位上出现1的次数，而每一位出现1的次数要分三种情况讨论：</p><ol><li>该位是0，则出现次数仅与高位相关：<code>high * 10 ** i</code></li><li>该位是1，则出现次数与高位和地位相关：<code>high * 10 ** i + low + 1</code></li><li>该位是除0，1之外的其他数字，则出现次数仅与高位相关：<code>(high + 1) * 10 ** i</code></li></ol><h4 id="Offer-44-数字序列中某一位的数字"><a href="#Offer-44-数字序列中某一位的数字" class="headerlink" title="Offer 44. 数字序列中某一位的数字"></a><a href="https://leetcode-cn.com/problems/shu-zi-xu-lie-zhong-mou-yi-wei-de-shu-zi-lcof/">Offer 44. 数字序列中某一位的数字</a></h4><p>这一题和上一题一样，也是需要通过题目本身的逻辑推演出迭代思路，不能够通过递归的方法进行。也是根据数的位数作为突破口，先寻找这是几位数，然后再看数字是几，最后再得出答案</p><h4 id="Offer-45-把数组排成最小的数"><a href="#Offer-45-把数组排成最小的数" class="headerlink" title="Offer 45. 把数组排成最小的数"></a><a href="https://leetcode-cn.com/problems/ba-shu-zu-pai-cheng-zui-xiao-de-shu-lcof/">Offer 45. 把数组排成最小的数</a></h4><p>这一题本质是一个排序问题，如何比较两个数 x, y 的大小定义为前后两种不同拼接的字符串大小：若 xy &lt; yx 则 x &lt; y 反之 x &gt; y</p><p>python 中自定义排序需要使用 <code>functools.cmp_to_key(cmp_func)</code>，该函数作为参数传入  <code>sorted(,key=)</code>，更多原理参考 <a href="https://zhuanlan.zhihu.com/p/26546486">知乎</a>，其核心是通过重载算符返回一个可比较的类</p><h4 id="Offer-46-把数字翻译成字符串"><a href="#Offer-46-把数字翻译成字符串" class="headerlink" title="Offer 46. 把数字翻译成字符串"></a><a href="https://leetcode-cn.com/problems/ba-shu-zi-fan-yi-cheng-zi-fu-chuan-lcof/">Offer 46. 把数字翻译成字符串</a></h4><p>比较明显一道深度搜索的题目，很快就解出来了，这题学到的是答案一般在完成一条搜索路径后再添加，在中途是不添加的</p><h4 id="Offer-47-礼物的最大价值"><a href="#Offer-47-礼物的最大价值" class="headerlink" title="Offer 47. 礼物的最大价值"></a><a href="https://leetcode-cn.com/problems/li-wu-de-zui-da-jie-zhi-lcof/">Offer 47. 礼物的最大价值</a></h4><p>先尝试了深度搜索，但超时了，再做了动态规划</p><h4 id="Offer-48-最长不含重复字符的子字符串"><a href="#Offer-48-最长不含重复字符的子字符串" class="headerlink" title="Offer 48. 最长不含重复字符的子字符串"></a><a href="https://leetcode-cn.com/problems/zui-chang-bu-han-zhong-fu-zi-fu-de-zi-zi-fu-chuan-lcof/">Offer 48. 最长不含重复字符的子字符串</a></h4><p>这一题之前做过，使用双指针 + 一个哈希表存储，也可以尝试使用动态规划解决但思路就比较复杂一点</p><h4 id="Offer-49-丑数"><a href="#Offer-49-丑数" class="headerlink" title="Offer 49. 丑数"></a><a href="https://leetcode-cn.com/problems/chou-shu-lcof/">Offer 49. 丑数</a></h4><p>这一题比较好理解的是堆方法，动态规划方法不太好理解，如果推导出下一个丑数的过程（三指针逐渐往前滚动），下面引用题解中的评论</p><blockquote><p>设置3个索引a, b, c，分别记录前几个数已经被乘2， 乘3， 乘5了，比如a表示前(a-1)个数都已经乘过一次2了，下次应该乘2的是第a个数；b表示前(b-1)个数都已经乘过一次3了，下次应该乘3的是第b个数；c表示前(c-1)个数都已经乘过一次5了，下次应该乘5的是第c个数</p></blockquote><h4 id="Offer-50-第一个只出现一次的字符"><a href="#Offer-50-第一个只出现一次的字符" class="headerlink" title="Offer 50. 第一个只出现一次的字符"></a><a href="https://leetcode-cn.com/problems/di-yi-ge-zhi-chu-xian-yi-ci-de-zi-fu-lcof/">Offer 50. 第一个只出现一次的字符</a></h4><p>直接调用 counter 杀死比赛。这里还有一种解法是使用有序字典 OrderedDict，实际上 python 在 3.6 之后其字典就是有序的，所以可以不必使用 collections 库</p><h4 id="Offer-51-数组中的逆序对"><a href="#Offer-51-数组中的逆序对" class="headerlink" title="Offer 51. 数组中的逆序对"></a><a href="https://leetcode-cn.com/problems/shu-zu-zhong-de-ni-xu-dui-lcof/">Offer 51. 数组中的逆序对</a></h4><p>先思考了各种方法，其关键在于求出当前数字之后比其小的数字有多少，思路其实已经出来了，只需要维护之前的数组有序即可。这里我先使用了 python 中的一个库进行实现 bisect，简单介绍一下这个库的两个方法 <code>inosrt_left(list, num) &amp; bisect_left(list, num)</code>，这两个方法分别代表插入和查找，left 代表当有相同数字的时候，将插入在其左侧。其实插入时插在哪边都没有影响，有影响的是在寻找时返回的 index，该 index 是该数字插入后在数组中的 index</p><p>实际上 Python 中的 insert 操作都是 O(N) 的，两个列表相加的速度也比较慢，此题真正的做法应该是使用归并排序达到 O(NlogN) 时间复杂度</p><h4 id="Offer-52-两个链表的第一个公共节点"><a href="#Offer-52-两个链表的第一个公共节点" class="headerlink" title="Offer 52. 两个链表的第一个公共节点"></a><a href="https://leetcode-cn.com/problems/liang-ge-lian-biao-de-di-yi-ge-gong-gong-jie-dian-lcof/">Offer 52. 两个链表的第一个公共节点</a></h4><p>首先想到的是哈希表解决，比较优雅的方法是两个指针都向前走 (a + b - c) 步一定能够得到其交点 or None，其中 a, b 分别为链表的长度，c 为公共链表的长度，具体操作为当二者的指针不相等时则一直循环，若二者的指针为 None 则将其指向对方的头节点</p><h4 id="Offer-53-I-在排序数组中查找数字-I"><a href="#Offer-53-I-在排序数组中查找数字-I" class="headerlink" title="Offer 53 - I. 在排序数组中查找数字 I"></a><a href="https://leetcode-cn.com/problems/zai-pai-xu-shu-zu-zhong-cha-zhao-shu-zi-lcof/">Offer 53 - I. 在排序数组中查找数字 I</a></h4><p>显然使用二分查找，这里再重新自己写一遍</p><h4 id="Offer-53-II-0～n-1中缺失的数字"><a href="#Offer-53-II-0～n-1中缺失的数字" class="headerlink" title="Offer 53 - II. 0～n-1中缺失的数字"></a><a href="https://leetcode-cn.com/problems/que-shi-de-shu-zi-lcof/">Offer 53 - II. 0～n-1中缺失的数字</a></h4><p>显然使用二分查找，再重新总结一下套路：首先标定 left &amp; right，然后进入循环：1. 二分；2. 搜索区间的界定；3. 边界情况的判断（left &amp; right 相邻，判断最终返回值的具体位置）</p><h4 id="Offer-54-二叉搜索树的第k大节点"><a href="#Offer-54-二叉搜索树的第k大节点" class="headerlink" title="Offer 54. 二叉搜索树的第k大节点"></a><a href="https://leetcode-cn.com/problems/er-cha-sou-suo-shu-de-di-kda-jie-dian-lcof/">Offer 54. 二叉搜索树的第k大节点</a></h4><p>中序遍历，并在 count &gt;= k 时进行剪枝，剪枝的技巧通常在搜索函数的开头，可以把其作为 basic cases</p><h4 id="Offer-55-I-二叉树的深度"><a href="#Offer-55-I-二叉树的深度" class="headerlink" title="Offer 55 - I. 二叉树的深度"></a><a href="https://leetcode-cn.com/problems/er-cha-shu-de-shen-du-lcof/">Offer 55 - I. 二叉树的深度</a></h4><p>可以用任一序的遍历解题，我采用了先序，同样为了省去回溯的麻烦，我将 path / depth 作为参数放入了搜索函数当中，这也是递归的思想</p><h4 id="Offer-55-II-平衡二叉树"><a href="#Offer-55-II-平衡二叉树" class="headerlink" title="Offer 55 - II. 平衡二叉树"></a><a href="https://leetcode-cn.com/problems/ping-heng-er-cha-shu-lcof/">Offer 55 - II. 平衡二叉树</a></h4><p>这一题的迷惑主要是在于剪枝方面。首先我定义了一个递归的解法，在递归的过程中一旦发现不符合就可以不用继续递归了，但是递归的返回值是树的深度，而在计算中会使用这个深度，其中就容易出错了。粗暴的剪枝可以在所有递归结束的地方都进行，而不仅仅是在开头</p><h4 id="Offer-56-I-数组中数字出现的次数"><a href="#Offer-56-I-数组中数字出现的次数" class="headerlink" title="Offer 56 - I. 数组中数字出现的次数"></a><a href="https://leetcode-cn.com/problems/shu-zu-zhong-shu-zi-chu-xian-de-ci-shu-lcof/">Offer 56 - I. 数组中数字出现的次数</a></h4><p>这一题是想破头都没相出来，直接看答案吧！答案首先提出使用位运算：异或。首先提出了异或的性质：</p><ol><li>交换律：a + b = b + a</li><li>可移动性：a + b = c, a + c = b, b + c = a</li><li>自反性：a + 0 = a 或表达为 a + b + b = a</li></ol><p>答案首先提出了简单例子：只含有一个不一样的数字怎么找出来，就是直接把所有数字取异或操作即可。那么两个不一样的数字，就可以把两个数字分到不同的组，而其他一样的数字分到同一个组即可。符合分组的方法：找到 c (= a + b) 中某一位为 1 的数，让其他所有数字对应位上的数字与其左异或操作，这样就能够达到上述的分组效果</p><h4 id="Offer-56-II-数组中数字出现的次数-II"><a href="#Offer-56-II-数组中数字出现的次数-II" class="headerlink" title="Offer 56 - II. 数组中数字出现的次数 II"></a><a href="https://leetcode-cn.com/problems/shu-zu-zhong-shu-zi-chu-xian-de-ci-shu-ii-lcof/">Offer 56 - II. 数组中数字出现的次数 II</a></h4><p>这一题没有要求空间复杂度 O(1) 所以先考虑简单做法，使用 Counter 一行骚操作解决。而从位运算的角度来思考，如果全是重复的数字，则每一位0和1出现的次数均位3的倍数，而多了一个单独的数字则会打破3的倍数，我们只需要确定这一位是多少即可，这就是位运算的神奇魔力，不需要确定是哪一个，而是算出来哪一个该是什么值。事实上从题目下方的数字范围有时也能猜测这题是否使用位运算，比如0~2^31</p><h4 id="Offer-57-和为s的两个数字"><a href="#Offer-57-和为s的两个数字" class="headerlink" title="Offer 57. 和为s的两个数字"></a><a href="https://leetcode-cn.com/problems/he-wei-sde-liang-ge-shu-zi-lcof/">Offer 57. 和为s的两个数字</a></h4><p>先用二分查找的方法试了一下，很奇怪，为什么我第一想法不是使用哈希查找呢？但实际上哈希查找的空间复杂度比较高，我没有使用递增这个条件。使用双指针可将空间复杂度降为 O(1)</p><h4 id="Offer-57-II-和为s的连续正数序列"><a href="#Offer-57-II-和为s的连续正数序列" class="headerlink" title="Offer 57 - II. 和为s的连续正数序列"></a><a href="https://leetcode-cn.com/problems/he-wei-sde-lian-xu-zheng-shu-xu-lie-lcof/">Offer 57 - II. 和为s的连续正数序列</a></h4><p>首先使用了一个栈作为滑窗。另一种方式为，作为连续正数的和，可以使用求和公式简化搜搜</p><h4 id="Offer-58-I-翻转单词顺序"><a href="#Offer-58-I-翻转单词顺序" class="headerlink" title="Offer 58 - I. 翻转单词顺序"></a><a href="https://leetcode-cn.com/problems/fan-zhuan-dan-ci-shun-xu-lcof/">Offer 58 - I. 翻转单词顺序</a></h4><p>使用了 split 方法直接一行带走，当然也要用不使用这个方法实现一次</p><h4 id="Offer-59-I-滑动窗口的最大值"><a href="#Offer-59-I-滑动窗口的最大值" class="headerlink" title="Offer 59 - I. 滑动窗口的最大值"></a><a href="https://leetcode-cn.com/problems/hua-dong-chuang-kou-de-zui-da-zhi-lcof/">Offer 59 - I. 滑动窗口的最大值</a></h4><p>首先想到的是使用堆来维护滑窗的最大值，但是这个堆顶元素可能不再滑动窗口中之中，所以需要进行判定，这样还需要滑动窗口的范围和该堆顶元素的 Index。这里插入堆中的是一个元组 <code>(number, index)</code>，注意：插入堆中的元素必须可以比较，元组和队列都行，但字典不可以。但这并不是这一题的最优解，最优应该使用单调（双端）队列来维护滑动窗口的最大值：</p><ol><li>获得元素 i</li><li>若将此元素入队，判断此时长度是否大于滑动窗口，如果大于则左侧出队</li><li>判断是否大于队列尾部元素，如果大于则底部元素出列，因为该元素将不会被作为最大值取到，如此循环，知道碰到大于元素 i 的数</li><li>元素入队，并返回队列头部作为最大值</li></ol><h4 id="Offer-59-II-队列的最大值"><a href="#Offer-59-II-队列的最大值" class="headerlink" title="Offer 59 - II. 队列的最大值"></a><a href="https://leetcode-cn.com/problems/dui-lie-de-zui-da-zhi-lcof/">Offer 59 - II. 队列的最大值</a></h4><p>这一题就是上面滑动窗口的最大值的翻版，按照之前的算法进行即可，只是少了滑动窗口的长度这一判断条件</p><h4 id="Offer-60-n个骰子的点数"><a href="#Offer-60-n个骰子的点数" class="headerlink" title="Offer 60. n个骰子的点数"></a><a href="https://leetcode-cn.com/problems/nge-tou-zi-de-dian-shu-lcof/">Offer 60. n个骰子的点数</a></h4><p>先写了一个简单的搜索，发现时间太长了，赶紧使用动态规划，这里依然要拓展维度，因为添加骰子能够让状态更好把握</p><h4 id="Offer-61-扑克牌中的顺子"><a href="#Offer-61-扑克牌中的顺子" class="headerlink" title="Offer 61. 扑克牌中的顺子"></a><a href="https://leetcode-cn.com/problems/bu-ke-pai-zhong-de-shun-zi-lcof/">Offer 61. 扑克牌中的顺子</a></h4><p>关键考虑顺子的充要条件：1. 非零元素不重复；2. 非零元素的最大最小值相差小于5</p><h4 id="Offer-62-圆圈中最后剩下的数字"><a href="#Offer-62-圆圈中最后剩下的数字" class="headerlink" title="Offer 62. 圆圈中最后剩下的数字"></a><a href="https://leetcode-cn.com/problems/yuan-quan-zhong-zui-hou-sheng-xia-de-shu-zi-lcof/">Offer 62. 圆圈中最后剩下的数字</a></h4><p>这一题不应该是个简单题，还是挺难的！一开始使用暴力解法，显然因为删除复杂度太高而超时了。想了动态规划，但是没想明白怎么推导状态方程…然后开始思考递归，最后获得了递归的答案，既然递归能够完成，那么迭代（动态规划）就一定能够完成，最终反推迭代方程解决</p><p>开始思考递归和动态规划之间的联系…我感觉二者应该是等价的，不过递归可能发散出去的状态是很多的（例如深度搜索），但是动态规划最终的状态是更清晰的</p><h4 id="Offer-64-求1-2-…-n"><a href="#Offer-64-求1-2-…-n" class="headerlink" title="Offer 64. 求1+2+…+n"></a><a href="https://leetcode-cn.com/problems/qiu-12n-lcof/">Offer 64. 求1+2+…+n</a></h4><p>这一题使用了逻辑运算的短路功能，利用递归来代替循环</p><h4 id="Offer-65-不用加减乘除做加法"><a href="#Offer-65-不用加减乘除做加法" class="headerlink" title="Offer 65. 不用加减乘除做加法"></a><a href="https://leetcode-cn.com/problems/bu-yong-jia-jian-cheng-chu-zuo-jia-fa-lcof/">Offer 65. 不用加减乘除做加法</a></h4><p>这一题补充一下整数在计算机中的表达的相关知识，参考 <a href="https://zhuanlan.zhihu.com/p/376848035">知乎</a>：</p><ol><li><p>0b, 0o, 0x 分别表示二进制和十六进制，可能取的是 binary, octal, hexadecimal 的某个字母</p></li><li><p>关于原码，反码，补码：</p><ol><li><p>原码：最高位为符号位，0表示正数，1表示负数</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">hex</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># = 0x1 补码</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">hex</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># = -0x1 负号 + 原码 （ Python 特色，Java 会直接输出补码 1111 1101）</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li><li><p>反码：最高位为符号位，正数的反码等于本身，负数的反码为除符号位外，对应正数各位取反</p></li><li><p>补码：最高位为符号位，正数的补码等于本身，负数的补码为反码 + 1</p><p>我们可以把补码当作一个一般的操作（取反 + 1，不需要特殊考虑符号位），对正数我们不做操作，对负数进行补码操作。相当于用补码来表示正数的相反数，在进行计算时，我们用补码代替负数，也即将减法转为为加法。得知负数的补码，在对其取补码，就可得到正数，也即补码的补码就是原码</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 假设 a 为负数，a 的补码为 b + 1，其中 b 为 a 的反码</span><span class="token comment"># 根据反码的定义有</span>a <span class="token operator">+</span> b <span class="token operator">=</span> <span class="token number">0xffffffff</span><span class="token comment"># f 代表4个1</span>a <span class="token operator">+</span> b <span class="token operator">+</span> <span class="token number">1</span> <span class="token operator">=</span> <span class="token number">0x00000000</span><span class="token comment"># 由以上等式得出</span>x <span class="token operator">-</span> a <span class="token operator">=</span> x <span class="token operator">+</span> b <span class="token operator">+</span> <span class="token number">1</span><span class="token comment"># 这样就将减法和加法统一起来了</span><span class="token comment"># 用4个 bit 来做一个示范</span><span class="token builtin">bin</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token number">0b0101</span><span class="token comment"># 3 的反码和补码等于其本身</span><span class="token builtin">bin</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">3</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token number">0b1101</span><span class="token comment"># 将最高位变为 1（这里仅用于示范，与 python 实际的逻辑不符！！！！</span><span class="token comment"># -3 的反码</span><span class="token number">0b1010</span><span class="token comment"># -3 的补码</span><span class="token number">0b1011</span><span class="token comment"># 从 -3 的补码推测其源码，先确定符号位，然后取反码 + 1</span><span class="token number">0b0100</span> <span class="token operator">+</span> <span class="token number">1</span> <span class="token operator">=</span> <span class="token number">0b0101</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ol></li><li><p>由于 python 的特殊表示，即其没有最高位的概念，输入一个补码的二进制会输出一个正数，所以需要特殊处理</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 同样以 -3 举例</span><span class="token builtin">bin</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">3</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token number">0b1101</span><span class="token comment"># -3 的理论补码表示</span><span class="token builtin">int</span><span class="token punctuation">(</span><span class="token number">0b1101</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token number">13</span> <span class="token operator">&gt;</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token operator">**</span><span class="token number">3</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token comment"># -3 在 python 中实际的表示</span><span class="token comment"># 现在要想把 13 转换为 -3，思路是先转回原码，再使用 ~ 取反得到补码</span><span class="token comment"># 为了转回原码不能使用 ~，因为 python 没有最高位的概念，~13 = -14</span><span class="token comment"># 只能使用异或操作进行取反</span><span class="token number">0b1101</span> <span class="token operator">^</span> <span class="token number">0b1111</span><span class="token operator">=</span> <span class="token number">0b0010</span> <span class="token operator">=</span> <span class="token number">2</span><span class="token comment"># ~x 在 python 中等价于 -x - 1</span><span class="token operator">~</span><span class="token number">0b0010</span> <span class="token operator">=</span> <span class="token operator">-</span>x <span class="token operator">-</span> <span class="token number">1</span> <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">2</span> <span class="token operator">-</span> <span class="token number">1</span> <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">3</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ol><h4 id="Offer-66-构建乘积数组"><a href="#Offer-66-构建乘积数组" class="headerlink" title="Offer 66. 构建乘积数组"></a><a href="https://leetcode-cn.com/problems/gou-jian-cheng-ji-shu-zu-lcof/">Offer 66. 构建乘积数组</a></h4><p>没办法使用除法，那就只能高效使用乘法，通过构建上下三角来重复利用已求得的结果</p><h4 id="Offer-67-把字符串转换成整数"><a href="#Offer-67-把字符串转换成整数" class="headerlink" title="Offer 67. 把字符串转换成整数"></a><a href="https://leetcode-cn.com/problems/ba-zi-fu-chuan-zhuan-huan-cheng-zheng-shu-lcof/">Offer 67. 把字符串转换成整数</a></h4><p>没什么特别的方法，就是跟着逻辑硬判断，但是其实文字描述并不够清晰…这一题就这样吧，直接抄的答案</p><h4 id="Offer-68-I-二叉搜索树的最近公共祖先"><a href="#Offer-68-I-二叉搜索树的最近公共祖先" class="headerlink" title="Offer 68 - I. 二叉搜索树的最近公共祖先"></a><a href="https://leetcode-cn.com/problems/er-cha-sou-suo-shu-de-zui-jin-gong-gong-zu-xian-lcof/">Offer 68 - I. 二叉搜索树的最近公共祖先</a></h4><p>利用二叉搜索树的性质能够加速搜索，如果不是二叉搜索树则先将路径搜索出来，然后查询公共节点。使用 append &amp; pop 能够极大加速搜索速度并减少内存，而不使用 + 方法省去剪枝的流程</p><h4 id="面试题32-I-从上到下打印二叉树"><a href="#面试题32-I-从上到下打印二叉树" class="headerlink" title="面试题32 - I. 从上到下打印二叉树"></a><a href="https://leetcode-cn.com/problems/cong-shang-dao-xia-da-yin-er-cha-shu-lcof/">面试题32 - I. 从上到下打印二叉树</a></h4><p>层序遍历</p><h4 id="面试题19-正则表达式匹配"><a href="#面试题19-正则表达式匹配" class="headerlink" title="面试题19. 正则表达式匹配"></a><a href="https://leetcode-cn.com/problems/zheng-ze-biao-da-shi-pi-pei-lcof/">面试题19. 正则表达式匹配</a></h4><p>比较复杂的一道动态规划，调试了很久很久，我其实也不能确定这样的状态转移能够推理出全部的解，我尽可能的写出了为 true 的状态转移方程，显然我写出的方程已经覆盖了所有为 true 的情况，不满足的自然为 false</p><h2 id="补充：常见输入输出"><a href="#补充：常见输入输出" class="headerlink" title="补充：常见输入输出"></a>补充：常见输入输出</h2><p>因为在进行笔试的时候，不像 leetcode 提供了输入输出，而是需要使用标准输入输出 input &amp; print。这里总结一下 python 的标准输入输出模板。要点就是：</p><ol><li>所有的输入可以看作为一个文件</li><li>每一行的输入都要用 input 接受，通常使用 try &amp; except 处理循环结束 end of file</li></ol><h3 id="一行输入"><a href="#一行输入" class="headerlink" title="一行输入"></a>一行输入</h3><p>每个样例只有一行输入</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">while</span> <span class="token boolean">True</span><span class="token punctuation">:</span>    <span class="token keyword">try</span><span class="token punctuation">:</span>a <span class="token operator">=</span> <span class="token builtin">input</span><span class="token punctuation">(</span><span class="token punctuation">)</span>        function<span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token keyword">except</span><span class="token punctuation">:</span>        <span class="token keyword">break</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="多行输入"><a href="#多行输入" class="headerlink" title="多行输入"></a>多行输入</h3><p>每个样例有多个输入，这个时候通常会告诉你有多少行，使用循环接收即可</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">while</span> <span class="token boolean">True</span><span class="token punctuation">:</span>    <span class="token keyword">try</span><span class="token punctuation">:</span>        n<span class="token punctuation">,</span> m <span class="token operator">=</span> <span class="token builtin">input</span><span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">:</span>            a <span class="token operator">=</span> <span class="token builtin">input</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 编程 </category>
          
          <category> Leetcode </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Leetcode </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Leetcode-diary 4 String</title>
      <link href="/archives/984b9f00.html"/>
      <url>/archives/984b9f00.html</url>
      
        <content type="html"><![CDATA[<h1 id="String"><a href="#String" class="headerlink" title="String"></a>String</h1><p>对 string 类的题目进行深度学习，重点总结方法，过多的代码就不放出来了</p><h3 id="556-Next-Greater-Element"><a href="#556-Next-Greater-Element" class="headerlink" title="556 Next Greater Element |||"></a>556 Next Greater Element |||</h3><p><a href="https://leetcode-cn.com/problems/next-greater-element-iii/">leetcode link</a></p><p>这一题的代码写的也是相当丑，题目中其实有两个要求，相当于是求最大中的最小，我在解题的时候没有考虑全，所以修改了较长的时间。这种最大中的最小基本上都有一个单调栈的感觉在里面：数列必须是单增的，遇到第一个减少的数字则是关键点！</p><p>学习点：简易的将字符串列表转为数字的方法</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token builtin">int</span><span class="token punctuation">(</span><span class="token string">''</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>list_of_str<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="395-Longest-Substring-with-At-Least-K-Repeating-Characters"><a href="#395-Longest-Substring-with-At-Least-K-Repeating-Characters" class="headerlink" title="395 Longest Substring with At Least K Repeating Characters"></a>395 Longest Substring with At Least K Repeating Characters</h3><p><a href="https://leetcode-cn.com/problems/longest-substring-with-at-least-k-repeating-characters/">leetcode link</a></p><p>又是一个与子序列相关的问题，一般有几种思路：递归，动态规划，通过条件不断地扩充解或者剔除不满足的成员（这几种思路也可能相互重叠）。一开始选择了不断扩充的方法，但是会遗漏部分的解。在此基础之上很快就延申出了递归的思路迅速求解了：递归地剔除不满足的数字</p><h3 id="419-Battleships-in-a-Board"><a href="#419-Battleships-in-a-Board" class="headerlink" title="419 Battleships in a Board"></a>419 Battleships in a Board</h3><p><a href="https://leetcode-cn.com/problems/battleships-in-a-board/">leetcode link</a></p><p>这一题我使用了连通的想法，既然不相邻，那么连通的 X 就是一个战舰。另一个进阶的想法是统计左上角 X 的个数</p><h3 id="151-Reverse-Words-in-a-String"><a href="#151-Reverse-Words-in-a-String" class="headerlink" title="151 Reverse Words in a String"></a>151 Reverse Words in a String</h3><p><a href="https://leetcode-cn.com/problems/reverse-words-in-a-string/">leetcode link</a></p><p>两行代码写完：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">reverseWords</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> s<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">str</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>s<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> <span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>s<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>注意这里使用的是 <code>split()</code> 而不是 <code>split(' ')</code>，二者有着细微的差别，如果有多个空格存在的话，后者分隔后会多出一些空字符串成员 <code>''</code>，而前者不会</p><h3 id="5-Longest-Palindromic-Substring"><a href="#5-Longest-Palindromic-Substring" class="headerlink" title="5 Longest Palindromic Substring"></a>5 Longest Palindromic Substring</h3><p><a href="https://leetcode-cn.com/problems/longest-palindromic-substring/">leetcode link</a></p><p>这一题给了我一个教训，如果长时间想不到好的方法，如果有一个平方时间复杂度的想法也应该尽快实现！这一题采用中心扩展法</p><h3 id="516-Longest-Palindromic-Subsequence"><a href="#516-Longest-Palindromic-Subsequence" class="headerlink" title="516 Longest Palindromic Subsequence"></a>516 Longest Palindromic Subsequence</h3><p><a href="https://leetcode-cn.com/problems/longest-palindromic-subsequence/">leetcode link</a></p><p>动态规划又给我上了一课：</p><ol><li>什么是状态：在确定条件下的问题的解（即子问题的解），并且状态需要是唯一的（或者说最优的）</li><li>状态转移：不同条件下的子问题之间的关联，这就是这一题的难点。状态转移的方向我习惯性地认为是两个状态之间的转移，实际上，一个复杂状态是由多个可能的子状态转移而来</li><li>状态转移的着力点在于：从简单到复杂的推演过程，或者从复杂到简单的退化过程</li></ol><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">longestPalindromeSubseq</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> s<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">int</span><span class="token punctuation">:</span>        n <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span>        dp <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">*</span> n <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">]</span>        <span class="token comment"># 不能用 [[0] * n] * n 因为这样列表中的成员指向的是同一个</span>        <span class="token comment"># 注意遍历顺序，需要从短到长的遍历，并且有一个倒序</span>        <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> n<span class="token punctuation">)</span><span class="token punctuation">:</span>            dp<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>            <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>j <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                <span class="token keyword">if</span> s<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">==</span> s<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">:</span>                    dp<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">=</span> dp<span class="token punctuation">[</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span>j <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token number">2</span>                <span class="token keyword">else</span><span class="token punctuation">:</span>                    dp<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token builtin">max</span><span class="token punctuation">(</span>dp<span class="token punctuation">[</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">,</span> dp<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> dp<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>n <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="647-Palindromic-Substrings"><a href="#647-Palindromic-Substrings" class="headerlink" title="647 Palindromic Substrings"></a>647 Palindromic Substrings</h3><p><a href="https://leetcode-cn.com/problems/palindromic-substrings/">leetcode link</a></p><p>这一题就是求出字符串中所有的回文字符串，这一题相当于第5题。我顺便使用动态规划把这一题给完成了，即判断某个字串是否是回文字符串</p><h3 id="336-Palindrome-Pairs"><a href="#336-Palindrome-Pairs" class="headerlink" title="336 Palindrome Pairs"></a>336 Palindrome Pairs</h3><p><a href="https://leetcode-cn.com/problems/palindrome-pairs/">leetcode link</a></p><p>显然不可能使用平方时间去做，这样的话大概率需要做 N 次，也就是说对每一个成员进行分析，根据分析结果将其分配到其属于的地方，而这个分配过程是一个 O(1) 的时间，这显然就需要用到字典，因为只有字典的查询时间才是最快的</p><p>这一题的虽然大体思路很快就拿出来了，但是其中的细节太多了，比如：如何找到需要的字串，使用前缀后缀的思想最快；遇到相同长度的会重复计算…</p><h3 id="115-Distinct-Subsequences"><a href="#115-Distinct-Subsequences" class="headerlink" title="115 Distinct Subsequences"></a>115 Distinct Subsequences</h3><p><a href="https://leetcode-cn.com/problems/distinct-subsequences/">leetcode link</a></p><p>使用了两种方法，第一种是递归的思路，很快就实现出来了，但是复杂度没有经过仔细考虑，答案超时。马上开始动态规划的思路，很快就联想到了增加状态的思路，也很快实现出来了，不过还是有一些边界条件需要进行考虑，没有考虑清楚。这里依然使用了与之前相同的策略：使得表格中的最左侧初始化为1</p><h3 id="334-Increasing-Triplet-Subsequence"><a href="#334-Increasing-Triplet-Subsequence" class="headerlink" title="334 Increasing Triplet Subsequence"></a>334 Increasing Triplet Subsequence</h3><p><a href="https://leetcode-cn.com/problems/increasing-triplet-subsequence/">leetcode link</a></p><p>这一题并不是特别常规，一开始想用单调栈，但后面发现单调栈并不好维护。之后直接通过三元组的特性解决了</p><h3 id="32-Longest-Valid-Parenthese"><a href="#32-Longest-Valid-Parenthese" class="headerlink" title="32 Longest Valid Parenthese"></a>32 Longest Valid Parenthese</h3><p><a href="https://leetcode-cn.com/problems/longest-valid-parentheses/">leetcode link</a></p><p>这一题首先想到的就是用动态规划来做，但是转移方程的讨论比较别扭，最终使用栈的方法来匹配括号，留下未匹配的括号，最后求得最长间隔即可</p><h3 id="301-Remove-Invalid-Parentheses"><a href="#301-Remove-Invalid-Parentheses" class="headerlink" title="301 Remove Invalid Parentheses"></a>301 Remove Invalid Parentheses</h3><p><a href="https://leetcode-cn.com/problems/remove-invalid-parentheses/">leetcode link</a></p><p>这一题竟然是直接用的搜索算法！大失误大失误，因为题目给的字符串长度是比较小的，几乎只能穷举，最终使用深度搜索完成</p><p>深度搜索又有了新的解题框架：在计算各种路径的时候，一个直观考虑是某个数字是否被选进路径当中，这样就省下一些循环，只需要记录搜索位置和路径即可</p><h3 id="443-String-Compression"><a href="#443-String-Compression" class="headerlink" title="443 String Compression"></a>443 String Compression</h3><p><a href="https://leetcode-cn.com/problems/string-compression/">leetcode link</a></p><p>这一题好像服务器的判定方法有点不一样，需要点击右下角的执行代码能够看到结果。好像也需要原地修改数组</p><h3 id="820-Short-Encoding-of-Words"><a href="#820-Short-Encoding-of-Words" class="headerlink" title="820 Short Encoding of Words"></a>820 Short Encoding of Words</h3><p><a href="https://leetcode-cn.com/problems/short-encoding-of-words/">leetcode link</a></p><p>这一题的题目描述真的很糟糕，理解了好几次才发现与顺序无关，如果发现理解错误过后应当从头来过，看有没有更简单的解法</p><p>最后通过总结其融合的规律，看一个字符串是否能否被融合</p><h3 id="49-Group-Anagrams"><a href="#49-Group-Anagrams" class="headerlink" title="49 Group Anagrams"></a>49 Group Anagrams</h3><p><a href="https://leetcode-cn.com/problems/group-anagrams/">leetcode link</a></p><p>这一题差一点又被这个异位词的概念给误导了。学习点：</p><ol><li>字符串是可以被 <code>sorted</code> 的，返回一个排好序的列表</li><li>字典和列表等可变类型是不可以作为关键字的</li><li><code>collection.defualtdict</code> 可以解决由于不存在关键字产生的报错，当关键字不存在时直接创建定义好的数据类型</li></ol><h3 id="3-Longest-Substring-Without-Repeating-Characters"><a href="#3-Longest-Substring-Without-Repeating-Characters" class="headerlink" title="3 Longest Substring Without Repeating Characters"></a>3 Longest Substring Without Repeating Characters</h3><p><a href="https://leetcode-cn.com/problems/longest-substring-without-repeating-characters/">leetcode link</a></p><p>双指针滑动窗口，没啥好说的</p><h3 id="76-Minimum-Window-Substring"><a href="#76-Minimum-Window-Substring" class="headerlink" title="76 Minimum Window Substring"></a>76 Minimum Window Substring</h3><p><a href="76 Minimum Window Substring">leetcode link</a></p><p>这也是典型的思路简单，但是写起来有比较多的细节的困难题。很容易就想到了双指针滑动窗口的写法，但是依然犯了很多错</p><h3 id="1004-Max-Consecutive-Ones"><a href="#1004-Max-Consecutive-Ones" class="headerlink" title="1004 Max Consecutive Ones |||"></a>1004 Max Consecutive Ones |||</h3><p><a href="https://leetcode-cn.com/problems/max-consecutive-ones-iii/">leetcode link</a></p><p>依然是双指针滑动窗口，滑动滑动！似乎双指针的特点：左右两端能够以清晰的条件进行移动，在过程中能够遍历出所有值，并求得最优</p><p>一路整下来还是挺伤的…之后不太能把每个板块都刷了…还是重点突击一下剑指offer吧！之后的秋招有时间再继续弄弄</p>]]></content>
      
      
      <categories>
          
          <category> 编程 </category>
          
          <category> Leetcode </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Leetcode </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Leetcode-diary 2</title>
      <link href="/archives/65138f4a.html"/>
      <url>/archives/65138f4a.html</url>
      
        <content type="html"><![CDATA[<h1 id="leetcode-diary-2"><a href="#leetcode-diary-2" class="headerlink" title="leetcode-diary 2"></a>leetcode-diary 2</h1><p>diary 1 &amp; diary 2 的目的是了解多种题型，没有深入</p><h2 id="DFS-amp-BFS"><a href="#DFS-amp-BFS" class="headerlink" title="DFS &amp; BFS"></a>DFS &amp; BFS</h2><p>在进行刷题之前，有必要小小总结一下深度优先搜索（Depth First Search, DFS）和广度优先搜索（Broad First Search, BFS）</p><p>两个搜索除了深度和广度两个重要概念外，还需要更多的关键概念：</p><ol><li>候选元素 candidates，存储与节点联系的其他节点。这些节点将作为 candidates 在未来进行遍历</li><li>访问状态 visited，存储节点是否被经过的状态</li><li>目标 target</li></ol><p><strong>深度优先</strong>我自己总结为：逐层循环中嵌套递归（递归+回溯？</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># grpah[v] 存储节点 v 的相邻节点</span><span class="token keyword">def</span> <span class="token function">DFS</span><span class="token punctuation">(</span>v<span class="token punctuation">,</span> visited<span class="token punctuation">)</span><span class="token punctuation">:</span>    visited<span class="token punctuation">[</span>v<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">True</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>v<span class="token punctuation">,</span> end<span class="token operator">=</span><span class="token string">' '</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> neighbour <span class="token keyword">in</span> graph<span class="token punctuation">[</span>v<span class="token punctuation">]</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> visited<span class="token punctuation">[</span>neighbour<span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token boolean">False</span><span class="token punctuation">:</span>            DFS<span class="token punctuation">(</span>neighbour<span class="token punctuation">,</span> visited<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>广度优先</strong>总结为：使用容器，逐层循环，直至容器为空</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># graph[v] 存储节点 v 的相邻节点</span><span class="token keyword">def</span> <span class="token function">BFS</span><span class="token punctuation">(</span>v<span class="token punctuation">,</span> graph<span class="token punctuation">,</span> visited<span class="token punctuation">)</span><span class="token punctuation">:</span>    container <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    container<span class="token punctuation">.</span>append<span class="token punctuation">(</span>v<span class="token punctuation">)</span>    visited<span class="token punctuation">[</span>v<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">True</span>    <span class="token keyword">while</span> container<span class="token punctuation">:</span>        v <span class="token operator">=</span> container<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>v<span class="token punctuation">,</span> end<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">)</span>        <span class="token keyword">for</span> v_ <span class="token keyword">in</span> graph<span class="token punctuation">[</span>v<span class="token punctuation">]</span><span class="token punctuation">:</span>            <span class="token keyword">if</span> visited<span class="token punctuation">[</span>v_<span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token boolean">False</span><span class="token punctuation">:</span>                container<span class="token punctuation">.</span>append<span class="token punctuation">(</span>v_<span class="token punctuation">)</span>                visited<span class="token punctuation">[</span>v_<span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token boolean">True</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>以上的代码仅体现思想，并没有 return 任何值，而且仅仅是使用了遍历图的特例，具体情况需要具体分析</p><h3 id="40-Combination-Sum-ii"><a href="#40-Combination-Sum-ii" class="headerlink" title="40 Combination Sum ii"></a>40 Combination Sum ii</h3><p><a href="https://leetcode-cn.com/problems/combination-sum-ii/">leetcode link</a></p><p>这一题其实有很多的东西需要学习。我这里简要总结一下：</p><ol><li><p>python 的 nonlocal &amp; global 关键字作用。二者的作用是相似，都可以将变量的命名空间延长到“局部”，<a href="https://zhuanlan.zhihu.com/p/341378844">知乎</a></p></li><li><p>copy 是 shallow copy，对于列表来讲只拷贝顶层，考虑使用副本的时候可以使用，<a href="https://www.runoob.com/python3/python3-att-list-copy.html">菜鸟教程</a></p></li><li><p>列表的 + 运算符一般会创造一个新的列表对象，如果想要原地修改列表有几个选择：</p><ol><li>append</li><li>+= 运算也能够原地修改</li><li>List[:] 切片修改</li></ol><pre class="line-numbers language-python" data-language="python"><code class="language-python">a <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">id</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># 2588593621952</span>a <span class="token operator">+=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">id</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># 2588593621952</span>a <span class="token operator">=</span> a <span class="token operator">+</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">id</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># 2588593875520</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ol><p>更需要学习的其实是深度搜索的思想：</p><ol><li>给一个清晰的定义：从某个节点开始遍历所有的</li><li>剪枝是一个节省计算资源的重要操作，不仅是 visited 记录状态，还排除不可能的搜索空间</li></ol><p>深度搜索的思想，还需要进一步的理解，尤其是对于<strong>回溯</strong>时候的操作</p><ol><li><p>之前关于 copy 的矛盾来自于一个赋值操作（实际上是让指针指向了 copy 对象，从而之后都修改了 copy 对象）</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">combinationSum2</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> candidates<span class="token punctuation">:</span> List<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span><span class="token punctuation">,</span> target<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> List<span class="token punctuation">[</span>List<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">:</span>        <span class="token keyword">from</span> collections <span class="token keyword">import</span> Counter        counter <span class="token operator">=</span> Counter<span class="token punctuation">(</span>candidates<span class="token punctuation">)</span>        uniq_cand <span class="token operator">=</span> <span class="token builtin">sorted</span><span class="token punctuation">(</span>counter<span class="token punctuation">)</span>        ans <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">def</span> <span class="token function">dfs</span><span class="token punctuation">(</span>pos<span class="token punctuation">,</span> sub_ans<span class="token punctuation">:</span> List<span class="token punctuation">,</span> target<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">if</span> target <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>                ans<span class="token punctuation">.</span>append<span class="token punctuation">(</span>sub_ans<span class="token punctuation">)</span>                <span class="token keyword">return</span>            <span class="token keyword">if</span> pos <span class="token operator">==</span> <span class="token builtin">len</span><span class="token punctuation">(</span>uniq_cand<span class="token punctuation">)</span> <span class="token keyword">or</span> uniq_cand<span class="token punctuation">[</span>pos<span class="token punctuation">]</span> <span class="token operator">&gt;</span> target<span class="token punctuation">:</span>                <span class="token keyword">return</span>            origin_sub <span class="token operator">=</span> sub_ans<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token keyword">for</span> pos_ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>pos<span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>uniq_cand<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                num <span class="token operator">=</span> uniq_cand<span class="token punctuation">[</span>pos_<span class="token punctuation">]</span>                freq <span class="token operator">=</span> counter<span class="token punctuation">[</span>num<span class="token punctuation">]</span>                repeat <span class="token operator">=</span> <span class="token builtin">min</span><span class="token punctuation">(</span>freq<span class="token punctuation">,</span> target <span class="token operator">//</span> num<span class="token punctuation">)</span>                <span class="token keyword">for</span> r_ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> repeat <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                    sub_ans <span class="token operator">+=</span> <span class="token punctuation">[</span>num<span class="token punctuation">]</span> <span class="token operator">*</span> r_                    dfs<span class="token punctuation">(</span>pos_ <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> sub_ans<span class="token punctuation">,</span> target <span class="token operator">-</span> num <span class="token operator">*</span> r_<span class="token punctuation">)</span>                    sub_ans <span class="token operator">=</span> origin_sub        dfs<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> target<span class="token punctuation">)</span>        <span class="token keyword">return</span> ans<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>如果需要修改原对象，需要使用方法 <code>sub_ans[:] = sub_ans[:-r_]</code> 否则会返回新的对象/新的 id，<code>a = sub_ans[:]</code> 和 <code>a = sub_ans.copy()</code> 是等效的</p></li><li><p>加号 + 和 append 对于 list 的区别：+ 一般会创建一个新的对象，而 append 不会，并且 append 速度更快，但是 += 方法不会创建新的对象</p></li><li><p>nonlocal 和 global 是相似的，只是使用场合不同</p></li></ol><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">combinationSum2</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> candidates<span class="token punctuation">:</span> List<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span><span class="token punctuation">,</span> target<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> List<span class="token punctuation">[</span>List<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">:</span>        <span class="token keyword">from</span> collections <span class="token keyword">import</span> Counter        counter <span class="token operator">=</span> Counter<span class="token punctuation">(</span>candidates<span class="token punctuation">)</span>        uniq_cand <span class="token operator">=</span> <span class="token builtin">sorted</span><span class="token punctuation">(</span>counter<span class="token punctuation">)</span>        ans <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">def</span> <span class="token function">dfs</span><span class="token punctuation">(</span>pos<span class="token punctuation">,</span> sub_ans<span class="token punctuation">:</span> List<span class="token punctuation">,</span> target<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">if</span> target <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>                ans<span class="token punctuation">.</span>append<span class="token punctuation">(</span>sub_ans<span class="token punctuation">)</span>                <span class="token keyword">return</span>            <span class="token keyword">if</span> pos <span class="token operator">==</span> <span class="token builtin">len</span><span class="token punctuation">(</span>uniq_cand<span class="token punctuation">)</span> <span class="token keyword">or</span> uniq_cand<span class="token punctuation">[</span>pos<span class="token punctuation">]</span> <span class="token operator">&gt;</span> target<span class="token punctuation">:</span>                <span class="token keyword">return</span>            <span class="token keyword">for</span> pos_ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>pos<span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>uniq_cand<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                num <span class="token operator">=</span> uniq_cand<span class="token punctuation">[</span>pos_<span class="token punctuation">]</span>                freq <span class="token operator">=</span> counter<span class="token punctuation">[</span>num<span class="token punctuation">]</span>                repeat <span class="token operator">=</span> <span class="token builtin">min</span><span class="token punctuation">(</span>freq<span class="token punctuation">,</span> target <span class="token operator">//</span> num<span class="token punctuation">)</span>                <span class="token keyword">for</span> r_ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> repeat <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                    sub_ans_copy <span class="token operator">=</span> sub_ans<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>                    sub_ans_copy <span class="token operator">+=</span> <span class="token punctuation">[</span>num<span class="token punctuation">]</span> <span class="token operator">*</span> r_                    dfs<span class="token punctuation">(</span>pos_ <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> sub_ans_copy<span class="token punctuation">,</span> target <span class="token operator">-</span> num <span class="token operator">*</span> r_<span class="token punctuation">)</span>        dfs<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> target<span class="token punctuation">)</span>        <span class="token keyword">return</span> ans<span class="token comment"># 我的最终版本</span><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">combinationSum2</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> candidates<span class="token punctuation">:</span> List<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span><span class="token punctuation">,</span> target<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> List<span class="token punctuation">[</span>List<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">:</span>        uniq_cand <span class="token operator">=</span> <span class="token builtin">sorted</span><span class="token punctuation">(</span>collections<span class="token punctuation">.</span>Counter<span class="token punctuation">(</span>candidates<span class="token punctuation">)</span><span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        ans <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        sub_ans <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">def</span> <span class="token function">dfs</span><span class="token punctuation">(</span>pos<span class="token punctuation">,</span> target<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">nonlocal</span> sub_ans            <span class="token keyword">if</span> target <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>                ans<span class="token punctuation">.</span>append<span class="token punctuation">(</span>sub_ans<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>                <span class="token keyword">return</span>            <span class="token keyword">if</span> pos <span class="token operator">==</span> <span class="token builtin">len</span><span class="token punctuation">(</span>uniq_cand<span class="token punctuation">)</span> <span class="token keyword">or</span> uniq_cand<span class="token punctuation">[</span>pos<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">&gt;</span> target<span class="token punctuation">:</span>                <span class="token keyword">return</span>            <span class="token keyword">for</span> pos_ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>pos<span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>uniq_cand<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                num <span class="token operator">=</span> uniq_cand<span class="token punctuation">[</span>pos_<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>                freq <span class="token operator">=</span> uniq_cand<span class="token punctuation">[</span>pos_<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>                repeat <span class="token operator">=</span> <span class="token builtin">min</span><span class="token punctuation">(</span>freq<span class="token punctuation">,</span> target <span class="token operator">//</span> num<span class="token punctuation">)</span>                <span class="token keyword">for</span> r_ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> repeat <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                    sub_ans <span class="token operator">+=</span> <span class="token punctuation">[</span>num<span class="token punctuation">]</span> <span class="token operator">*</span> r_                    dfs<span class="token punctuation">(</span>pos_ <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> target <span class="token operator">-</span> num <span class="token operator">*</span> r_<span class="token punctuation">)</span>                    sub_ans<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> sub_ans<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span>r_<span class="token punctuation">]</span>        dfs<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> target<span class="token punctuation">)</span>        <span class="token keyword">return</span> ans<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="Stack"><a href="#Stack" class="headerlink" title="Stack"></a>Stack</h2><h3 id="225-amp-232-Implement-Stack-using-Queues-amp-vice-versa"><a href="#225-amp-232-Implement-Stack-using-Queues-amp-vice-versa" class="headerlink" title="225 &amp; 232 Implement Stack using Queues &amp; vice versa"></a>225 &amp; 232 Implement Stack using Queues &amp; vice versa</h3><p><a href="https://leetcode-cn.com/problems/implement-stack-using-queues/solution/yong-dui-lie-shi-xian-zhan-by-leetcode-solution/">leetcode link</a></p><h3 id="150-Evaluate-Reverse-Polish-Notation"><a href="#150-Evaluate-Reverse-Polish-Notation" class="headerlink" title="150 Evaluate Reverse Polish Notation"></a>150 Evaluate Reverse Polish Notation</h3><p><a href="https://leetcode-cn.com/problems/evaluate-reverse-polish-notation/">leetcode link</a></p><p>之前接触过类似的题，所以做起来很快，使用栈来计算。注意使用 int 来进行整数转换</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">evalRPN</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> tokens<span class="token punctuation">:</span> List<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">int</span><span class="token punctuation">:</span>        symbol <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'+'</span><span class="token punctuation">,</span> <span class="token string">'-'</span><span class="token punctuation">,</span> <span class="token string">'*'</span><span class="token punctuation">,</span> <span class="token string">'/'</span><span class="token punctuation">]</span>        stack <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> <span class="token builtin">input</span> <span class="token keyword">in</span> tokens<span class="token punctuation">:</span>            <span class="token keyword">if</span> <span class="token builtin">input</span> <span class="token keyword">in</span> symbol<span class="token punctuation">:</span>                b <span class="token operator">=</span> stack<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token punctuation">)</span>                a <span class="token operator">=</span> stack<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token punctuation">)</span>                <span class="token keyword">if</span> <span class="token builtin">input</span> <span class="token operator">==</span> <span class="token string">'+'</span><span class="token punctuation">:</span>                    c <span class="token operator">=</span> a <span class="token operator">+</span> b                <span class="token keyword">elif</span> <span class="token builtin">input</span> <span class="token operator">==</span> <span class="token string">'-'</span><span class="token punctuation">:</span>                    c <span class="token operator">=</span> a <span class="token operator">-</span> b                <span class="token keyword">elif</span> <span class="token builtin">input</span> <span class="token operator">==</span> <span class="token string">'*'</span><span class="token punctuation">:</span>                    c <span class="token operator">=</span> a <span class="token operator">*</span> b                <span class="token keyword">else</span><span class="token punctuation">:</span>                    c <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>a <span class="token operator">/</span> b<span class="token punctuation">)</span>                stack<span class="token punctuation">.</span>append<span class="token punctuation">(</span>c<span class="token punctuation">)</span>            <span class="token keyword">else</span><span class="token punctuation">:</span>                stack<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> stack<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="PriorityQueue"><a href="#PriorityQueue" class="headerlink" title="PriorityQueue"></a>PriorityQueue</h2><h3 id="347-Top-K-Frequent-Elements"><a href="#347-Top-K-Frequent-Elements" class="headerlink" title="347 Top K Frequent Elements"></a>347 Top K Frequent Elements</h3><p><a href="https://leetcode-cn.com/problems/top-k-frequent-elements/submissions/">leetcode link</a></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">topKFrequent</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> nums<span class="token punctuation">:</span> List<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span><span class="token punctuation">,</span> k<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> List<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span><span class="token punctuation">:</span>        <span class="token keyword">from</span> collections <span class="token keyword">import</span> Counter        counter <span class="token operator">=</span> Counter<span class="token punctuation">(</span>nums<span class="token punctuation">)</span>        top_k <span class="token operator">=</span> counter<span class="token punctuation">.</span>most_common<span class="token punctuation">(</span>k<span class="token punctuation">)</span>        <span class="token keyword">return</span> <span class="token punctuation">[</span>obj<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token keyword">for</span> obj <span class="token keyword">in</span> top_k<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="973-K-Closest-Points-to-Origin"><a href="#973-K-Closest-Points-to-Origin" class="headerlink" title="973 K Closest Points to Origin"></a>973 K Closest Points to Origin</h3><p><a href="https://leetcode-cn.com/problems/k-closest-points-to-origin/">leetcode link</a></p><p>了解 sorted 的 key 怎么用</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">kClosest</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> points<span class="token punctuation">:</span> List<span class="token punctuation">[</span>List<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> k<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> List<span class="token punctuation">[</span>List<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">:</span>        sort <span class="token operator">=</span> <span class="token builtin">sorted</span><span class="token punctuation">(</span>points<span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">**</span><span class="token number">2</span> <span class="token operator">+</span> x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">**</span><span class="token number">2</span><span class="token punctuation">)</span>        top_k <span class="token operator">=</span> <span class="token punctuation">[</span>sort<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>k<span class="token punctuation">)</span><span class="token punctuation">]</span>        <span class="token keyword">return</span> top_k<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>使用<strong>堆</strong>数据结构可以降低复杂度，到 O(nlogk)，下面简单介绍一下堆：</p><ul><li>堆总是一棵完全二叉树</li><li>堆中某个结点的值总是不大于或不小于其父结点的值</li></ul><p>堆有3个常用操作：1. 插入数据 insert 2. 删除堆顶 pop 3. 获得堆顶 peak</p><h2 id="DP"><a href="#DP" class="headerlink" title="DP"></a>DP</h2><h3 id="120-Triangle"><a href="#120-Triangle" class="headerlink" title="120 Triangle"></a>120 Triangle</h3><p><a href="https://leetcode-cn.com/problems/triangle/">leetcode link</a></p><p>函数的自调用可以有两个不同的作用：</p><ol><li>形成递归，以数学归纳法的方式。需要解决最简单的情况</li><li>形成深度搜索，进行状态转移</li></ol><p>数学归纳法的形式比较直观，深度搜索的代码就没有那么直觉了。这里总结一些深度搜索中的重要元素：</p><ol><li>初始状态 initial status</li><li>条件 conditions，停止搜索的条件，通常用于剪枝</li><li>目标 target，搜索的目标，也是停止搜索的条件</li><li>答案 solution，通常为搜索路径</li></ol><p>但是动态规划一般不需要自调用，只需要循环。因为自调用形成递归被 memoization 替代，具体来说是被一个数组替代，这个数组存储了最优子问题的答案。这样看来动态规划更像是一种迭代</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">minimumTotal</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> triangle<span class="token punctuation">:</span> List<span class="token punctuation">[</span>List<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">int</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>triangle<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">if</span> i <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>                <span class="token keyword">continue</span>            <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>triangle<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                <span class="token keyword">if</span> j <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>                    right <span class="token operator">=</span> triangle<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">+</span> triangle<span class="token punctuation">[</span>i <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span>                    triangle<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">=</span> right                <span class="token keyword">elif</span> j <span class="token operator">==</span> i <span class="token operator">-</span> <span class="token number">1</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">:</span>                    left <span class="token operator">=</span> triangle<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">+</span> triangle<span class="token punctuation">[</span>i <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span>j <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>                    triangle<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">=</span> left                <span class="token keyword">else</span><span class="token punctuation">:</span>                    triangle<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token builtin">min</span><span class="token punctuation">(</span>triangle<span class="token punctuation">[</span>i <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span>j <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> triangle<span class="token punctuation">[</span>i <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> <span class="token builtin">min</span><span class="token punctuation">(</span>triangle<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="518-Coin-Change-2"><a href="#518-Coin-Change-2" class="headerlink" title="518 Coin Change 2"></a>518 Coin Change 2</h3><p><a href="https://leetcode-cn.com/problems/coin-change-2/">leetcode link</a></p><p>看到这一题，我首先想到的就是 40 题，先用搜索的方法实现了一遍，顺便复习了一下深度搜索</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">change</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> amount<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span> coins<span class="token punctuation">:</span> List<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">int</span><span class="token punctuation">:</span>        num <span class="token operator">=</span> <span class="token number">0</span>        n <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>coins<span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">search</span><span class="token punctuation">(</span>pos<span class="token punctuation">,</span> target<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">nonlocal</span> num            <span class="token keyword">if</span> target <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>                <span class="token comment"># 判定 target</span>                num <span class="token operator">+=</span> <span class="token number">1</span>                <span class="token keyword">return</span>            <span class="token keyword">if</span> pos <span class="token operator">==</span> n <span class="token keyword">or</span> coins<span class="token punctuation">[</span>pos<span class="token punctuation">]</span> <span class="token operator">&gt;</span> target<span class="token punctuation">:</span>                <span class="token comment"># 剪枝</span>                <span class="token keyword">return</span>            <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>pos<span class="token punctuation">,</span> n<span class="token punctuation">)</span><span class="token punctuation">:</span>                <span class="token comment"># 子搜索空间</span>                times <span class="token operator">=</span> target <span class="token operator">//</span> coins<span class="token punctuation">[</span>i<span class="token punctuation">]</span>                <span class="token keyword">for</span> r_ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> times <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                    <span class="token comment"># 子搜索空间中的状态转移</span>                    search<span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> target <span class="token operator">-</span> r_ <span class="token operator">*</span> coins<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>        search<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> amount<span class="token punctuation">)</span>        <span class="token keyword">return</span> num<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>最终时间超时，想了很久都没有结果，于是乎只能看解答，这样才能感受动态规划的魔力啊</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">change</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> amount<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span> coins<span class="token punctuation">:</span> List<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">int</span><span class="token punctuation">:</span>                dp <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token punctuation">(</span>amount<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span>        dp<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>coins<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>coins<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> amount<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                dp<span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">+=</span> dp<span class="token punctuation">[</span>j <span class="token operator">-</span> coins<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">]</span>        <span class="token keyword">return</span> dp<span class="token punctuation">[</span>amount<span class="token punctuation">]</span>    <span class="token comment"># small case looks like this</span>        <span class="token comment">#       amount 1 2 3 4 5</span>        <span class="token comment"># coin1        1 1 1 1 1</span>        <span class="token comment"># coin2        1 2 2 3 3</span>        <span class="token comment"># coin5        1 2 2 3 4</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>简短的几行代码直接秒杀通关…当然思想咱还是要学一学，首先看看自己的思路差在哪里：当放弃使用深度搜索采用动态规划时，我需要先定义状态，很自然地就想到以 coins 为状态，但是这个思路很快就被否定了…因为假设已知子问题 coins’ 的答案，基于此再添加一个新的面额，也很难得到问题的答案。事实上问题就出在对于状态的定义，似乎不够详细，巧妇难为无米之炊！如果知道 coins’ 在 1~amount 所有数值的组合数，是否可以得到问题的答案呢？这是可以的</p><p>假设有 <code>amount = 500, coins = [3,5,7,8,9,10]</code>，已知 <code>coins' = [3,5,7,8,9]</code> 从 1~500 的所有 amount 的组合数，记为 <code>dp, len(dp) = 500</code>。先从简单的情况开始，然后逐步递进：</p><ol><li>硬币面值只使用一次：结果为 <code>result = dp[490] + dp[500]</code>，也就是说是和为500的组合数，加上和为490的组合数（因为新加入了面值为10的硬币）</li><li>接下来就有灵感了，如果硬币面值能使用两次：结果为 <code>result = dp[480] + dp[490] + dp[500]</code></li><li>如果硬币面值能不限次数的使用：结果为 <code>result = dp[10] + ... + dp[500]</code></li><li>为了让所有的状态都进行更新，除了计算 <code>amount = 500</code> 的结果，还需要计算 <code>amount = 1~499</code> 的结果</li></ol><p>这里的状态和之前的不太一样，感觉多了一个<strong>维度</strong>，拓展了可使用的子结构</p><h3 id="64-Minimum-Path-Sum"><a href="#64-Minimum-Path-Sum" class="headerlink" title="64 Minimum Path Sum"></a>64 Minimum Path Sum</h3><p><a href="https://leetcode-cn.com/problems/minimum-path-sum/">leetcode link</a></p><p>没啥好说的，跟120题一样的</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">minPathSum</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> grid<span class="token punctuation">:</span> List<span class="token punctuation">[</span>List<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">int</span><span class="token punctuation">:</span>        m <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>grid<span class="token punctuation">)</span>        n <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>grid<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>m<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">:</span>                <span class="token keyword">if</span> i <span class="token operator">==</span> <span class="token number">0</span> <span class="token keyword">and</span> j <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>                    <span class="token keyword">continue</span>                up<span class="token punctuation">,</span> left <span class="token operator">=</span> i <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">,</span> j <span class="token operator">-</span> <span class="token number">1</span>                <span class="token keyword">if</span> up <span class="token operator">&lt;</span> <span class="token number">0</span><span class="token punctuation">:</span>                    grid<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">+=</span> grid<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>left<span class="token punctuation">]</span>                <span class="token keyword">elif</span> left <span class="token operator">&lt;</span> <span class="token number">0</span><span class="token punctuation">:</span>                    grid<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">+=</span> grid<span class="token punctuation">[</span>up<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span>                <span class="token keyword">else</span><span class="token punctuation">:</span>                    grid<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token builtin">min</span><span class="token punctuation">(</span>grid<span class="token punctuation">[</span>up<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">,</span>grid<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>left<span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> grid<span class="token punctuation">[</span>m<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span>n<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="Bit-Manipulation"><a href="#Bit-Manipulation" class="headerlink" title="Bit Manipulation"></a>Bit Manipulation</h2><h3 id="421-Maximum-XOR-of-Two-Numbers-in-an-Array"><a href="#421-Maximum-XOR-of-Two-Numbers-in-an-Array" class="headerlink" title="421 Maximum XOR of Two Numbers in an Array"></a>421 Maximum XOR of Two Numbers in an Array</h3><p><a href="https://leetcode-cn.com/problems/maximum-xor-of-two-numbers-in-an-array/">leetcode link</a></p><p>这块知识真心不会，虽然实现了暴力解法，但时间超太多了，直接上参考链接：<a href="https://leetcode-cn.com/problems/maximum-xor-of-two-numbers-in-an-array/solution/li-yong-yi-huo-yun-suan-de-xing-zhi-tan-xin-suan-f/">leetcode</a>, <a href="https://www.bilibili.com/video/BV15q4y1L7n9?from=search&amp;seid=1379165254846016152">bilibili</a></p><p>关于 python 位运算：<a href="https://www.bilibili.com/video/BV16K41137ZM?from=search&amp;seid=1575516065609888964">bilibili</a>，<code>&lt;&lt;, &gt;&gt;, ~, &amp;, |, ^</code></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">findMaximumXOR</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> nums<span class="token punctuation">:</span> List<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">int</span><span class="token punctuation">:</span>        res <span class="token operator">=</span> <span class="token number">0</span>        mask <span class="token operator">=</span> <span class="token number">0</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">30</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            mask <span class="token operator">|</span><span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">&lt;&lt;</span> i<span class="token punctuation">)</span>            <span class="token comment"># 当前得到的所有前缀都放在这个哈希表中</span>            s <span class="token operator">=</span> <span class="token builtin">set</span><span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token keyword">for</span> num <span class="token keyword">in</span> nums<span class="token punctuation">:</span>                s<span class="token punctuation">.</span>add<span class="token punctuation">(</span>mask <span class="token operator">&amp;</span> num<span class="token punctuation">)</span>            <span class="token comment"># 先“贪心地”假设这个数位上是 “1” ，如果全部前缀都看完，都不符合条件，这个数位上就是 “0” </span>            temp <span class="token operator">=</span> res <span class="token operator">|</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">&lt;&lt;</span> i<span class="token punctuation">)</span>            <span class="token keyword">for</span> prefix <span class="token keyword">in</span> s<span class="token punctuation">:</span>                <span class="token keyword">if</span> temp <span class="token operator">^</span> prefix <span class="token keyword">in</span> s<span class="token punctuation">:</span>                    res <span class="token operator">=</span> temp                    <span class="token keyword">break</span>        <span class="token keyword">return</span> res<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="89-Gray-Code"><a href="#89-Gray-Code" class="headerlink" title="89 Gray Code"></a>89 Gray Code</h3><p><a href="https://leetcode-cn.com/problems/gray-code/">leetcode link</a></p><p>这一题有两种思路，一个是自己想的逐步插入推导，另一个就是参考答案中的镜像法</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">grayCode</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> n<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> List<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> n <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span>        <span class="token keyword">def</span> <span class="token function">expand</span><span class="token punctuation">(</span>idx<span class="token punctuation">,</span> num<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">if</span> idx <span class="token operator">%</span> <span class="token number">2</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>                <span class="token keyword">return</span> <span class="token punctuation">[</span>num <span class="token operator">&lt;&lt;</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>num <span class="token operator">&lt;&lt;</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span>            <span class="token keyword">else</span><span class="token punctuation">:</span>                <span class="token keyword">return</span> <span class="token punctuation">[</span><span class="token punctuation">(</span>num <span class="token operator">&lt;&lt;</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> num <span class="token operator">&lt;&lt;</span> <span class="token number">1</span><span class="token punctuation">]</span>        sub <span class="token operator">=</span> self<span class="token punctuation">.</span>grayCode<span class="token punctuation">(</span>n <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span>        ret <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>sub<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            ret <span class="token operator">+=</span> expand<span class="token punctuation">(</span>i<span class="token punctuation">,</span> sub<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> ret<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>另一个思路，速度一样，但是代码更简单</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">        <span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">grayCode</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> n<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> List<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> n <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span>        sub <span class="token operator">=</span> self<span class="token punctuation">.</span>grayCode<span class="token punctuation">(</span>n <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span>        rev <span class="token operator">=</span> <span class="token punctuation">[</span>num <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">&lt;&lt;</span><span class="token punctuation">(</span>n<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">for</span> num <span class="token keyword">in</span> sub<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span>        <span class="token keyword">return</span> sub <span class="token operator">+</span> rev<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>注意其中的位运算只是计算了 $2^{n-1}$，但速度更快</p><h3 id="190-Reverse-Bits"><a href="#190-Reverse-Bits" class="headerlink" title="190 Reverse Bits"></a>190 Reverse Bits</h3><p><a href="https://leetcode-cn.com/problems/reverse-bits/">leetcode link</a></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">reverseBits</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> n<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">int</span><span class="token punctuation">:</span>        ret <span class="token operator">=</span> <span class="token number">0</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token comment"># 获得第 i 位置的数</span>            <span class="token keyword">if</span> n <span class="token operator">&amp;</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">&lt;&lt;</span> i<span class="token punctuation">)</span><span class="token punctuation">:</span>                ret <span class="token operator">=</span> ret <span class="token operator">|</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">&lt;&lt;</span> <span class="token punctuation">(</span><span class="token number">31</span> <span class="token operator">-</span> i<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> retn <span class="token operator">=</span> <span class="token number">0b00000010100101000001111010011100</span><span class="token comment"># python 表示二进制</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="191-Number-of-1-Bits"><a href="#191-Number-of-1-Bits" class="headerlink" title="191 Number of 1 Bits"></a>191 Number of 1 Bits</h3><p><a href="https://leetcode-cn.com/problems/number-of-1-bits/">leetcode link</a></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">hammingWeight</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> n<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">int</span><span class="token punctuation">:</span>        ret <span class="token operator">=</span> <span class="token number">0</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">if</span> n <span class="token operator">&amp;</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">&lt;&lt;</span> i<span class="token punctuation">)</span><span class="token punctuation">:</span>               ret <span class="token operator">+=</span> <span class="token number">1</span>        <span class="token keyword">return</span> ret <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="201-Bitwise-AND-of-Numbers-Range"><a href="#201-Bitwise-AND-of-Numbers-Range" class="headerlink" title="201 Bitwise AND of Numbers Range"></a>201 Bitwise AND of Numbers Range</h3><p><a href="https://leetcode-cn.com/problems/bitwise-and-of-numbers-range/">leetcode link</a></p><p>两个思路：</p><ol><li>找 left 和 right 的公共前缀</li><li>查看每一位是否有可能为0</li></ol><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">rangeBitwiseAnd</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> m<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span> n<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">int</span><span class="token punctuation">:</span>        shift <span class="token operator">=</span> <span class="token number">0</span>           <span class="token comment"># 找到公共前缀</span>        <span class="token keyword">while</span> m <span class="token operator">&lt;</span> n<span class="token punctuation">:</span>            m <span class="token operator">=</span> m <span class="token operator">&gt;&gt;</span> <span class="token number">1</span>            n <span class="token operator">=</span> n <span class="token operator">&gt;&gt;</span> <span class="token number">1</span>            shift <span class="token operator">+=</span> <span class="token number">1</span>        <span class="token keyword">return</span> m <span class="token operator">&lt;&lt;</span> shift<span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">rangeBitwiseAnd</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> left<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span> right<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">int</span><span class="token punctuation">:</span>        <span class="token comment"># 逐个某个位是否会经过零，那么我们就假定这个位为0，来看看什么会发生</span>        <span class="token comment"># 如果这个位高于 right 则必定为0，如果低于 right，则需要看 left 决定是否能经过 0</span>        <span class="token comment"># 实际上将 right 这一位数字变为0，后面的数字全为 1，如果这个数字小于 left 则这一位不能经过0，反之一定能经过0</span>        ret <span class="token operator">=</span> <span class="token number">0</span>        mask <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">&lt;&lt;</span> <span class="token number">32</span> <span class="token operator">-</span> <span class="token number">1</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            mask <span class="token operator">=</span> mask <span class="token operator">&gt;&gt;</span> <span class="token number">1</span>            <span class="token keyword">if</span> right <span class="token operator">&lt;</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">&lt;&lt;</span> <span class="token punctuation">(</span>i <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">or</span> left <span class="token operator">&lt;</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">&lt;&lt;</span> <span class="token punctuation">(</span>i <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                <span class="token keyword">continue</span>            <span class="token keyword">if</span> right <span class="token operator">&amp;</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">&lt;&lt;</span> <span class="token punctuation">(</span>i <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                tempt <span class="token operator">=</span> right <span class="token operator">^</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">&lt;&lt;</span> <span class="token punctuation">(</span>i <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>                tempt <span class="token operator">=</span> tempt <span class="token operator">|</span> mask                <span class="token keyword">if</span> tempt <span class="token operator">&lt;</span> left<span class="token punctuation">:</span>                    ret <span class="token operator">+=</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">&lt;&lt;</span> <span class="token punctuation">(</span>i <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> ret<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="Graph"><a href="#Graph" class="headerlink" title="Graph"></a>Graph</h2><h3 id="785-Is-Graph-Bipartite"><a href="#785-Is-Graph-Bipartite" class="headerlink" title="785 Is Graph Bipartite?"></a>785 Is Graph Bipartite?</h3><p><a href="https://leetcode-cn.com/problems/is-graph-bipartite/">leetcode link</a></p><p>这题一看就是需要使用并查集的思想，再加上深度搜索就解决了</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">isBipartite</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> graph<span class="token punctuation">:</span> List<span class="token punctuation">[</span>List<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">bool</span><span class="token punctuation">:</span>        n <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>graph<span class="token punctuation">)</span>        status <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">]</span>        ret <span class="token operator">=</span> <span class="token boolean">True</span>        <span class="token keyword">def</span> <span class="token function">dfs</span><span class="token punctuation">(</span>node<span class="token punctuation">,</span> status<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">nonlocal</span> ret            <span class="token keyword">for</span> neighbor <span class="token keyword">in</span> graph<span class="token punctuation">[</span>node<span class="token punctuation">]</span><span class="token punctuation">:</span>                <span class="token keyword">if</span> status<span class="token punctuation">[</span>node<span class="token punctuation">]</span><span class="token punctuation">:</span>                    <span class="token keyword">if</span> status<span class="token punctuation">[</span>neighbor<span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>                        <span class="token keyword">return</span> <span class="token boolean">False</span>                    <span class="token keyword">elif</span> status<span class="token punctuation">[</span>neighbor<span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span>                        status<span class="token punctuation">[</span>neighbor<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>                        ret <span class="token operator">=</span> dfs<span class="token punctuation">(</span>neighbor<span class="token punctuation">,</span> status<span class="token punctuation">)</span>                <span class="token keyword">else</span><span class="token punctuation">:</span>                    <span class="token keyword">if</span> status<span class="token punctuation">[</span>neighbor<span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>                        <span class="token keyword">return</span> <span class="token boolean">False</span>                    <span class="token keyword">elif</span> status<span class="token punctuation">[</span>neighbor<span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span>                        status<span class="token punctuation">[</span>neighbor<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>                        ret <span class="token operator">=</span> dfs<span class="token punctuation">(</span>neighbor<span class="token punctuation">,</span> status<span class="token punctuation">)</span>            <span class="token keyword">return</span> ret        <span class="token keyword">while</span> <span class="token operator">-</span><span class="token number">1</span> <span class="token keyword">in</span> status<span class="token punctuation">:</span>            node <span class="token operator">=</span> status<span class="token punctuation">.</span>index<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>            status<span class="token punctuation">[</span>node<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>            ret <span class="token operator">=</span> dfs<span class="token punctuation">(</span>node<span class="token punctuation">,</span> status<span class="token punctuation">)</span> <span class="token keyword">and</span> ret        <span class="token keyword">return</span> ret<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>虽然代码比较丑，但是管用…</p><p>至此完成了几乎所有类型的题目，下面的任务就是增加题量了！</p>]]></content>
      
      
      <categories>
          
          <category> 编程 </category>
          
          <category> Leetcode </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Leetcode </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Leetcode-diary 1</title>
      <link href="/archives/fc1adef0.html"/>
      <url>/archives/fc1adef0.html</url>
      
        <content type="html"><![CDATA[<h1 id="Leetcode-diary-1"><a href="#Leetcode-diary-1" class="headerlink" title="Leetcode-diary 1"></a>Leetcode-diary 1</h1><p>diary 1 &amp; diary 2 的目的是了解多种题型，没有深入</p><h2 id="String"><a href="#String" class="headerlink" title="String"></a>String</h2><h3 id="14-Longest-Common-prefix"><a href="#14-Longest-Common-prefix" class="headerlink" title="14 Longest Common prefix"></a>14 Longest Common prefix</h3><p>最短写法，妙用 zip 函数</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">longestCommonPrefix</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> strs<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        :type strs: List[str]        :rtype: str        """</span>        res <span class="token operator">=</span> <span class="token string">""</span>        <span class="token keyword">for</span> tmp <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span><span class="token operator">*</span>strs<span class="token punctuation">)</span><span class="token punctuation">:</span>            tmp_set <span class="token operator">=</span> <span class="token builtin">set</span><span class="token punctuation">(</span>tmp<span class="token punctuation">)</span>            <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>tmp_set<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>                res <span class="token operator">+=</span> tmp<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>            <span class="token keyword">else</span><span class="token punctuation">:</span>                <span class="token keyword">break</span>        <span class="token keyword">return</span> res<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>我的写法，使用两个循环</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">longestCommonPrefix</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> strs<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        :type strs: List[str]        :rtype: str        """</span>        res <span class="token operator">=</span> <span class="token string">""</span>        first <span class="token operator">=</span> strs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> idx<span class="token punctuation">,</span> f_str <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>first<span class="token punctuation">)</span><span class="token punctuation">:</span>            match <span class="token operator">=</span> <span class="token boolean">True</span>            <span class="token keyword">for</span> <span class="token builtin">str</span> <span class="token keyword">in</span> strs<span class="token punctuation">:</span>                <span class="token keyword">if</span> idx <span class="token operator">&gt;=</span> <span class="token builtin">len</span><span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">)</span> <span class="token keyword">or</span> <span class="token builtin">str</span><span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">!=</span> f_str<span class="token punctuation">:</span>                    match <span class="token operator">=</span> <span class="token boolean">False</span>                    <span class="token keyword">break</span>            <span class="token keyword">if</span> <span class="token keyword">not</span> match<span class="token punctuation">:</span>                <span class="token keyword">break</span>            res <span class="token operator">+=</span> f_str        <span class="token keyword">return</span> res<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="58-Length-Of-Last-Word"><a href="#58-Length-Of-Last-Word" class="headerlink" title="58 Length Of Last Word"></a>58 Length Of Last Word</h3><p>没有特别好注意的</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">lengthOfLastWord</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> s<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        :type s: str        :rtype: int        """</span>        l <span class="token operator">=</span> s<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span>        ret <span class="token operator">=</span> <span class="token boolean">None</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>l<span class="token punctuation">)</span>        <span class="token keyword">for</span> word <span class="token keyword">in</span> l<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">:</span>            <span class="token keyword">if</span> word <span class="token operator">!=</span> <span class="token string">''</span><span class="token punctuation">:</span>                ret <span class="token operator">=</span> word                <span class="token keyword">break</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>ret<span class="token punctuation">)</span>        <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>ret<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="387-First-Unique-Character-in-a-String"><a href="#387-First-Unique-Character-in-a-String" class="headerlink" title="387 First Unique Character in a String"></a>387 First Unique Character in a String</h3><p><a href="https://leetcode-cn.com/problems/first-unique-character-in-a-string/">leetcode link</a></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> collections <span class="token keyword">import</span> Counter<span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">firstUniqChar</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> s<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        :type s: str        :rtype: int        """</span>        counter <span class="token operator">=</span> Counter<span class="token punctuation">(</span>s<span class="token punctuation">)</span>        idx <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1</span>        <span class="token keyword">for</span> <span class="token builtin">str</span> <span class="token keyword">in</span> s<span class="token punctuation">:</span>            <span class="token keyword">if</span> counter<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>                idx <span class="token operator">=</span> s<span class="token punctuation">.</span>index<span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">)</span>                <span class="token keyword">break</span>        <span class="token keyword">return</span> idx<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>实际测试是可以使用 collections 库，Counter: Dict subclass for counting hashable items. </p><h3 id="383-Ransom-Note"><a href="#383-Ransom-Note" class="headerlink" title="383 Ransom Note"></a>383 Ransom Note</h3><p><a href="https://leetcode-cn.com/problems/ransom-note/">leetcode link</a></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">canConstruct</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> ransomNote<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span> magazine<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">bool</span><span class="token punctuation">:</span>        <span class="token keyword">from</span> collections <span class="token keyword">import</span> Counter        counter_r <span class="token operator">=</span> Counter<span class="token punctuation">(</span>ransomNote<span class="token punctuation">)</span>        counter_m <span class="token operator">=</span> Counter<span class="token punctuation">(</span>magazine<span class="token punctuation">)</span>        flag <span class="token operator">=</span> <span class="token boolean">True</span>        <span class="token keyword">for</span> s<span class="token punctuation">,</span> num <span class="token keyword">in</span> counter_r<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">if</span> counter_m<span class="token punctuation">.</span>get<span class="token punctuation">(</span>s<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">&lt;</span> num<span class="token punctuation">:</span>                flag <span class="token operator">=</span> <span class="token boolean">False</span>                <span class="token keyword">break</span>        <span class="token keyword">return</span> flag<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="415-Add-Strings"><a href="#415-Add-Strings" class="headerlink" title="415 Add Strings"></a>415 Add Strings</h3><p><a href="https://leetcode-cn.com/problems/add-strings/">leetcode link</a></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">addStrings</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> num1<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span> num2<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">str</span><span class="token punctuation">:</span>        num1<span class="token punctuation">,</span> num2<span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>num1<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span>num2<span class="token punctuation">)</span>        <span class="token keyword">return</span> <span class="token builtin">str</span><span class="token punctuation">(</span>num1<span class="token operator">+</span>num2<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h3 id="205-Isomorphic-Strings"><a href="#205-Isomorphic-Strings" class="headerlink" title="205 Isomorphic Strings"></a>205 Isomorphic Strings</h3><p><a href="https://leetcode-cn.com/problems/isomorphic-strings/">leetcode link</a></p><p>我的解法是先建立两个字典，然后逐对匹配，如果两者非空，则进行匹配；如果两者均以匹配，则看匹配是否一致；如果仅一个匹配则配对失败</p><p>另一种解法是单向匹配做两次，也能成</p><p>还有一种更简洁的写法是使用 map 函数，<strong>一行解决</strong> <code>return list(map(s.index, s)) == list(map(t.index, t))</code></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">isIsomorphic</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> s<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span> t<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">bool</span><span class="token punctuation">:</span>        d_s <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">.</span>fromkeys<span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">)</span>        d_t <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">.</span>fromkeys<span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">(</span>t<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">)</span>        flag <span class="token operator">=</span> <span class="token boolean">True</span>        <span class="token keyword">for</span> idx<span class="token punctuation">,</span> s_ <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token punctuation">:</span>            t_<span class="token punctuation">,</span> ds<span class="token punctuation">,</span> dt <span class="token operator">=</span> t<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">,</span> d_s<span class="token punctuation">[</span>s_<span class="token punctuation">]</span><span class="token punctuation">,</span> d_t<span class="token punctuation">[</span>t_<span class="token punctuation">]</span>            <span class="token keyword">if</span> ds <span class="token keyword">is</span> <span class="token boolean">None</span> <span class="token keyword">and</span> dt <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>                d_s<span class="token punctuation">[</span>s_<span class="token punctuation">]</span><span class="token punctuation">,</span> d_t<span class="token punctuation">[</span>t_<span class="token punctuation">]</span> <span class="token operator">=</span> t_<span class="token punctuation">,</span> s            <span class="token keyword">elif</span> ds <span class="token keyword">and</span> dt<span class="token punctuation">:</span>                <span class="token keyword">if</span> ds <span class="token operator">!=</span> t_ <span class="token keyword">or</span> dt <span class="token operator">!=</span> s<span class="token punctuation">:</span>                    flag <span class="token operator">=</span> <span class="token boolean">False</span>                    <span class="token keyword">break</span>            <span class="token keyword">else</span><span class="token punctuation">:</span>                <span class="token keyword">return</span> <span class="token boolean">False</span>        <span class="token keyword">return</span> flag<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="451-Sort-Characters-By-Frequency"><a href="#451-Sort-Characters-By-Frequency" class="headerlink" title="451 Sort Characters By Frequency"></a>451 Sort Characters By Frequency</h3><p><a href="https://leetcode-cn.com/problems/sort-characters-by-frequency/">leetcode link</a></p><p>使用 <code>most_common()</code> 将其按照出现频率顺序排列，还可以指定参数能够输出 Top k 个词</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">frequencySort</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> s<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">str</span><span class="token punctuation">:</span>        <span class="token keyword">from</span> collections <span class="token keyword">import</span> Counter        counter <span class="token operator">=</span> Counter<span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token punctuation">.</span>most_common<span class="token punctuation">(</span><span class="token punctuation">)</span>        ret <span class="token operator">=</span> <span class="token string">''</span>        <span class="token keyword">for</span> s_<span class="token punctuation">,</span> nums <span class="token keyword">in</span> counter<span class="token punctuation">:</span>            ret <span class="token operator">+=</span> s_ <span class="token operator">*</span> nums        <span class="token keyword">return</span> ret<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="294-Flip-Game-ii"><a href="#294-Flip-Game-ii" class="headerlink" title="294 Flip Game ii"></a>294 Flip Game ii</h3><p>这一题竟是会员题…那就只能看看题目，再看看其他解答了！有趣的是这一题需要一点点博弈论的知识，能更好的理解 <a href="https://zhuanlan.zhihu.com/p/21300536">知乎</a>。代码参考 <a href="https://blog.csdn.net/qq_32424059/article/details/100765272">CSDN</a>，既然每一种状态都有确定的输赢，那么使用递归去求解是再适合不过的了。定义递归问题：当前状态为必胜状态</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">generatePossibleNextMoves</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> s<span class="token punctuation">)</span><span class="token punctuation">:</span>        res <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">if</span> s<span class="token punctuation">[</span>i<span class="token punctuation">:</span> i<span class="token operator">+</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'++'</span><span class="token punctuation">:</span>                res<span class="token punctuation">.</span>append<span class="token punctuation">(</span>s<span class="token punctuation">[</span><span class="token punctuation">:</span>i<span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token string">'--'</span> <span class="token operator">+</span> s<span class="token punctuation">[</span>i<span class="token operator">+</span><span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> res        <span class="token keyword">def</span> <span class="token function">canWin</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> s<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">if</span> s<span class="token punctuation">[</span>i<span class="token punctuation">:</span> i<span class="token operator">+</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'++'</span> <span class="token keyword">and</span> <span class="token keyword">not</span> self<span class="token punctuation">.</span>canWin<span class="token punctuation">(</span>s<span class="token punctuation">[</span><span class="token punctuation">:</span>i<span class="token punctuation">]</span><span class="token operator">+</span><span class="token string">'--'</span><span class="token operator">+</span>s<span class="token punctuation">[</span>i<span class="token operator">+</span><span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                <span class="token keyword">return</span> <span class="token boolean">True</span>        <span class="token keyword">return</span> <span class="token boolean">False</span> <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="290-Word-Pattern"><a href="#290-Word-Pattern" class="headerlink" title="290 Word Pattern"></a>290 Word Pattern</h3><p><a href="https://leetcode-cn.com/problems/word-pattern/">leetcode link</a></p><p>这一题和之前的 205 同质字符串是一样的题，考察一个一一对应的问题，<strong>最短写法：妙用 map 函数</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">wordPattern</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> pattern<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span> <span class="token builtin">str</span><span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">bool</span><span class="token punctuation">:</span>    s_list <span class="token operator">=</span> <span class="token builtin">str</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">map</span><span class="token punctuation">(</span>pattern<span class="token punctuation">.</span>index<span class="token punctuation">,</span> pattern<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">==</span><span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">map</span><span class="token punctuation">(</span>s_list<span class="token punctuation">.</span>index<span class="token punctuation">,</span>res<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>自己的写法。区别在于 205 有一个条件：两个字符出串的长度相等，这一题没有，在一开始判断即可，如果不满足直接判负</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">wordPattern</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> pattern<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span> s<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">bool</span><span class="token punctuation">:</span>        s_list <span class="token operator">=</span> s<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>s_list<span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>pattern<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> <span class="token boolean">False</span>        pattern_dict <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">.</span>fromkeys<span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">(</span>pattern<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">)</span>        s_dict <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">.</span>fromkeys<span class="token punctuation">(</span>s_list<span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">)</span>        <span class="token keyword">for</span> idx<span class="token punctuation">,</span> s_ <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>s_list<span class="token punctuation">)</span><span class="token punctuation">:</span>            p_<span class="token punctuation">,</span> p_d<span class="token punctuation">,</span> s_d <span class="token operator">=</span> pattern<span class="token punctuation">[</span>idx<span class="token punctuation">]</span><span class="token punctuation">,</span> pattern_dict<span class="token punctuation">[</span>p_<span class="token punctuation">]</span><span class="token punctuation">,</span> s_dict<span class="token punctuation">[</span>s_<span class="token punctuation">]</span>            <span class="token keyword">if</span> p_d <span class="token keyword">is</span> <span class="token boolean">None</span> <span class="token keyword">and</span> s_d <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>                pattern_dict<span class="token punctuation">[</span>p_<span class="token punctuation">]</span> <span class="token operator">=</span> s_                s_dict<span class="token punctuation">[</span>s_<span class="token punctuation">]</span> <span class="token operator">=</span> p_            <span class="token keyword">elif</span> p_d <span class="token keyword">and</span> s_d<span class="token punctuation">:</span>                <span class="token keyword">if</span> p_d <span class="token operator">!=</span> s_ <span class="token keyword">or</span> s_d <span class="token operator">!=</span> p_<span class="token punctuation">:</span>                    <span class="token keyword">return</span> <span class="token boolean">False</span>            <span class="token keyword">else</span><span class="token punctuation">:</span>                <span class="token keyword">return</span> <span class="token boolean">False</span>        <span class="token keyword">return</span> <span class="token boolean">True</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="38-Count-and-Say"><a href="#38-Count-and-Say" class="headerlink" title="38 Count and Say"></a>38 Count and Say</h3><p><a href="https://leetcode-cn.com/problems/count-and-say/submissions/">leetcode link</a></p><p>用迭代思维求解</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">countAndSay</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> n<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">str</span><span class="token punctuation">:</span>        <span class="token keyword">def</span> <span class="token function">desc</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token punctuation">:</span>            ret <span class="token operator">=</span> <span class="token string">''</span>            cur <span class="token operator">=</span> s<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>            <span class="token keyword">for</span> idx_<span class="token punctuation">,</span> s_ <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token punctuation">:</span>                <span class="token keyword">if</span> s_ <span class="token operator">==</span> cur<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">:</span>                    cur <span class="token operator">=</span> cur <span class="token operator">+</span> s_ <span class="token keyword">if</span> idx_ <span class="token operator">!=</span> <span class="token number">0</span> <span class="token keyword">else</span> s_                <span class="token keyword">else</span><span class="token punctuation">:</span>                    ret <span class="token operator">+=</span> <span class="token builtin">str</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>cur<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">+</span> cur<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>                    cur <span class="token operator">=</span> s_                <span class="token keyword">if</span> idx_ <span class="token operator">==</span> <span class="token builtin">len</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">:</span>                    ret <span class="token operator">+=</span> <span class="token builtin">str</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>cur<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">+</span> cur<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>            <span class="token keyword">return</span>  ret                s <span class="token operator">=</span> <span class="token string">'1'</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>n <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            s <span class="token operator">=</span> desc<span class="token punctuation">(</span>s<span class="token punctuation">)</span>        <span class="token keyword">return</span> s<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>用递归思维求解：</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">countAndSay</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> n<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">str</span><span class="token punctuation">:</span>        <span class="token keyword">def</span> <span class="token function">desc</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">pass</span><span class="token comment"># 和上面定义一样</span>        <span class="token keyword">if</span> n <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> <span class="token string">'1'</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            s <span class="token operator">=</span> self<span class="token punctuation">.</span>countAndSay<span class="token punctuation">(</span>n <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span>            <span class="token keyword">return</span> desc<span class="token punctuation">(</span>s<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="316-Remove-Duplicate-Letters"><a href="#316-Remove-Duplicate-Letters" class="headerlink" title="316 Remove Duplicate Letters"></a>316 Remove Duplicate Letters</h3><p><a href="https://leetcode-cn.com/problems/remove-duplicate-letters/">leetcode link</a></p><p>一开始还是想使用动态规划来做这一题，但发现这题并不适合使用动态规划，因为其最优子结构之间并不存在关系，也就是无后效性。这题的本质在于：遍历时舍弃与保留数字的条件：</p><ol><li>为保证顺序性采用顺序遍历</li><li>为保证不重复性，当当前数字已存在于已保留的数字中时舍弃当前数字，若不存在则保留当前数字</li><li>当前数字小于前一个保留数字，并且之后仍会出前一个保留数字时，则舍弃前一个保留数字。这一步骤是整个题的核心，因为这保证了递减</li><li>循环2，至到不舍弃前一个保留数字，此时保留当前数字，并遍历下一个数</li></ol><p>这样的条件是否能够获我们想要的结果呢？很多算法题并没有给出各种算法的数学证明，只是一种直觉性的介绍，我认为需要证明在这样条件之下所保留的答案就是最终答案。使用反证法，该条件满足顺序性，也满足不重复性，只需要证明最小即可：</p><p>假设原序列为 $a=\{a_1, a_2,…,a_n\}$ 使用该方法获得的子序列为 $z=\{z_1,z_2,…,z_k\}$，若存在更小的序列 $z’=\{z_1,z_2,…,z_j,z_i,…\}$，具体来说就是将数字 $z_j$ 放到数字 $z_i$ 之前，显然有 $z_i&gt;z_j\ (i&lt;j)$，为保证这个序列 $z’$ 的任意性，$z_i$ 之后的数字可以时任意排列的。下面证明这样的序列是不存在的：</p><p>假设 $z_{i-1},z_i,z_j$ 在原序列中分别对应 $a_p,a_q,a_m\ (p&lt;q&lt;m)$。考虑使用算法获得的子序列得出：我们舍弃了 $p, q$ 之间的原序列 $\{a_p,a_{p+1},…,a_q\}$；再由假设序列得出：$a_m$ 存在于 $p,q$ 之间。<strong>由两个推论得出：$a_m$ 存在于 $p,q$ 之间并被舍弃</strong>，这个结论是不成立的！</p><p> 因为 $a_m$ 并不属于之前所保留的集合 $\{…,z_{i-1}\}$，当 $a_m$ 第一次出现时，一定会被作为保留数字留下来，所以要在之后舍弃 $a_m$ 则之后必须出现保留数字 $a_x$，该数字满足 $a_x &lt; a_m$ 且 $a_x \notin \{…,z_i\}$，而 $a_x$ 也必须被舍弃，如此往复当遍历到 $a_q(=z_i)$ 时，最后一个 $a_x$ 将无法被舍弃，因为 $a_x &lt; a_m = z_j &lt; z_i=a_q$ 与推论矛盾，所以这样的序列 $z’$ 不存在</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># empty</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="539-Minimum-Time-Difference"><a href="#539-Minimum-Time-Difference" class="headerlink" title="539 Minimum Time Difference"></a>539 Minimum Time Difference</h3><p><a href="https://leetcode-cn.com/problems/minimum-time-difference/">leetcode link</a></p><p>先进行升序排序即可</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">findMinDifference</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> timePoints<span class="token punctuation">:</span> List<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">int</span><span class="token punctuation">:</span>        <span class="token keyword">def</span> <span class="token function">get_time_list</span><span class="token punctuation">(</span>timePoints<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>timePoints<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                time <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">map</span><span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">,</span>timePoints<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">':'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>                time <span class="token operator">=</span> time<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token number">60</span> <span class="token operator">+</span> time<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>                timePoints<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> time            <span class="token keyword">return</span> timePoints        <span class="token keyword">def</span> <span class="token function">get_diff</span><span class="token punctuation">(</span>t1<span class="token punctuation">,</span> t2<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> <span class="token builtin">min</span><span class="token punctuation">(</span><span class="token builtin">abs</span><span class="token punctuation">(</span>t1<span class="token operator">-</span>t2<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token builtin">abs</span><span class="token punctuation">(</span>t1<span class="token operator">-</span>t2<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">24</span> <span class="token operator">*</span> <span class="token number">60</span><span class="token punctuation">)</span>        t_list <span class="token operator">=</span> <span class="token builtin">sorted</span><span class="token punctuation">(</span>get_time_list<span class="token punctuation">(</span>timePoints<span class="token punctuation">)</span><span class="token punctuation">)</span>        minimum <span class="token operator">=</span> get_diff<span class="token punctuation">(</span>t_list<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> t_list<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>t_list<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            minimum <span class="token operator">=</span> <span class="token builtin">min</span><span class="token punctuation">(</span>minimum<span class="token punctuation">,</span> get_diff<span class="token punctuation">(</span>t_list<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> t_list<span class="token punctuation">[</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token keyword">if</span> minimum <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>                <span class="token keyword">return</span> <span class="token number">0</span>        <span class="token keyword">return</span> minimum<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="Binary-Search"><a href="#Binary-Search" class="headerlink" title="Binary Search"></a>Binary Search</h2><h3 id="704-Binary-Search"><a href="#704-Binary-Search" class="headerlink" title="704 Binary Search"></a>704 Binary Search</h3><p><a href="https://leetcode-cn.com/problems/binary-search/">leetcode link</a></p><p>写了两种写法，一种是直接用列表自带的功能，另一种就是朴素的二分查找</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">search</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> nums<span class="token punctuation">:</span> List<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span><span class="token punctuation">,</span> target<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">int</span><span class="token punctuation">:</span>        <span class="token keyword">try</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> nums<span class="token punctuation">.</span>index<span class="token punctuation">(</span>target<span class="token punctuation">)</span>        <span class="token keyword">except</span> ValueError<span class="token punctuation">:</span>            <span class="token keyword">return</span> <span class="token operator">-</span><span class="token number">1</span><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">search</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> nums<span class="token punctuation">:</span> List<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span><span class="token punctuation">,</span> target<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">int</span><span class="token punctuation">:</span>        begin <span class="token operator">=</span> <span class="token number">0</span>        end <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>nums<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span>        <span class="token comment"># 终止条件</span>        <span class="token keyword">while</span> begin <span class="token operator">&lt;=</span> end<span class="token punctuation">:</span>            <span class="token comment"># 二分</span>            mid <span class="token operator">=</span> <span class="token punctuation">(</span>begin <span class="token operator">+</span> end<span class="token punctuation">)</span> <span class="token operator">//</span> <span class="token number">2</span>            <span class="token comment"># 判定</span>            <span class="token keyword">if</span> nums<span class="token punctuation">[</span>mid<span class="token punctuation">]</span> <span class="token operator">==</span> target<span class="token punctuation">:</span>                <span class="token keyword">return</span> mid            <span class="token comment"># 更改搜索范围</span>            <span class="token keyword">if</span> nums<span class="token punctuation">[</span>mid<span class="token punctuation">]</span> <span class="token operator">&gt;</span> target<span class="token punctuation">:</span>            end <span class="token operator">=</span> mid <span class="token operator">-</span> <span class="token number">1</span><span class="token keyword">else</span><span class="token punctuation">:</span>            begin <span class="token operator">=</span> mid <span class="token operator">+</span> <span class="token number">1</span>        <span class="token keyword">return</span> <span class="token operator">-</span><span class="token number">1</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>总结：</p><ol><li>搜索范围一定要包含目标值，且要不断地缩小，这样才能够满足终止条件而不陷入死循环</li><li>当目标超出了整个数组范围，二分搜索可能需要要特殊处理的</li><li>当 begin &amp; end 相邻的时候，情况会变得复杂一点，但是这个过程需要更清晰才能写好代码。以此题为例，此时 target 有两种情况：begin &amp; end 的二者之一或者二者之间。下面具体分析一下最后的细节：<ol><li>继续二分计算，mid 会因为整除操作而等于 begin</li><li>如果 begin 就是 target 则结束</li><li>如果 begin 不是 target 则说明 <code>nums[mid] &lt; target</code> 即 <code>nums[begin] &lt; target</code>，执行 <code>begin = mid + 1</code></li><li>继续二分计算，mid 会因为整除操作而等于 end</li><li>如果 end 就是 target 则结束</li><li>如果 end 不是 target 则说明 <code>nums[mid] &gt; target</code> 即 <code>nums[end] &gt; target</code>，执行 <code>end = mid - 1</code></li><li>此时 begin &gt; end，循环结束</li></ol></li><li>判定条件一定要清晰</li></ol><h3 id="278-First-Bad-Version"><a href="#278-First-Bad-Version" class="headerlink" title="278 First Bad Version"></a>278 First Bad Version</h3><p><a href="https://leetcode-cn.com/problems/first-bad-version/">leetcode link</a></p><p>不知道 <code>isBadVersion()</code> 能不能判断 0 版本，所以先判断一下初始版本，好在之后统一写起来</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># The isBadVersion API is already defined for you.</span><span class="token comment"># @param version, an integer</span><span class="token comment"># @return an integer</span><span class="token comment"># def isBadVersion(version):</span><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">firstBadVersion</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> n<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        :type n: int        :rtype: int        """</span>        end<span class="token punctuation">,</span> begin <span class="token operator">=</span> n<span class="token punctuation">,</span> <span class="token number">1</span>        <span class="token keyword">while</span> begin <span class="token operator">&lt;=</span> end<span class="token punctuation">:</span>            mid <span class="token operator">=</span> <span class="token punctuation">(</span>end <span class="token operator">+</span> begin<span class="token punctuation">)</span> <span class="token operator">//</span> <span class="token number">2</span>            <span class="token comment"># 为避免多次查询，先存储结果</span>            result <span class="token operator">=</span> isBadVersion<span class="token punctuation">(</span>mid<span class="token punctuation">)</span>            <span class="token comment"># 判定</span>            <span class="token keyword">if</span> mid <span class="token operator">&gt;</span> <span class="token number">1</span> <span class="token keyword">and</span> result <span class="token keyword">and</span> isBadVersion<span class="token punctuation">(</span>mid <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token boolean">False</span><span class="token punctuation">:</span>                <span class="token keyword">return</span> mid            <span class="token keyword">if</span> mid <span class="token operator">==</span> <span class="token number">1</span> <span class="token keyword">and</span> isBadVersion<span class="token punctuation">(</span>mid<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token boolean">True</span><span class="token punctuation">:</span>                <span class="token keyword">return</span> <span class="token number">1</span>            <span class="token comment"># 改变搜索范围</span>            <span class="token keyword">if</span> result <span class="token operator">==</span> <span class="token boolean">False</span><span class="token punctuation">:</span>                begin <span class="token operator">=</span> mid <span class="token operator">+</span> <span class="token number">1</span>            <span class="token keyword">else</span><span class="token punctuation">:</span>                end <span class="token operator">=</span> mid <span class="token operator">-</span> <span class="token number">1</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="35-Search-Insert-Position"><a href="#35-Search-Insert-Position" class="headerlink" title="35 Search Insert Position"></a>35 Search Insert Position</h3><p><a href="https://leetcode-cn.com/problems/search-insert-position/">leetcode link</a></p><p>注意处理一下初始值问题（边界）就好</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">searchInsert</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> nums<span class="token punctuation">:</span> List<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span><span class="token punctuation">,</span> target<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">int</span><span class="token punctuation">:</span>        begin<span class="token punctuation">,</span> end <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>nums<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span>        <span class="token comment"># 处理边界，否则目标超出搜索范围</span>        <span class="token keyword">if</span> target <span class="token operator">&lt;</span> nums<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> <span class="token number">0</span>        <span class="token keyword">elif</span> target <span class="token operator">&gt;</span> nums<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> end <span class="token operator">+</span> <span class="token number">1</span>        <span class="token keyword">while</span> begin <span class="token operator">&lt;=</span> end<span class="token punctuation">:</span>            mid <span class="token operator">=</span> <span class="token punctuation">(</span>end <span class="token operator">+</span> begin<span class="token punctuation">)</span> <span class="token operator">//</span> <span class="token number">2</span>            <span class="token keyword">if</span> nums<span class="token punctuation">[</span>mid<span class="token punctuation">]</span> <span class="token operator">==</span> target<span class="token punctuation">:</span>                <span class="token keyword">return</span> mid            <span class="token keyword">if</span> nums<span class="token punctuation">[</span>mid<span class="token punctuation">]</span> <span class="token operator">&gt;</span> target<span class="token punctuation">:</span>                end <span class="token operator">=</span> mid <span class="token operator">-</span> <span class="token number">1</span>            <span class="token keyword">else</span><span class="token punctuation">:</span>                begin <span class="token operator">=</span> mid <span class="token operator">+</span> <span class="token number">1</span>        <span class="token keyword">return</span> begin<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="33-Search-in-Rotated-Sorted-Array"><a href="#33-Search-in-Rotated-Sorted-Array" class="headerlink" title="33 Search in Rotated Sorted Array"></a>33 Search in Rotated Sorted Array</h3><p><a href="https://leetcode-cn.com/problems/search-in-rotated-sorted-array/">leetcode link</a></p><p>我首先的想法是使用3次二分搜索解决问题，但我先偷个懒，写了第一种写法🤣效果也还不错，可能是因为 N 不够大，所以二叉搜索的优势显现不出来</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">search</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> nums<span class="token punctuation">:</span> List<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span><span class="token punctuation">,</span> target<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">int</span><span class="token punctuation">:</span>        <span class="token keyword">try</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> nums<span class="token punctuation">.</span>index<span class="token punctuation">(</span>target<span class="token punctuation">)</span>        <span class="token keyword">except</span> ValueError<span class="token punctuation">:</span>            <span class="token keyword">return</span> <span class="token operator">-</span><span class="token number">1</span><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">search</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> nums<span class="token punctuation">:</span> List<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span><span class="token punctuation">,</span> target<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">int</span><span class="token punctuation">:</span>        <span class="token keyword">def</span> <span class="token function">find_point</span><span class="token punctuation">(</span>nums<span class="token punctuation">:</span> List<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            begin<span class="token punctuation">,</span> end <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>nums<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span>            <span class="token comment"># 边界处理，否则目标超出搜索范围</span>            <span class="token keyword">if</span> nums<span class="token punctuation">[</span>begin<span class="token punctuation">]</span> <span class="token operator">&lt;</span> nums<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">:</span>                <span class="token keyword">return</span> end            <span class="token keyword">while</span> begin <span class="token operator">&lt;=</span> end<span class="token punctuation">:</span>                mid <span class="token operator">=</span> <span class="token punctuation">(</span>begin <span class="token operator">+</span> end<span class="token punctuation">)</span> <span class="token operator">//</span> <span class="token number">2</span>                <span class="token keyword">if</span> mid <span class="token operator">&lt;</span> <span class="token builtin">len</span><span class="token punctuation">(</span>nums<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span> <span class="token keyword">and</span> nums<span class="token punctuation">[</span>mid<span class="token punctuation">]</span> <span class="token operator">&gt;</span> nums<span class="token punctuation">[</span>mid <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">:</span>                    <span class="token keyword">return</span> mid                <span class="token keyword">if</span> mid <span class="token operator">&gt;</span> <span class="token number">0</span> <span class="token keyword">and</span> nums<span class="token punctuation">[</span>mid<span class="token punctuation">]</span> <span class="token operator">&lt;</span> nums<span class="token punctuation">[</span>mid <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">:</span>                    <span class="token keyword">return</span> mid <span class="token operator">-</span> <span class="token number">1</span>                <span class="token keyword">if</span> nums<span class="token punctuation">[</span>mid<span class="token punctuation">]</span> <span class="token operator">&gt;=</span> nums<span class="token punctuation">[</span>begin<span class="token punctuation">]</span><span class="token punctuation">:</span>                    begin <span class="token operator">=</span> mid <span class="token operator">+</span> <span class="token number">1</span>                <span class="token keyword">else</span><span class="token punctuation">:</span>                    end <span class="token operator">=</span> mid <span class="token operator">-</span> <span class="token number">1</span>            <span class="token comment"># 只有一个数的情况</span>            <span class="token keyword">return</span> <span class="token operator">-</span><span class="token number">1</span>        <span class="token keyword">def</span> <span class="token function">searchInsert</span><span class="token punctuation">(</span>nums<span class="token punctuation">:</span> List<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span><span class="token punctuation">,</span> target<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">int</span><span class="token punctuation">:</span>                begin<span class="token punctuation">,</span> end <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>nums<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span>                <span class="token keyword">while</span> begin <span class="token operator">&lt;=</span> end<span class="token punctuation">:</span>                    mid <span class="token operator">=</span> <span class="token punctuation">(</span>end <span class="token operator">+</span> begin<span class="token punctuation">)</span> <span class="token operator">//</span> <span class="token number">2</span>                    <span class="token keyword">if</span> nums<span class="token punctuation">[</span>mid<span class="token punctuation">]</span> <span class="token operator">==</span> target<span class="token punctuation">:</span>                        <span class="token keyword">return</span> mid                    <span class="token keyword">elif</span> nums<span class="token punctuation">[</span>mid<span class="token punctuation">]</span> <span class="token operator">&gt;</span> target<span class="token punctuation">:</span>                        end <span class="token operator">=</span> mid <span class="token operator">-</span> <span class="token number">1</span>                    <span class="token keyword">else</span><span class="token punctuation">:</span>                        begin <span class="token operator">=</span> mid <span class="token operator">+</span> <span class="token number">1</span>                <span class="token keyword">return</span> <span class="token operator">-</span><span class="token number">1e5</span>        point <span class="token operator">=</span> find_point<span class="token punctuation">(</span>nums<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span>        idx <span class="token operator">=</span> <span class="token builtin">max</span><span class="token punctuation">(</span>searchInsert<span class="token punctuation">(</span>nums<span class="token punctuation">[</span><span class="token punctuation">:</span>point<span class="token punctuation">]</span><span class="token punctuation">,</span> target<span class="token punctuation">)</span><span class="token punctuation">,</span> searchInsert<span class="token punctuation">(</span>nums<span class="token punctuation">[</span>point<span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> target<span class="token punctuation">)</span> <span class="token operator">+</span> point<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> idx        <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>题解使用了更简洁的代码，思想就是将范围转移讨论得更加清晰，根据 target &amp; nums[mid] 和 nums[0] 的关系判断</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">search</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> nums<span class="token punctuation">:</span> List<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span><span class="token punctuation">,</span> target<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">int</span><span class="token punctuation">:</span>        begin<span class="token punctuation">,</span> end <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>nums<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span>        <span class="token keyword">while</span> begin <span class="token operator">&lt;=</span> end<span class="token punctuation">:</span>            mid <span class="token operator">=</span> <span class="token punctuation">(</span>begin <span class="token operator">+</span> end<span class="token punctuation">)</span> <span class="token operator">//</span> <span class="token number">2</span>            <span class="token keyword">if</span> nums<span class="token punctuation">[</span>mid<span class="token punctuation">]</span> <span class="token operator">==</span> target<span class="token punctuation">:</span>                <span class="token keyword">return</span> mid            <span class="token keyword">if</span> nums<span class="token punctuation">[</span>mid<span class="token punctuation">]</span> <span class="token operator">&gt;=</span> nums<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">:</span>                <span class="token comment"># 均在左</span>                <span class="token keyword">if</span> target <span class="token operator">&gt;=</span> nums<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">:</span>                    <span class="token keyword">if</span> target <span class="token operator">&gt;</span> nums<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token punctuation">:</span>                        begin <span class="token operator">=</span> mid <span class="token operator">+</span> <span class="token number">1</span>                    <span class="token keyword">else</span><span class="token punctuation">:</span>                        end <span class="token operator">=</span> mid <span class="token operator">-</span> <span class="token number">1</span>                <span class="token comment"># mid 在左，target 在右</span>                <span class="token keyword">else</span><span class="token punctuation">:</span>                    begin <span class="token operator">=</span> mid <span class="token operator">+</span> <span class="token number">1</span>            <span class="token keyword">else</span><span class="token punctuation">:</span>                <span class="token comment"># mid 在右，target 在左</span>                <span class="token keyword">if</span> target <span class="token operator">&gt;=</span> nums<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">:</span>                    end <span class="token operator">=</span> mid <span class="token operator">-</span> <span class="token number">1</span>                <span class="token comment"># 均在右</span>                <span class="token keyword">else</span><span class="token punctuation">:</span>                    <span class="token keyword">if</span> target <span class="token operator">&gt;</span> nums<span class="token punctuation">[</span>mid<span class="token punctuation">]</span><span class="token punctuation">:</span>                        begin <span class="token operator">=</span> mid <span class="token operator">+</span> <span class="token number">1</span>                    <span class="token keyword">else</span><span class="token punctuation">:</span>                        end <span class="token operator">=</span> mid <span class="token operator">-</span> <span class="token number">1</span>        <span class="token keyword">return</span> <span class="token operator">-</span><span class="token number">1</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="153-Find-Minimum-in-Rotated-Sorted-Array"><a href="#153-Find-Minimum-in-Rotated-Sorted-Array" class="headerlink" title="153 Find Minimum in Rotated Sorted Array"></a>153 Find Minimum in Rotated Sorted Array</h3><p><a href="https://leetcode-cn.com/problems/find-minimum-in-rotated-sorted-array/">leetcode link</a></p><p>调用上一题写的函数就可以了，当然最暴力的还是排序啦</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">findMin</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> nums<span class="token punctuation">:</span> List<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">int</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> <span class="token builtin">sorted</span><span class="token punctuation">(</span>nums<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">findMin</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> nums<span class="token punctuation">:</span> List<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">int</span><span class="token punctuation">:</span>        <span class="token keyword">def</span> <span class="token function">find_point</span><span class="token punctuation">(</span>nums<span class="token punctuation">:</span> List<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            begin<span class="token punctuation">,</span> end <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>nums<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span>            <span class="token comment"># 边界处理，否则目标超出搜索范围</span>            <span class="token keyword">if</span> nums<span class="token punctuation">[</span>begin<span class="token punctuation">]</span> <span class="token operator">&lt;</span> nums<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">:</span>                <span class="token keyword">return</span> <span class="token operator">-</span><span class="token number">1</span>            <span class="token keyword">while</span> begin <span class="token operator">&lt;=</span> end<span class="token punctuation">:</span>                mid <span class="token operator">=</span> <span class="token punctuation">(</span>begin <span class="token operator">+</span> end<span class="token punctuation">)</span> <span class="token operator">//</span> <span class="token number">2</span>                <span class="token keyword">if</span> mid <span class="token operator">&lt;</span> <span class="token builtin">len</span><span class="token punctuation">(</span>nums<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span> <span class="token keyword">and</span> nums<span class="token punctuation">[</span>mid<span class="token punctuation">]</span> <span class="token operator">&gt;</span> nums<span class="token punctuation">[</span>mid <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">:</span>                    <span class="token keyword">return</span> mid                <span class="token keyword">if</span> mid <span class="token operator">&gt;</span> <span class="token number">0</span> <span class="token keyword">and</span> nums<span class="token punctuation">[</span>mid<span class="token punctuation">]</span> <span class="token operator">&lt;</span> nums<span class="token punctuation">[</span>mid <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">:</span>                    <span class="token keyword">return</span> mid <span class="token operator">-</span> <span class="token number">1</span>                <span class="token comment"># 判断在哪一边</span>                <span class="token keyword">if</span> nums<span class="token punctuation">[</span>mid<span class="token punctuation">]</span> <span class="token operator">&gt;=</span> nums<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">:</span>                    begin <span class="token operator">=</span> mid <span class="token operator">+</span> <span class="token number">1</span>                <span class="token keyword">else</span><span class="token punctuation">:</span>                    end <span class="token operator">=</span> mid <span class="token operator">-</span> <span class="token number">1</span>            <span class="token comment"># 只有一个数的情况</span>            <span class="token keyword">return</span> <span class="token operator">-</span><span class="token number">1</span>        <span class="token keyword">return</span> nums<span class="token punctuation">[</span>find_point<span class="token punctuation">(</span>nums<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="154-Find-Minimum-in-Rotated-Sorted-Array-ii"><a href="#154-Find-Minimum-in-Rotated-Sorted-Array-ii" class="headerlink" title="154 Find Minimum in Rotated Sorted Array ii"></a>154 Find Minimum in Rotated Sorted Array ii</h3><p><a href="https://leetcode-cn.com/problems/find-minimum-in-rotated-sorted-array-ii/">leetcode link</a></p><p>这里需要处理的是重复值，当有重复值存在时，则不能盲目缩小一般搜索范围，而是让仅往前走一步即可。我让 begin 向右走一步，但这可能会导致 begin 落入右侧范围，这时说明 begin 即为所求值 index</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">findMin</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> nums<span class="token punctuation">:</span> List<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">int</span><span class="token punctuation">:</span>        <span class="token keyword">def</span> <span class="token function">find_point</span><span class="token punctuation">(</span>nums<span class="token punctuation">:</span> List<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            begin<span class="token punctuation">,</span> end <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>nums<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span>            <span class="token comment"># 边界处理，否则目标超出搜索范围</span>            <span class="token keyword">if</span> nums<span class="token punctuation">[</span>begin<span class="token punctuation">]</span> <span class="token operator">&lt;</span> nums<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">:</span>                <span class="token keyword">return</span> <span class="token number">0</span>            <span class="token keyword">while</span> begin <span class="token operator">&lt;=</span> end<span class="token punctuation">:</span>                mid <span class="token operator">=</span> <span class="token punctuation">(</span>begin <span class="token operator">+</span> end<span class="token punctuation">)</span> <span class="token operator">//</span> <span class="token number">2</span>                <span class="token keyword">if</span> mid <span class="token operator">&lt;</span> <span class="token builtin">len</span><span class="token punctuation">(</span>nums<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span> <span class="token keyword">and</span> nums<span class="token punctuation">[</span>mid<span class="token punctuation">]</span> <span class="token operator">&gt;</span> nums<span class="token punctuation">[</span>mid <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">:</span>                    <span class="token keyword">return</span> mid <span class="token operator">+</span> <span class="token number">1</span>                <span class="token keyword">if</span> mid <span class="token operator">&gt;</span> <span class="token number">0</span> <span class="token keyword">and</span> nums<span class="token punctuation">[</span>mid<span class="token punctuation">]</span> <span class="token operator">&lt;</span> nums<span class="token punctuation">[</span>mid <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">:</span>                    <span class="token keyword">return</span> mid                <span class="token comment"># 判断在哪一边</span>                <span class="token keyword">if</span> nums<span class="token punctuation">[</span>mid<span class="token punctuation">]</span> <span class="token operator">&gt;</span> nums<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">:</span>                    begin <span class="token operator">=</span> mid <span class="token operator">+</span> <span class="token number">1</span>                <span class="token keyword">elif</span> nums<span class="token punctuation">[</span>mid<span class="token punctuation">]</span> <span class="token operator">&lt;</span> nums<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">:</span>                    end <span class="token operator">=</span> mid <span class="token operator">-</span> <span class="token number">1</span>                <span class="token keyword">else</span><span class="token punctuation">:</span>                <span class="token comment"># 如果 begin 仍然在左侧</span>                    <span class="token keyword">if</span> nums<span class="token punctuation">[</span>begin<span class="token punctuation">]</span> <span class="token operator">&gt;=</span> nums<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">:</span>                        begin <span class="token operator">+=</span> <span class="token number">1</span>                <span class="token comment"># 如果 begin 在右侧</span>                    <span class="token keyword">else</span><span class="token punctuation">:</span>                        <span class="token keyword">return</span> begin            <span class="token comment"># 只有一个数的情况</span>            <span class="token keyword">return</span> <span class="token number">0</span>        <span class="token keyword">return</span> nums<span class="token punctuation">[</span>find_point<span class="token punctuation">(</span>nums<span class="token punctuation">)</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="LinkedList"><a href="#LinkedList" class="headerlink" title="LinkedList"></a>LinkedList</h2><h3 id="876-Middle-of-the-Linked-List"><a href="#876-Middle-of-the-Linked-List" class="headerlink" title="876 Middle of the Linked List"></a>876 Middle of the Linked List</h3><p><a href="https://leetcode-cn.com/problems/middle-of-the-linked-list/">leetcode link</a></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">middleNode</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> head<span class="token punctuation">:</span> ListNode<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> ListNode<span class="token punctuation">:</span>        length <span class="token operator">=</span> <span class="token number">0</span>        pointer <span class="token operator">=</span> head        <span class="token keyword">while</span> pointer <span class="token operator">!=</span> <span class="token boolean">None</span><span class="token punctuation">:</span>            pointer <span class="token operator">=</span> pointer<span class="token punctuation">.</span><span class="token builtin">next</span>            length <span class="token operator">+=</span> <span class="token number">1</span>        middile <span class="token operator">=</span> length <span class="token operator">//</span> <span class="token number">2</span>        pointer <span class="token operator">=</span> head        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>middile<span class="token punctuation">)</span><span class="token punctuation">:</span>            pointer <span class="token operator">=</span> pointer<span class="token punctuation">.</span><span class="token builtin">next</span>        <span class="token keyword">return</span> pointer<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="21-Merge-Two-Sorted-Lists"><a href="#21-Merge-Two-Sorted-Lists" class="headerlink" title="21 Merge Two Sorted Lists"></a>21 Merge Two Sorted Lists</h3><p><a href="https://leetcode-cn.com/problems/merge-two-sorted-lists/">leetcoke link</a></p><p>竟然没有马上想到递归，还是练习得不够啊</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">mergeTwoLists</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> list1<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>ListNode<span class="token punctuation">]</span><span class="token punctuation">,</span> list2<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>ListNode<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> Optional<span class="token punctuation">[</span>ListNode<span class="token punctuation">]</span><span class="token punctuation">:</span>        pointer1 <span class="token operator">=</span> list1        pointer2 <span class="token operator">=</span> list2        <span class="token keyword">if</span> pointer1 <span class="token operator">==</span> <span class="token boolean">None</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> pointer2        <span class="token keyword">elif</span> pointer2 <span class="token operator">==</span> <span class="token boolean">None</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> pointer1        <span class="token keyword">if</span> pointer1<span class="token punctuation">.</span>val <span class="token operator">&gt;</span> pointer2<span class="token punctuation">.</span>val<span class="token punctuation">:</span>            ret <span class="token operator">=</span> pointer2            pointer2<span class="token punctuation">.</span><span class="token builtin">next</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>mergeTwoLists<span class="token punctuation">(</span>pointer1<span class="token punctuation">,</span> pointer2<span class="token punctuation">.</span><span class="token builtin">next</span><span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            ret <span class="token operator">=</span> pointer1            pointer1<span class="token punctuation">.</span><span class="token builtin">next</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>mergeTwoLists<span class="token punctuation">(</span>pointer1<span class="token punctuation">.</span><span class="token builtin">next</span><span class="token punctuation">,</span> pointer2<span class="token punctuation">)</span>        <span class="token keyword">return</span> ret<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="160-Intersection-of-Two-Linked-Lists"><a href="#160-Intersection-of-Two-Linked-Lists" class="headerlink" title="160 Intersection of Two Linked Lists"></a>160 Intersection of Two Linked Lists</h3><p><a href="https://leetcode-cn.com/problems/intersection-of-two-linked-lists/">leetcode link</a></p><p>从尾部开始遍历，比较好判断</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">getIntersectionNode</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> headA<span class="token punctuation">:</span> ListNode<span class="token punctuation">,</span> headB<span class="token punctuation">:</span> ListNode<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> ListNode<span class="token punctuation">:</span>        l1 <span class="token operator">=</span> self<span class="token punctuation">.</span>get_list<span class="token punctuation">(</span>headA<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>        l2 <span class="token operator">=</span> self<span class="token punctuation">.</span>get_list<span class="token punctuation">(</span>headB<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>        <span class="token keyword">if</span> l1<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token keyword">is</span> <span class="token keyword">not</span> l2<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> <span class="token boolean">None</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>l1<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">if</span> i <span class="token operator">&lt;</span> <span class="token builtin">len</span><span class="token punctuation">(</span>l2<span class="token punctuation">)</span> <span class="token keyword">and</span> l1<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token keyword">is</span> <span class="token keyword">not</span> l2<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">:</span>                <span class="token keyword">return</span> l1<span class="token punctuation">[</span>i<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>            <span class="token keyword">elif</span> i <span class="token operator">&gt;=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>l2<span class="token punctuation">)</span><span class="token punctuation">:</span>                <span class="token keyword">return</span>  l1<span class="token punctuation">[</span>i<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>        <span class="token keyword">return</span> l1<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>    <span class="token keyword">def</span> <span class="token function">get_list</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> head<span class="token punctuation">)</span><span class="token punctuation">:</span>        l <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        pointer <span class="token operator">=</span> head        <span class="token keyword">while</span> pointer <span class="token operator">!=</span> <span class="token boolean">None</span><span class="token punctuation">:</span>            l<span class="token punctuation">.</span>append<span class="token punctuation">(</span>pointer<span class="token punctuation">)</span>            pointer <span class="token operator">=</span> pointer<span class="token punctuation">.</span><span class="token builtin">next</span>        <span class="token keyword">return</span> l<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="24-Swap-Nodes-in-Pairs"><a href="#24-Swap-Nodes-in-Pairs" class="headerlink" title="24 Swap Nodes in Pairs"></a>24 Swap Nodes in Pairs</h3><p><a href="https://leetcode-cn.com/problems/swap-nodes-in-pairs/">leetcode link</a></p><p>依然是递归思想</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">swapPairs</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> head<span class="token punctuation">:</span> ListNode<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> ListNode<span class="token punctuation">:</span>        <span class="token comment"># recursive idea</span>        pointer_1 <span class="token operator">=</span> head        <span class="token keyword">if</span> pointer_1 <span class="token operator">==</span> <span class="token boolean">None</span> <span class="token keyword">or</span> pointer_1<span class="token punctuation">.</span><span class="token builtin">next</span> <span class="token operator">==</span> <span class="token boolean">None</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> pointer_1        <span class="token comment"># original pointer</span>        pointer_2 <span class="token operator">=</span> pointer_1<span class="token punctuation">.</span><span class="token builtin">next</span>        pointer_3 <span class="token operator">=</span> pointer_2<span class="token punctuation">.</span><span class="token builtin">next</span>                pointer_1 <span class="token operator">=</span> pointer_2        pointer_1<span class="token punctuation">.</span><span class="token builtin">next</span> <span class="token operator">=</span> head        head<span class="token punctuation">.</span><span class="token builtin">next</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>swapPairs<span class="token punctuation">(</span>pointer_3<span class="token punctuation">)</span>        <span class="token keyword">return</span> pointer_1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="2-Add-Two-Numbers"><a href="#2-Add-Two-Numbers" class="headerlink" title="2 Add Two Numbers"></a>2 Add Two Numbers</h3><p><a href="https://leetcode-cn.com/problems/add-two-numbers/submissions/">leetcode link</a></p><p>比较笨的方法就是按照一般思维，先得到数字再相加，再创建链表</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">addTwoNumbers</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> l1<span class="token punctuation">:</span> ListNode<span class="token punctuation">,</span> l2<span class="token punctuation">:</span> ListNode<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> ListNode<span class="token punctuation">:</span>        <span class="token keyword">def</span> <span class="token function">get_number</span><span class="token punctuation">(</span>l<span class="token punctuation">:</span>ListNode<span class="token punctuation">)</span><span class="token punctuation">:</span>            s <span class="token operator">=</span> <span class="token string">''</span>            pointer <span class="token operator">=</span> l            <span class="token keyword">while</span> pointer <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>                s <span class="token operator">+=</span> <span class="token builtin">str</span><span class="token punctuation">(</span>pointer<span class="token punctuation">.</span>val<span class="token punctuation">)</span>                pointer <span class="token operator">=</span> pointer<span class="token punctuation">.</span><span class="token builtin">next</span>            num <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>s<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>            <span class="token keyword">return</span> num        <span class="token keyword">def</span> <span class="token function">build_list</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token punctuation">:</span>            head <span class="token operator">=</span> pointer <span class="token operator">=</span> ListNode<span class="token punctuation">(</span><span class="token punctuation">)</span>            n <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span>            <span class="token keyword">for</span> idx<span class="token punctuation">,</span> i <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token punctuation">:</span>                pointer<span class="token punctuation">.</span>val <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span>                pointer<span class="token punctuation">.</span><span class="token builtin">next</span> <span class="token operator">=</span> ListNode<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">if</span> idx <span class="token operator">&lt;</span> n <span class="token keyword">else</span> <span class="token boolean">None</span>                pointer <span class="token operator">=</span> pointer<span class="token punctuation">.</span><span class="token builtin">next</span>            <span class="token keyword">return</span> head        num1<span class="token punctuation">,</span> num2 <span class="token operator">=</span> get_number<span class="token punctuation">(</span>l1<span class="token punctuation">)</span><span class="token punctuation">,</span> get_number<span class="token punctuation">(</span>l2<span class="token punctuation">)</span>        s <span class="token operator">=</span> <span class="token builtin">str</span><span class="token punctuation">(</span>num1 <span class="token operator">+</span> num2<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>        <span class="token keyword">return</span> build_list<span class="token punctuation">(</span>s<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>更好的办法还是用递归的方法，这其实才是我看到这题的第一想法</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">addTwoNumbers</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> l1<span class="token punctuation">:</span> ListNode<span class="token punctuation">,</span> l2<span class="token punctuation">:</span> ListNode<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> ListNode<span class="token punctuation">:</span>        <span class="token comment"># recursion</span>        <span class="token keyword">if</span> l1 <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> l2        <span class="token keyword">if</span> l2 <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> l1        pointer <span class="token operator">=</span> node <span class="token operator">=</span> ListNode<span class="token punctuation">(</span><span class="token punctuation">)</span>        pointer<span class="token punctuation">.</span>val <span class="token operator">=</span> l1<span class="token punctuation">.</span>val <span class="token operator">+</span> l2<span class="token punctuation">.</span>val        sub_l <span class="token operator">=</span> self<span class="token punctuation">.</span>addTwoNumbers<span class="token punctuation">(</span>l1<span class="token punctuation">.</span><span class="token builtin">next</span><span class="token punctuation">,</span> l2<span class="token punctuation">.</span><span class="token builtin">next</span><span class="token punctuation">)</span>        pointer<span class="token punctuation">.</span><span class="token builtin">next</span> <span class="token operator">=</span> sub_l        <span class="token keyword">while</span> pointer<span class="token punctuation">.</span>val <span class="token operator">&gt;=</span> <span class="token number">10</span><span class="token punctuation">:</span>            res <span class="token operator">=</span> pointer<span class="token punctuation">.</span>val <span class="token operator">%</span> <span class="token number">10</span>            pointer<span class="token punctuation">.</span>val <span class="token operator">=</span> res            <span class="token keyword">if</span> pointer<span class="token punctuation">.</span><span class="token builtin">next</span> <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>                pointer<span class="token punctuation">.</span><span class="token builtin">next</span> <span class="token operator">=</span> ListNode<span class="token punctuation">(</span><span class="token punctuation">)</span>            pointer <span class="token operator">=</span> pointer<span class="token punctuation">.</span><span class="token builtin">next</span>            pointer<span class="token punctuation">.</span>val <span class="token operator">=</span> pointer<span class="token punctuation">.</span>val <span class="token operator">+</span> <span class="token number">1</span>        <span class="token keyword">return</span> node<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="Array"><a href="#Array" class="headerlink" title="Array"></a>Array</h2><h3 id="27-Remove-Element"><a href="#27-Remove-Element" class="headerlink" title="27 Remove Element"></a>27 Remove Element</h3><p><a href="https://leetcode-cn.com/problems/remove-element/">leetcode link</a></p><p>使用双指针的思想，“删除”不一定是真的删除。因为删除是很耗时的，但是实际使用来看，我用 remove 也能够达到同样的速度。leetcode 的服务器多次运行可能有不同的结果</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">removeElement</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> nums<span class="token punctuation">:</span> <span class="token builtin">list</span><span class="token punctuation">,</span> val<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        :type nums: List[int]        :type val: int        :rtype: int        """</span>        counter <span class="token operator">=</span> <span class="token number">0</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> nums<span class="token punctuation">:</span>            <span class="token keyword">if</span> i <span class="token operator">!=</span> val<span class="token punctuation">:</span>                nums<span class="token punctuation">[</span>counter<span class="token punctuation">]</span> <span class="token operator">=</span> i                counter <span class="token operator">+=</span> <span class="token number">1</span>        <span class="token keyword">return</span> counter<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="26-Remove-Duplicate-from-Sorted-Array"><a href="#26-Remove-Duplicate-from-Sorted-Array" class="headerlink" title="26 Remove Duplicate from Sorted Array"></a>26 Remove Duplicate from Sorted Array</h3><p><a href="https://leetcode-cn.com/problems/remove-duplicates-from-sorted-array/">leetcode link</a></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">removeDuplicates</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> nums<span class="token punctuation">:</span> List<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">int</span><span class="token punctuation">:</span>        d <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">.</span>fromkeys<span class="token punctuation">(</span>nums<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>        counter <span class="token operator">=</span> <span class="token number">0</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>nums<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">if</span> d<span class="token punctuation">[</span>nums<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>                d<span class="token punctuation">[</span>nums<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>                nums<span class="token punctuation">[</span>counter<span class="token punctuation">]</span> <span class="token operator">=</span> nums<span class="token punctuation">[</span>i<span class="token punctuation">]</span>                counter <span class="token operator">+=</span> <span class="token number">1</span>            <span class="token keyword">else</span><span class="token punctuation">:</span>                nums<span class="token punctuation">[</span>counter<span class="token punctuation">]</span> <span class="token operator">=</span> nums<span class="token punctuation">[</span>i<span class="token punctuation">]</span>        <span class="token keyword">return</span> counter<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="53-Maximum-Subarray"><a href="#53-Maximum-Subarray" class="headerlink" title="53 Maximum Subarray"></a>53 Maximum Subarray</h3><p><a href="https://leetcode-cn.com/problems/maximum-subarray/">leetcode link</a></p><p>这题一开始我想要使用递归的思想来解决，递归的数学模型其实就是数学归纳法：中止条件（推倒第一块积木） + 利用假设解决问题（多米诺效应）</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">recursive</span><span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> end<span class="token punctuation">:</span>        statement<span class="token keyword">else</span><span class="token punctuation">:</span>        solve        recursive<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>但是似乎不能够通过归纳法简单地得出结论，我定义假设：已知序列 nums[:k] 的和及其开始位置，那么序列 nums[:k+1] 的连续最大和及其开始位置在哪里。<strong>解析：使用动态规划</strong></p><p>动态规划其实是一个很大的研究领域，我认为之后有必要好好总结这个思想（recursive + momoization）。动态规划有几个关键概念：</p><ol><li><p>状态</p></li><li><p>状态转移方程</p></li><li><p>初始化</p></li><li><p>无后效性：如果之前的阶段求解的子问题的结果包含了一些不确定的信息，导致了后面的阶段求解的子问题无法得到，或者很难得到，这叫「有后效性」</p><p>解决「有后效性」的办法是固定住需要分类讨论的地方，通常有两个解决方法：</p><ol><li>状态数组增加维度</li><li>把状态定义得更细致、准确</li></ol></li></ol><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># empty</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="Matrix"><a href="#Matrix" class="headerlink" title="Matrix"></a>Matrix</h2><h3 id="74-Search-a-2D-Matrix"><a href="#74-Search-a-2D-Matrix" class="headerlink" title="74 Search a 2D Matrix"></a>74 Search a 2D Matrix</h3><p><a href="https://leetcode-cn.com/problems/reconstruct-a-2-row-binary-matrix/">leetcode link</a></p><p>这一题想使用 numpy 来做，但速度比较慢，可能因为 import 的原因</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">reconstructMatrix</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> upper<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span> lower<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span> colsum<span class="token punctuation">:</span> List<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> List<span class="token punctuation">[</span>List<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">:</span>        <span class="token keyword">import</span> numpy <span class="token keyword">as</span> np        sum_col <span class="token operator">=</span> <span class="token builtin">sum</span><span class="token punctuation">(</span>colsum<span class="token punctuation">)</span>        n <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>colsum<span class="token punctuation">)</span>        <span class="token keyword">if</span> sum_col <span class="token operator">-</span> lower <span class="token operator">!=</span> upper<span class="token punctuation">:</span>            <span class="token keyword">return</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        mark_2 <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>colsum<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">2</span>        sum_ <span class="token operator">=</span> mark_2<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> sum_ <span class="token operator">&gt;</span> lower<span class="token punctuation">:</span>            <span class="token keyword">return</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        upper <span class="token operator">-=</span> sum_        a <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> n<span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span><span class="token builtin">int</span><span class="token punctuation">)</span>        a<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> mark_2<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">if</span> mark_2<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token boolean">True</span><span class="token punctuation">:</span>                <span class="token keyword">continue</span>            <span class="token keyword">if</span> colsum<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">&gt;</span> <span class="token number">0</span> <span class="token keyword">and</span> upper <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">:</span>                a<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> i<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>                upper <span class="token operator">-=</span> <span class="token number">1</span>            a<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> i<span class="token punctuation">]</span> <span class="token operator">=</span> colsum<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">-</span> a<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> i<span class="token punctuation">]</span>        <span class="token keyword">return</span> a<span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="240-Search-a-2D-Matrix-ii"><a href="#240-Search-a-2D-Matrix-ii" class="headerlink" title="240 Search a 2D Matrix ii"></a>240 Search a 2D Matrix ii</h3><p><a href="https://leetcode-cn.com/problems/search-a-2d-matrix-ii/submissions/">leetcode link</a></p><p>第一个直观的想法就是二分查找</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">searchMatrix</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> matrix<span class="token punctuation">:</span> List<span class="token punctuation">[</span>List<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> target<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">bool</span><span class="token punctuation">:</span>        <span class="token comment"># solution_1 binary search</span>        <span class="token keyword">def</span> <span class="token function">binary_search</span><span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">,</span> target<span class="token punctuation">)</span><span class="token punctuation">:</span>            begin<span class="token punctuation">,</span> end <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span>            <span class="token keyword">while</span> begin <span class="token operator">&lt;=</span> end<span class="token punctuation">:</span>                mid <span class="token operator">=</span> <span class="token punctuation">(</span>begin <span class="token operator">+</span> end<span class="token punctuation">)</span> <span class="token operator">//</span> <span class="token number">2</span>                <span class="token keyword">if</span> <span class="token builtin">list</span><span class="token punctuation">[</span>mid<span class="token punctuation">]</span> <span class="token operator">==</span> target<span class="token punctuation">:</span>                    <span class="token keyword">return</span> <span class="token boolean">True</span>                <span class="token keyword">if</span> <span class="token builtin">list</span><span class="token punctuation">[</span>mid<span class="token punctuation">]</span> <span class="token operator">&gt;</span> target<span class="token punctuation">:</span>                    end <span class="token operator">=</span> mid <span class="token operator">-</span> <span class="token number">1</span>                <span class="token keyword">else</span><span class="token punctuation">:</span>                    begin <span class="token operator">=</span> mid <span class="token operator">+</span> <span class="token number">1</span>            <span class="token keyword">return</span> <span class="token boolean">False</span>        <span class="token keyword">for</span> array <span class="token keyword">in</span> matrix<span class="token punctuation">:</span>            ret <span class="token operator">=</span> binary_search<span class="token punctuation">(</span>array<span class="token punctuation">,</span> target<span class="token punctuation">)</span>            <span class="token keyword">if</span> ret<span class="token punctuation">:</span>                <span class="token keyword">return</span> <span class="token boolean">True</span>        <span class="token keyword">return</span> <span class="token boolean">False</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>但直觉感觉复杂度应该在 O(m + n) 所以还有更好的搜索方法，又想到一个方法：重视对角。因为对角是最小和最大值，先看 target 值在哪个区间，然后就去对应的区域搜索。但实现起来过于复杂，看题解是从右上角开始搜索，这的确更好</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">searchMatrix</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> matrix<span class="token punctuation">:</span> List<span class="token punctuation">[</span>List<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> target<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">bool</span><span class="token punctuation">:</span>        <span class="token comment"># seach from top right corner</span>        m<span class="token punctuation">,</span> n <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>matrix<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>matrix<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        i<span class="token punctuation">,</span> j <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> n <span class="token operator">-</span> <span class="token number">1</span>        <span class="token keyword">while</span> i <span class="token operator">&lt;</span> m <span class="token keyword">and</span> j <span class="token operator">&gt;=</span> <span class="token number">0</span><span class="token punctuation">:</span>            top_right <span class="token operator">=</span> matrix<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span>            <span class="token keyword">if</span> top_right <span class="token operator">==</span> target<span class="token punctuation">:</span>                <span class="token keyword">return</span> <span class="token boolean">True</span>            <span class="token keyword">elif</span> top_right <span class="token operator">&gt;</span> target<span class="token punctuation">:</span>                j <span class="token operator">-=</span> <span class="token number">1</span>            <span class="token keyword">else</span><span class="token punctuation">:</span>                i <span class="token operator">+=</span> <span class="token number">1</span>        <span class="token keyword">return</span> <span class="token boolean">False</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="Math"><a href="#Math" class="headerlink" title="Math"></a>Math</h2><h3 id="15-3Sum"><a href="#15-3Sum" class="headerlink" title="15 3Sum"></a>15 3Sum</h3><p><a href="https://leetcode-cn.com/problems/power-of-three/">leetcode link</a></p><p>算法时间复杂度为 O(1)，或者使用 log 逆运算</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">isPowerOfThree</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> n<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">bool</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> n <span class="token operator">&gt;</span> <span class="token number">0</span> <span class="token keyword">and</span> <span class="token number">1162261467</span> <span class="token operator">%</span> n <span class="token operator">==</span> <span class="token number">0</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="18-4Sum"><a href="#18-4Sum" class="headerlink" title="18 4Sum"></a>18 4Sum</h3><p><a href="https://leetcode-cn.com/problems/power-of-four/">leetcode link</a></p><p>类似于 3sum</p><h3 id="560-Subarray-Sum-Equals-K"><a href="#560-Subarray-Sum-Equals-K" class="headerlink" title="560 Subarray Sum Equals K"></a>560 Subarray Sum Equals K</h3><p><a href="https://leetcode-cn.com/problems/subarray-sum-equals-k/submissions/">leetcode link</a></p><p>前缀和 + 哈希表查找</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">subarraySum</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> nums<span class="token punctuation">:</span> List<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span><span class="token punctuation">,</span> k<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">int</span><span class="token punctuation">:</span>        n <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>nums<span class="token punctuation">)</span>        d <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>        count<span class="token punctuation">,</span> s_ <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token comment"># 前缀和</span>            s_ <span class="token operator">+=</span> nums<span class="token punctuation">[</span>i<span class="token punctuation">]</span>            <span class="token comment"># 检查 sum 自身是否等于</span>            <span class="token keyword">if</span> s_ <span class="token operator">==</span> k<span class="token punctuation">:</span>                count <span class="token operator">+=</span> <span class="token number">1</span>            <span class="token comment"># 检查当前 sum_ 是否是别人的期待</span>            count <span class="token operator">+=</span> d<span class="token punctuation">.</span>get<span class="token punctuation">(</span>s_<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>            <span class="token comment"># 将当前期待更新到字典</span>            new_target <span class="token operator">=</span> s_ <span class="token operator">+</span> k            d<span class="token punctuation">[</span>new_target<span class="token punctuation">]</span> <span class="token operator">=</span> d<span class="token punctuation">.</span>get<span class="token punctuation">(</span>new_target<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span>        <span class="token keyword">return</span> count<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="Tree"><a href="#Tree" class="headerlink" title="Tree"></a>Tree</h2><h3 id="94-Binary-Tree-Inorder-Traversal"><a href="#94-Binary-Tree-Inorder-Traversal" class="headerlink" title="94 Binary Tree Inorder Traversal"></a>94 Binary Tree Inorder Traversal</h3><p><a href="https://leetcode-cn.com/problems/binary-tree-inorder-traversal/">leetcode link</a></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">inorderTraversal</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> root<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>TreeNode<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> List<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span><span class="token punctuation">:</span>        l <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">if</span> root <span class="token operator">!=</span> <span class="token boolean">None</span><span class="token punctuation">:</span>            l <span class="token operator">+=</span> self<span class="token punctuation">.</span>inorderTraversal<span class="token punctuation">(</span>root<span class="token punctuation">.</span>left<span class="token punctuation">)</span>            l<span class="token punctuation">.</span>append<span class="token punctuation">(</span>root<span class="token punctuation">.</span>val<span class="token punctuation">)</span>            l <span class="token operator">+=</span> self<span class="token punctuation">.</span>inorderTraversal<span class="token punctuation">(</span>root<span class="token punctuation">.</span>right<span class="token punctuation">)</span>        <span class="token keyword">return</span> l<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="95-Unique-Binary-Search-Trees-ii"><a href="#95-Unique-Binary-Search-Trees-ii" class="headerlink" title="95 Unique Binary Search Trees ii"></a>95 Unique Binary Search Trees ii</h3><p><a href="https://leetcode-cn.com/problems/unique-binary-search-trees-ii/">leetcode link</a></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Solution</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">generateTrees</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> n<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> List<span class="token punctuation">[</span>TreeNode<span class="token punctuation">]</span><span class="token punctuation">:</span>        <span class="token keyword">def</span> <span class="token function">g</span><span class="token punctuation">(</span>start<span class="token punctuation">,</span> end<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">if</span> start <span class="token operator">&gt;</span> end<span class="token punctuation">:</span>                <span class="token comment"># None 也是要占一个位置的！</span>                <span class="token keyword">return</span> <span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">]</span>            ret <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>            <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>start<span class="token punctuation">,</span> end <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                left_tree_list <span class="token operator">=</span> g<span class="token punctuation">(</span>start<span class="token punctuation">,</span> i <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span>                right_tree_list  <span class="token operator">=</span> g<span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> end<span class="token punctuation">)</span>                <span class="token keyword">for</span> left <span class="token keyword">in</span> left_tree_list<span class="token punctuation">:</span>                    <span class="token keyword">for</span> right <span class="token keyword">in</span> right_tree_list<span class="token punctuation">:</span>                        <span class="token comment"># 根节点要在里面定义，不然会出错，因为修改了 root 列表中的 root 也会跟着修改！！</span>                        root <span class="token operator">=</span> TreeNode<span class="token punctuation">(</span>val<span class="token operator">=</span>i<span class="token punctuation">)</span>                        root<span class="token punctuation">.</span>left <span class="token operator">=</span> left                        root<span class="token punctuation">.</span>right <span class="token operator">=</span> right                        ret<span class="token punctuation">.</span>append<span class="token punctuation">(</span>root<span class="token punctuation">)</span>            <span class="token keyword">return</span> ret        <span class="token keyword">return</span> g<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> n<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="144-Binary-Tree-Preorder-Traversal"><a href="#144-Binary-Tree-Preorder-Traversal" class="headerlink" title="144 Binary Tree Preorder Traversal"></a>144 Binary Tree Preorder Traversal</h3><p><a href="https://leetcode-cn.com/problems/binary-tree-preorder-traversal/">leetcode link</a></p><p>前序遍历：根节点，左，右</p><p>中序遍历：左，根节点，右</p><p>后序遍历：左，右，根节点</p>]]></content>
      
      
      <categories>
          
          <category> 编程 </category>
          
          <category> Leetcode </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Leetcode </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenPCDet VoxelRCNN</title>
      <link href="/archives/c3e4f95d.html"/>
      <url>/archives/c3e4f95d.html</url>
      
        <content type="html"><![CDATA[<h1 id="Voxel-R-CNN"><a href="#Voxel-R-CNN" class="headerlink" title="Voxel R-CNN"></a>Voxel R-CNN</h1><h2 id="VoxelRCNN"><a href="#VoxelRCNN" class="headerlink" title="VoxelRCNN"></a>VoxelRCNN</h2><p>来看看 Voxel R-CNN 的实现，由于高度的抽象化和良好的封装，其模型代码和 SECOND 相比，仅多一行 <code>loss_rcnn, tb_dict = self.roi_head.get_loss(tb_dict)</code> 与 roi 相关</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">VoxelRCNN</span><span class="token punctuation">(</span>Detector3DTemplate<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> model_cfg<span class="token punctuation">,</span> num_class<span class="token punctuation">,</span> dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span>model_cfg<span class="token operator">=</span>model_cfg<span class="token punctuation">,</span> num_class<span class="token operator">=</span>num_class<span class="token punctuation">,</span> dataset<span class="token operator">=</span>dataset<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>module_list <span class="token operator">=</span> self<span class="token punctuation">.</span>build_networks<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch_dict<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> cur_module <span class="token keyword">in</span> self<span class="token punctuation">.</span>module_list<span class="token punctuation">:</span>            batch_dict <span class="token operator">=</span> cur_module<span class="token punctuation">(</span>batch_dict<span class="token punctuation">)</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>training<span class="token punctuation">:</span>            loss<span class="token punctuation">,</span> tb_dict<span class="token punctuation">,</span> disp_dict <span class="token operator">=</span> self<span class="token punctuation">.</span>get_training_loss<span class="token punctuation">(</span><span class="token punctuation">)</span>            ret_dict <span class="token operator">=</span> <span class="token punctuation">{</span>                <span class="token string">'loss'</span><span class="token punctuation">:</span> loss            <span class="token punctuation">}</span>            <span class="token keyword">return</span> ret_dict<span class="token punctuation">,</span> tb_dict<span class="token punctuation">,</span> disp_dict        <span class="token keyword">else</span><span class="token punctuation">:</span>            pred_dicts<span class="token punctuation">,</span> recall_dicts <span class="token operator">=</span> self<span class="token punctuation">.</span>post_processing<span class="token punctuation">(</span>batch_dict<span class="token punctuation">)</span>            <span class="token keyword">return</span> pred_dicts<span class="token punctuation">,</span> recall_dicts    <span class="token keyword">def</span> <span class="token function">get_training_loss</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        disp_dict <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>        loss <span class="token operator">=</span> <span class="token number">0</span>                loss_rpn<span class="token punctuation">,</span> tb_dict <span class="token operator">=</span> self<span class="token punctuation">.</span>dense_head<span class="token punctuation">.</span>get_loss<span class="token punctuation">(</span><span class="token punctuation">)</span>        loss_rcnn<span class="token punctuation">,</span> tb_dict <span class="token operator">=</span> self<span class="token punctuation">.</span>roi_head<span class="token punctuation">.</span>get_loss<span class="token punctuation">(</span>tb_dict<span class="token punctuation">)</span>        loss <span class="token operator">=</span> loss <span class="token operator">+</span> loss_rpn <span class="token operator">+</span> loss_rcnn        <span class="token keyword">return</span> loss<span class="token punctuation">,</span> tb_dict<span class="token punctuation">,</span> disp_dict<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="MeanVFE-VFE"><a href="#MeanVFE-VFE" class="headerlink" title="MeanVFE (VFE)"></a>MeanVFE (VFE)</h2><p>将体素中每个点的特征进行平均，batch_dict 添加了 vfe_features 关键字</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch_dict<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token string">""</span>"    Args<span class="token punctuation">:</span>        batch_dict<span class="token punctuation">:</span>            voxels<span class="token punctuation">:</span> <span class="token punctuation">(</span>num_voxels<span class="token punctuation">,</span> max_points_per_voxel<span class="token punctuation">,</span> C<span class="token punctuation">)</span>            voxel_num_points<span class="token punctuation">:</span> optional <span class="token punctuation">(</span>num_voxels<span class="token punctuation">)</span>        <span class="token operator">**</span>kwargs<span class="token punctuation">:</span>    Returns<span class="token punctuation">:</span>        vfe_features<span class="token punctuation">:</span> <span class="token punctuation">(</span>num_voxels<span class="token punctuation">,</span> C<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="VoxelBackBone8x-BACKBONE-3D"><a href="#VoxelBackBone8x-BACKBONE-3D" class="headerlink" title="VoxelBackBone8x (BACKBONE_3D)"></a>VoxelBackBone8x (BACKBONE_3D)</h2><h3 id="Spconv"><a href="#Spconv" class="headerlink" title="Spconv"></a>Spconv</h3><p>首先总结一下 spconv1.2 的操作逻辑</p><ol><li><p>生成 <code>SparseConvTensor</code> </p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> spconvfeatures <span class="token operator">=</span> <span class="token comment"># [N, num_channels]</span>indices <span class="token operator">=</span> <span class="token comment"># your indices/coordinates with shape [N, ndim + 1] (in 3D ndim=3), batch index must be put in indices[:, 0]</span>spatial_shape <span class="token operator">=</span> <span class="token comment"># spatial shape of your sparse tensor, (in 3D its shape=[3]) .</span>batch_size <span class="token operator">=</span> <span class="token comment"># batch size of your sparse tensor.</span>x <span class="token operator">=</span> spconv<span class="token punctuation">.</span>SparseConvTensor<span class="token punctuation">(</span>features<span class="token punctuation">,</span> indices<span class="token punctuation">,</span> spatial_shape<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>像 Pytorch 一样使用卷积，常用两种卷积 <code>SparseConv3d &amp; SubMconv3d</code>，常用一个容器模块 <code>spconv.SparseSequential</code>，<code>indice_key</code> 可以用于节省相同形状/相同索引的稀疏卷积层建立时间</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">self<span class="token punctuation">.</span>net <span class="token operator">=</span> spconv<span class="token punctuation">.</span>SparseSequential<span class="token punctuation">(</span>            spconv<span class="token punctuation">.</span>SparseConv3d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment"># just like nn.Conv3d but don't support group</span>            nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment"># non-spatial layers can be used directly in SparseSequential.</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            spconv<span class="token punctuation">.</span>SubMConv3d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> indice_key<span class="token operator">=</span><span class="token string">"subm0"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token comment"># when use submanifold convolutions, their indices can be shared to save indices generation time.</span>            spconv<span class="token punctuation">.</span>SubMConv3d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> indice_key<span class="token operator">=</span><span class="token string">"subm0"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            spconv<span class="token punctuation">.</span>SparseConvTranspose3d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            spconv<span class="token punctuation">.</span>ToDense<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment"># convert spconv tensor to dense and convert it to NCHW format.</span>            nn<span class="token punctuation">.</span>Conv3d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>将 <code>SparseConvTensor</code> 转变为正常的 dense tensor</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">x_dense_NCHW <span class="token operator">=</span> x<span class="token punctuation">.</span>dense<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># convert sparse tensor to dense (N,C,D,H,W) tensor.</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li></ol><h3 id="VoxelBackBone8x"><a href="#VoxelBackBone8x" class="headerlink" title="VoxelBackBone8x"></a>VoxelBackBone8x</h3><p>这部分直接看前向方程会有更直观的理解，最终返回了一个字典，不仅包含了输出的特征图谱，还有在卷积过程中每一个分辨率的特征图谱也保存下来了 <code>encoded_spconv_tensor &amp; multi_scale_3d_features</code>，卷积层的具体设置请直接看源码</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch_dict<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""    Args:        batch_dict:            batch_size: int            vfe_features: (num_voxels, C)            voxel_coords: (num_voxels, 4), [batch_idx, z_idx, y_idx, x_idx]    Returns:        batch_dict:            - encoded_spconv_tensor: sparse tensor                To be exact: in KITTI, spatial shape is [200, 176, 2], channel num is 128                But haven't converted to dense format yet            - encoded_spconv_tensor_stride            - multi_scale_3d_features            - multi_scale_3d_strides    """</span>    voxel_features<span class="token punctuation">,</span> voxel_coords <span class="token operator">=</span> batch_dict<span class="token punctuation">[</span><span class="token string">'voxel_features'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> batch_dict<span class="token punctuation">[</span><span class="token string">'voxel_coords'</span><span class="token punctuation">]</span>    batch_size <span class="token operator">=</span> batch_dict<span class="token punctuation">[</span><span class="token string">'batch_size'</span><span class="token punctuation">]</span>    input_sp_tensor <span class="token operator">=</span> spconv<span class="token punctuation">.</span>SparseConvTensor<span class="token punctuation">(</span>        features<span class="token operator">=</span>voxel_features<span class="token punctuation">,</span>        indices<span class="token operator">=</span>voxel_coords<span class="token punctuation">.</span><span class="token builtin">int</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        spatial_shape<span class="token operator">=</span>self<span class="token punctuation">.</span>sparse_shape<span class="token punctuation">,</span>        batch_size<span class="token operator">=</span>batch_size    <span class="token punctuation">)</span>    x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv_input<span class="token punctuation">(</span>input_sp_tensor<span class="token punctuation">)</span>    x_conv1 <span class="token operator">=</span> self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>    x_conv2 <span class="token operator">=</span> self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>x_conv1<span class="token punctuation">)</span>    x_conv3 <span class="token operator">=</span> self<span class="token punctuation">.</span>conv3<span class="token punctuation">(</span>x_conv2<span class="token punctuation">)</span>    x_conv4 <span class="token operator">=</span> self<span class="token punctuation">.</span>conv4<span class="token punctuation">(</span>x_conv3<span class="token punctuation">)</span>    <span class="token comment"># for detection head</span>    <span class="token comment"># [200, 176, 5] -&gt; [200, 176, 2]</span>    out <span class="token operator">=</span> self<span class="token punctuation">.</span>conv_out<span class="token punctuation">(</span>x_conv4<span class="token punctuation">)</span>    batch_dict<span class="token punctuation">.</span>update<span class="token punctuation">(</span><span class="token punctuation">{</span>        <span class="token string">'encoded_spconv_tensor'</span><span class="token punctuation">:</span> out<span class="token punctuation">,</span>        <span class="token string">'encoded_spconv_tensor_stride'</span><span class="token punctuation">:</span> <span class="token number">8</span>    <span class="token punctuation">}</span><span class="token punctuation">)</span>    batch_dict<span class="token punctuation">.</span>update<span class="token punctuation">(</span><span class="token punctuation">{</span>        <span class="token string">'multi_scale_3d_features'</span><span class="token punctuation">:</span> <span class="token punctuation">{</span>            <span class="token string">'x_conv1'</span><span class="token punctuation">:</span> x_conv1<span class="token punctuation">,</span>            <span class="token string">'x_conv2'</span><span class="token punctuation">:</span> x_conv2<span class="token punctuation">,</span>            <span class="token string">'x_conv3'</span><span class="token punctuation">:</span> x_conv3<span class="token punctuation">,</span>            <span class="token string">'x_conv4'</span><span class="token punctuation">:</span> x_conv4<span class="token punctuation">,</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">)</span>    batch_dict<span class="token punctuation">.</span>update<span class="token punctuation">(</span><span class="token punctuation">{</span>        <span class="token string">'multi_scale_3d_strides'</span><span class="token punctuation">:</span> <span class="token punctuation">{</span>            <span class="token string">'x_conv1'</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">,</span>            <span class="token string">'x_conv2'</span><span class="token punctuation">:</span> <span class="token number">2</span><span class="token punctuation">,</span>            <span class="token string">'x_conv3'</span><span class="token punctuation">:</span> <span class="token number">4</span><span class="token punctuation">,</span>            <span class="token string">'x_conv4'</span><span class="token punctuation">:</span> <span class="token number">8</span><span class="token punctuation">,</span>        <span class="token punctuation">}</span>    <span class="token punctuation">}</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> batch_dict<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>发现代码库里实现了残差模块 <code>VoxelResBackBone8x</code>，但是在论文当中并没有使用残差网络</p><h2 id="HeightCompression-MAP-TO-BEV"><a href="#HeightCompression-MAP-TO-BEV" class="headerlink" title="HeightCompression (MAP_TO_BEV)"></a>HeightCompression (MAP_TO_BEV)</h2><p>这部分就是将 <code>SparseConvTensor</code> 转为 dense tensor 并将高度的特征堆叠</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch_dict<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""    Args:        batch_dict:            encoded_spconv_tensor: sparse tensor    Returns:        batch_dict:            - spatial_features: shape is (N, C * D, H, W)            - spatial_feature_stride: encoded_spconv_tensor_stride    """</span>    encoded_spconv_tensor <span class="token operator">=</span> batch_dict<span class="token punctuation">[</span><span class="token string">'encoded_spconv_tensor'</span><span class="token punctuation">]</span>    spatial_features <span class="token operator">=</span> encoded_spconv_tensor<span class="token punctuation">.</span>dense<span class="token punctuation">(</span><span class="token punctuation">)</span>    N<span class="token punctuation">,</span> C<span class="token punctuation">,</span> D<span class="token punctuation">,</span> H<span class="token punctuation">,</span> W <span class="token operator">=</span> spatial_features<span class="token punctuation">.</span>shape    spatial_features <span class="token operator">=</span> spatial_features<span class="token punctuation">.</span>view<span class="token punctuation">(</span>N<span class="token punctuation">,</span> C <span class="token operator">*</span> D<span class="token punctuation">,</span> H<span class="token punctuation">,</span> W<span class="token punctuation">)</span>    batch_dict<span class="token punctuation">[</span><span class="token string">'spatial_features'</span><span class="token punctuation">]</span> <span class="token operator">=</span> spatial_features    batch_dict<span class="token punctuation">[</span><span class="token string">'spatial_features_stride'</span><span class="token punctuation">]</span> <span class="token operator">=</span> batch_dict<span class="token punctuation">[</span><span class="token string">'encoded_spconv_tensor_stride'</span><span class="token punctuation">]</span>    <span class="token keyword">return</span> batch_dict<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="BaseBEVBackbone-BACKBONE-2D"><a href="#BaseBEVBackbone-BACKBONE-2D" class="headerlink" title="BaseBEVBackbone (BACKBONE_2D)"></a>BaseBEVBackbone (BACKBONE_2D)</h2><p>接下来进入 2D 卷积网络，对 <code>encoded_spconv_tensor</code> 进行特征提取，这里用配置文件进行说明比较方便</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">BACKBONE_2D</span><span class="token punctuation">:</span>    <span class="token key atrule">NAME</span><span class="token punctuation">:</span> BaseBEVBackbone    <span class="token comment"># 5 convolution layers, input channel == output channel == num_filters[idx], stride = 1</span>    <span class="token key atrule">LAYER_NUMS</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span>    <span class="token key atrule">LAYER_STRIDES</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span>    <span class="token key atrule">NUM_FILTERS</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">]</span>    <span class="token key atrule">UPSAMPLE_STRIDES</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span>    <span class="token key atrule">NUM_UPSAMPLE_FILTERS</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>使用了两个卷积块，每个卷积块由 (5 + 1) 个卷积层组成，+1 代表的卷积层用于通道数的转换，两个卷积块有不同的 stride 以获得不同分辨率。之后使用上采样将两个不同分辨率的特征图谱转换成相同的特征图谱，然后将二者进行通道连接</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data_dict<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""    Args:        data_dict:            spatial_features: shape is (N, C * D, H, W)    Returns:        data_dict: spatial_features_2d (N, channels, H, W)    """</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="AnchorHeadSingle-DENSE-HEAD"><a href="#AnchorHeadSingle-DENSE-HEAD" class="headerlink" title="AnchorHeadSingle (DENSE_HEAD)"></a>AnchorHeadSingle (DENSE_HEAD)</h2><p>这将会比较复杂的部分。anchor 生成，target 分配，损失函数的计算，预测结果，都将在这个 <code>DENSE_HEAD</code> 中完成。该类的实现也是有基类的 <code>AnchorHeadTemplate</code></p><h3 id="AnchorHeadTemplate"><a href="#AnchorHeadTemplate" class="headerlink" title="AnchorHeadTemplate"></a>AnchorHeadTemplate</h3><p>这个基类功能也非常多，我暂且把它的功能分为两大类：anchor 相关和 loss 相关</p><h4 id="Anchor-相关"><a href="#Anchor-相关" class="headerlink" title="Anchor 相关"></a>Anchor 相关</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">AnchorHeadTemplate</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> model_cfg<span class="token punctuation">,</span> num_class<span class="token punctuation">,</span> class_names<span class="token punctuation">,</span> grid_size<span class="token punctuation">,</span> point_cloud_range<span class="token punctuation">,</span> predict_boxes_when_training<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        Attributes:        - self.anchors            - self.box_coder            - self.target_assigner            - self.forward_ret_dict        """</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol><li><p><code>anchors</code>：一个列表，每个成员对一个类别，一般成员的张量形状都是一样的，<code>anchors[0].shape = (z, y, x, num_anchor_size, num_anchor_rotation, 7)</code>，anchors 的生成就不过多介绍了</p></li><li><p><code>box_encoder</code>：可以看作生成回归目标的类，有两个主要功能：输入 anchors 和 gt_boxes，将返回二者的残差；输入残差和 anchors 返回真实的 boxes</p></li><li><p><code>target_assigner</code>：其 <code>assign_targets</code> 方法返回一个字典</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">all_targets_dict <span class="token operator">=</span> <span class="token punctuation">{</span>            <span class="token string">'box_cls_labels'</span><span class="token punctuation">:</span> cls_labels<span class="token punctuation">,</span>   <span class="token comment"># shape is (4, 211200) in KITTI, bg box is 0, fg box is int like (1, 2, 3)</span>    <span class="token comment"># those don't care is -1</span>            <span class="token string">'box_reg_targets'</span><span class="token punctuation">:</span> bbox_targets<span class="token punctuation">,</span>    <span class="token comment"># (4, 211200, 7) to be exact, (4, 200*176*2*3, 7)</span>            <span class="token string">'reg_weights'</span><span class="token punctuation">:</span> reg_weights<span class="token comment"># 1 or 1 / positive_anchors (if normalize), negative anchors are 0</span>    <span class="token comment"># regression weights 在之后似乎并没有用到，而是直接从 cls_label 里进行判断</span>        <span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>发现这里没有使用 $sin(\Delta \theta)$ 对 target 进行编码，而是直接使用 $\Delta \theta$ 表示方向残差，之后单独用 <code>add_sin_difference</code> 处理。assign targets 是<strong>分批分类</strong>进行处理的，这里贴一下其中的核心代码，了解处理一个 sample 一个类该怎么做，因为制作 targets 的过程比较细，不好好看一下真的不清晰</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">labels <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span>num_anchors<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>int32<span class="token punctuation">,</span> device<span class="token operator">=</span>anchors<span class="token punctuation">.</span>device<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token operator">-</span><span class="token number">1</span>gt_ids <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span>num_anchors<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>int32<span class="token punctuation">,</span> device<span class="token operator">=</span>anchors<span class="token punctuation">.</span>device<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token operator">-</span><span class="token number">1</span><span class="token comment"># 返回与 gt 重叠最大的 anchor index 一般形状为 (num_gt,)</span>anchors_with_max_overlap <span class="token operator">=</span> <span class="token punctuation">(</span>anchor_by_gt_overlap <span class="token operator">==</span> gt_to_anchor_max<span class="token punctuation">)</span><span class="token punctuation">.</span>nonzero<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token comment"># 返回被选中的 gt index, anchor_to_gt_argmax.shape = (num_anchors,)</span>gt_inds_force <span class="token operator">=</span> anchor_to_gt_argmax<span class="token punctuation">[</span>anchors_with_max_overlap<span class="token punctuation">]</span><span class="token comment"># 标记 max_overlap anchor 并记录其 gt index</span>labels<span class="token punctuation">[</span>anchors_with_max_overlap<span class="token punctuation">]</span> <span class="token operator">=</span> gt_classes<span class="token punctuation">[</span>gt_inds_force<span class="token punctuation">]</span>gt_ids<span class="token punctuation">[</span>anchors_with_max_overlap<span class="token punctuation">]</span> <span class="token operator">=</span> gt_inds_force<span class="token punctuation">.</span><span class="token builtin">int</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># 需要注意的是 positive anchor 与 anchors_with_max_overlap 是两个不同的集合</span>pos_inds <span class="token operator">=</span> anchor_to_gt_max <span class="token operator">&gt;=</span> matched_thresholdgt_inds_over_thresh <span class="token operator">=</span> anchor_to_gt_argmax<span class="token punctuation">[</span>pos_inds<span class="token punctuation">]</span><span class="token comment"># 标记 positive anchor 并记录其 gt index</span>labels<span class="token punctuation">[</span>pos_inds<span class="token punctuation">]</span> <span class="token operator">=</span> gt_classes<span class="token punctuation">[</span>gt_inds_over_thresh<span class="token punctuation">]</span>gt_ids<span class="token punctuation">[</span>pos_inds<span class="token punctuation">]</span> <span class="token operator">=</span> gt_inds_over_thresh<span class="token punctuation">.</span><span class="token builtin">int</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># 需要注意的是 negative thres 和 positive thres 之间是有间隙的，二者不相等</span>bg_inds <span class="token operator">=</span> <span class="token punctuation">(</span>anchor_to_gt_max <span class="token operator">&lt;</span> unmatched_threshold<span class="token punctuation">)</span><span class="token punctuation">.</span>nonzero<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token comment"># 标记 background anchor</span>labels<span class="token punctuation">[</span>bg_inds<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span><span class="token comment"># 综上 fg_inds 是 positive_inds | anchors_with_max_overlap - bg_inds</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>重要的总结再说一遍：综上 <code>fg_inds</code> 是 <code>positive_inds | anchors_with_max_overlap - bg_inds</code></strong></p></li><li><p><code>forward_ret_dict</code>: 虽然这是与 loss 相关的部分，暂且先放在这里。该字典存储向前传播中的预测结果及其标签，用于之后计算 loss</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">cls_predsbox_predsdir_cls_predsbox_cls_labelsbox_reg_targetsreg_weights<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ol><h4 id="Loss-相关"><a href="#Loss-相关" class="headerlink" title="Loss 相关"></a>Loss 相关</h4><p>有了 anchor 和对应的 target 还需要预测结果 prediction 才能够计算，需要注意的是：预测的结果是选框残差，还需要 <code>generate_predicted_boxes</code> 产生实际的选框结果。</p><p><code>get_loss</code> 将获得每个 batch 的损失函数，需要注意的是，loss 相关的方法一般不会在 AnchorHeadSingle 的前向方程中使用，<strong>而是在总模型的前向方程中调用（即：在 VoxelRCNN 类中）</strong>。下面具体看看其组成内容，也不做细节了解</p><ol><li><p><code>get_loss</code> 将返回分类损失和回归损失，其中方向分类损失是在回归损失中计算的。<code>get_loss</code> 的调用一般是在模型的 <code>get_training_loss</code> 中，请查看该笔记之前记录的 <code>SECOND</code> 部分中的 <code>forward</code> 代码 </p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">get_loss</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># 获得分类损失 (batch, num_anchors_all)</span>    cls_loss<span class="token punctuation">,</span> tb_dict <span class="token operator">=</span> self<span class="token punctuation">.</span>get_cls_layer_loss<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token comment"># 获得回归损失</span>    box_loss<span class="token punctuation">,</span> tb_dict_box <span class="token operator">=</span> self<span class="token punctuation">.</span>get_box_reg_layer_loss<span class="token punctuation">(</span><span class="token punctuation">)</span>    tb_dict<span class="token punctuation">.</span>update<span class="token punctuation">(</span>tb_dict_box<span class="token punctuation">)</span>    rpn_loss <span class="token operator">=</span> cls_loss <span class="token operator">+</span> box_loss    tb_dict<span class="token punctuation">[</span><span class="token string">'rpn_loss'</span><span class="token punctuation">]</span> <span class="token operator">=</span> rpn_loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> rpn_loss<span class="token punctuation">,</span> tb_dict<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可学习的技巧：使用 weight 来进行筛选，因为在并行运算的情况下，乘法比索引筛选更快</p></li><li><p><code>generate_predicted_boxes</code></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">generate_predicted_boxes</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> cls_preds<span class="token punctuation">,</span> box_preds<span class="token punctuation">,</span> dir_cls_preds<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>   <span class="token triple-quoted-string string">"""   Args:       batch_size:       cls_preds: (N, H, W, C1)       box_preds: (N, H, W, C2)       dir_cls_preds: (N, H, W, C3)      Returns:       batch_cls_preds: (B, num_boxes, num_classes)       batch_box_preds: (B, num_boxes, 7+C)   """</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>因为 target 是残差，所以在预测了结果过后需要 <code>box_coder</code> 进行解码，变为真实的 box</p></li></ol><h3 id="AnchorHeadSingle"><a href="#AnchorHeadSingle" class="headerlink" title="AnchorHeadSingle"></a>AnchorHeadSingle</h3><p>有了基类的功能，<code>AnchorHeadSingle</code> 就可以把中心放在网络的搭建之上了，模块在 <code>__init__</code> 中定义了三个卷积层：<code>conv_cls &amp; conv_box &amp; conv_dir_cls</code> 分别对类别，bbox，朝向进行预测，注意这里并没有全连接层的存在，直接把各个 channel 中的结果作为预测结果。获得预测结果过后：</p><ol><li>如果是单阶段检测器基本前向方程就结束了，接下来回到 <code>Detector</code> 模块中计算损失函数。如果是测试阶段，需要将预测结果进一步生成最终选框（因为预测的结果是残差），然后进行 NMS 后处理</li><li>如果是两阶段检测器，也是将预测结果进一步生成选框，然后继续向前计算</li></ol><p>下面来看看前向方程，有一个具体感受</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data_dict<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># 获得 BEV 特征图谱</span>    spatial_features_2d <span class="token operator">=</span> data_dict<span class="token punctuation">[</span><span class="token string">'spatial_features_2d'</span><span class="token punctuation">]</span>    <span class="token comment"># 分类和回归图谱</span>    cls_preds <span class="token operator">=</span> self<span class="token punctuation">.</span>conv_cls<span class="token punctuation">(</span>spatial_features_2d<span class="token punctuation">)</span>    box_preds <span class="token operator">=</span> self<span class="token punctuation">.</span>conv_box<span class="token punctuation">(</span>spatial_features_2d<span class="token punctuation">)</span>    <span class="token comment"># 把 channel 移动到最后一个维度，便于之后计算损失函数</span>    cls_preds <span class="token operator">=</span> cls_preds<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># [N, H, W, C]</span>    box_preds <span class="token operator">=</span> box_preds<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># [N, H, W, C]</span>    self<span class="token punctuation">.</span>forward_ret_dict<span class="token punctuation">[</span><span class="token string">'cls_preds'</span><span class="token punctuation">]</span> <span class="token operator">=</span> cls_preds    self<span class="token punctuation">.</span>forward_ret_dict<span class="token punctuation">[</span><span class="token string">'box_preds'</span><span class="token punctuation">]</span> <span class="token operator">=</span> box_preds    <span class="token comment"># 方向分类图谱</span>    <span class="token keyword">if</span> self<span class="token punctuation">.</span>conv_dir_cls <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>        dir_cls_preds <span class="token operator">=</span> self<span class="token punctuation">.</span>conv_dir_cls<span class="token punctuation">(</span>spatial_features_2d<span class="token punctuation">)</span>        dir_cls_preds <span class="token operator">=</span> dir_cls_preds<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>forward_ret_dict<span class="token punctuation">[</span><span class="token string">'dir_cls_preds'</span><span class="token punctuation">]</span> <span class="token operator">=</span> dir_cls_preds    <span class="token keyword">else</span><span class="token punctuation">:</span>        dir_cls_preds <span class="token operator">=</span> <span class="token boolean">None</span>    <span class="token comment"># targets_dict 返回值在 anchor 相关部分里</span>    <span class="token keyword">if</span> self<span class="token punctuation">.</span>training<span class="token punctuation">:</span>        targets_dict <span class="token operator">=</span> self<span class="token punctuation">.</span>assign_targets<span class="token punctuation">(</span>            gt_boxes<span class="token operator">=</span>data_dict<span class="token punctuation">[</span><span class="token string">'gt_boxes'</span><span class="token punctuation">]</span>        <span class="token punctuation">)</span>        self<span class="token punctuation">.</span>forward_ret_dict<span class="token punctuation">.</span>update<span class="token punctuation">(</span>targets_dict<span class="token punctuation">)</span>    <span class="token comment"># 如果是测试或者是两阶段检测器，则需要生成选框预测</span>    <span class="token keyword">if</span> <span class="token keyword">not</span> self<span class="token punctuation">.</span>training <span class="token keyword">or</span> self<span class="token punctuation">.</span>predict_boxes_when_training<span class="token punctuation">:</span>        batch_cls_preds<span class="token punctuation">,</span> batch_box_preds <span class="token operator">=</span> self<span class="token punctuation">.</span>generate_predicted_boxes<span class="token punctuation">(</span>            batch_size<span class="token operator">=</span>data_dict<span class="token punctuation">[</span><span class="token string">'batch_size'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>            cls_preds<span class="token operator">=</span>cls_preds<span class="token punctuation">,</span> box_preds<span class="token operator">=</span>box_preds<span class="token punctuation">,</span> dir_cls_preds<span class="token operator">=</span>dir_cls_preds        <span class="token punctuation">)</span>        data_dict<span class="token punctuation">[</span><span class="token string">'batch_cls_preds'</span><span class="token punctuation">]</span> <span class="token operator">=</span> batch_cls_preds        data_dict<span class="token punctuation">[</span><span class="token string">'batch_box_preds'</span><span class="token punctuation">]</span> <span class="token operator">=</span> batch_box_preds        data_dict<span class="token punctuation">[</span><span class="token string">'cls_preds_normalized'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">False</span>    <span class="token keyword">return</span> data_dict<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="VoxelRCNNHead-ROI-HEAD"><a href="#VoxelRCNNHead-ROI-HEAD" class="headerlink" title="VoxelRCNNHead (ROI_HEAD)"></a>VoxelRCNNHead (ROI_HEAD)</h2><p>从配置文件看，这一部分也是最复杂的。不过不要担心，有了足够的理论知识和对之前代码的解读，咱也能大致掌握其中的重要的流程🤨先来看基类 <code>RoIHeadTemplate</code> 实现</p><h3 id="RoIHeadTemplate"><a href="#RoIHeadTemplate" class="headerlink" title="RoIHeadTemplate"></a>RoIHeadTemplate</h3><p>还是按照之前 AnchorHeadTemplate 的总结方式，分为两类：proposal 相关和 loss 相关</p><h4 id="Proposal-相关"><a href="#Proposal-相关" class="headerlink" title="Proposal 相关"></a>Proposal 相关</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">RoIHeadTemplate</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> num_class<span class="token punctuation">,</span> model_cfg<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        Attribute:            - self.box_coder: ResidualCoder            - self.proposal_target_layer            - self.forward_ret_dict        """</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>以上是初始化函数，<code>box_coder</code> 和之前的是一样的 <code>ResidualCoder</code>；比较重要的是 <code>proposal_target_layer</code>，这部分对应的配置是 <code>TARGET_CONFIG</code>，其功能是对 NMS 筛选过后的 proposal（此时应该叫 rois）进行采样并制作其标签；<code>forward_ret_dict</code> 用于存储向前传播中的预测结果及其标签，用于之后计算 loss。下面进行进一步介绍 proposal 相关方法：</p><ol><li><code>proposal_layer</code> 该方法将使用 NMS，（通常）返回 512 个 rois</li></ol><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch_dict<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""    Args:        batch_dict:            batch_size:            rois: (B, num_rois, 7 + C)            roi_scores: (B, num_rois)            gt_boxes: (B, N, 7 + C + 1)            roi_labels: (B, num_rois)    Returns:        batch_dict:            rois: (B, M, 7 + C)            gt_of_rois: (B, M, 7 + C)            gt_iou_of_rois: (B, M)            roi_scores: (B, M)            roi_labels: (B, M) cls-based label            reg_valid_mask: (B, M) positive bbox            rcnn_cls_labels: (B, M) iou-based label    """</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><ol><li><p><code>assign_targets</code> 方法完成了两个事情：</p><ol><li><p>在 rois 采样 M 个 roi，并获得其对应的 gt 标签。通常采样 128 个 roi，以 1:1 正负比例进行采样，正负判定条件依然为 iou 相关阈值，负采样仅参与置信度损失的计算，不参与回归损失的计算。Target 的分配是通过 <code>ProposalTargetLayer</code> 类的前向方程完成</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">targets_dict <span class="token operator">=</span> self<span class="token punctuation">.</span>proposal_target_layer<span class="token punctuation">.</span>forward<span class="token punctuation">(</span>batch_dict<span class="token punctuation">)</span><span class="token triple-quoted-string string">"""Args:    batch_dict:        batch_size:        rois: (B, num_rois, 7 + C)        roi_scores: (B, num_rois)        gt_boxes: (B, N, 7 + C + 1)        roi_labels: (B, num_rois)Returns:    batch_dict:        rois: (B, M, 7 + C)        gt_of_rois: (B, M, 7 + C)        gt_iou_of_rois: (B, M)        roi_scores: (B, M) cls-based score        roi_labels: (B, M) cls-based label        reg_valid_mask: (B, M) positive bbox        rcnn_cls_labels: (B, M) iou-based label"""</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>将 gt 转换到对应的 roi 坐标系当中（平移+旋转），需要注意的是还对方向相反的 gt 进行了 flip orientation 处理，以减少错误预测的损失。虽然这不是真实的标签，但损失太大可能不利于维护 R-CNN 训练的稳定</p></li><li><p>这里提一下，所有获得的 target 都使用 detach 从计算图中分离，也就是不希望更新用于预测 roi 部分的网络参数，仅关注用于预测残差以及 backbone 中的网络参数。建议画一下计算图</p></li></ol></li></ol><h4 id="Loss-相关-1"><a href="#Loss-相关-1" class="headerlink" title="Loss 相关"></a>Loss 相关</h4><p>与 AnchorHeadTemplate 一样，这里也是两个主要方法：</p><ol><li><code>get_loss</code> 计算分类损失和回归损失，有趣的是在回归损失中还使用了一个 <code>corner_loss</code>，这是论文中没有提到的，而且在代码的注释中也写了 <code>TODO: NEED TO BE CHECK</code></li><li><code>generate_predicted_boxes</code>，将预测的残差结果，还原为真实选框</li></ol><p>这么一看是不是结构就清晰很多了呢？下面就看看 VoxelRCNNHead 干了些什么吧！</p><h3 id="VoxelRCNNHead"><a href="#VoxelRCNNHead" class="headerlink" title="VoxelRCNNHead"></a>VoxelRCNNHead</h3><p>当有了基类 RoiHeadTemplate 过后就可以专注实现 R-CNN 的核心功能，即 roi pooling 提取特征</p><h4 id="init"><a href="#init" class="headerlink" title="init"></a>init</h4><p>在搭建该部分的网络之前，先来看看需要哪些子模块需要定义</p><ol><li><code>pool_layer</code>，这是通过另一个类实现 <code>NeighborVoxelSAModuleMSG</code>。这个层用于 voxel query 寻找附近的非空体素，并对 grouping 特征进行特征提取</li><li><code>shared_fc_layer</code>，过渡全连接层，<code>nn.Linear + nn.BatchNorm1d + nn.ReLU</code></li><li><code>cls_fc_layer</code>，分类全连接层，<code>nn.Linear + nn.BatchNorm1d + nn.ReLU</code></li><li><code>reg_fc_layer</code>，预测全连接层，<code>nn.Linear + nn.BatchNorm1d + nn.ReLU</code></li></ol><h4 id="roi-grid-pooling"><a href="#roi-grid-pooling" class="headerlink" title="roi_grid_pooling"></a>roi_grid_pooling</h4><p>这个功能函数基本上就是 roi grid pooling 的核心，其作用简单叙述为：在不同分辨率 feature source 下，对每个 grid point 进行 roi pooling，并将不同分辨率的结果连接起来。下面具体分析其中的步骤：</p><ol><li><p>获得 roi 中的 grid point 在当前 feature source 特征图谱的 voxel 坐标 (B, x, y, z) 以及 lidar 坐标 (BxN, 6x6x6, 3)，用于之后的 grouping</p></li><li><p>获得 <code>pooled_feature_list</code>，即对每个分辨率的 feature source，使用 <code>pool_layer</code> 对每个 grid point 进行 roi pooling。然后将所有分辨率的特征连接起来 <code>torch.concat</code> 得到每个 grid point 最终的特征。<code>pool_layer</code> 是比较复杂的一个层，其有四个子模块</p><ol><li><p><code>mlp_in</code>，对所有的 grid point 进行统一特征提取，由 kernel size = 1 的 <code>Conv1d</code> 完成</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">##################### Note ########################</span><span class="token comment"># Mi = 128x6x6x6 = roi numbers * grid points per roi 是个常数</span><span class="token comment"># 并且本笔记中没有对 channel 数量进行区分，都用 C 表示</span><span class="token comment"># k 表示 k 个不同分辨率的特征图谱</span><span class="token comment">##################### Note ########################</span><span class="token comment"># features_in: (1, C, M1+M2+...)</span>features_in <span class="token operator">=</span> self<span class="token punctuation">.</span>mlps_in<span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token punctuation">(</span>features_in<span class="token punctuation">)</span>features_in <span class="token operator">=</span> features_in<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># features_in: (1, M1+M2+..., C)</span>features_in <span class="token operator">=</span> features_in<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> features_in<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment"># features_in: (M1+M2+..., C)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>获得了 <code>features_in</code> 之后将会输入到 <code>self.groupers</code> 当中</p></li><li><p><code>self.groupers</code>，执行 grouping 操作，由类 <code>VoxelQueryAndGrouping</code> 实现。当邻居数量没有 nsample 这么多时使用第一个 sample grid 进行补位。再通过标注 <code>empty_ball_mask</code> 得知该 grid point 是否有邻居，在之后使用 MLP 提取特征时把空 grid point 的特征设置为 0 即可。该类的前向方程获得的结果如下</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> new_coords<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">,</span> xyz<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">,</span> xyz_batch_cnt<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">,</span>            new_xyz<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">,</span> new_xyz_batch_cnt<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">,</span>            features<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">,</span> voxel2point_indices<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""    Args:        # voxel data        xyz: (N1 + N2 ..., 3) xyz coordinates of the features        xyz_batch_cnt: (batch_size), [N1, N2, ...]        features: (N1 + N2 ..., C) tensor of features to group        voxel2point_indices: (B, Z, Y, X) tensor of points indices of feature source voxels              # grid point data        new_coords: (M1 + M2 ..., 3) centers voxel indices of the ball query        new_xyz: (M1 + M2 ..., 3) centers of the ball query        new_xyz_batch_cnt: (batch_size), [M1, M2, ...] Mi = 128x6x6x6          Returns:        grouped_xyz: (M1 + M2 ..., 3, nsample)        empty_ball_mask: (M1 + M2 ...,)        grouped_features: (M1 + M2 ..., C, nsample)    """</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><code>mlp_pos</code>，对 group 得到的 nsample 个 voxel positions 进行特征提取，由 kernel size = 1 的  <code>Conv2d</code> 完成 <code>grouped_xyz: (1, 3, M1+M2+..., nsample)</code></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># grouped_xyz: (1, 3, M1+M2, nsample)</span>position_features <span class="token operator">=</span> self<span class="token punctuation">.</span>mlps_pos<span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token punctuation">(</span>grouped_xyz<span class="token punctuation">)</span><span class="token comment"># position_features: (1, C, M1+M2+..., nsample)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li><li><p><code>mlp_out</code>，在使用该 MLP 之前，需要将前两个 MLP 提取的特征加起来 <code>mlp_in + mpl_pos</code>，然后使用 max pooling 消除 nsample 维度，得到汇聚特征 (1, C, M1+M2+…)。然后再进行特征提取，由 <code>Conv1d</code> 完成</p></li></ol><p><strong>下面整体来看看 <code>pool_layer</code> 层的输入和输出</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"> pooled_features <span class="token operator">=</span> pool_layer<span class="token punctuation">(</span>                xyz<span class="token operator">=</span>cur_voxel_xyz<span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                xyz_batch_cnt<span class="token operator">=</span>cur_voxel_xyz_batch_cnt<span class="token punctuation">,</span>                new_xyz<span class="token operator">=</span>roi_grid_xyz<span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                new_xyz_batch_cnt<span class="token operator">=</span>roi_grid_batch_cnt<span class="token punctuation">,</span>                new_coords<span class="token operator">=</span>cur_roi_grid_coords<span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                features<span class="token operator">=</span>cur_sp_tensors<span class="token punctuation">.</span>features<span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                voxel2point_indices<span class="token operator">=</span>v2p_ind_tensor            <span class="token punctuation">)</span><span class="token comment"># return:</span><span class="token comment"># new_xyz: (M1 + M2 ..., 3) tensor of the new features' xyz</span><span class="token comment"># new_features: (M1 + M2 ..., C) tensor of the new_features descriptors</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>连接不同的 feature source 下得到的 roi pooling 特征并改变其维度得到 (BxMi, 6x6x6, C)</p></li></ol><h4 id="forward"><a href="#forward" class="headerlink" title="forward"></a>forward</h4><p>看完了之前的复杂模块，感觉头都要晕了…好消息是到了这一步，基本上就没有其他复杂模块了，事情变成了简单的组合。有了基类处理 proposal &amp; target &amp; loss，有了 roi grid pooling 获得 grid point features，还要有的就是使用 MLP 进行预测</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch_dict<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""    :param input_data: input dict    :return:    """</span>    <span class="token comment"># 根据 NMS 获得 512 个得分最高的选框</span>    targets_dict <span class="token operator">=</span> self<span class="token punctuation">.</span>proposal_layer<span class="token punctuation">(</span>        batch_dict<span class="token punctuation">,</span> nms_config<span class="token operator">=</span>self<span class="token punctuation">.</span>model_cfg<span class="token punctuation">.</span>NMS_CONFIG<span class="token punctuation">[</span><span class="token string">'TRAIN'</span> <span class="token keyword">if</span> self<span class="token punctuation">.</span>training <span class="token keyword">else</span> <span class="token string">'TEST'</span><span class="token punctuation">]</span>    <span class="token punctuation">)</span>    <span class="token keyword">if</span> self<span class="token punctuation">.</span>training<span class="token punctuation">:</span>        <span class="token comment"># 采样 128 个 rois 并获得 gt，并将 gt 移动到对应 rois 的坐标系当中</span>        targets_dict <span class="token operator">=</span> self<span class="token punctuation">.</span>assign_targets<span class="token punctuation">(</span>batch_dict<span class="token punctuation">)</span>        batch_dict<span class="token punctuation">[</span><span class="token string">'rois'</span><span class="token punctuation">]</span> <span class="token operator">=</span> targets_dict<span class="token punctuation">[</span><span class="token string">'rois'</span><span class="token punctuation">]</span>        batch_dict<span class="token punctuation">[</span><span class="token string">'roi_labels'</span><span class="token punctuation">]</span> <span class="token operator">=</span> targets_dict<span class="token punctuation">[</span><span class="token string">'roi_labels'</span><span class="token punctuation">]</span>    <span class="token comment"># RoI aware pooling</span>    pooled_features <span class="token operator">=</span> self<span class="token punctuation">.</span>roi_grid_pool<span class="token punctuation">(</span>batch_dict<span class="token punctuation">)</span>  <span class="token comment"># (BxN, 6x6x6, C)</span>    <span class="token comment"># Box Refinement</span>    pooled_features <span class="token operator">=</span> pooled_features<span class="token punctuation">.</span>view<span class="token punctuation">(</span>pooled_features<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment"># (BxN, -1)</span>    shared_features <span class="token operator">=</span> self<span class="token punctuation">.</span>shared_fc_layer<span class="token punctuation">(</span>pooled_features<span class="token punctuation">)</span>    rcnn_cls <span class="token operator">=</span> self<span class="token punctuation">.</span>cls_pred_layer<span class="token punctuation">(</span>self<span class="token punctuation">.</span>cls_fc_layers<span class="token punctuation">(</span>shared_features<span class="token punctuation">)</span><span class="token punctuation">)</span>    rcnn_reg <span class="token operator">=</span> self<span class="token punctuation">.</span>reg_pred_layer<span class="token punctuation">(</span>self<span class="token punctuation">.</span>reg_fc_layers<span class="token punctuation">(</span>shared_features<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">if</span> <span class="token keyword">not</span> self<span class="token punctuation">.</span>training<span class="token punctuation">:</span>        batch_cls_preds<span class="token punctuation">,</span> batch_box_preds <span class="token operator">=</span> self<span class="token punctuation">.</span>generate_predicted_boxes<span class="token punctuation">(</span>            batch_size<span class="token operator">=</span>batch_dict<span class="token punctuation">[</span><span class="token string">'batch_size'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> rois<span class="token operator">=</span>batch_dict<span class="token punctuation">[</span><span class="token string">'rois'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> cls_preds<span class="token operator">=</span>rcnn_cls<span class="token punctuation">,</span> box_preds<span class="token operator">=</span>rcnn_reg        <span class="token punctuation">)</span>        batch_dict<span class="token punctuation">[</span><span class="token string">'batch_cls_preds'</span><span class="token punctuation">]</span> <span class="token operator">=</span> batch_cls_preds        batch_dict<span class="token punctuation">[</span><span class="token string">'batch_box_preds'</span><span class="token punctuation">]</span> <span class="token operator">=</span> batch_box_preds        batch_dict<span class="token punctuation">[</span><span class="token string">'cls_preds_normalized'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">False</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        targets_dict<span class="token punctuation">[</span><span class="token string">'rcnn_cls'</span><span class="token punctuation">]</span> <span class="token operator">=</span> rcnn_cls        targets_dict<span class="token punctuation">[</span><span class="token string">'rcnn_reg'</span><span class="token punctuation">]</span> <span class="token operator">=</span> rcnn_reg        self<span class="token punctuation">.</span>forward_ret_dict <span class="token operator">=</span> targets_dict    <span class="token keyword">return</span> batch_dict<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="感言"><a href="#感言" class="headerlink" title="感言"></a>感言</h2><p>至此，Voxel R-CNN 的框架就总结完了😭一路上真的有太多的困难了，但是整个代码看下来感觉自己还是收获不少！虽然路还很长，但是至少迈出了第一步</p><p>过程中遇到了代码之外的问题，例如 localhost:10.0 问题，一般是因为没能找到本机的显示器，把所有的东西都重启一遍，包括你自己的电脑！</p><h2 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h2><ol><li>整理损失函数</li><li>整理常用功能函数 utils 以及三方库</li><li>pytorch 技巧总结</li><li>Summary SPG, Lidar R-CNN</li><li>SA-SSD 代码阅读</li></ol>]]></content>
      
      
      <categories>
          
          <category> 编程 </category>
          
          <category> OpenMMLab </category>
          
      </categories>
      
      
        <tags>
            
            <tag> OpenPCDet </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>OpenPCDet review</title>
      <link href="/archives/6b4af7d3.html"/>
      <url>/archives/6b4af7d3.html</url>
      
        <content type="html"><![CDATA[<h1 id="OpenPCDet-review"><a href="#OpenPCDet-review" class="headerlink" title="OpenPCDet review"></a>OpenPCDet review</h1><p>现在想要打造自己的网络了，就要对这个框架完全的熟悉。虽然之前把代码都过了一遍，但是熟悉度还是不够，打算重新整理过。目标就是完成 SA-SSD 在 OpenPCDet 框架下的复现。贴一个 <a href="https://www.zhihu.com/people/yilu-kuang-shuai">Shaoshuai Shi</a> 本人在知乎的解读 <a href="https://zhuanlan.zhihu.com/p/152120636">OpenPCDet: Open-MMLab 面向LiDAR点云表征的3D目标检测代码库</a></p><h2 id="零碎的知识"><a href="#零碎的知识" class="headerlink" title="零碎的知识"></a>零碎的知识</h2><h3 id="库"><a href="#库" class="headerlink" title="库"></a>库</h3><p>之前在看代码的时候遇到了一些有用的第三方库，总结如下：</p><ol><li>pathlib， <a href="https://zhuanlan.zhihu.com/p/33524938">知乎</a></li><li>logging， <a href="https://zhuanlan.zhihu.com/p/360306588">知乎</a></li><li>tqdm，<a href="https://zhuanlan.zhihu.com/p/163613814">知乎</a></li><li>tensorboard，<a href="https://www.bilibili.com/video/BV1Qf4y1C7kz">bilibili</a> <a href="https://pytorch.org/docs/stable/tensorboard.html">pytorch</a></li><li>pdb，<a href="https://zhuanlan.zhihu.com/p/37294138">知乎</a></li><li>分布式训练，<a href="https://zhuanlan.zhihu.com/p/113694038">知乎</a>，关于指定 GPU, CUDA_VISIBLE_DEVICES <a href="https://blog.csdn.net/alip39/article/details/87913543">CSDN</a> </li><li>collections, pickle</li></ol><h3 id="重要的参数"><a href="#重要的参数" class="headerlink" title="重要的参数"></a>重要的参数</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token operator">-</span><span class="token operator">-</span>cfg_file<span class="token operator">-</span><span class="token operator">-</span>batch_size<span class="token operator">-</span><span class="token operator">-</span>workers<span class="token operator">-</span><span class="token operator">-</span>ckpt<span class="token operator">-</span><span class="token operator">-</span>start_epoch<span class="token operator">-</span><span class="token operator">-</span>save_to_file<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>其中对于 <code>--workers</code> 的作用需要更多的理解，参考 <a href="https://blog.csdn.net/jiongjiongxia123/article/details/112850223">CSDN</a>，个人理解就是 CPU 作为搬运工 workers 提前将需要的 batch 放入内存 RAM 中（非显存），然后 GPU 处理完一个 batch 过后来取</p><h3 id="EasyDict"><a href="#EasyDict" class="headerlink" title="EasyDict"></a>EasyDict</h3><p>项目写了一个 <code>EasyDict</code> 类作为更好用的字典，能够将 <code>key</code> 直接作为 <code>attribute</code> 进行调用</p><h3 id="Yaml"><a href="#Yaml" class="headerlink" title="Yaml"></a>Yaml</h3><p>模型的参数是以 <a href="https://www.runoob.com/w3cnote/yaml-intro.html">yaml</a> 格式，使用如下方法导入</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> yaml<span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token builtin">file</span><span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'r'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>    cfg_dict <span class="token operator">=</span> yaml<span class="token punctuation">.</span>load<span class="token punctuation">(</span>f<span class="token punctuation">,</span> Loader<span class="token operator">=</span>FullLoader<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Python"><a href="#Python" class="headerlink" title="Python"></a>Python</h3><ol><li><p>关于 python 类中的内置属性：<a href="https://luobuda.github.io/2015/01/16/python-class/">class</a> <a href="https://www.jianshu.com/p/c390d591ce65">dict</a></p></li><li><p>关于  <a href="https://stackoverflow.com/questions/44834/can-someone-explain-all-in-python">all &amp; init</a>：<code>__all__</code> 定义在 <code>__init__.py</code> 中，代表着在这一个 package，你想要暴露的接口/函数/类（但也要先导入到 package 中），外部如果从这个包里 import，只能 import <code>__all__</code> 列表中包含的接口。如果确实希望导入某个接口，但该模块不在 <code>__all__</code> 中，可以通过具体的路径进行导入 </p><p>如果是嵌套的包内调用，需要从包的根路径开始调用</p></li></ol><h2 id="KITTI-Dataset"><a href="#KITTI-Dataset" class="headerlink" title="KITTI Dataset"></a>KITTI Dataset</h2><h3 id="kitti-infos-train-pkl"><a href="#kitti-infos-train-pkl" class="headerlink" title="kitti_infos_train.pkl"></a>kitti_infos_train.pkl</h3><p>这里应该还有2个 pkl 文件 <code>kitti_infos_val.pkl &amp; kitti_dbinfos_train.pkl</code> 也很重要，这些 pkl 文件保存了 KITTI 的数据信息便于使用 python 进行操作，下面看看其中存储了什么</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token comment"># kitti_infos_train.pkl &amp; kitti_infos_val.pkl 都以如下形式存储</span>point_cloud         num_features         lidar_idx image         image_idx         image_shape <span class="token punctuation">(</span><span class="token number">2</span>,<span class="token punctuation">)</span>calib         P2 <span class="token punctuation">(</span><span class="token number">4</span>, <span class="token number">4</span><span class="token punctuation">)</span>        R0_rect <span class="token punctuation">(</span><span class="token number">4</span>, <span class="token number">4</span><span class="token punctuation">)</span>        Tr_velo_to_cam <span class="token punctuation">(</span><span class="token number">4</span>, <span class="token number">4</span><span class="token punctuation">)</span>annos         name <span class="token punctuation">(</span><span class="token number">1</span>,<span class="token punctuation">)</span>        truncated <span class="token punctuation">(</span><span class="token number">1</span>,<span class="token punctuation">)</span>        occluded <span class="token punctuation">(</span><span class="token number">1</span>,<span class="token punctuation">)</span>        alpha <span class="token punctuation">(</span><span class="token number">1</span>,<span class="token punctuation">)</span>        bbox <span class="token punctuation">(</span><span class="token number">1</span>, <span class="token number">4</span><span class="token punctuation">)</span>        dimensions <span class="token punctuation">(</span><span class="token number">1</span>, <span class="token number">3</span><span class="token punctuation">)</span>        location <span class="token punctuation">(</span><span class="token number">1</span>, <span class="token number">3</span><span class="token punctuation">)</span>        rotation_y <span class="token punctuation">(</span><span class="token number">1</span>,<span class="token punctuation">)</span>        score <span class="token punctuation">(</span><span class="token number">1</span>,<span class="token punctuation">)</span>        difficulty <span class="token punctuation">(</span><span class="token number">1</span>,<span class="token punctuation">)</span>        index <span class="token punctuation">(</span><span class="token number">1</span>,<span class="token punctuation">)</span>        gt_boxes_lidar <span class="token punctuation">(</span><span class="token number">1</span>, <span class="token number">7</span><span class="token punctuation">)</span>        num_points_in_gt <span class="token punctuation">(</span><span class="token number">1</span>,<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>每一个 pkl 文件是一个列表，列表的成员是一个层级字典，保存了对应样本的信息（将 <code>ndarray</code> 的形状在关键字后标出）</p><p><code>kitti_dbinfos_train.pkl</code> 有点不一样，它是一个字典，关键字就是标签类别</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">Pedestrian Car Cyclist Van Truck Tram Misc Person_sitting<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>每一个字典又对应了一个列表，列表的成员又是一个字典，以 Pedestrian 为例</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">name Pedestrian-------------------------------------path gt_database/000000_Pedestrian_0.bin-------------------------------------image_idx 000000-------------------------------------gt_idx <span class="token number">0</span>-------------------------------------box3d_lidar <span class="token punctuation">(</span><span class="token number">7</span>,<span class="token punctuation">)</span><span class="token punctuation">[</span> <span class="token number">8.7</span> -1.9 -0.7  <span class="token number">1.2</span>  <span class="token number">0.5</span>  <span class="token number">1.9</span> -1.6<span class="token punctuation">]</span>-------------------------------------num_points_in_gt <span class="token number">383</span>-------------------------------------difficulty <span class="token number">0</span>-------------------------------------bbox <span class="token punctuation">(</span><span class="token number">4</span>,<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">712.4</span> <span class="token number">143</span>.  <span class="token number">810.7</span> <span class="token number">307.9</span><span class="token punctuation">]</span>-------------------------------------score -1.0-------------------------------------<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="DatasetTemplate"><a href="#DatasetTemplate" class="headerlink" title="DatasetTemplate"></a>DatasetTemplate</h3><p>这是一个数据集的基础类，先看其参数和基本属性</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">DatasetTemplate</span><span class="token punctuation">(</span>torch_data<span class="token punctuation">.</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> dataset_cfg<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> class_names<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> training<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> root_path<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> logger<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        Args:            root_path: 一般为 None            dataset_cfg: cfg.DATA_CONFIG            class_names: pedestrian car cyclist            training: True            logger:        Attributes:            - dataset config            - training            - class_names            - root_path 通常为 dataset config 中的指定 DATA_PATH            - logger            - point cloud range 点云范围             - point_feature_encoder 点云特征编码器             - data_augmentor 数据增强器 sampling &amp; rotation            - data_processor 数据处理器 voxelization        """</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在初始化的过程中，只有在 <code>data_augmentor</code> 中的 <code>gt_sampling</code> 实际处理了数据，即对 gt database 进行筛选，去除点少的和困难的样本</p><p>该类中还定义了两个重要的方法，在之后调用：1. <code>prepare_data(self, data_dict)</code> 2. <code>collate_batch(batch_list)</code> </p><h4 id="prepare-data"><a href="#prepare-data" class="headerlink" title="prepare_data"></a>prepare_data</h4><p><code>prepare_data(self, data_dict)</code> 通过该方法准备数据。数据的采样、增强和体素化都是在这一方法中进行调用。需要注意的是返回的 voxel 坐标排列为 zyx 而不是 xyz，这是由于 spconv 的设计导致的</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">prepare_data</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data_dict<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment">################# IMPORTANT #################</span>        <span class="token triple-quoted-string string">"""        Args:            data_dict:                points: optional, (N, 3 + C_in)                gt_boxes: optional, (N, 7 + C) [x, y, z, dx, dy, dz, heading, ...]                gt_names: optional, (N), string                ...        Returns:            data_dict:                frame_id: string                points: (N, 3 + C_in)                gt_boxes: optional, (N, 7 + C) [x, y, z, dx, dy, dz, heading, ...]                (poped) gt_names: optional, (N), string                use_lead_xyz: bool                voxels: optional (num_voxels, max_points_per_voxel, 3 + C)                voxel_coords: optional (num_voxels, 3)                voxel_num_points: optional (num_voxels)                ...                batch_size: 在 dataloader collate_fn 中加入        """</span><span class="token comment"># voxels: [M, max_points, ndim] float tensor. only contain points.</span>        <span class="token comment"># coordinates: [M, 3] int32 tensor. zyx format. #### note zyx not xyz !!!####</span>        <span class="token comment"># num_points_per_voxel: [M] int32 tensor.</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="collate-batch"><a href="#collate-batch" class="headerlink" title="collate_batch"></a>collate_batch</h4><p><code>collate_batch(batch_list)</code> 用于传入 <code>DataLoader</code> 中的 <code>collate_fn</code>，这样就能定义每一个 batch 返回的具体形式（为一个字典），关于 <a href="https://zhuanlan.zhihu.com/p/361830892">collate_fn</a>，核心的工作如下：</p><ol><li>将 batch 每个 sample 的数据 concat</li><li>在 points, voxel_coords… 中增加 batch 维度以区分是来自哪个 sample</li><li>batch 中每个 sample 的 boxes 数量不一样，需要将形状统一然后合并起来</li></ol><pre class="line-numbers language-python" data-language="python"><code class="language-python">frame_id <span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token punctuation">)</span>gt_boxes <span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">36</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span><span class="token comment"># 在 prepare_data 中加入了类别特征</span>points <span class="token punctuation">(</span><span class="token number">94168</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>use_lead_xyz <span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token punctuation">)</span>voxels <span class="token punctuation">(</span><span class="token number">64000</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>voxel_coords <span class="token punctuation">(</span><span class="token number">64000</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span> <span class="token comment"># bzyx order</span>voxel_num_points <span class="token punctuation">(</span><span class="token number">64000</span><span class="token punctuation">,</span><span class="token punctuation">)</span>image_shape <span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>当然作为一个 <code>Dataset</code> 的子类，需要定义 <code>__len__ &amp; __getitem__</code> 方法，这些方法没有在 <code>DatasetTemplate</code> 中实现，而是在更具体的类中实现比如 <code>KittiDataset</code></p><h3 id="kitti-dataset-py"><a href="#kitti-dataset-py" class="headerlink" title="kitti_dataset.py"></a>kitti_dataset.py</h3><p>这个文件用于定义 <code>KittiDataset</code> 类，这个类比较大，因为该类实现了对原始 KITTI 数据集的处理函数，<code>kitti_infos_train.pkl</code> 就是使用这些函数生成的。先看看该类的初始化</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">KittiDataset</span><span class="token punctuation">(</span>DatasetTemplate<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> dataset_cfg<span class="token punctuation">,</span> class_names<span class="token punctuation">,</span> training<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> root_path<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> logger<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""        Args:            root_path:            dataset_cfg:            class_names:            training:            logger:        Attributes:        - split_dir &amp; sample_id_list: 根据训练集/验证集确定 sample 列表            - kitti_infos: 来自 train/test pkl 文件，加载后为一个列表，列表中的元素为形如下面的字典            ### 当然还有基类中的属性，这里不再重复 ###        """</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="getitem"><a href="#getitem" class="headerlink" title="getitem"></a>getitem</h4><p>其核心函数 <code>__getitem__</code>，返回一个字典，其实大部分都是返回了 <code>kitti_infos_train.pkl</code> 中的信息，特别的操作就是增加了点云信息，并选取了视场角中的点 <code>get_fov_flag</code></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 获得原始点云 points (N, 4)</span><span class="token keyword">if</span> <span class="token string">"points"</span> <span class="token keyword">in</span> get_item_list<span class="token punctuation">:</span>    points <span class="token operator">=</span> self<span class="token punctuation">.</span>get_lidar<span class="token punctuation">(</span>sample_idx<span class="token punctuation">)</span>    <span class="token comment"># 仅取视角中的点，其余点放弃</span>    <span class="token keyword">if</span> self<span class="token punctuation">.</span>dataset_cfg<span class="token punctuation">.</span>FOV_POINTS_ONLY<span class="token punctuation">:</span>        pts_rect <span class="token operator">=</span> calib<span class="token punctuation">.</span>lidar_to_rect<span class="token punctuation">(</span>points<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        fov_flag <span class="token operator">=</span> self<span class="token punctuation">.</span>get_fov_flag<span class="token punctuation">(</span>pts_rect<span class="token punctuation">,</span> img_shape<span class="token punctuation">,</span> calib<span class="token punctuation">)</span>        points <span class="token operator">=</span> points<span class="token punctuation">[</span>fov_flag<span class="token punctuation">]</span>        input_dict<span class="token punctuation">[</span><span class="token string">'points'</span><span class="token punctuation">]</span> <span class="token operator">=</span> points<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>__getitem__</code> 中在最后调用了基类 <code>prepare_data</code> 方法，对点云进行采样、增强和体素化，最终返回一个字典包含了每个样本的信息</p><h4 id="generate-prediction-results"><a href="#generate-prediction-results" class="headerlink" title="generate_prediction_results"></a>generate_prediction_results</h4><p>除了核心函数外，该类还实现了一个静态方法 <code>generate_prediction_results</code>，这个方法的目的是将预测的 bbox, scores, label 等结果转化为 kitti 原始标签格式，用于之后的评估</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">generate_prediction_dicts</span><span class="token punctuation">(</span>batch_dict<span class="token punctuation">,</span> pred_dicts<span class="token punctuation">,</span> class_names<span class="token punctuation">,</span> output_path<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""    Args:        batch_dict:            frame_id:        pred_dicts: list of pred_dicts            pred_boxes: (N, 7), Tensor            pred_scores: (N), Tensor            pred_labels: (N), Tensor        class_names:        output_path:    Returns:    - annos: a list, contains batch prediction results, consists of dict            pred_dict['name'] = np.array(class_names)[pred_labels - 1]            pred_dict['alpha'] = -np.arctan2(-pred_boxes[:, 1], pred_boxes[:, 0]) + pred_boxes_camera[:, 6]            pred_dict['bbox'] = pred_boxes_img            pred_dict['dimensions'] = pred_boxes_camera[:, 3:6]            pred_dict['location'] = pred_boxes_camera[:, 0:3]            pred_dict['rotation_y'] = pred_boxes_camera[:, 6]            pred_dict['score'] = pred_scores            pred_dict['boxes_lidar'] = pred_boxes    """</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="evaluation"><a href="#evaluation" class="headerlink" title="evaluation"></a>evaluation</h4><p>使用 kitti 的评价标准对预测结果进行评估，返回一个元组 <code>ap_result_str, ap_dict</code> 其实二者的数据是一致的，前者将保存到日志中方便查看，后者将记录到 tensorboard 中</p><p>之后有需要可以整理一下其中的 <code>box_utils &amp; common_utils &amp; calib</code> ，里面有哪些操作是常用的，不用自己造轮子 </p><h2 id="Detector"><a href="#Detector" class="headerlink" title="Detector"></a>Detector</h2><p>下面总结如何建造一个模型，代码传入了三个参数：模型配置，类别，数据集（KittiDataset instance）</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">__all__ <span class="token operator">=</span> <span class="token punctuation">{</span>    <span class="token string">'Detector3DTemplate'</span><span class="token punctuation">:</span> Detector3DTemplate<span class="token punctuation">,</span>    <span class="token string">'SECONDNet'</span><span class="token punctuation">:</span> SECONDNet<span class="token punctuation">,</span>    <span class="token string">'PartA2Net'</span><span class="token punctuation">:</span> PartA2Net<span class="token punctuation">,</span>    <span class="token string">'PVRCNN'</span><span class="token punctuation">:</span> PVRCNN<span class="token punctuation">,</span>    <span class="token string">'PointPillar'</span><span class="token punctuation">:</span> PointPillar<span class="token punctuation">,</span>    <span class="token string">'PointRCNN'</span><span class="token punctuation">:</span> PointRCNN<span class="token punctuation">,</span>    <span class="token string">'SECONDNetIoU'</span><span class="token punctuation">:</span> SECONDNetIoU<span class="token punctuation">,</span>    <span class="token string">'CaDDN'</span><span class="token punctuation">:</span> CaDDN<span class="token punctuation">,</span>    <span class="token string">'VoxelRCNN'</span><span class="token punctuation">:</span> VoxelRCNN<span class="token punctuation">}</span><span class="token keyword">def</span> <span class="token function">build_network</span><span class="token punctuation">(</span>model_cfg<span class="token punctuation">,</span> num_class<span class="token punctuation">,</span> dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>    model <span class="token operator">=</span> build_detector<span class="token punctuation">(</span>        model_cfg<span class="token operator">=</span>model_cfg<span class="token punctuation">,</span> num_class<span class="token operator">=</span>num_class<span class="token punctuation">,</span> dataset<span class="token operator">=</span>dataset    <span class="token punctuation">)</span>    <span class="token keyword">return</span> model<span class="token keyword">def</span> <span class="token function">build_detector</span><span class="token punctuation">(</span>model_cfg<span class="token punctuation">,</span> num_class<span class="token punctuation">,</span> dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>    model <span class="token operator">=</span> __all__<span class="token punctuation">[</span>model_cfg<span class="token punctuation">.</span>NAME<span class="token punctuation">]</span><span class="token punctuation">(</span>        model_cfg<span class="token operator">=</span>model_cfg<span class="token punctuation">,</span> num_class<span class="token operator">=</span>num_class<span class="token punctuation">,</span> dataset<span class="token operator">=</span>dataset    <span class="token punctuation">)</span>    <span class="token keyword">return</span> model<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>通过模型配置中的关键字段创建模型实例，例如：<code>SECONDNet</code>。检测器都有一个共同的基类 <code>Detector3DTemplate</code>  下面看看它具有什么功能，然后再结合具体模型学习</p><h3 id="Detector3DTemplate"><a href="#Detector3DTemplate" class="headerlink" title="Detector3DTemplate"></a>Detector3DTemplate</h3><p>先看初始化函数</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Detector3DTemplate</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> model_cfg<span class="token punctuation">,</span> num_class<span class="token punctuation">,</span> dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>model_cfg <span class="token operator">=</span> model_cfg        self<span class="token punctuation">.</span>num_class <span class="token operator">=</span> num_class        self<span class="token punctuation">.</span>dataset <span class="token operator">=</span> dataset        self<span class="token punctuation">.</span>class_names <span class="token operator">=</span> dataset<span class="token punctuation">.</span>class_names        <span class="token comment"># 用于记录 epoch</span>        self<span class="token punctuation">.</span>register_buffer<span class="token punctuation">(</span><span class="token string">'global_step'</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>LongTensor<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>zero_<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>module_topology <span class="token operator">=</span> <span class="token punctuation">[</span>            <span class="token string">'vfe'</span><span class="token punctuation">,</span> <span class="token string">'backbone_3d'</span><span class="token punctuation">,</span> <span class="token string">'map_to_bev_module'</span><span class="token punctuation">,</span> <span class="token string">'pfe'</span><span class="token punctuation">,</span>            <span class="token string">'backbone_2d'</span><span class="token punctuation">,</span> <span class="token string">'dense_head'</span><span class="token punctuation">,</span>  <span class="token string">'point_head'</span><span class="token punctuation">,</span> <span class="token string">'roi_head'</span>        <span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>该类的核心方法有三个主要功能：</p><ol><li>构造网络结构方法</li><li>后处理方法，对 NMS 算法和 recall 数据都在这个部分实现</li><li>载入参数方法，将 checkpoint 中的参数载入模型中</li></ol><p>这里主要对前两个方法进行整理</p><h4 id="build-networks"><a href="#build-networks" class="headerlink" title="build_networks"></a>build_networks</h4><p>该方法最终返回一个 <code>module_list</code> 保存各个结构的模块，在之后的向前传播路径中，数据将按顺序经过各个模块。<code>model_info_dict</code> 还用于记录每个模块输出的特征数/通道数之类的信息，以便于传入下一个模块进行初始化，当然初始化过程还要结合 <code>self.model_cfg</code> 传入必要参数</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">build_networks</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># 创建一个 module info dict 储存模型中的各个模块与模型信息</span>    model_info_dict <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token string">'module_list'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token comment"># 下面两个 featrue 初始化都是 4 (x, y, z, intensity)</span>        <span class="token string">'num_rawpoint_features'</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>dataset<span class="token punctuation">.</span>point_feature_encoder<span class="token punctuation">.</span>num_point_features<span class="token punctuation">,</span>        <span class="token string">'num_point_features'</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>dataset<span class="token punctuation">.</span>point_feature_encoder<span class="token punctuation">.</span>num_point_features<span class="token punctuation">,</span>        <span class="token string">'grid_size'</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>dataset<span class="token punctuation">.</span>grid_size<span class="token punctuation">,</span>        <span class="token string">'point_cloud_range'</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>dataset<span class="token punctuation">.</span>point_cloud_range<span class="token punctuation">,</span>        <span class="token string">'voxel_size'</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>dataset<span class="token punctuation">.</span>voxel_size<span class="token punctuation">,</span>        <span class="token comment"># 有的没有 downsample 为 None</span>        <span class="token string">'depth_downsample_factor'</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>dataset<span class="token punctuation">.</span>depth_downsample_factor    <span class="token punctuation">}</span>    <span class="token keyword">for</span> module_name <span class="token keyword">in</span> self<span class="token punctuation">.</span>module_topology<span class="token punctuation">:</span>        module<span class="token punctuation">,</span> model_info_dict <span class="token operator">=</span> <span class="token builtin">getattr</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token string">'build_%s'</span> <span class="token operator">%</span> module_name<span class="token punctuation">)</span><span class="token punctuation">(</span>            model_info_dict<span class="token operator">=</span>model_info_dict        <span class="token punctuation">)</span>        self<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span>module_name<span class="token punctuation">,</span> module<span class="token punctuation">)</span>        <span class="token keyword">return</span> model_info_dict<span class="token punctuation">[</span><span class="token string">'module_list'</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="post-processing"><a href="#post-processing" class="headerlink" title="post_processing"></a>post_processing</h4><p>该方法仅在测试的时候被调用，其功能是使用 NMS 算法筛选出最终的选框</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">post_processing</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch_dict<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token string">""</span>"        Args<span class="token punctuation">:</span>            batch_dict<span class="token punctuation">:</span>                batch_size<span class="token punctuation">:</span>                batch_cls_preds<span class="token punctuation">:</span> <span class="token punctuation">(</span>B<span class="token punctuation">,</span> num_boxes<span class="token punctuation">,</span> num_classes <span class="token operator">|</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token keyword">or</span> <span class="token punctuation">(</span>N1<span class="token operator">+</span>N2<span class="token operator">+</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> num_classes <span class="token operator">|</span> <span class="token number">1</span><span class="token punctuation">)</span>                                <span class="token keyword">or</span> <span class="token punctuation">[</span><span class="token punctuation">(</span>B<span class="token punctuation">,</span> num_boxes<span class="token punctuation">,</span> num_class1<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>B<span class="token punctuation">,</span> num_boxes<span class="token punctuation">,</span> num_class2<span class="token punctuation">)</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span>                <span class="token punctuation">(</span><span class="token keyword">not</span> often<span class="token punctuation">)</span> multihead_label_mapping<span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">(</span>num_class1<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>num_class2<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span>                batch_box_preds<span class="token punctuation">:</span> <span class="token punctuation">(</span>B<span class="token punctuation">,</span> num_boxes<span class="token punctuation">,</span> <span class="token number">7</span><span class="token operator">+</span>C<span class="token punctuation">)</span> <span class="token keyword">or</span> <span class="token punctuation">(</span>N1<span class="token operator">+</span>N2<span class="token operator">+</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token operator">+</span>C<span class="token punctuation">)</span>                cls_preds_normalized<span class="token punctuation">:</span> indicate whether batch_cls_preds <span class="token keyword">is</span> normalized                batch_index<span class="token punctuation">:</span> optional <span class="token punctuation">(</span>N1<span class="token operator">+</span>N2<span class="token operator">+</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>                has_class_labels<span class="token punctuation">:</span> <span class="token boolean">True</span><span class="token operator">/</span><span class="token boolean">False</span>                roi_labels<span class="token punctuation">:</span> <span class="token punctuation">(</span>B<span class="token punctuation">,</span> num_rois<span class="token punctuation">)</span>  <span class="token number">1</span> <span class="token punctuation">.</span><span class="token punctuation">.</span> num_classes                batch_pred_labels<span class="token punctuation">:</span> <span class="token punctuation">(</span>B<span class="token punctuation">,</span> num_boxes<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        Returns<span class="token punctuation">:</span>        <span class="token operator">-</span> pred_dicts<span class="token punctuation">:</span> 实际是一个列表，其成员是字典                <span class="token operator">-</span> pred_boxes                    <span class="token operator">-</span> pred_scores                    <span class="token operator">-</span> pred_labels<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>以上就是模板检测器的主要功能，下面看看 SECOND 类是怎么在基类上创建的</p><h3 id="SECOND"><a href="#SECOND" class="headerlink" title="SECOND"></a>SECOND</h3><p>其实 SECOND 类的实现在基类之上是比较简单的，主要需要定义三个部分：</p><ol><li>调用基类的 <code>build_networks</code> 实现模型构建</li><li>定义前向方程</li></ol><p>模型的构建在初始化中完成，只用两行代码就完成了</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">SECONDNet</span><span class="token punctuation">(</span>Detector3DTemplate<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> model_cfg<span class="token punctuation">,</span> num_class<span class="token punctuation">,</span> dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span>model_cfg<span class="token operator">=</span>model_cfg<span class="token punctuation">,</span> num_class<span class="token operator">=</span>num_class<span class="token punctuation">,</span> dataset<span class="token operator">=</span>dataset<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>module_list <span class="token operator">=</span> self<span class="token punctuation">.</span>build_networks<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h4 id="forward"><a href="#forward" class="headerlink" title="forward"></a>forward</h4><p>前向方程 <code>forward</code> 也比较简单，就是将数据按顺序输入各个模块中，最后根据模式返回损失函数或者预测结果，其中损失函数一般定义在 </p><p><code>dense_head</code> 当中</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch_dict<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> cur_module <span class="token keyword">in</span> self<span class="token punctuation">.</span>module_list<span class="token punctuation">:</span>        batch_dict <span class="token operator">=</span> cur_module<span class="token punctuation">(</span>batch_dict<span class="token punctuation">)</span>    <span class="token comment"># 每一个 batch 的 loss (cls_loss + reg_loss +...)</span>    <span class="token comment"># tb_dict 是 tensor.item() 用于 tensorboard 可视化</span>    <span class="token keyword">if</span> self<span class="token punctuation">.</span>training<span class="token punctuation">:</span>        loss<span class="token punctuation">,</span> tb_dict<span class="token punctuation">,</span> disp_dict <span class="token operator">=</span> self<span class="token punctuation">.</span>get_training_loss<span class="token punctuation">(</span><span class="token punctuation">)</span>        ret_dict <span class="token operator">=</span> <span class="token punctuation">{</span>            <span class="token string">'loss'</span><span class="token punctuation">:</span> loss        <span class="token punctuation">}</span>        <span class="token keyword">return</span> ret_dict<span class="token punctuation">,</span> tb_dict<span class="token punctuation">,</span> disp_dict    <span class="token keyword">else</span><span class="token punctuation">:</span>        pred_dicts<span class="token punctuation">,</span> recall_dicts <span class="token operator">=</span> self<span class="token punctuation">.</span>post_processing<span class="token punctuation">(</span>batch_dict<span class="token punctuation">)</span>        <span class="token keyword">return</span> pred_dicts<span class="token punctuation">,</span> recall_dicts <span class="token keyword">def</span> <span class="token function">get_training_loss</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>    disp_dict <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>    loss_rpn<span class="token punctuation">,</span> tb_dict <span class="token operator">=</span> self<span class="token punctuation">.</span>dense_head<span class="token punctuation">.</span>get_loss<span class="token punctuation">(</span><span class="token punctuation">)</span>    tb_dict <span class="token operator">=</span> <span class="token punctuation">{</span>        <span class="token string">'loss_rpn'</span><span class="token punctuation">:</span> loss_rpn<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token operator">**</span>tb_dict    <span class="token punctuation">}</span>    loss <span class="token operator">=</span> loss_rpn    <span class="token keyword">return</span> loss<span class="token punctuation">,</span> tb_dict<span class="token punctuation">,</span> disp_dict<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>要深入学习还得看每个子模块的具体实现，继续痛苦的源码阅读，Voxel R-CNN 我来了…</p>]]></content>
      
      
      <categories>
          
          <category> 编程 </category>
          
          <category> OpenMMLab </category>
          
      </categories>
      
      
        <tags>
            
            <tag> OpenPCDet </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>D2L 10 注意力机制</title>
      <link href="/archives/b7d04b34.html"/>
      <url>/archives/b7d04b34.html</url>
      
        <content type="html"><![CDATA[<h1 id="D2L-10-注意力机制"><a href="#D2L-10-注意力机制" class="headerlink" title="D2L 10 注意力机制"></a>D2L 10 注意力机制</h1><p>555终于可以开始看注意力机制了😆Transformer 我来啦！</p><h2 id="注意力提示"><a href="#注意力提示" class="headerlink" title="注意力提示"></a>注意力提示</h2><h3 id="生物学中的注意力提示"><a href="#生物学中的注意力提示" class="headerlink" title="生物学中的注意力提示"></a>生物学中的注意力提示</h3><p>主要有两个概念：</p><ol><li><strong>非自主性提示/非随意线索</strong>（non-volitional cue），基于环境中物体的突出性和易见性</li><li><strong>自主性提示/随意线索</strong>（volitional cue），受主观意愿推动</li></ol><h3 id="查询、键和值"><a href="#查询、键和值" class="headerlink" title="查询、键和值"></a>查询、键和值</h3><p>教材对于这三个概念的解释并不清晰，还是看沐神的讲解吧 <a href="https://www.bilibili.com/video/BV1264y1i7R1?p=1&amp;t=447">bilibili</a></p><p>卷积、全连接、池化层都只考虑不随意线索，注意力机制则显式地考虑随意线索：</p><ol><li>随意线索被称之为查询（query）</li><li>每个<strong>输入</strong>是一个键值对 (key, value)，其中 key 可视为非随意线索，（下面这句是我自己乱想的）value 可以视为该线索的相关属性</li><li>通过注意力池化层来有偏向性的选择某些输入</li></ol><h3 id="非参数注意力汇聚：Nadaraya-Watson-核回归"><a href="#非参数注意力汇聚：Nadaraya-Watson-核回归" class="headerlink" title="非参数注意力汇聚：Nadaraya-Watson 核回归"></a>非参数注意力汇聚：Nadaraya-Watson 核回归</h3><p>实际上一个数学表达的例子能够更清楚展示这三个概念。给定数据 $(x_i, y_i), i=1,…,n$</p><p>给定查询 $x$，平均池化将获得输出</p><script type="math/tex; mode=display">f(x) = \frac{1}{n}\sum_{i}{y_i}</script><p>这就是没有注意力机制的情况，与查询值无关，全凭非随意线索获得输出。而更好的方案是60年代提出来的 Nadaraya-Waston 核回归</p><script type="math/tex; mode=display">f(x)=\sum_{i=1}^{n} \frac{K\left(x-x_{i}\right)}{\sum_{j=1}^{n} K\left(x-x_{j}\right)} y_{i}</script><p>其中 K 可以看作一个核函数，例如一个高斯核，用于衡量两点之间的距离</p><script type="math/tex; mode=display">K(u)=\frac{1}{\sqrt{2 \pi}} \exp \left(-\frac{u^{2}}{2}\right)</script><p>这就将注意力机制显式地用于输出，也就是给各个 value 加入相关权重。现在再来看这个图示可能会更好</p><p><img src="/archives/b7d04b34/image-20211210215054690.png" style="zoom:80%;"></p><h3 id="带参数注意力汇聚"><a href="#带参数注意力汇聚" class="headerlink" title="带参数注意力汇聚"></a>带参数注意力汇聚</h3><p>非参数的Nadaraya-Watson核回归具有一致性（consistency）的优点：如果有足够的数据，此模型会收敛到最优结果。尽管如此，我们还是可以轻松地将可学习的参数集成到注意力汇聚中</p><script type="math/tex; mode=display">\begin{aligned}f(x) &=\sum_{i=1}^{n} \alpha\left(x, x_{i}\right) y_{i} \\&=\sum_{i=1}^{n} \frac{\exp \left(-\frac{1}{2}\left(\left(x-x_{i}\right) w\right)^{2}\right)}{\sum_{j=1}^{n} \exp \left(-\frac{1}{2}\left(\left(x-x_{j}\right) w\right)^{2}\right)} y_{i} \\&=\sum_{i=1}^{n} \operatorname{softmax}\left(-\frac{1}{2}\left(\left(x-x_{i}\right) w\right)^{2}\right) y_{i} .\end{aligned}</script><p>注意这里 $w$ 只是一个标量，如果 $w$ 越大说明越注意近距离的键值。这里提一下，一个训练样本的输入都会和<strong>除自己以外</strong>的所有训练样本的“键－值”对进行计算，如果加入自己的 key 那么训练结果可想而知，就是给自己的 key 加入很大的权重</p><h3 id="注意力可视化"><a href="#注意力可视化" class="headerlink" title="注意力可视化"></a>注意力可视化</h3><p>平均池化可以被视为输入的加权平均值，只是权重相等。而注意力池化则是真正的加权平均，其中权重是在给定的查询 query 和不同的键 key 之间计算得出的。教材这里写了一些代码，在之后用于注意力可视化，以描绘图像 $weight = f(query, key)$ ，这里直接看看上一小节中的非参 N-W 核回归（左侧） &amp; 带参 N-W 核回归（右侧）的图像</p><p><img src="/archives/b7d04b34/image-20211212175647738.png" style="zoom:80%;"></p><p>可以明显看到注意力权重在 $query = key$ 的时候加重了</p><h2 id="注意力评分函数"><a href="#注意力评分函数" class="headerlink" title="注意力评分函数"></a>注意力评分函数</h2><p>我们可以将上一节中的高斯核指数部分视为注意力评分函数（attention scoring function），简称评分函数（scoring function），然后把这个函数的输出结果输入到 softmax 函数中进行运算（这样就能使评分以概率分布形式展现，换句话说就是使权重的和为一）</p><p>让 score function 表示更加数学化</p><script type="math/tex; mode=display">\alpha\left(\mathbf{q}, \mathbf{k}_{i}\right)=\operatorname{softmax}\left(a\left(\mathbf{q}, \mathbf{k}_{i}\right)\right)=\frac{\exp \left(a\left(\mathbf{q}, \mathbf{k}_{i}\right)\right)}{\sum_{j=1}^{m} \exp \left(a\left(\mathbf{q}, \mathbf{k}_{j}\right)\right)} \in \mathbb{R}</script><p>此时注意力汇聚函数 $f$ 就被表示为</p><script type="math/tex; mode=display">f\left(\mathbf{q},\left(\mathbf{k}_{1}, \mathbf{v}_{1}\right), \ldots,\left(\mathbf{k}_{m}, \mathbf{v}_{m}\right)\right)=\sum_{i=1}^{m} \alpha\left(\mathbf{q}, \mathbf{k}_{i}\right) \mathbf{v}_{i} \in \mathbb{R}^{v}</script><p>在本节中，我们将介绍两个流行的评分函数，稍后将用他们来实现更复杂的注意力机制</p><h3 id="掩蔽-softmax-操作"><a href="#掩蔽-softmax-操作" class="headerlink" title="掩蔽 softmax 操作"></a>掩蔽 softmax 操作</h3><p>在某些情况下，并非所有的值都应该被纳入到注意力汇聚中。例如，为了高效处理小批量数据集，某些文本序列被填充了没有意义的特殊词元。为了仅将有意义的词元作为值来获取注意力汇聚，我们可以指定一个有效序列长度，以便在计算softmax时过滤掉超出指定范围的位置。看看大概效果是什么样子</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># (batch, num_query, num_key)</span>masked_softmax<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.4527</span><span class="token punctuation">,</span> <span class="token number">0.5473</span><span class="token punctuation">,</span> <span class="token number">0.0000</span><span class="token punctuation">,</span> <span class="token number">0.0000</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token number">0.3458</span><span class="token punctuation">,</span> <span class="token number">0.6542</span><span class="token punctuation">,</span> <span class="token number">0.0000</span><span class="token punctuation">,</span> <span class="token number">0.0000</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.4151</span><span class="token punctuation">,</span> <span class="token number">0.3528</span><span class="token punctuation">,</span> <span class="token number">0.2321</span><span class="token punctuation">,</span> <span class="token number">0.0000</span><span class="token punctuation">]</span><span class="token punctuation">,</span>         <span class="token punctuation">[</span><span class="token number">0.2604</span><span class="token punctuation">,</span> <span class="token number">0.2631</span><span class="token punctuation">,</span> <span class="token number">0.4765</span><span class="token punctuation">,</span> <span class="token number">0.0000</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="加性注意力"><a href="#加性注意力" class="headerlink" title="加性注意力"></a>加性注意力</h3><p>当查询和键是不同长度的矢量时， 我们可以使用加性注意力（additive attention）作为评分函数</p><script type="math/tex; mode=display">a(\mathbf{q}, \mathbf{k})=\mathbf{w}_{v}^{\top} \tanh \left(\mathbf{W}_{q} \mathbf{q}+\mathbf{W}_{k} \mathbf{k}\right) \in \mathbb{R}</script><p>上代码，注意代码中对 query, key, value 的数量（sequence length / time step）具有一般性，它们的形状表示为 (batch_size, seq_len, feature)，教材中使用的 query, key, value 具体形状为：(2, 1, 20)，(2, 10, 2) 和 (2, 10, 4)，具体走一遍会比较清晰</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#@save</span><span class="token keyword">class</span> <span class="token class-name">AdditiveAttention</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""加性注意力"""</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> key_size<span class="token punctuation">,</span> query_size<span class="token punctuation">,</span> num_hiddens<span class="token punctuation">,</span> dropout<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>AdditiveAttention<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span>        <span class="token comment"># 无偏置</span>        <span class="token comment"># nn.Linear 的 input 为 (*,H_in) * 代表任意数量的维度，包括 none </span>        self<span class="token punctuation">.</span>W_k <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>key_size<span class="token punctuation">,</span> num_hiddens<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>W_q <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>query_size<span class="token punctuation">,</span> num_hiddens<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>w_v <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>num_hiddens<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>dropout <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>dropout<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> queries<span class="token punctuation">,</span> keys<span class="token punctuation">,</span> values<span class="token punctuation">,</span> valid_lens<span class="token punctuation">)</span><span class="token punctuation">:</span>        queries<span class="token punctuation">,</span> keys <span class="token operator">=</span> self<span class="token punctuation">.</span>W_q<span class="token punctuation">(</span>queries<span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>W_k<span class="token punctuation">(</span>keys<span class="token punctuation">)</span>        <span class="token comment"># 在维度扩展后，</span>        <span class="token comment"># queries的形状：(batch_size，查询的个数，1，num_hidden)</span>        <span class="token comment"># key的形状：(batch_size，1，“键－值”对的个数，num_hiddens)</span>        <span class="token comment"># 使用广播方式进行求和</span>        features <span class="token operator">=</span> queries<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">+</span> keys<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>        features <span class="token operator">=</span> torch<span class="token punctuation">.</span>tanh<span class="token punctuation">(</span>features<span class="token punctuation">)</span>        <span class="token comment"># self.w_v仅有一个输出，因此从形状中移除最后那个维度。</span>        <span class="token comment"># scores的形状：(batch_size，查询的个数，“键-值”对的个数)</span>        scores <span class="token operator">=</span> self<span class="token punctuation">.</span>w_v<span class="token punctuation">(</span>features<span class="token punctuation">)</span><span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>attention_weights <span class="token operator">=</span> masked_softmax<span class="token punctuation">(</span>scores<span class="token punctuation">,</span> valid_lens<span class="token punctuation">)</span>        <span class="token comment"># values的形状：(batch_size，“键－值”对的个数，值的维度)</span>        <span class="token comment"># 使用 batch matrix multiplication（@ 重载符既可以计算 mm 又可以计算 bmm）</span>        <span class="token comment"># 使用 dropout 进行正则化</span>        <span class="token keyword">return</span> torch<span class="token punctuation">.</span>bmm<span class="token punctuation">(</span>self<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>self<span class="token punctuation">.</span>attention_weights<span class="token punctuation">)</span><span class="token punctuation">,</span> values<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>运行下面的代码</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">queries<span class="token punctuation">,</span> keys <span class="token operator">=</span> torch<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># values的小批量，两个值矩阵是相同的</span>values <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">40</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">.</span>repeat<span class="token punctuation">(</span>    <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>valid_lens <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">)</span>attention <span class="token operator">=</span> AdditiveAttention<span class="token punctuation">(</span>key_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> query_size<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">,</span> num_hiddens<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span>                              dropout<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span>attention<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>attention<span class="token punctuation">(</span>queries<span class="token punctuation">,</span> keys<span class="token punctuation">,</span> values<span class="token punctuation">,</span> valid_lens<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>结果如下</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">2.0000</span><span class="token punctuation">,</span>  <span class="token number">3.0000</span><span class="token punctuation">,</span>  <span class="token number">4.0000</span><span class="token punctuation">,</span>  <span class="token number">5.0000</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">10.0000</span><span class="token punctuation">,</span> <span class="token number">11.0000</span><span class="token punctuation">,</span> <span class="token number">12.0000</span><span class="token punctuation">,</span> <span class="token number">13.0000</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>BmmBackward0<span class="token operator">&gt;</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="缩放点积注意力"><a href="#缩放点积注意力" class="headerlink" title="缩放点积注意力"></a>缩放点积注意力</h3><p>使用点积可以得到计算效率更高的评分函数，但是点积操作要求查询和键具有相同的长度 d</p><p>假设查询和键的所有元素都是独立的随机变量， 并且都满足零均值和单位方差， 那么两个向量的点积的均值为0，方差为 d。为确保无论向量长度如何，点积的方差在不考虑向量长度的情况下仍然是1，我们将点积除以 $\sqrt d$</p><script type="math/tex; mode=display">a(\mathbf{q}, \mathbf{k})=\mathbf{q}^{\top} \mathbf{k} / \sqrt{d}</script><p>查询 $Q\in R^{n\times d}$，键 $K \in R^{m \times d}$ ，值 $V \in R^{m \times v}$ 的缩放点积注意力（scaled dot-product attention）是：</p><script type="math/tex; mode=display">\operatorname{softmax}\left(\frac{\mathbf{Q K}^{\top}}{\sqrt{d}}\right) \mathbf{V} \in \mathbb{R}^{n \times v}</script><p>它的代码就相对简单一些</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#@save</span><span class="token keyword">class</span> <span class="token class-name">DotProductAttention</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""缩放点积注意力"""</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> dropout<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>DotProductAttention<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>dropout <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>dropout<span class="token punctuation">)</span>    <span class="token comment"># queries的形状：(batch_size，查询的个数，d)</span>    <span class="token comment"># keys的形状：(batch_size，“键－值”对的个数，d)</span>    <span class="token comment"># values的形状：(batch_size，“键－值”对的个数，值的维度)</span>    <span class="token comment"># valid_lens的形状:(batch_size，)或者(batch_size，查询的个数)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> queries<span class="token punctuation">,</span> keys<span class="token punctuation">,</span> values<span class="token punctuation">,</span> valid_lens<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        d <span class="token operator">=</span> queries<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>        <span class="token comment"># 设置transpose_b=True为了交换keys的最后两个维度</span>        scores <span class="token operator">=</span> torch<span class="token punctuation">.</span>bmm<span class="token punctuation">(</span>queries<span class="token punctuation">,</span> keys<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">/</span> math<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>d<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>attention_weights <span class="token operator">=</span> masked_softmax<span class="token punctuation">(</span>scores<span class="token punctuation">,</span> valid_lens<span class="token punctuation">)</span>        <span class="token keyword">return</span> torch<span class="token punctuation">.</span>bmm<span class="token punctuation">(</span>self<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>self<span class="token punctuation">.</span>attention_weights<span class="token punctuation">)</span><span class="token punctuation">,</span> values<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="Bahdanau-注意力"><a href="#Bahdanau-注意力" class="headerlink" title="Bahdanau 注意力"></a>Bahdanau 注意力</h2><p>之前教材讨论了机器翻译问题：通过编码器-解码器架构，用于序列到序列学习。具体来说，编码器将长度可变的序列转换为固定形状的上下文变量，然后解码器根据生成的词元和上下文变量按词元生成输出（目标）序列词元。然而，即使并非所有输入（源）词元都对解码某个词元都有用，但我们在每个解码步骤中仍使用编码相同的上下文变量</p><p>有什么方法能在不同解码步骤中，<strong>使用不同的上下文变量</strong>呢？这个时候 Bahdanau 注意力机制就登场了，下面具体来看看吧</p><h3 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h3><p>上下文变量任意解码时间步 $t’$ 会被替换为 $c_{t’}$</p><script type="math/tex; mode=display">\mathbf{c}_{t^{\prime}}=\sum_{t=1}^{T} \alpha\left(\mathbf{s}_{t^{\prime}-1}, \mathbf{h}_{t}\right) \mathbf{h}_{t}</script><p>其中，$h_t$ 为<strong>编码器</strong> t 时间步的隐状态，它即使 key 又是 value；$s_{t’-1}$ 为<strong>解码器</strong> $t’-1$ 时刻步的隐状态；注意力权重 $\alpha$ 是之前定义的加性注意力打分函数。看一下模型代码</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Seq2SeqAttentionDecoder</span><span class="token punctuation">(</span>AttentionDecoder<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> vocab_size<span class="token punctuation">,</span> embed_size<span class="token punctuation">,</span> num_hiddens<span class="token punctuation">,</span> num_layers<span class="token punctuation">,</span>                 dropout<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>Seq2SeqAttentionDecoder<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>attention <span class="token operator">=</span> d2l<span class="token punctuation">.</span>AdditiveAttention<span class="token punctuation">(</span>            num_hiddens<span class="token punctuation">,</span> num_hiddens<span class="token punctuation">,</span> num_hiddens<span class="token punctuation">,</span> dropout<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>embedding <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>vocab_size<span class="token punctuation">,</span> embed_size<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>rnn <span class="token operator">=</span> nn<span class="token punctuation">.</span>GRU<span class="token punctuation">(</span>            embed_size <span class="token operator">+</span> num_hiddens<span class="token punctuation">,</span> num_hiddens<span class="token punctuation">,</span> num_layers<span class="token punctuation">,</span>            dropout<span class="token operator">=</span>dropout<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>dense <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>num_hiddens<span class="token punctuation">,</span> vocab_size<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">init_state</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> enc_outputs<span class="token punctuation">,</span> enc_valid_lens<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># outputs的形状为(batch_size，num_steps，num_hiddens).</span>        <span class="token comment"># hidden_state的形状为(num_layers，batch_size，num_hiddens)</span>        outputs<span class="token punctuation">,</span> hidden_state <span class="token operator">=</span> enc_outputs        <span class="token keyword">return</span> <span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> hidden_state<span class="token punctuation">,</span> enc_valid_lens<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">,</span> state<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># X.shape = (num_batch, num_steps) 存储词元的索引</span>        <span class="token comment"># enc_outputs的形状为(batch_size,num_steps,num_hiddens).</span>        <span class="token comment"># hidden_state的形状为(num_layers,batch_size,</span>        <span class="token comment"># num_hiddens)</span>        enc_outputs<span class="token punctuation">,</span> hidden_state<span class="token punctuation">,</span> enc_valid_lens <span class="token operator">=</span> state        <span class="token comment"># 输出X的形状为(num_steps,batch_size,embed_size)</span>        X <span class="token operator">=</span> self<span class="token punctuation">.</span>embedding<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        outputs<span class="token punctuation">,</span> self<span class="token punctuation">.</span>_attention_weights <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> x <span class="token keyword">in</span> X<span class="token punctuation">:</span>            <span class="token comment"># query的形状为(batch_size,1,num_hiddens)</span>            query <span class="token operator">=</span> torch<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>hidden_state<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>            <span class="token comment"># context的形状为(batch_size,1,num_hiddens)</span>            context <span class="token operator">=</span> self<span class="token punctuation">.</span>attention<span class="token punctuation">(</span>                query<span class="token punctuation">,</span> enc_outputs<span class="token punctuation">,</span> enc_outputs<span class="token punctuation">,</span> enc_valid_lens<span class="token punctuation">)</span>            <span class="token comment"># 在特征维度上连结</span>            x <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>context<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>x<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>            <span class="token comment"># 将x变形为(1,batch_size,embed_size+num_hiddens)</span>            out<span class="token punctuation">,</span> hidden_state <span class="token operator">=</span> self<span class="token punctuation">.</span>rnn<span class="token punctuation">(</span>x<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> hidden_state<span class="token punctuation">)</span>            outputs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>out<span class="token punctuation">)</span>            self<span class="token punctuation">.</span>_attention_weights<span class="token punctuation">.</span>append<span class="token punctuation">(</span>self<span class="token punctuation">.</span>attention<span class="token punctuation">.</span>attention_weights<span class="token punctuation">)</span>        <span class="token comment"># 全连接层变换后，outputs的形状为</span>        <span class="token comment"># (num_steps,batch_size,vocab_size)</span>        outputs <span class="token operator">=</span> self<span class="token punctuation">.</span>dense<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> outputs<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">[</span>enc_outputs<span class="token punctuation">,</span> hidden_state<span class="token punctuation">,</span>                                          enc_valid_lens<span class="token punctuation">]</span>    <span class="token decorator annotation punctuation">@property</span>    <span class="token keyword">def</span> <span class="token function">attention_weights</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>_attention_weights<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>关于 <code>nn.Embedding</code>，其实在之前 seq2seq 中的代码也有使用，整理几个点：</p><ol><li>Embedding 层将每个词元转化为 embed_size 维度的向量（也称为词向量）</li><li>Embedding layer 存储了一个参数矩阵 (vocab_size, embed_size) 是可以随着训练更新的</li><li>经过训练之后相似词元的词向量可能会变得更接近</li></ol><p>来看看其中的权重是什么样子的吧，输入和输出分别为： <code>i'm home . =&gt; je suis chez moi .</code></p><p><img src="/archives/b7d04b34/image-20211213155221786.png" alt="image-20211213155221786"></p><p>应该是加入了 <code>&lt;eos&gt;</code> 特殊词元，所以 (key positions, Query positions) = (3+1, 5+1)</p><h2 id="多头注意力"><a href="#多头注意力" class="headerlink" title="多头注意力"></a>多头注意力</h2><p>多头注意力这一部分的视频讲解是在 Transformer 中进行的 <a href="https://www.bilibili.com/video/BV1Kq4y1H7FL?p=1&amp;t=1256">bilibili</a></p><p>在实践中，当给定相同的查询、键和值的集合时， 我们希望模型可以<strong>基于相同的注意力机制学习到不同的行为</strong>，然后将不同的行为作为知识组合起来，捕获序列内各种范围的依赖关系（例如，短距离依赖和长距离依赖关系）</p><p>对于其中一个头 $i$ 的操作简述如下：是对 query, key, value 先使用全连接层进行维度转换，转换到一个相同的维度 $p_v$，然后再使用缩放点积注意力。每一个头都将进行这样的操作，假设有 $m$ 个头，那么就会得到 $m$ 个注意力汇聚输出 $h_i, i=1,…,m$，最后将所有的 $h_i$ 连接起来，使用一个全连接层进行特征组合得到最终的输出，数学形式如下：</p><script type="math/tex; mode=display">\mathbf{h}_{i}=f\left(\mathbf{W}_{i}^{(q)} \mathbf{q}, \mathbf{W}_{i}^{(k)} \mathbf{k}, \mathbf{W}_{i}^{(v)} \mathbf{v}\right) \in \mathbb{R}^{p_{v}}\\\mathbf{W}_{o}\left[\begin{array}{c}\mathbf{h}_{1} \\\vdots \\\mathbf{h}_{h}\end{array}\right] \in \mathbb{R}^{p_{o}}</script><p>这里 $W_0$ 是一个 $p_0 \times p_0$ 的矩阵，$p_0 = \text{number of heads} \times p_v$，图示如下</p><p><img src="/archives/b7d04b34/image-20211213235228429.png" style="zoom:80%;"></p><p>代码要注意一下，$p_0$ 就是 <code>num_hiddens</code>，代码是将 <code>num_hiddens</code> 拆为 <code>num_heads</code> 份来计算每一个头的注意力输出，但是又为了并行计算的方便，在进行维度操作的时候需要注意维度的变换，非常巧妙，详细过程请看代码</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#@save</span><span class="token keyword">class</span> <span class="token class-name">MultiHeadAttention</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""多头注意力"""</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> key_size<span class="token punctuation">,</span> query_size<span class="token punctuation">,</span> value_size<span class="token punctuation">,</span> num_hiddens<span class="token punctuation">,</span>                 num_heads<span class="token punctuation">,</span> dropout<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>MultiHeadAttention<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>num_heads <span class="token operator">=</span> num_heads        self<span class="token punctuation">.</span>attention <span class="token operator">=</span> d2l<span class="token punctuation">.</span>DotProductAttention<span class="token punctuation">(</span>dropout<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>W_q <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>query_size<span class="token punctuation">,</span> num_hiddens<span class="token punctuation">,</span> bias<span class="token operator">=</span>bias<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>W_k <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>key_size<span class="token punctuation">,</span> num_hiddens<span class="token punctuation">,</span> bias<span class="token operator">=</span>bias<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>W_v <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>value_size<span class="token punctuation">,</span> num_hiddens<span class="token punctuation">,</span> bias<span class="token operator">=</span>bias<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>W_o <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>num_hiddens<span class="token punctuation">,</span> num_hiddens<span class="token punctuation">,</span> bias<span class="token operator">=</span>bias<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> queries<span class="token punctuation">,</span> keys<span class="token punctuation">,</span> values<span class="token punctuation">,</span> valid_lens<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># queries，keys，values的形状:</span>        <span class="token comment"># (batch_size，查询或者“键－值”对的个数，num_hiddens)</span>        <span class="token comment"># valid_lens　的形状:</span>        <span class="token comment"># (batch_size，)或(batch_size，查询的个数)</span>        <span class="token comment"># 经过变换后，输出的queries，keys，values　的形状:</span>        <span class="token comment"># (batch_size*num_heads，查询或者“键－值”对的个数，</span>        <span class="token comment"># num_hiddens/num_heads)</span>        queries <span class="token operator">=</span> transpose_qkv<span class="token punctuation">(</span>self<span class="token punctuation">.</span>W_q<span class="token punctuation">(</span>queries<span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_heads<span class="token punctuation">)</span>        keys <span class="token operator">=</span> transpose_qkv<span class="token punctuation">(</span>self<span class="token punctuation">.</span>W_k<span class="token punctuation">(</span>keys<span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_heads<span class="token punctuation">)</span>        values <span class="token operator">=</span> transpose_qkv<span class="token punctuation">(</span>self<span class="token punctuation">.</span>W_v<span class="token punctuation">(</span>values<span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_heads<span class="token punctuation">)</span>        <span class="token keyword">if</span> valid_lens <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>            <span class="token comment"># 在轴0，将第一项（标量或者矢量）复制num_heads次，</span>            <span class="token comment"># 然后如此复制第二项，然后诸如此类。</span>            valid_lens <span class="token operator">=</span> torch<span class="token punctuation">.</span>repeat_interleave<span class="token punctuation">(</span>                valid_lens<span class="token punctuation">,</span> repeats<span class="token operator">=</span>self<span class="token punctuation">.</span>num_heads<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>        <span class="token comment"># output的形状:(batch_size*num_heads，查询的个数，</span>        <span class="token comment"># num_hiddens/num_heads)</span>        output <span class="token operator">=</span> self<span class="token punctuation">.</span>attention<span class="token punctuation">(</span>queries<span class="token punctuation">,</span> keys<span class="token punctuation">,</span> values<span class="token punctuation">,</span> valid_lens<span class="token punctuation">)</span>        <span class="token comment"># output_concat的形状:(batch_size，查询的个数，num_hiddens)</span>        output_concat <span class="token operator">=</span> transpose_output<span class="token punctuation">(</span>output<span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_heads<span class="token punctuation">)</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>W_o<span class="token punctuation">(</span>output_concat<span class="token punctuation">)</span><span class="token comment">#@save</span><span class="token keyword">def</span> <span class="token function">transpose_qkv</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> num_heads<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""为了多注意力头的并行计算而变换形状"""</span>    <span class="token comment"># 输入X的形状:(batch_size，查询或者“键－值”对的个数，num_hiddens)</span>    <span class="token comment"># 输出X的形状:(batch_size，查询或者“键－值”对的个数，num_heads，</span>    <span class="token comment"># num_hiddens/num_heads)</span>    X <span class="token operator">=</span> X<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> num_heads<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>    <span class="token comment"># 输出X的形状:(batch_size，num_heads，查询或者“键－值”对的个数,</span>    <span class="token comment"># num_hiddens/num_heads)</span>    X <span class="token operator">=</span> X<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>    <span class="token comment"># 最终输出的形状:(batch_size*num_heads,查询或者“键－值”对的个数,</span>    <span class="token comment"># num_hiddens/num_heads)</span>    <span class="token keyword">return</span> X<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment">#@save</span><span class="token keyword">def</span> <span class="token function">transpose_output</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> num_heads<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""逆转transpose_qkv函数的操作"""</span>    X <span class="token operator">=</span> X<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> num_heads<span class="token punctuation">,</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    X <span class="token operator">=</span> X<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> X<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="自注意力和位置编码"><a href="#自注意力和位置编码" class="headerlink" title="自注意力和位置编码"></a>自注意力和位置编码</h2><p>终于进入自注意力部分了，离 transformer 只有一步之遥！</p><p>在深度学习中，我们经常使用卷积神经网络（CNN）或循环神经网络（RNN）对序列进行编码。想象一下，有了注意力机制之后，我们将词元序列输入注意力池化层中，同一组词元同时充当查询、键和值。每个查询都会关注所有的键－值对并生成一个注意力输出。由于查询、键和值来自同一组输入，因此被称为 自注意力（self-attention）在本节中，我们将使用自注意力进行序列编码，以及如何使用序列的顺序作为补充信息</p><h3 id="自注意力"><a href="#自注意力" class="headerlink" title="自注意力"></a>自注意力</h3><p>给定一个由词元组成的输入序列，其中任意 $x_i \in R^ d$。该序列的自注意力输出为一个长度相同的序列：</p><script type="math/tex; mode=display">\mathbf{y}_{i}=f\left(\mathbf{x}_{i},\left(\mathbf{x}_{1}, \mathbf{x}_{1}\right), \ldots,\left(\mathbf{x}_{n}, \mathbf{x}_{n}\right)\right) \in \mathbb{R}^{d}</script><h3 id="比较卷积神经网络、循环神经网络和自注意力"><a href="#比较卷积神经网络、循环神经网络和自注意力" class="headerlink" title="比较卷积神经网络、循环神经网络和自注意力"></a>比较卷积神经网络、循环神经网络和自注意力</h3><p>下图为三者计算的图示</p><p><img src="/archives/b7d04b34/image-20211213171227551.png" style="zoom:80%;"></p><p>现在让我们比较这三个架构，目标都是将由 n 个词元组成的序列映射到另一个长度相等的序列，其中的每个输入词元或输出词元都由 d 维向量表示。具体来说，我们将比较的是卷积神经网络、循环神经网络和自注意力这几个架构的计算复杂性、顺序操作和最大路径长度。请注意，<strong>顺序操作会妨碍并行计算，而任意的序列位置组合之间的路径越短，则能更轻松地学习序列中的远距离依赖关系</strong></p><p>下面这个表依然来自于沐神视频 <a href="https://www.bilibili.com/video/BV19o4y1m7mo">bilibili</a>，非常清晰地对比了三者的关系，其中 k 是一维卷积核的 kernel size</p><p><img src="/archives/b7d04b34/image-20211213172102475.png" style="zoom: 50%;"></p><p>稍微解释一下：</p><ol><li>最长路径中的路径为：两个词元进行信息传递的计算次数</li><li>循环神经网络的隐状态时， d×d 权重矩阵和 d 维隐状态的乘法计算复杂度为 $O(d^2)$</li><li>在自注意力中，查询、键和值都是 n×d 矩阵。 并且使用缩放点积注意力，故自注意力计算复杂度为 $O(n^2d)$，并且由于使用的是矩阵乘法，而矩阵乘法的并行度为 $O(n)$</li></ol><p>总而言之，卷积神经网络和自注意力都拥有并行计算的优势，而且自注意力的最大路径长度最短。但是因为其计算复杂度是关于序列长度的二次方，所以在很长的序列中计算会非常慢</p><h3 id="位置编码"><a href="#位置编码" class="headerlink" title="位置编码"></a>位置编码</h3><p>不同于 CNN 和 RNN，以上得到的自注意力计算结果是不包含位置（顺序）信息的。也就是说换个输入顺序，得到的结果还是那些结果，这显然不是我们想要的，接下来，我们描述的是基于正弦函数和余弦函数的固定位置编码（不得不吐槽一下这个编码真的略微抽象</p><p>以下是我的个人理解：对于一个序列 <code>range(n)</code>，我需要使用 d 个维度对其位置进行编码，采取如下编码形式， $p_{i,j}$ 即是第 i 个位置的第 j 个维度的编码数</p><script type="math/tex; mode=display">\begin{aligned}p_{i, 2 j} &=\sin \left(\frac{i}{10000^{2 j / d}}\right) \\p_{i, 2 j+1} &=\cos \left(\frac{i}{10000^{2 j / d}}\right)\end{aligned}</script><p>第一次看这个编码真的太蒙圈了，不过教材举了一个例子：绝对位置信息。也就是我们使用 d 位二进制对序列 <code>range(n)</code> 的位置进行编码，这样来看是不是就简单不少了</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># d = 5</span><span class="token number">0</span>的二进制是：<span class="token number">00000</span><span class="token number">1</span>的二进制是：<span class="token number">00001</span><span class="token number">2</span>的二进制是：<span class="token number">00010</span><span class="token number">3</span>的二进制是：<span class="token number">00011</span><span class="token number">4</span>的二进制是：<span class="token number">00100</span><span class="token number">5</span>的二进制是：<span class="token number">00101</span><span class="token number">6</span>的二进制是：<span class="token number">00110</span><span class="token number">7</span>的二进制是：<span class="token number">00111</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>越高位的数字变化得越慢，一共能够编码 $2^n$ 个数。那如果我们用 d 维 (0, 1) 之间的数去对位置进行编码是不是也可以呢？教材中的位置编码就属于其中一种。还可以从平面空间的角度来进行理解，假设有 d 个维度，此时我们画出 d/2 个平面</p><p><img src="/archives/b7d04b34/image-20211213201150635.png" alt="image-20211213201150635"></p><p>旋转角度就是对应着 (cos, sin)，随着位数越高每次 i 进一时，旋转的幅度越小。下面是 position 和 endoding dimension 的热力图</p><p><img src="/archives/b7d04b34/image-20211213201335149.png" style="zoom:80%;"></p><p>我已经尽力去理解了…但是还是有点云里雾里，不过还是先继续前行吧</p><h2 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h2><p>与 CNN 和 RNN 比较，自注意力同时具有并行计算和最短的最大路径长度这两个优势，因此，使用自注意力来设计深度架构是很有吸引力的。尽管 transformer 最初是应用于在文本数据上的序列到序列学习，但现在已经推广到各种现代的深度学习中，例如语言、视觉、语音和强化学习领域</p><p>我认为这里贴英文的图示比较好，第一次看这个图肯定是一头雾水，可以先看代码，了解每个模块的结构，然后再拼起来</p><p><img src="/archives/b7d04b34/image-20211213212144723.png" style="zoom:80%;"></p><h3 id="基于位置的前馈网络-（Positionwise-FFN）"><a href="#基于位置的前馈网络-（Positionwise-FFN）" class="headerlink" title="基于位置的前馈网络 （Positionwise FFN）"></a>基于位置的前馈网络 （Positionwise FFN）</h3><p>名字很酷，实际上是两个全连接层</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#@save</span><span class="token keyword">class</span> <span class="token class-name">PositionWiseFFN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""基于位置的前馈网络"""</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> ffn_num_input<span class="token punctuation">,</span> ffn_num_hiddens<span class="token punctuation">,</span> ffn_num_outputs<span class="token punctuation">,</span>                 <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>PositionWiseFFN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>dense1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>ffn_num_input<span class="token punctuation">,</span> ffn_num_hiddens<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>relu <span class="token operator">=</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>dense2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>ffn_num_hiddens<span class="token punctuation">,</span> ffn_num_outputs<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>dense2<span class="token punctuation">(</span>self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>dense1<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="残差连接和层规范化（add-amp-norm）"><a href="#残差连接和层规范化（add-amp-norm）" class="headerlink" title="残差连接和层规范化（add &amp; norm）"></a>残差连接和层规范化（add &amp; norm）</h3><p>残差连接是很常见的网络结构，这里主要讲讲规范化使用的是 LayerNorm。假设数据 $X$ 的形状为 (batch, num_steps, channels)，BatchNorm 针对的是 batch 维度，最后得到的均值和方差形状是 (num_steps, channels)</p><p>但问题来了，在计算机视觉中 num_steps 一般代表的是图片的形状 (H, W) 所以是一个固定的值，而在序列模型中，由于每个样本的时间步可能不一样</p><p>所以 LayerNorm 针对的是 num_steps 维度（更宽泛的讲可以是除了 batch 以外的其他维度），最终得到的均值和方差形状是 (batch, channels) or (batch,)，这就保证了统一性，因为 batch &amp; channel 一般是一个固定值。</p><p>除了使用 LayerNorm 还使用了 dropout 正则化，下面来看看核心代码（<a href="https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html">LayerNorm</a> 输入是 normalized_shape，我理解为计算单个统计值，数据所需的形状）</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#@save</span><span class="token keyword">class</span> <span class="token class-name">AddNorm</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""残差连接后进行层规范化"""</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> normalized_shape<span class="token punctuation">,</span> dropout<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>AddNorm<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>dropout <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>dropout<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>ln <span class="token operator">=</span> nn<span class="token punctuation">.</span>LayerNorm<span class="token punctuation">(</span>normalized_shape<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">,</span> Y<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>ln<span class="token punctuation">(</span>self<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>Y<span class="token punctuation">)</span> <span class="token operator">+</span> X<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="编码器"><a href="#编码器" class="headerlink" title="编码器"></a>编码器</h3><h4 id="EncoderBlock"><a href="#EncoderBlock" class="headerlink" title="EncoderBlock"></a>EncoderBlock</h4><p>有了以上两个模块：FFN &amp; AddNorm，再加上之前介绍的多头注意力模块，就能够构建一个完整的 transformer 编码器模块</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#@save</span><span class="token keyword">class</span> <span class="token class-name">EncoderBlock</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""transformer编码器块"""</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> key_size<span class="token punctuation">,</span> query_size<span class="token punctuation">,</span> value_size<span class="token punctuation">,</span> num_hiddens<span class="token punctuation">,</span>                 norm_shape<span class="token punctuation">,</span> ffn_num_input<span class="token punctuation">,</span> ffn_num_hiddens<span class="token punctuation">,</span> num_heads<span class="token punctuation">,</span>                 dropout<span class="token punctuation">,</span> use_bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>EncoderBlock<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>attention <span class="token operator">=</span> d2l<span class="token punctuation">.</span>MultiHeadAttention<span class="token punctuation">(</span>            key_size<span class="token punctuation">,</span> query_size<span class="token punctuation">,</span> value_size<span class="token punctuation">,</span> num_hiddens<span class="token punctuation">,</span> num_heads<span class="token punctuation">,</span> dropout<span class="token punctuation">,</span>            use_bias<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>addnorm1 <span class="token operator">=</span> AddNorm<span class="token punctuation">(</span>norm_shape<span class="token punctuation">,</span> dropout<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>ffn <span class="token operator">=</span> PositionWiseFFN<span class="token punctuation">(</span>            ffn_num_input<span class="token punctuation">,</span> ffn_num_hiddens<span class="token punctuation">,</span> num_hiddens<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>addnorm2 <span class="token operator">=</span> AddNorm<span class="token punctuation">(</span>norm_shape<span class="token punctuation">,</span> dropout<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">,</span> valid_lens<span class="token punctuation">)</span><span class="token punctuation">:</span>        Y <span class="token operator">=</span> self<span class="token punctuation">.</span>addnorm1<span class="token punctuation">(</span>X<span class="token punctuation">,</span> self<span class="token punctuation">.</span>attention<span class="token punctuation">(</span>X<span class="token punctuation">,</span> X<span class="token punctuation">,</span> X<span class="token punctuation">,</span> valid_lens<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>addnorm2<span class="token punctuation">(</span>Y<span class="token punctuation">,</span> self<span class="token punctuation">.</span>ffn<span class="token punctuation">(</span>Y<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>transformer 一个很好的性质是：<strong>编码器中的任何层都不会改变其输入的形状！</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">X <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">)</span><span class="token punctuation">)</span>valid_lens <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>encoder_blk <span class="token operator">=</span> EncoderBlock<span class="token punctuation">(</span><span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">48</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span>encoder_blk<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>encoder_blk<span class="token punctuation">(</span>X<span class="token punctuation">,</span> valid_lens<span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token comment"># torch.Size([2, 100, 24])</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="TransformerEncoder"><a href="#TransformerEncoder" class="headerlink" title="TransformerEncoder"></a>TransformerEncoder</h4><p>有了单个模块之后，就可以将它们堆叠起来获得更强大编码器，当然这里还有两个需要注意的点：</p><ol><li>Positional encoding，给每一个序列使用之前所将的三角函数位置编码</li><li>由于 embedding 的数值是经过归一化的，也就是说除以了 $\sqrt{d}$，而 Positional encoding 的值是 (-1, 1) 之间的三角函数，为了让两个数相加（加入位置信息），并且让二者的数值大小相差更小，则需要将 embedding 再乘以长度 $\sqrt{d}$ 以还原</li></ol><p>代码如下</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#@save</span><span class="token keyword">class</span> <span class="token class-name">TransformerEncoder</span><span class="token punctuation">(</span>d2l<span class="token punctuation">.</span>Encoder<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""transformer编码器"""</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> vocab_size<span class="token punctuation">,</span> key_size<span class="token punctuation">,</span> query_size<span class="token punctuation">,</span> value_size<span class="token punctuation">,</span>                 num_hiddens<span class="token punctuation">,</span> norm_shape<span class="token punctuation">,</span> ffn_num_input<span class="token punctuation">,</span> ffn_num_hiddens<span class="token punctuation">,</span>                 num_heads<span class="token punctuation">,</span> num_layers<span class="token punctuation">,</span> dropout<span class="token punctuation">,</span> use_bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>TransformerEncoder<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>num_hiddens <span class="token operator">=</span> num_hiddens        self<span class="token punctuation">.</span>embedding <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>vocab_size<span class="token punctuation">,</span> num_hiddens<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>pos_encoding <span class="token operator">=</span> d2l<span class="token punctuation">.</span>PositionalEncoding<span class="token punctuation">(</span>num_hiddens<span class="token punctuation">,</span> dropout<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>blks <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_layers<span class="token punctuation">)</span><span class="token punctuation">:</span>            self<span class="token punctuation">.</span>blks<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">"block"</span><span class="token operator">+</span><span class="token builtin">str</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">,</span>                EncoderBlock<span class="token punctuation">(</span>key_size<span class="token punctuation">,</span> query_size<span class="token punctuation">,</span> value_size<span class="token punctuation">,</span> num_hiddens<span class="token punctuation">,</span>                             norm_shape<span class="token punctuation">,</span> ffn_num_input<span class="token punctuation">,</span> ffn_num_hiddens<span class="token punctuation">,</span>                             num_heads<span class="token punctuation">,</span> dropout<span class="token punctuation">,</span> use_bias<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">,</span> valid_lens<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># 因为位置编码值在-1和1之间，</span>        <span class="token comment"># 因此嵌入值乘以嵌入维度的平方根进行缩放，</span>        <span class="token comment"># 然后再与位置编码相加。</span>        X <span class="token operator">=</span> self<span class="token punctuation">.</span>pos_encoding<span class="token punctuation">(</span>self<span class="token punctuation">.</span>embedding<span class="token punctuation">(</span>X<span class="token punctuation">)</span> <span class="token operator">*</span> math<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_hiddens<span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>attention_weights <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>blks<span class="token punctuation">)</span>        <span class="token keyword">for</span> i<span class="token punctuation">,</span> blk <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>blks<span class="token punctuation">)</span><span class="token punctuation">:</span>            X <span class="token operator">=</span> blk<span class="token punctuation">(</span>X<span class="token punctuation">,</span> valid_lens<span class="token punctuation">)</span>            self<span class="token punctuation">.</span>attention_weights<span class="token punctuation">[</span>                i<span class="token punctuation">]</span> <span class="token operator">=</span> blk<span class="token punctuation">.</span>attention<span class="token punctuation">.</span>attention<span class="token punctuation">.</span>attention_weights        <span class="token keyword">return</span> X<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>下面我们指定了超参数来创建一个两层的 transformer 编码器。Transformer 编码器输出的形状是（批量大小，时间步数目，<code>num_hiddens</code>）</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">encoder <span class="token operator">=</span> TransformerEncoder<span class="token punctuation">(</span>    <span class="token number">200</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">48</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span>encoder<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>encoder<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">)</span><span class="token punctuation">,</span> valid_lens<span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token comment"># torch.Size([2, 100, 24])</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="解码器"><a href="#解码器" class="headerlink" title="解码器"></a>解码器</h3><h4 id="DecoderBlock"><a href="#DecoderBlock" class="headerlink" title="DecoderBlock"></a>DecoderBlock</h4><p>同样的，先实现单个解码器模块。其实基本的模块之前已经全部实现了，细节上的不同是：</p><ol><li>与 encoder 相比，decoder 先使用自注意力汇聚对 targets 输入进行编码。然后将该编码作为 query、将 encoder 的输出作为 key &amp; value，输入到多头注意力汇聚中</li><li>同 seq2seq 一样，在进行解码时不应该看到该时间步及其之后的信息，所以需要掩码 <code>dec_valid_lens</code>，以保持其自回归属性</li></ol><p>具体代码如下</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">DecoderBlock</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""解码器中第 i 个块"""</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> key_size<span class="token punctuation">,</span> query_size<span class="token punctuation">,</span> value_size<span class="token punctuation">,</span> num_hiddens<span class="token punctuation">,</span>                 norm_shape<span class="token punctuation">,</span> ffn_num_input<span class="token punctuation">,</span> ffn_num_hiddens<span class="token punctuation">,</span> num_heads<span class="token punctuation">,</span>                 dropout<span class="token punctuation">,</span> i<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>DecoderBlock<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>i <span class="token operator">=</span> i        self<span class="token punctuation">.</span>attention1 <span class="token operator">=</span> d2l<span class="token punctuation">.</span>MultiHeadAttention<span class="token punctuation">(</span>            key_size<span class="token punctuation">,</span> query_size<span class="token punctuation">,</span> value_size<span class="token punctuation">,</span> num_hiddens<span class="token punctuation">,</span> num_heads<span class="token punctuation">,</span> dropout<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>addnorm1 <span class="token operator">=</span> AddNorm<span class="token punctuation">(</span>norm_shape<span class="token punctuation">,</span> dropout<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>attention2 <span class="token operator">=</span> d2l<span class="token punctuation">.</span>MultiHeadAttention<span class="token punctuation">(</span>            key_size<span class="token punctuation">,</span> query_size<span class="token punctuation">,</span> value_size<span class="token punctuation">,</span> num_hiddens<span class="token punctuation">,</span> num_heads<span class="token punctuation">,</span> dropout<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>addnorm2 <span class="token operator">=</span> AddNorm<span class="token punctuation">(</span>norm_shape<span class="token punctuation">,</span> dropout<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>ffn <span class="token operator">=</span> PositionWiseFFN<span class="token punctuation">(</span>ffn_num_input<span class="token punctuation">,</span> ffn_num_hiddens<span class="token punctuation">,</span>                                   num_hiddens<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>addnorm3 <span class="token operator">=</span> AddNorm<span class="token punctuation">(</span>norm_shape<span class="token punctuation">,</span> dropout<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">,</span> state<span class="token punctuation">)</span><span class="token punctuation">:</span>        enc_outputs<span class="token punctuation">,</span> enc_valid_lens <span class="token operator">=</span> state<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> state<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>        <span class="token comment"># 训练阶段，输出序列的所有词元都在同一时间处理，</span>        <span class="token comment"># 因此 `state[2][self.i]` 初始化为 `None`。</span>        <span class="token comment"># 预测阶段，输出序列是通过词元一个接着一个解码的，</span>        <span class="token comment"># 因此 `state[2][self.i]` 包含着直到当前时间步第 `i` 个块解码的输出表示</span>        <span class="token keyword">if</span> state<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>i<span class="token punctuation">]</span> <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>            key_values <span class="token operator">=</span> X        <span class="token keyword">else</span><span class="token punctuation">:</span>            key_values <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>state<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> X<span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        state<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> key_values        <span class="token keyword">if</span> self<span class="token punctuation">.</span>training<span class="token punctuation">:</span>            batch_size<span class="token punctuation">,</span> num_steps<span class="token punctuation">,</span> _ <span class="token operator">=</span> X<span class="token punctuation">.</span>shape            <span class="token comment"># `dec_valid_lens` 的开头: (`batch_size`, `num_steps`),</span>            <span class="token comment"># 其中每一行是 [1, 2, ..., `num_steps`]</span>            dec_valid_lens <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>                <span class="token number">1</span><span class="token punctuation">,</span> num_steps <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> device<span class="token operator">=</span>X<span class="token punctuation">.</span>device<span class="token punctuation">)</span><span class="token punctuation">.</span>repeat<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            dec_valid_lens <span class="token operator">=</span> <span class="token boolean">None</span>        <span class="token comment"># 自注意力</span>        X2 <span class="token operator">=</span> self<span class="token punctuation">.</span>attention1<span class="token punctuation">(</span>X<span class="token punctuation">,</span> key_values<span class="token punctuation">,</span> key_values<span class="token punctuation">,</span> dec_valid_lens<span class="token punctuation">)</span>        Y <span class="token operator">=</span> self<span class="token punctuation">.</span>addnorm1<span class="token punctuation">(</span>X<span class="token punctuation">,</span> X2<span class="token punctuation">)</span>        <span class="token comment"># 编码器－解码器注意力。</span>        <span class="token comment"># `enc_outputs` 的开头: (`batch_size`, `num_steps`, `num_hiddens`)</span>        Y2 <span class="token operator">=</span> self<span class="token punctuation">.</span>attention2<span class="token punctuation">(</span>Y<span class="token punctuation">,</span> enc_outputs<span class="token punctuation">,</span> enc_outputs<span class="token punctuation">,</span> enc_valid_lens<span class="token punctuation">)</span>        Z <span class="token operator">=</span> self<span class="token punctuation">.</span>addnorm2<span class="token punctuation">(</span>Y<span class="token punctuation">,</span> Y2<span class="token punctuation">)</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>addnorm3<span class="token punctuation">(</span>Z<span class="token punctuation">,</span> self<span class="token punctuation">.</span>ffn<span class="token punctuation">(</span>Z<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> state<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>为了便于在“编码器－解码器”注意力中进行缩放点积计算和残差连接中进行加法计算，编码器和解码器的特征维度都是 <code>num_hiddens</code>，所以说 decoder 也是不改变数据形状的</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">decoder_blk <span class="token operator">=</span> DecoderBlock<span class="token punctuation">(</span><span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">48</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>decoder_blk<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>X <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">)</span><span class="token punctuation">)</span>state <span class="token operator">=</span> <span class="token punctuation">[</span>encoder_blk<span class="token punctuation">(</span>X<span class="token punctuation">,</span> valid_lens<span class="token punctuation">)</span><span class="token punctuation">,</span> valid_lens<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">]</span><span class="token punctuation">]</span>decoder_blk<span class="token punctuation">(</span>X<span class="token punctuation">,</span> state<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token comment"># torch.Size([2, 100, 24])</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="TransformerDecoder"><a href="#TransformerDecoder" class="headerlink" title="TransformerDecoder"></a>TransformerDecoder</h4><p>下面将多个 decoder 组合起来，并保存注意力权重用于可视化</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">TransformerDecoder</span><span class="token punctuation">(</span>d2l<span class="token punctuation">.</span>AttentionDecoder<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> vocab_size<span class="token punctuation">,</span> key_size<span class="token punctuation">,</span> query_size<span class="token punctuation">,</span> value_size<span class="token punctuation">,</span>                 num_hiddens<span class="token punctuation">,</span> norm_shape<span class="token punctuation">,</span> ffn_num_input<span class="token punctuation">,</span> ffn_num_hiddens<span class="token punctuation">,</span>                 num_heads<span class="token punctuation">,</span> num_layers<span class="token punctuation">,</span> dropout<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>TransformerDecoder<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>num_hiddens <span class="token operator">=</span> num_hiddens        self<span class="token punctuation">.</span>num_layers <span class="token operator">=</span> num_layers        self<span class="token punctuation">.</span>embedding <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>vocab_size<span class="token punctuation">,</span> num_hiddens<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>pos_encoding <span class="token operator">=</span> d2l<span class="token punctuation">.</span>PositionalEncoding<span class="token punctuation">(</span>num_hiddens<span class="token punctuation">,</span> dropout<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>blks <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_layers<span class="token punctuation">)</span><span class="token punctuation">:</span>            self<span class="token punctuation">.</span>blks<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">"block"</span><span class="token operator">+</span><span class="token builtin">str</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">,</span>                DecoderBlock<span class="token punctuation">(</span>key_size<span class="token punctuation">,</span> query_size<span class="token punctuation">,</span> value_size<span class="token punctuation">,</span> num_hiddens<span class="token punctuation">,</span>                             norm_shape<span class="token punctuation">,</span> ffn_num_input<span class="token punctuation">,</span> ffn_num_hiddens<span class="token punctuation">,</span>                             num_heads<span class="token punctuation">,</span> dropout<span class="token punctuation">,</span> i<span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>dense <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>num_hiddens<span class="token punctuation">,</span> vocab_size<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">init_state</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> enc_outputs<span class="token punctuation">,</span> enc_valid_lens<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> <span class="token punctuation">[</span>enc_outputs<span class="token punctuation">,</span> enc_valid_lens<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">]</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>num_layers<span class="token punctuation">]</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">,</span> state<span class="token punctuation">)</span><span class="token punctuation">:</span>        X <span class="token operator">=</span> self<span class="token punctuation">.</span>pos_encoding<span class="token punctuation">(</span>self<span class="token punctuation">.</span>embedding<span class="token punctuation">(</span>X<span class="token punctuation">)</span> <span class="token operator">*</span> math<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_hiddens<span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>_attention_weights <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>blks<span class="token punctuation">)</span> <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> i<span class="token punctuation">,</span> blk <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>blks<span class="token punctuation">)</span><span class="token punctuation">:</span>            X<span class="token punctuation">,</span> state <span class="token operator">=</span> blk<span class="token punctuation">(</span>X<span class="token punctuation">,</span> state<span class="token punctuation">)</span>            <span class="token comment"># 解码器自注意力权重</span>            self<span class="token punctuation">.</span>_attention_weights<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span>                i<span class="token punctuation">]</span> <span class="token operator">=</span> blk<span class="token punctuation">.</span>attention1<span class="token punctuation">.</span>attention<span class="token punctuation">.</span>attention_weights            <span class="token comment"># “编码器－解码器”自注意力权重</span>            self<span class="token punctuation">.</span>_attention_weights<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span>                i<span class="token punctuation">]</span> <span class="token operator">=</span> blk<span class="token punctuation">.</span>attention2<span class="token punctuation">.</span>attention<span class="token punctuation">.</span>attention_weights        <span class="token keyword">return</span> self<span class="token punctuation">.</span>dense<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">,</span> state    <span class="token decorator annotation punctuation">@property</span>    <span class="token keyword">def</span> <span class="token function">attention_weights</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>_attention_weights<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>下面来看看三个 Multi-attention 的可视化结果，主要是体会 valid_len 的效果</p><ol><li><p>Encoder self-attention weights</p><p><img src="/archives/b7d04b34/image-20211215153222782.png" style="zoom: 67%;"></p><p>可以看到在某个 key positions 过后是没有注意力权重的，是因为之后的 key 都是 <pad> 词元，不需要进行注意力计算</pad></p></li><li><p>Decoder self-attention weights</p><p><img src="/archives/b7d04b34/image-20211215153713172.png" alt="image-20211215153713172" style="zoom: 67%;"></p><p>由于 decoder 的每个 valid_len 是随着时间步逐渐增加的，所以可以看到 self-attention weights 似乎整体是呈下三角形状</p></li><li><p>Encoder-decoder attention weights</p><p><img src="/archives/b7d04b34/image-20211215154614074.png" alt="image-20211215154614074" style="zoom:67%;"></p><p>又出现了 encoder self-attention 中的情况，超过某个 key position 就没有权重了，因为只有这么多个 key (source time step)</p></li></ol><h3 id="感言"><a href="#感言" class="headerlink" title="感言"></a>感言</h3><p>可算是完成了总结😭😭虽然看得还是比较粗糙，但是总归是有些概念了。在沐神读论文的视频 <a href="https://www.bilibili.com/video/BV1pu411o7BE">bilibili</a> 中讲到：虽然 transformer 论文叫做 <code>Attention Is All You Need</code>，但事实上各个结构都是很重要的，例如：残差连接和层规规范化在训练深度网络时是非常重要的。Transformer (attention) 整体来看仍是一个发展初期的架构，在未来或许有更多的架构出现，一起期待吧</p>]]></content>
      
      
      <categories>
          
          <category> 课程 </category>
          
          <category> Dive into deep learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Dive into deep learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>D2L 09 现代循环神经网络</title>
      <link href="/archives/5c4d4ee5.html"/>
      <url>/archives/5c4d4ee5.html</url>
      
        <content type="html"><![CDATA[<h1 id="D2L-09-现代循环神经网络"><a href="#D2L-09-现代循环神经网络" class="headerlink" title="D2L 09 现代循环神经网络"></a>D2L 09 现代循环神经网络</h1><p>循环神经网络在实践中一个常见问题是数值不稳定性。 尽管我们已经应用了梯度裁剪等技巧来缓解这个问题， 但是仍需要通过设计更复杂的序列模型可以进一步处理它。 具体来说，我们将引入两个广泛使用的网络， 即门控循环单元（gated recurrent units，GRU）和 长短期记忆网络（long short-term memory，LSTM）。 然后，我们将基于一个单向隐藏层来扩展循环神经网络架构。 我们将描述具有多个隐藏层的深层架构， 并讨论基于前向和后向循环计算的双向设计。 现代循环网络经常采用这种扩展</p><p>事实上，语言建模只揭示了序列学习能力的冰山一角。 在各种序列学习问题中，如自动语音识别、文本到语音转换和机器翻译， 输入和输出都是任意长度的序列。 为了阐述如何拟合这种类型的数据， 我们将以机器翻译为例介绍基于循环神经网络的 “编码器－解码器”架构和束搜索，并用它们来生成序列</p><p><strong>由于我对于 RNN 的研究甚少，所以这些章节整理将会比较粗糙</strong></p><h2 id="门控循环单元（GRU）"><a href="#门控循环单元（GRU）" class="headerlink" title="门控循环单元（GRU）"></a>门控循环单元（GRU）</h2><p>对于一个系列来说，不是每一个观察值都是同等重要，我们希望循环神经网络能够记住想要的观察，忽略不重要观察。GRU 使用了两个门：更新门和重置门来达到这样的目的，两个门具有以下两个显著特征：</p><ul><li>重置门有助于捕获序列中的短期依赖关系</li><li>更新门有助于捕获序列中的长期依赖关系</li></ul><p>这意味着模型有专门的机制来确定应该何时更新隐状态， 以及应该何时重置隐状态。 这些机制是可学习的，并且能够解决了上面列出的问题。 例如，如果第一个词元非常重要， 模型将学会在第一次观测之后不更新隐状态。 同样，模型也可以学会跳过不相关的临时观测</p><h3 id="门控隐状态"><a href="#门控隐状态" class="headerlink" title="门控隐状态"></a>门控隐状态</h3><h4 id="重置门和更新门"><a href="#重置门和更新门" class="headerlink" title="重置门和更新门"></a>重置门和更新门</h4><p>先看一个简单图解</p><p><img src="/archives/5c4d4ee5/image-20211209195253434.png" style="zoom:80%;"></p><p>再来看其数学表达，对于给定的时间步 t，假设输入是一个小批量 $X_t∈R^{n×d}$， 上一个时间步的隐状态是 $H_{t−1}∈R^{n×h}$ ，重置门 $R_t∈R^{n×h}$和更新门 $Z_t∈R^{n×h}$</p><script type="math/tex; mode=display">\begin{aligned}\mathbf{R}_{t} &=\sigma\left(\mathbf{X}_{t} \mathbf{W}_{x r}+\mathbf{H}_{t-1} \mathbf{W}_{h r}+\mathbf{b}_{r}\right), \\\mathbf{Z}_{t} &=\sigma\left(\mathbf{X}_{t} \mathbf{W}_{x z}+\mathbf{H}_{t-1} \mathbf{W}_{h z}+\mathbf{b}_{z}\right),\end{aligned}</script><p>使用 sigmoid 函数将输入值转换到区间 (0,1)，权重将 $X_t$ 和 $H_{t-1}$ 转化到维度为 $h$ 的隐状态</p><h4 id="候选隐状态"><a href="#候选隐状态" class="headerlink" title="候选隐状态"></a>候选隐状态</h4><p>将重置门 $R_t$ 与常规隐状态更新机制集成， 得到在时间步 t 的候选隐状态（candidate hidden state） $\tilde{H}_t \in R^{n \times h}$</p><script type="math/tex; mode=display">\tilde{\mathbf{H}}_{t}=\tanh \left(\mathbf{X}_{t} \mathbf{W}_{x h}+\left(\mathbf{R}_{t} \odot \mathbf{H}_{t-1}\right) \mathbf{W}_{h h}+\mathbf{b}_{h}\right)</script><p>符号 ⊙ 是 Hadamard 积（按元素乘积）运算符，我们使用 tanh 非线性激活函数来确保候选隐状态中的值保持在区间 (−1,1) 中</p><p>当重置门接近为1就回到普通的循环神经网络，若重置门为0则放弃之前的隐状态</p><h4 id="隐状态"><a href="#隐状态" class="headerlink" title="隐状态"></a>隐状态</h4><p>更新门将 $H_{t-1}$ 和 $\tilde{H}_t$ 之间进行按元素的凸组合，以确定保留多少上一步的隐状态，到此就得出了门控循环单元的最终更新公式</p><script type="math/tex; mode=display">\mathbf{H}_{t}=\mathbf{Z}_{t} \odot \mathbf{H}_{t-1}+\left(1-\mathbf{Z}_{t}\right) \odot \tilde{\mathbf{H}}_{t}</script><p>最后放一个“花哨”的图示，来表示整个流程，实际上并没有数学表达看起来清晰</p><p><img src="/archives/5c4d4ee5/image-20211209202833640.png" style="zoom: 80%;"></p><p>到现在我都挺难以理解这两个门的作用，只能自己生硬理解了：</p><ol><li>重置门，决定当前候选隐状态对于当前输入的影响程度（及时），能够让网络更轻松地关注当下</li><li>更新门，有点像残差一样，决定保留多少前一时刻隐状态的特征（长期），能够让网络更轻松地记住之前</li></ol><h3 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h3><p>以上四个公式就是 GRU 的核心，贴一下从零实现的 GRU 核心代码，略去数据的初始化和隐状态的初始化</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">gru</span><span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> state<span class="token punctuation">,</span> params<span class="token punctuation">)</span><span class="token punctuation">:</span>    W_xz<span class="token punctuation">,</span> W_hz<span class="token punctuation">,</span> b_z<span class="token punctuation">,</span> W_xr<span class="token punctuation">,</span> W_hr<span class="token punctuation">,</span> b_r<span class="token punctuation">,</span> W_xh<span class="token punctuation">,</span> W_hh<span class="token punctuation">,</span> b_h<span class="token punctuation">,</span> W_hq<span class="token punctuation">,</span> b_q <span class="token operator">=</span> params    H<span class="token punctuation">,</span> <span class="token operator">=</span> state    outputs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> X <span class="token keyword">in</span> inputs<span class="token punctuation">:</span>        Z <span class="token operator">=</span> torch<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span><span class="token punctuation">(</span>X @ W_xz<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">(</span>H @ W_hz<span class="token punctuation">)</span> <span class="token operator">+</span> b_z<span class="token punctuation">)</span>        R <span class="token operator">=</span> torch<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span><span class="token punctuation">(</span>X @ W_xr<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">(</span>H @ W_hr<span class="token punctuation">)</span> <span class="token operator">+</span> b_r<span class="token punctuation">)</span>        H_tilda <span class="token operator">=</span> torch<span class="token punctuation">.</span>tanh<span class="token punctuation">(</span><span class="token punctuation">(</span>X @ W_xh<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>R <span class="token operator">*</span> H<span class="token punctuation">)</span> @ W_hh<span class="token punctuation">)</span> <span class="token operator">+</span> b_h<span class="token punctuation">)</span>        H <span class="token operator">=</span> Z <span class="token operator">*</span> H <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> Z<span class="token punctuation">)</span> <span class="token operator">*</span> H_tilda        Y <span class="token operator">=</span> H @ W_hq <span class="token operator">+</span> b_q        outputs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>Y<span class="token punctuation">)</span>    <span class="token keyword">return</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>H<span class="token punctuation">,</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>简洁实现 GRU 只需要一行，将其替换上一节的 RNN 单元，即可得到新的 RNN 模型</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">num_inputs <span class="token operator">=</span> vocab_sizegru_layer <span class="token operator">=</span> nn<span class="token punctuation">.</span>GRU<span class="token punctuation">(</span>num_inputs<span class="token punctuation">,</span> num_hiddens<span class="token punctuation">)</span>model <span class="token operator">=</span> d2l<span class="token punctuation">.</span>RNNModel<span class="token punctuation">(</span>gru_layer<span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>vocab<span class="token punctuation">)</span><span class="token punctuation">)</span>model <span class="token operator">=</span> model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>d2l<span class="token punctuation">.</span>train_ch8<span class="token punctuation">(</span>model<span class="token punctuation">,</span> train_iter<span class="token punctuation">,</span> vocab<span class="token punctuation">,</span> lr<span class="token punctuation">,</span> num_epochs<span class="token punctuation">,</span> device<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="长短期记忆网络（LSTM）"><a href="#长短期记忆网络（LSTM）" class="headerlink" title="长短期记忆网络（LSTM）"></a>长短期记忆网络（LSTM）</h2><p>长期以来，隐变量模型存在着长期信息保存和短期输入缺失的问题。 解决这一问题的最早方法之一是长短期存储器（long short-term memory，LSTM），有趣的是，长短期记忆网络的设计比门控循环单元稍微复杂一些， 却比门控循环单元早诞生了近20年</p><h3 id="门控记忆元"><a href="#门控记忆元" class="headerlink" title="门控记忆元"></a>门控记忆元</h3><p>该记忆元的实现比 GRU 稍微复杂一点，下面具体来看看</p><h4 id="输入门、遗忘门和输出门"><a href="#输入门、遗忘门和输出门" class="headerlink" title="输入门、遗忘门和输出门"></a>输入门、遗忘门和输出门</h4><p>同样先看一个简单图解</p><p><img src="/archives/5c4d4ee5/image-20211209203459078.png" style="zoom:80%;"></p><p>再来看其数学表达式</p><script type="math/tex; mode=display">\begin{aligned}\mathbf{I}_{t} &=\sigma\left(\mathbf{X}_{t} \mathbf{W}_{x i}+\mathbf{H}_{t-1} \mathbf{W}_{h i}+\mathbf{b}_{i}\right) \\\mathbf{F}_{t} &=\sigma\left(\mathbf{X}_{t} \mathbf{W}_{x f}+\mathbf{H}_{t-1} \mathbf{W}_{h f}+\mathbf{b}_{f}\right) \\\mathbf{O}_{t} &=\sigma\left(\mathbf{X}_{t} \mathbf{W}_{x o}+\mathbf{H}_{t-1} \mathbf{W}_{h o}+\mathbf{b}_{o}\right)\end{aligned}</script><p>就是和 GRU 的更新门和重置门一样的公式</p><h4 id="候选记忆元"><a href="#候选记忆元" class="headerlink" title="候选记忆元"></a>候选记忆元</h4><p>类似于 GRU 的候选隐状态，也是受用 tanh 作为激活函数，但是不同的是没有其他门控的参与</p><script type="math/tex; mode=display">\tilde{\mathbf{C}}_{t}=\tanh \left(\mathbf{X}_{t} \mathbf{W}_{x c}+\mathbf{H}_{t-1} \mathbf{W}_{h c}+\mathbf{b}_{c}\right)</script><h4 id="记忆元"><a href="#记忆元" class="headerlink" title="记忆元"></a>记忆元</h4><p>现在基础的材料准备完毕，开始进行组合控制。类似于 GRU 的最后隐状态更新，但是使用的是记忆元和两个门，其表达式如下</p><script type="math/tex; mode=display">\mathbf{C}_{t}=\mathbf{F}_{t} \odot \mathbf{C}_{t-1}+\mathbf{I}_{t} \odot \tilde{\mathbf{C}}_{t}</script><h4 id="隐状态-1"><a href="#隐状态-1" class="headerlink" title="隐状态"></a>隐状态</h4><p>最终的隐状态更新公式为</p><script type="math/tex; mode=display">\mathbf{H}_{t}=\mathbf{O}_{t} \odot \tanh \left(\mathbf{C}_{t}\right)</script><h3 id="实现-1"><a href="#实现-1" class="headerlink" title="实现"></a>实现</h3><p>从零实现的核心代码如下，同样这里忽略数据初始化和隐状态初始化</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">lstm</span><span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> state<span class="token punctuation">,</span> params<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token punctuation">[</span>W_xi<span class="token punctuation">,</span> W_hi<span class="token punctuation">,</span> b_i<span class="token punctuation">,</span> W_xf<span class="token punctuation">,</span> W_hf<span class="token punctuation">,</span> b_f<span class="token punctuation">,</span> W_xo<span class="token punctuation">,</span> W_ho<span class="token punctuation">,</span> b_o<span class="token punctuation">,</span> W_xc<span class="token punctuation">,</span> W_hc<span class="token punctuation">,</span> b_c<span class="token punctuation">,</span>     W_hq<span class="token punctuation">,</span> b_q<span class="token punctuation">]</span> <span class="token operator">=</span> params    <span class="token punctuation">(</span>H<span class="token punctuation">,</span> C<span class="token punctuation">)</span> <span class="token operator">=</span> state    outputs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> X <span class="token keyword">in</span> inputs<span class="token punctuation">:</span>        I <span class="token operator">=</span> torch<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span><span class="token punctuation">(</span>X @ W_xi<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">(</span>H @ W_hi<span class="token punctuation">)</span> <span class="token operator">+</span> b_i<span class="token punctuation">)</span>        F <span class="token operator">=</span> torch<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span><span class="token punctuation">(</span>X @ W_xf<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">(</span>H @ W_hf<span class="token punctuation">)</span> <span class="token operator">+</span> b_f<span class="token punctuation">)</span>        O <span class="token operator">=</span> torch<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span><span class="token punctuation">(</span>X @ W_xo<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">(</span>H @ W_ho<span class="token punctuation">)</span> <span class="token operator">+</span> b_o<span class="token punctuation">)</span>        C_tilda <span class="token operator">=</span> torch<span class="token punctuation">.</span>tanh<span class="token punctuation">(</span><span class="token punctuation">(</span>X @ W_xc<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">(</span>H @ W_hc<span class="token punctuation">)</span> <span class="token operator">+</span> b_c<span class="token punctuation">)</span>        C <span class="token operator">=</span> F <span class="token operator">*</span> C <span class="token operator">+</span> I <span class="token operator">*</span> C_tilda        H <span class="token operator">=</span> O <span class="token operator">*</span> torch<span class="token punctuation">.</span>tanh<span class="token punctuation">(</span>C<span class="token punctuation">)</span>        Y <span class="token operator">=</span> <span class="token punctuation">(</span>H @ W_hq<span class="token punctuation">)</span> <span class="token operator">+</span> b_q        outputs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>Y<span class="token punctuation">)</span>    <span class="token keyword">return</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>H<span class="token punctuation">,</span> C<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>看可以看到 LSTM 除了隐状态 $H_t$ 需要传递到下一个时间步，还需要传递记忆元 $C_t$，简洁实现如下</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">num_inputs <span class="token operator">=</span> vocab_sizelstm_layer <span class="token operator">=</span> nn<span class="token punctuation">.</span>LSTM<span class="token punctuation">(</span>num_inputs<span class="token punctuation">,</span> num_hiddens<span class="token punctuation">)</span>model <span class="token operator">=</span> d2l<span class="token punctuation">.</span>RNNModel<span class="token punctuation">(</span>lstm_layer<span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>vocab<span class="token punctuation">)</span><span class="token punctuation">)</span>model <span class="token operator">=</span> model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>d2l<span class="token punctuation">.</span>train_ch8<span class="token punctuation">(</span>model<span class="token punctuation">,</span> train_iter<span class="token punctuation">,</span> vocab<span class="token punctuation">,</span> lr<span class="token punctuation">,</span> num_epochs<span class="token punctuation">,</span> device<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>教材仅仅是简单介绍了这些结构，对于这些结构为什么有用并没有深入分析。在吴恩达讲解的 <a href="https://www.bilibili.com/video/BV1FT4y1E74V?p=159">GRU</a> 讲解了一个简化版本，即没有重置门的版本，这就让重置门的作用变得更加模糊了。以我愚蠢的见解来看，GRU 的两个门控作用可能来自以下直觉：</p><ol><li>以残差网络的观点来理解更新门，能够让网络更好学习恒等变换，即方便保留历史信息</li><li>重置门进一步增加网络灵活性，对隐状态加以权重，是否放弃历史状态以专注当前输入</li></ol><h2 id="深度循环神经网路"><a href="#深度循环神经网路" class="headerlink" title="深度循环神经网路"></a>深度循环神经网路</h2><p>到目前为止，我们只讨论了具有一个单向隐藏层的循环神经网络， 而在循环神经网络中，我们首先需要确定如何添加更多的层， 以及在哪里添加额外的非线性</p><p>下面描述了一个具有 L 个隐藏层的深度循环神经网络， 每个隐状态都连续地传递到当前层的下一个时间步和下一层的当前时间步</p><p><img src="/archives/5c4d4ee5/image-20211210150421071.png" style="zoom:80%;"></p><p>数学表示如下：</p><script type="math/tex; mode=display">\mathbf{H}_{t}^{(l)}=\phi_{l}\left(\mathbf{H}_{t}^{(l-1)} \mathbf{W}_{x h}^{(l)}+\mathbf{H}_{t-1}^{(l)} \mathbf{W}_{h h}^{(l)}+\mathbf{b}_{h}^{(l)}\right)\\\mathbf{O}_{t}=\mathbf{H}_{t}^{(L)} \mathbf{W}_{h q}+\mathbf{b}_{q}</script><p>与多层感知机一样，隐藏层数目 L 和隐藏单元数目 h 都是超参数</p><h3 id="简介实现"><a href="#简介实现" class="headerlink" title="简介实现"></a>简介实现</h3><p>只需要多加一个参数 <code>num_layers</code> 就可以搞定了</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">vocab_size<span class="token punctuation">,</span> num_hiddens<span class="token punctuation">,</span> num_layers <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>vocab<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">2</span>num_inputs <span class="token operator">=</span> vocab_sizedevice <span class="token operator">=</span> d2l<span class="token punctuation">.</span>try_gpu<span class="token punctuation">(</span><span class="token punctuation">)</span>lstm_layer <span class="token operator">=</span> nn<span class="token punctuation">.</span>LSTM<span class="token punctuation">(</span>num_inputs<span class="token punctuation">,</span> num_hiddens<span class="token punctuation">,</span> num_layers<span class="token punctuation">)</span>model <span class="token operator">=</span> d2l<span class="token punctuation">.</span>RNNModel<span class="token punctuation">(</span>lstm_layer<span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>vocab<span class="token punctuation">)</span><span class="token punctuation">)</span>model <span class="token operator">=</span> model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>由于使用了长短期记忆网络模型来实例化两个层，因此训练速度被大大降低了（左侧为单层 GRU，右侧为两层 GRU）</p><p><img src="/archives/5c4d4ee5/image-20211210151851947.png" style="zoom:80%;"></p><h2 id="双向循环神经网络"><a href="#双向循环神经网络" class="headerlink" title="双向循环神经网络"></a>双向循环神经网络</h2><p>双向循环神经网络的一个关键特性是：使用来自序列两端的信息来估计输出。 也就是说，我们<strong>使用来自过去和未来的观测信息来预测当前的观测</strong>。 但是在对下一个词元进行预测的情况中，这样的模型并不是我们所需的</p><p>双向层的使用在实践中非常少，并且仅仅应用于部分场合。 例如，填充缺失的单词、词元注释（例如，用于命名实体识别） 以及作为序列处理流水线中的一个步骤对序列进行编码（<strong>例如，用于机器翻译</strong>）</p><p><img src="/archives/5c4d4ee5/image-20211210154429643.png" style="zoom: 80%;"></p><script type="math/tex; mode=display">\begin{array}{l}\overrightarrow{\mathbf{H}}_{t}=\phi\left(\mathbf{X}_{t} \mathbf{W}_{x h}^{(f)}+\overrightarrow{\mathbf{H}}_{t-1} \mathbf{W}_{h h}^{(f)}+\mathbf{b}_{h}^{(f)}\right) \\\overleftarrow{\mathbf{H}}_{t}=\phi\left(\mathbf{X}_{t} \mathbf{W}_{x h}^{(b)}+\overleftarrow{\mathbf{H}}_{t+1} \mathbf{W}_{h h}^{(b)}+\mathbf{b}_{h}^{(b)}\right)\end{array}</script><p>将两个方向的隐状态连接起来进行对输出的预测</p><script type="math/tex; mode=display">\mathbf{O}_{t}=\mathbf{H}_{t} \mathbf{W}_{h q}+\mathbf{b}_{q}</script><h2 id="机器翻译与数据集"><a href="#机器翻译与数据集" class="headerlink" title="机器翻译与数据集"></a>机器翻译与数据集</h2><p>需要了解的点：</p><ol><li><p>机器翻译的数据集是由源语言和目标语言的文本序列对组成的</p></li><li><p>在机器翻译中，我们更喜欢单词级词元化 （最先进的模型可能使用更高级的词元化技术）其中每个词元要么是一个词，要么是一个标点符号</p></li><li><p>由于机器翻译数据集由语言对组成， 因此我们可以分别为源语言和目标语言构建两个词表</p></li><li><p>我们还指定了额外的特定词元， 例如在小批量时用于将序列填充到相同长度的填充词元（“<pad>”）， 以及序列的开始词元（“<bos>”）和结束词元（“<eos>”）。 这些特殊词元在自然语言处理任务中比较常用</eos></bos></pad></p></li><li><p>在机器翻译中，每个样本都是由源和目标组成的文本序列对， 其中的每个文本序列可能具有不同的长度。为了提高计算效率，我们仍然可以通过截断（truncation）和 填充（padding）方式实现一次只处理一个小批量的文本序列</p></li></ol><h2 id="编码器-解码器架构"><a href="#编码器-解码器架构" class="headerlink" title="编码器-解码器架构"></a>编码器-解码器架构</h2><p> 为了处理这种类型的输入和输出， 我们可以设计一个包含两个主要组件的架构： 第一个组件是一个编码器（encoder）： 它接受一个长度可变的序列作为输入， 并将其转换为具有固定形状的编码状态。 第二个组件是解码器（decoder）： 它将固定形状的编码状态映射到长度可变的序列。 这被称为编码器-解码器（encoder-decoder）架构</p><p><img src="/archives/5c4d4ee5/image-20211210160641142.png" style="zoom:80%;"></p><h2 id="序列到序列学习（seq2seq）"><a href="#序列到序列学习（seq2seq）" class="headerlink" title="序列到序列学习（seq2seq）"></a>序列到序列学习（seq2seq）</h2><p> 本节，我们将使用两个循环神经网络的编码器和解码器， 并将其应用于序列到序列（sequence to sequence，seq2seq）类的学习任务</p><p>循环神经网络<strong>编码器</strong>使用长度可变的序列作为输入， 将其转换为固定形状的隐状态。 为了连续生成输出序列的词元， 独立的循环神经网络<strong>解码器</strong>是基于输入序列的编码信息和输出序列已经看见的（train mode）或者生成的词元（test mode）来预测下一个词元</p><p><img src="/archives/5c4d4ee5/image-20211210164750436.png" style="zoom:80%;"></p><p>需要了解的点：</p><ol><li><p>图示结构中，编码器最终的隐状态在每一个时间步都作为解码器的输入序列的一部分。具体来说是和 input 进行维度连接 <code>torch.cat</code></p></li><li><p>编码器 RNN 是没有输出层的，并且可以是双向 RNN</p></li><li><p>在训练时解码器使用标签作为输入；推理时解码器使用上一时间步的输出作为输入</p></li><li><p>衡量生成序列的好坏使用 BLEU (bilingual evaluation understudy)</p><script type="math/tex; mode=display">\exp \left(\min \left(0,1-\frac{\text { len }_{\text {label }}}{\text { len }_{\text {pred }}}\right)\right) \prod_{n=1}^{k} p_{n}^{1 / 2^{n}}</script><p>关于 BLEU:</p><ol><li><p>BLEU 值越大表示结果越好</p></li><li><p>其中 len 表示词元数，k 是用于匹配的最长的 n 元语法。 另外，用 $p_n$ 表示 n 元语法的精确度，它是两个数量的比值：</p><script type="math/tex; mode=display">\frac{\text{matched n-gram number}}{\text{total predicted n-gram number}}</script><p>第一个是预测序列与标签序列中匹配的 n 元语法的数量， 第二个是预测序列中 n 元语法的数量。看个小例子，来自教材的讲解视频 <a href="https://www.bilibili.com/video/BV16g411L7FG?p=1">bilibili</a></p><p><img src="/archives/5c4d4ee5/image-20211210173916201.png" style="zoom: 33%;"></p></li><li><p>n-gram 语法中，n 越大对其越重视（BLEU 中指数的原因）</p></li></ol></li></ol><p>看看编码器和解码器的代码</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#@save</span><span class="token keyword">class</span> <span class="token class-name">Seq2SeqEncoder</span><span class="token punctuation">(</span>d2l<span class="token punctuation">.</span>Encoder<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""用于序列到序列学习的循环神经网络编码器"""</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> vocab_size<span class="token punctuation">,</span> embed_size<span class="token punctuation">,</span> num_hiddens<span class="token punctuation">,</span> num_layers<span class="token punctuation">,</span>                 dropout<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>Seq2SeqEncoder<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span>        <span class="token comment"># 嵌入层</span>        self<span class="token punctuation">.</span>embedding <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>vocab_size<span class="token punctuation">,</span> embed_size<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>rnn <span class="token operator">=</span> nn<span class="token punctuation">.</span>GRU<span class="token punctuation">(</span>embed_size<span class="token punctuation">,</span> num_hiddens<span class="token punctuation">,</span> num_layers<span class="token punctuation">,</span>                          dropout<span class="token operator">=</span>dropout<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># 输出'X'的形状：(batch_size,num_steps,embed_size)</span>        X <span class="token operator">=</span> self<span class="token punctuation">.</span>embedding<span class="token punctuation">(</span>X<span class="token punctuation">)</span>        <span class="token comment"># 在循环神经网络模型中，第一个轴对应于时间步</span>        X <span class="token operator">=</span> X<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        <span class="token comment"># 如果未提及状态，则默认为0</span>        output<span class="token punctuation">,</span> state <span class="token operator">=</span> self<span class="token punctuation">.</span>rnn<span class="token punctuation">(</span>X<span class="token punctuation">)</span>        <span class="token comment"># output的形状:(num_steps,batch_size,num_hiddens)</span>        <span class="token comment"># state[0]的形状:(num_layers,batch_size,num_hiddens)</span>        <span class="token keyword">return</span> output<span class="token punctuation">,</span> state<span class="token keyword">class</span> <span class="token class-name">Seq2SeqDecoder</span><span class="token punctuation">(</span>d2l<span class="token punctuation">.</span>Decoder<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""用于序列到序列学习的循环神经网络解码器"""</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> vocab_size<span class="token punctuation">,</span> embed_size<span class="token punctuation">,</span> num_hiddens<span class="token punctuation">,</span> num_layers<span class="token punctuation">,</span>                 dropout<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>Seq2SeqDecoder<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>embedding <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>vocab_size<span class="token punctuation">,</span> embed_size<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>rnn <span class="token operator">=</span> nn<span class="token punctuation">.</span>GRU<span class="token punctuation">(</span>embed_size <span class="token operator">+</span> num_hiddens<span class="token punctuation">,</span> num_hiddens<span class="token punctuation">,</span> num_layers<span class="token punctuation">,</span>                          dropout<span class="token operator">=</span>dropout<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>dense <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>num_hiddens<span class="token punctuation">,</span> vocab_size<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">init_state</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> enc_outputs<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> enc_outputs<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">,</span> state<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># 输出'X'的形状：(batch_size,num_steps,embed_size)</span>        X <span class="token operator">=</span> self<span class="token punctuation">.</span>embedding<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        <span class="token comment"># 广播context，使其具有与X相同的num_steps</span>        context <span class="token operator">=</span> state<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>repeat<span class="token punctuation">(</span>X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>        X_and_context <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> context<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        output<span class="token punctuation">,</span> state <span class="token operator">=</span> self<span class="token punctuation">.</span>rnn<span class="token punctuation">(</span>X_and_context<span class="token punctuation">,</span> state<span class="token punctuation">)</span>        output <span class="token operator">=</span> self<span class="token punctuation">.</span>dense<span class="token punctuation">(</span>output<span class="token punctuation">)</span><span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        <span class="token comment"># output的形状:(batch_size,num_steps,vocab_size)</span>        <span class="token comment"># state[0]的形状:(num_layers,batch_size,num_hiddens)</span>        <span class="token keyword">return</span> output<span class="token punctuation">,</span> state<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="束搜索（beam-search）"><a href="#束搜索（beam-search）" class="headerlink" title="束搜索（beam search）"></a>束搜索（beam search）</h2><h3 id="贪心搜索"><a href="#贪心搜索" class="headerlink" title="贪心搜索"></a>贪心搜索</h3><p>对于输出序列的每一时间步 t′， 我们都将基于贪心搜索从输出中找到具有最高条件概率的词元</p><script type="math/tex; mode=display">y_{t^{\prime}}=\underset{y \in \mathcal{Y}}{\operatorname{argmax}} P\left(y \mid y_{1}, \ldots, y_{t^{\prime}-1}, \mathbf{c}\right)</script><p>那么贪心搜索存在的问题是什么呢？ 现实中，最优序列（optimal sequence）应该是最大化</p><script type="math/tex; mode=display">\prod_{t^{\prime}=1}^{T^{\prime}} P\left(y_{t^{\prime}} \mid y_{1}, \ldots, y_{t^{\prime}-1}, \mathbf{c}\right)</script><p>这是基于输入序列生成输出序列的条件概率。 然而，贪心搜索无法保证得到最优序列</p><h3 id="穷举搜索"><a href="#穷举搜索" class="headerlink" title="穷举搜索"></a>穷举搜索</h3><p>虽然穷举搜索能保证最优解，但其计算量是不可接受的，为 $O(|Y|^{T’})$ 其中 Y 为词表长度，T’ 为输出最大长度</p><h3 id="束搜索"><a href="#束搜索" class="headerlink" title="束搜索"></a>束搜索</h3><p>束搜索（beam search）是贪心搜索的一个改进版本。 它有一个超参数，名为束宽（beam size）k。 在时间步1，我们选择具有最高条件概率的 k 个词元。 在随后的每个时间步，基于上一时间步的 k 个候选输出序列， 我们将继续从 k|Y| 个可能的选择中挑出具有最高条件概率的 k 个候选输出序列，图示如下</p><p><img src="/archives/5c4d4ee5/image-20211210180349192.png" style="zoom:80%;"></p><p>束搜索的计算量为 $O(k|Y|T’)$</p><p>对于我们获得最终候选输出序列集合（不仅仅是最后 k 个集合，还可以包含之前的候选系列），选择其中条件概率乘积最高的序列作为输出序列</p><script type="math/tex; mode=display">\frac{1}{L^{\alpha}} \log P\left(y_{1}, \ldots, y_{L} \mid \mathbf{c}\right)=\frac{1}{L^{\alpha}} \sum_{t^{\prime}=1}^{L} \log P\left(y_{t^{\prime}} \mid y_{1}, \ldots, y_{t^{\prime}-1}, \mathbf{c}\right)</script><p>其中 L 部分是对长句的奖励，就像 BLEU 一样</p>]]></content>
      
      
      <categories>
          
          <category> 课程 </category>
          
          <category> Dive into deep learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Dive into deep learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>D2L 08 循环神经网络</title>
      <link href="/archives/a67a203a.html"/>
      <url>/archives/a67a203a.html</url>
      
        <content type="html"><![CDATA[<h1 id="D2L-08-循环神经网络"><a href="#D2L-08-循环神经网络" class="headerlink" title="D2L 08 循环神经网络"></a>D2L 08 循环神经网络</h1><h2 id="序列模型"><a href="#序列模型" class="headerlink" title="序列模型"></a>序列模型</h2><p>处理序列数据需要统计工具和新的深度神经网络架构</p><h3 id="统计工具"><a href="#统计工具" class="headerlink" title="统计工具"></a>统计工具</h3><p>教材以股票的例子作为例子，假设一个交易员想在第 $t$ 日的股市中表现良好，于是通过以下途径预测当天的价格 $x_t$</p><script type="math/tex; mode=display">x_{t} \sim P\left(x_{t} \mid x_{t-1}, \ldots, x_{1}\right)</script><h4 id="自回归模型"><a href="#自回归模型" class="headerlink" title="自回归模型"></a>自回归模型</h4><p>本章后面的大部分内容将围绕着如何有效估计 $P(x_t∣x_{t−1},…,x_1)$ 展开，简单地说，它归结为以下两种策略：</p><ol><li><p>假设在现实情况下相当长的序列 $x_{t−1},…,x_1$ 可能是不必要的， 因此我们只需要满足某个长度为 $\tau$ 的时间跨度， 即使用观测序列 $x_{t−1},…,x_{t−τ}$ 这种，模型被称为自回归模型（autoregressive models）， 因为它们是对自己执行回归</p></li><li><p>保留一些对过去观测的总结 $h_t$，并且同时更新预测 $\hat {x}_t$ 和总结 $h_t$ ，由于 $ht$ 从未被观测到，这类模型也被称为隐变量自回归模型（latent autoregressive models）</p></li></ol><h4 id="马尔可夫模型"><a href="#马尔可夫模型" class="headerlink" title="马尔可夫模型"></a>马尔可夫模型</h4><p>在自回归模型的近似法中， 我们使用 $x_{t−1},…,x_{t−τ}$ 而不是 $x_{t−1},…,x_1$ 来估计 $x_t$。 只要这种是近似精确的，我们就说序列满足马尔可夫条件（Markov condition），特别是，如果 $\tau =1$，得到一个一阶马尔可夫模型（first-order Markov model）， $P(x)$ 由下式给出</p><script type="math/tex; mode=display">P\left(x_{1}, \ldots, x_{T}\right)=\prod_{t=1}^{T} P\left(x_{t} \mid x_{t-1}\right) ,\ where\ P\left(x_{1} \mid x_{0}\right)=P\left(x_{1}\right) \text {. }</script><p>动态规划这些计算工具已经在控制算法和强化学习算法广泛使用</p><h3 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h3><p>接下来教材开始了一个小实践！首先，生成一些数据：使用正弦函数和一些可加性噪声来生成序列数据， 时间步为1,2,…,1000，并且将这个序列转换为模型的“特征－标签”（feature-label）对。 基于嵌入维度 $\tau$，我们将数据映射为数据对 $y_t=x_t$ 和 $x_t=[x_{t−τ},…,x_{t−1}]$</p><p><img src="/archives/a67a203a/image-20211206231256583.png" style="zoom:80%;"></p><p>换句话说，我们想要干这么一个事情：在时刻 $t$，根据之前的 $\tau$ 个数据 $[x_{t−τ},…,x_{t−1}]$，去预测 $x_t$ 的数据是什么。教材使用了一个 MLP 去做这个预测，效果还不错</p><p><img src="/archives/a67a203a/image-20211206231852458.png" style="zoom:80%;"></p><h3 id="预测"><a href="#预测" class="headerlink" title="预测"></a>预测</h3><p>通常，对于直到 $x_t$ 的观测序列，其在时间步 $t+k$ 处的预测输出 $x_{t+k}$ 称为 $k$ 步预测（k-step-ahead-prediction），上面展示的就是单步预测结果，当使训练好的模型进行多步预测时，会发现预测结果很快就变得离谱起来，一个原因是误差的累计导致预测结果与真实标签相差甚远</p><h2 id="文本预处理"><a href="#文本预处理" class="headerlink" title="文本预处理"></a>文本预处理</h2><p>序列数据存在许多种形式，文本是最常见例子之一，本节中，我们将解析文本的常见预处理步骤。 这些步骤通常包括：</p><ol><li>将文本作为字符串加载到内存中</li><li>将字符串拆分为词元（如单词和字符）</li><li>建立一个词表，将拆分的词元映射到数字索引</li><li>将文本转换为数字索引序列，方便模型操作</li></ol><h3 id="读取数据集"><a href="#读取数据集" class="headerlink" title="读取数据集"></a>读取数据集</h3><p>教材使用了一个 time machine 文本作为数据集</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">data_path <span class="token operator">=</span> Path<span class="token punctuation">(</span><span class="token string">'./d2l_data/timemachine.txt'</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">read_time_machine</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment">#@save</span>    <span class="token triple-quoted-string string">"""将时间机器数据集加载到文本行的列表中"""</span>    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>data_path<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>        lines <span class="token operator">=</span> f<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> <span class="token punctuation">[</span>re<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">'[^A-Za-z]+'</span><span class="token punctuation">,</span> <span class="token string">' '</span><span class="token punctuation">,</span> line<span class="token punctuation">)</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> line <span class="token keyword">in</span> lines<span class="token punctuation">]</span>lines <span class="token operator">=</span> read_time_machine<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'# 文本总行数: </span><span class="token interpolation"><span class="token punctuation">{</span><span class="token builtin">len</span><span class="token punctuation">(</span>lines<span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>lines<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>lines<span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="词元化"><a href="#词元化" class="headerlink" title="词元化"></a>词元化</h3><p>下面的 <code>tokenize</code> 函数将文本行列表（<code>lines</code>）作为输入，每个文本序列又被拆分成一个词元列表，词元（token）是文本的基本单位（例如，可以选择单词或字母作为基本单位）</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">tokenize</span><span class="token punctuation">(</span>lines<span class="token punctuation">,</span> token<span class="token operator">=</span><span class="token string">'word'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment">#@save</span>    <span class="token triple-quoted-string string">"""将文本行拆分为单词或字符词元"""</span>    <span class="token keyword">if</span> token <span class="token operator">==</span> <span class="token string">'word'</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> <span class="token punctuation">[</span>line<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> line <span class="token keyword">in</span> lines<span class="token punctuation">]</span>    <span class="token keyword">elif</span> token <span class="token operator">==</span> <span class="token string">'char'</span><span class="token punctuation">:</span>        <span class="token comment"># 把字符串转换为单个字母可以用 list 方法</span>        <span class="token keyword">return</span> <span class="token punctuation">[</span><span class="token builtin">list</span><span class="token punctuation">(</span>line<span class="token punctuation">)</span> <span class="token keyword">for</span> line <span class="token keyword">in</span> lines<span class="token punctuation">]</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'错误：未知词元类型：'</span> <span class="token operator">+</span> token<span class="token punctuation">)</span>tokens <span class="token operator">=</span> tokenize<span class="token punctuation">(</span>lines<span class="token punctuation">)</span><span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">11</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>tokens<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="词表"><a href="#词表" class="headerlink" title="词表"></a>词表</h3><p>词元的类型是字符串，而模型需要的输入是数字，因此这种类型不方便模型使用。 现在，让我们构建一个字典，通常也叫做词表（vocabulary）， 用来将字符串类型的词元映射到从0开始的数字索引中</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Vocab</span><span class="token punctuation">:</span>  <span class="token comment">#@save</span>    <span class="token triple-quoted-string string">"""文本词表"""</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> tokens<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> min_freq<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> reserved_tokens<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> tokens <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>            tokens <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">if</span> reserved_tokens <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>            reserved_tokens <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token comment"># 按出现频率排序</span>        counter <span class="token operator">=</span> count_corpus<span class="token punctuation">(</span>tokens<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>_token_freqs <span class="token operator">=</span> <span class="token builtin">sorted</span><span class="token punctuation">(</span>counter<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                                   reverse<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>        <span class="token comment"># 初始化未知词元 &amp; reserved_tokens</span>        self<span class="token punctuation">.</span>idx_to_token <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'&lt;unk&gt;'</span><span class="token punctuation">]</span> <span class="token operator">+</span> reserved_tokens        self<span class="token punctuation">.</span>token_to_idx <span class="token operator">=</span> <span class="token punctuation">{</span>token<span class="token punctuation">:</span> idx                             <span class="token keyword">for</span> idx<span class="token punctuation">,</span> token <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>idx_to_token<span class="token punctuation">)</span><span class="token punctuation">}</span>        <span class="token comment"># 下面这句话是多余的，是教材中的一个小失误</span>        <span class="token comment"># self.idx_to_token, self.token_to_idx = [], dict()</span>        <span class="token keyword">for</span> token<span class="token punctuation">,</span> freq <span class="token keyword">in</span> self<span class="token punctuation">.</span>_token_freqs<span class="token punctuation">:</span>            <span class="token comment"># 去除出现频率低的词元</span>            <span class="token keyword">if</span> freq <span class="token operator">&lt;</span> min_freq<span class="token punctuation">:</span>                <span class="token keyword">break</span>            <span class="token keyword">if</span> token <span class="token keyword">not</span> <span class="token keyword">in</span> self<span class="token punctuation">.</span>token_to_idx<span class="token punctuation">:</span>                self<span class="token punctuation">.</span>idx_to_token<span class="token punctuation">.</span>append<span class="token punctuation">(</span>token<span class="token punctuation">)</span>                <span class="token comment"># 核心是生成了 {token: idx} 字典</span>                self<span class="token punctuation">.</span>token_to_idx<span class="token punctuation">[</span>token<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>idx_to_token<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span>    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>idx_to_token<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> tokens<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> <span class="token keyword">not</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>tokens<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">,</span> <span class="token builtin">tuple</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> self<span class="token punctuation">.</span>token_to_idx<span class="token punctuation">.</span>get<span class="token punctuation">(</span>tokens<span class="token punctuation">,</span> self<span class="token punctuation">.</span>unk<span class="token punctuation">)</span>        <span class="token keyword">return</span> <span class="token punctuation">[</span>self<span class="token punctuation">.</span>__getitem__<span class="token punctuation">(</span>token<span class="token punctuation">)</span> <span class="token keyword">for</span> token <span class="token keyword">in</span> tokens<span class="token punctuation">]</span>    <span class="token keyword">def</span> <span class="token function">to_tokens</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> indices<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> <span class="token keyword">not</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>indices<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">,</span> <span class="token builtin">tuple</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> self<span class="token punctuation">.</span>idx_to_token<span class="token punctuation">[</span>indices<span class="token punctuation">]</span>        <span class="token keyword">return</span> <span class="token punctuation">[</span>self<span class="token punctuation">.</span>idx_to_token<span class="token punctuation">[</span>index<span class="token punctuation">]</span> <span class="token keyword">for</span> index <span class="token keyword">in</span> indices<span class="token punctuation">]</span>    <span class="token decorator annotation punctuation">@property</span>    <span class="token keyword">def</span> <span class="token function">unk</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># 未知词元的索引为0</span>        <span class="token keyword">return</span> <span class="token number">0</span>    <span class="token decorator annotation punctuation">@property</span>    <span class="token keyword">def</span> <span class="token function">token_freqs</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>_token_freqs<span class="token keyword">def</span> <span class="token function">count_corpus</span><span class="token punctuation">(</span>tokens<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment">#@save</span>    <span class="token triple-quoted-string string">"""统计词元的频率"""</span>    <span class="token comment"># 这里的 `tokens` 是 1D 列表或 2D 列表</span>    <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>tokens<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span> <span class="token keyword">or</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>tokens<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token builtin">list</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># 将词元列表展平成一个列表</span>        tokens <span class="token operator">=</span> <span class="token punctuation">[</span>token <span class="token keyword">for</span> line <span class="token keyword">in</span> tokens <span class="token keyword">for</span> token <span class="token keyword">in</span> line<span class="token punctuation">]</span>    <span class="token keyword">return</span> collections<span class="token punctuation">.</span>Counter<span class="token punctuation">(</span>tokens<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这里的代码比较复杂，为了让 vocab 的概念更清晰，再总结一下它的功能：</p><ol><li><p>index to token，给定一个 index 返回其 token</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">vocab<span class="token punctuation">.</span>to_tokens<span class="token punctuation">(</span>index<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li><p>token to index，给定一个 token 返回其 index</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 由 __getitem__ 实现</span>vocab<span class="token punctuation">[</span>token<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li><li><p><code>token_freqs</code> 返回一个 list of tuple，用于存储 token 出现的次数 (token, freqs)，该功能是由 <code>collections.Counter + sorted</code> 实现</p></li></ol><h3 id="语料库"><a href="#语料库" class="headerlink" title="语料库"></a>语料库</h3><p>将如下几个功能整合起来：将数据导入，生成词表，生成语料库（所谓语料库，就是一个 list of index，存储了文本中每一个 token 对应的 index）</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">load_corpus_time_machine</span><span class="token punctuation">(</span>max_tokens<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment">#@save</span>    <span class="token triple-quoted-string string">"""返回时光机器数据集的词元索引列表和词表"""</span>    lines <span class="token operator">=</span> read_time_machine<span class="token punctuation">(</span><span class="token punctuation">)</span>    tokens <span class="token operator">=</span> tokenize<span class="token punctuation">(</span>lines<span class="token punctuation">,</span> <span class="token string">'char'</span><span class="token punctuation">)</span>    vocab <span class="token operator">=</span> Vocab<span class="token punctuation">(</span>tokens<span class="token punctuation">)</span>    <span class="token comment"># 因为时光机器数据集中的每个文本行不一定是一个句子或一个段落，</span>    <span class="token comment"># 所以将所有文本行展平到一个列表中，并利用 vocab 查询其 index</span>    <span class="token comment"># 这里的语法非常的简洁，欣赏一下</span>    corpus <span class="token operator">=</span> <span class="token punctuation">[</span>vocab<span class="token punctuation">[</span>token<span class="token punctuation">]</span> <span class="token keyword">for</span> line <span class="token keyword">in</span> tokens <span class="token keyword">for</span> token <span class="token keyword">in</span> line<span class="token punctuation">]</span>    <span class="token keyword">if</span> max_tokens <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">:</span>        corpus <span class="token operator">=</span> corpus<span class="token punctuation">[</span><span class="token punctuation">:</span>max_tokens<span class="token punctuation">]</span>    <span class="token keyword">return</span> corpus<span class="token punctuation">,</span> vocab<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="语言模型和数据集"><a href="#语言模型和数据集" class="headerlink" title="语言模型和数据集"></a>语言模型和数据集</h2><p> 一个理想的语言模型就能够基于模型本身生成自然文本</p><h3 id="马尔可夫模型与-n-元语法"><a href="#马尔可夫模型与-n-元语法" class="headerlink" title="马尔可夫模型与 n 元语法"></a>马尔可夫模型与 n 元语法</h3><p>马尔可夫性质推导出了许多可以应用于序列建模的近似公式：</p><p><img src="/archives/a67a203a/image-20211207164553989.png" style="zoom:80%;"></p><p>通常，涉及一个、两个和三个变量的概率公式分别被称为 “一元语法”（unigram）、“二元语法”（bigram）和“三元语法”（trigram）模型。 下面，我们将学习如何去设计更好的模型</p><h3 id="自然语言统计"><a href="#自然语言统计" class="headerlink" title="自然语言统计"></a>自然语言统计</h3><p>自然语言中词频的分布是不均匀的，少部分的词会大量出现，而大部分的词出现的频率会比较少</p><p><img src="/archives/a67a203a/image-20211207164901392.png" style="zoom:80%;"></p><p> 这告诉我们想要通过计数统计和平滑来建模单词是不可行的， 因为这样建模的结果会大大高估尾部单词的频率，也就是所谓的不常用单词。那么其他的词元组合，比如二元语法、三元语法等等，又会如何呢？</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 二元语法示例</span>bigram_tokens <span class="token operator">=</span> <span class="token punctuation">[</span>pair <span class="token keyword">for</span> pair <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>corpus<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> corpus<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span>bigram_vocab <span class="token operator">=</span> d2l<span class="token punctuation">.</span>Vocab<span class="token punctuation">(</span>bigram_tokens<span class="token punctuation">)</span>bigram_vocab<span class="token punctuation">.</span>token_freqs<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">10</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/archives/a67a203a/image-20211207165753406.png" style="zoom:80%;"></p><p>这张图非常令人振奋！原因有很多： 首先，除了一元语法词，单词序列似乎也遵循齐普夫定律</p><script type="math/tex; mode=display">\begin{array}{c}n_{i} \propto \frac{1}{i^{\alpha}}, \\\log n_{i}=-\alpha \log i+c,\end{array}</script><p>其次，词表中 n 元组的数量并没有那么大，这说明语言中存在相当多的结构， 这些结构给了我们应用模型的希望</p><h3 id="读取长序列数据"><a href="#读取长序列数据" class="headerlink" title="读取长序列数据"></a>读取长序列数据</h3><p>假设我们将使用神经网络来训练语言模型， 模型中的网络一次处理具有预定义长度 （例如 n 个时间步）的一个小批量序列。 现在的问题是如何随机生成一个小批量数据的特征和标签以供读取</p><h4 id="随机采样"><a href="#随机采样" class="headerlink" title="随机采样"></a>随机采样</h4><p>在随机采样中，每个样本都是在原始的长序列上任意捕获的子序列</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">seq_data_iter_random</span><span class="token punctuation">(</span>corpus<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> num_steps<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment">#@save</span>    <span class="token triple-quoted-string string">"""使用随机抽样生成一个小批量子序列"""</span>    <span class="token comment"># 从随机偏移量开始对序列进行分区，随机范围包括`num_steps - 1`</span>    corpus <span class="token operator">=</span> corpus<span class="token punctuation">[</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> num_steps <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token punctuation">]</span>    <span class="token comment"># 减去1，是因为我们需要考虑标签</span>    num_subseqs <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>corpus<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">//</span> num_steps    <span class="token comment"># 长度为`num_steps`的子序列的起始索引</span>    initial_indices <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> num_subseqs <span class="token operator">*</span> num_steps<span class="token punctuation">,</span> num_steps<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment"># 在随机抽样的迭代过程中，</span>    <span class="token comment"># 来自两个相邻的、随机的、小批量中的子序列不一定在原始序列上相邻</span>    random<span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>initial_indices<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">data</span><span class="token punctuation">(</span>pos<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># 返回从`pos`位置开始的长度为`num_steps`的序列</span>        <span class="token keyword">return</span> corpus<span class="token punctuation">[</span>pos<span class="token punctuation">:</span> pos <span class="token operator">+</span> num_steps<span class="token punctuation">]</span>    num_batches <span class="token operator">=</span> num_subseqs <span class="token operator">//</span> batch_size    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> batch_size <span class="token operator">*</span> num_batches<span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># 在这里，`initial_indices`包含子序列的随机起始索引</span>        initial_indices_per_batch <span class="token operator">=</span> initial_indices<span class="token punctuation">[</span>i<span class="token punctuation">:</span> i <span class="token operator">+</span> batch_size<span class="token punctuation">]</span>        X <span class="token operator">=</span> <span class="token punctuation">[</span>data<span class="token punctuation">(</span>j<span class="token punctuation">)</span> <span class="token keyword">for</span> j <span class="token keyword">in</span> initial_indices_per_batch<span class="token punctuation">]</span>        Y <span class="token operator">=</span> <span class="token punctuation">[</span>data<span class="token punctuation">(</span>j <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token keyword">for</span> j <span class="token keyword">in</span> initial_indices_per_batch<span class="token punctuation">]</span>        <span class="token keyword">yield</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>Y<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="顺序分区"><a href="#顺序分区" class="headerlink" title="顺序分区"></a>顺序分区</h4><p>在迭代过程中，除了对原始序列可以随机抽样外， 我们还可以保证两个相邻的小批量中的子序列在原始序列上也是相邻的</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">seq_data_iter_sequential</span><span class="token punctuation">(</span>corpus<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> num_steps<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment">#@save</span>    <span class="token triple-quoted-string string">"""使用顺序分区生成一个小批量子序列"""</span>    <span class="token comment"># 从随机偏移量开始划分序列</span>    offset <span class="token operator">=</span> random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> num_steps<span class="token punctuation">)</span>    num_tokens <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>corpus<span class="token punctuation">)</span> <span class="token operator">-</span> offset <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">//</span> batch_size<span class="token punctuation">)</span> <span class="token operator">*</span> batch_size    Xs <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>corpus<span class="token punctuation">[</span>offset<span class="token punctuation">:</span> offset <span class="token operator">+</span> num_tokens<span class="token punctuation">]</span><span class="token punctuation">)</span>    Ys <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>corpus<span class="token punctuation">[</span>offset <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">:</span> offset <span class="token operator">+</span> <span class="token number">1</span> <span class="token operator">+</span> num_tokens<span class="token punctuation">]</span><span class="token punctuation">)</span>    Xs<span class="token punctuation">,</span> Ys <span class="token operator">=</span> Xs<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Ys<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>    num_batches <span class="token operator">=</span> Xs<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">//</span> num_steps    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> num_steps <span class="token operator">*</span> num_batches<span class="token punctuation">,</span> num_steps<span class="token punctuation">)</span><span class="token punctuation">:</span>        X <span class="token operator">=</span> Xs<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> i<span class="token punctuation">:</span> i <span class="token operator">+</span> num_steps<span class="token punctuation">]</span>        Y <span class="token operator">=</span> Ys<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> i<span class="token punctuation">:</span> i <span class="token operator">+</span> num_steps<span class="token punctuation">]</span>        <span class="token keyword">yield</span> X<span class="token punctuation">,</span> Y<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>从结果上直观感受一下顺序分区和随机采样的区别</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># my_seq = list(range(35))</span><span class="token comment"># 随机采样 batch_size=2, num_steps=5</span>X<span class="token punctuation">:</span>  tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">27</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">29</span><span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">,</span> <span class="token number">31</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">22</span><span class="token punctuation">,</span> <span class="token number">23</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">25</span><span class="token punctuation">,</span> <span class="token number">26</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>Y<span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">29</span><span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">,</span> <span class="token number">31</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">23</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">25</span><span class="token punctuation">,</span> <span class="token number">26</span><span class="token punctuation">,</span> <span class="token number">27</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>X<span class="token punctuation">:</span>  tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">17</span><span class="token punctuation">,</span> <span class="token number">18</span><span class="token punctuation">,</span> <span class="token number">19</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">21</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">13</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>Y<span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">18</span><span class="token punctuation">,</span> <span class="token number">19</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">21</span><span class="token punctuation">,</span> <span class="token number">22</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">13</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">17</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment"># 顺序分区</span>X<span class="token punctuation">:</span>  tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">3</span><span class="token punctuation">,</span>  <span class="token number">4</span><span class="token punctuation">,</span>  <span class="token number">5</span><span class="token punctuation">,</span>  <span class="token number">6</span><span class="token punctuation">,</span>  <span class="token number">7</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">18</span><span class="token punctuation">,</span> <span class="token number">19</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">21</span><span class="token punctuation">,</span> <span class="token number">22</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>Y<span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">4</span><span class="token punctuation">,</span>  <span class="token number">5</span><span class="token punctuation">,</span>  <span class="token number">6</span><span class="token punctuation">,</span>  <span class="token number">7</span><span class="token punctuation">,</span>  <span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">19</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">21</span><span class="token punctuation">,</span> <span class="token number">22</span><span class="token punctuation">,</span> <span class="token number">23</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>X<span class="token punctuation">:</span>  tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">8</span><span class="token punctuation">,</span>  <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">23</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">25</span><span class="token punctuation">,</span> <span class="token number">26</span><span class="token punctuation">,</span> <span class="token number">27</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>Y<span class="token punctuation">:</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">13</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token punctuation">[</span><span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">25</span><span class="token punctuation">,</span> <span class="token number">26</span><span class="token punctuation">,</span> <span class="token number">27</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="循环神经网络"><a href="#循环神经网络" class="headerlink" title="循环神经网络"></a>循环神经网络</h2><p>我们介绍了 n 元语法模型， 其中单词 $x_t$ 在时间步 t 的条件概率仅取决于前面 n−1 个单词。如果要增加 n，模型参数的数量也会随之呈指数增长，面临的次元组合数为 $|V|^n$</p><p>因此与其将 $P(x_t∣x_{t−1},…,x_{t−n+1})$ 模型化， 不如使用隐变量模型</p><script type="math/tex; mode=display">P\left(x_{t} \mid x_{t-1}, \ldots, x_{1}\right) \approx P\left(x_{t} \mid h_{t-1}\right)</script><p>其中 $h_{t−1}$ 是隐状态（hidden state）， 也称为隐藏变量（hidden variable）， 它存储了到时间步 t−1 的序列信息。 通常，我们可以基于当前输入和先前隐状态来计算时间步 t 处的任何时间的隐状态</p><script type="math/tex; mode=display">h_{t}=f\left(x_{t}, h_{t-1}\right)</script><h3 id="有隐状态的循环神经网络"><a href="#有隐状态的循环神经网络" class="headerlink" title="有隐状态的循环神经网络"></a>有隐状态的循环神经网络</h3><p>假设我们在时间步 t 有小批量输入 $X_t∈R^{n×d}$，与多层感知机不同的是， 我们在这里保存了前一个时间步的隐藏变量 $H_{t−1}$， 并引入了一个新的权重参数 $W_{hh}∈R^{h×h}$， 来描述如何在当前时间步中使用前一个时间步的隐藏变量。 具体地说，当前时间步隐藏变量由当前时间步的输入与前一个时间步的隐藏变量一起计算得出：</p><script type="math/tex; mode=display">\mathbf{H}_{t}=\phi\left(\mathbf{X}_{t} \mathbf{W}_{x h}+\mathbf{H}_{t-1} \mathbf{W}_{h h}+\mathbf{b}_{h}\right)</script><p>其中 $\phi$ 为激活函数。输出层的输出类似于多层感知机中的计算</p><script type="math/tex; mode=display">\mathbf{O}_{t}=\mathbf{H}_{t} \mathbf{W}_{h q}+\mathbf{b}_{q}</script><p><strong>值得一提的是，即使在不同的时间步，循环神经网络也总是使用这些模型参数</strong>。 因此，循环神经网络的参数开销不会随着时间步的增加而增加，下面来看一下图示对整个计算过程有更清晰的认识</p><p><img src="/archives/a67a203a/image-20211208212259258.png" style="zoom:80%;"></p><h3 id="困惑度（Perplexity）"><a href="#困惑度（Perplexity）" class="headerlink" title="困惑度（Perplexity）"></a>困惑度（Perplexity）</h3><p>在训练过程中，我们对每个时间步的输出层的输出进行softmax操作， 然后利用交叉熵损失计算模型输出和标签之间的误差</p><script type="math/tex; mode=display">\frac{1}{n} \sum_{t=1}^{n}-\log P\left(x_{t} \mid x_{t-1}, \ldots, x_{1}\right)</script><p>由于历史原因，自然语言处理的科学家更喜欢使用一个叫做困惑度（perplexity）的量，它是上式的指数</p><script type="math/tex; mode=display">exp(\frac{1}{n} \sum_{t=1}^{n}-\log P\left(x_{t} \mid x_{t-1}, \ldots, x_{1}\right))</script><h2 id="循环神经网络的从零实现"><a href="#循环神经网络的从零实现" class="headerlink" title="循环神经网络的从零实现"></a>循环神经网络的从零实现</h2><p>这里仅记录一些值得注意的知识点，详细的从零实现不做笔记</p><h3 id="One-hot-编码"><a href="#One-hot-编码" class="headerlink" title="One-hot 编码"></a>One-hot 编码</h3><p>每个词元都表示为一个数字索引， 将这些索引直接输入神经网络可能会使学习变得困难。 我们通常将每个词元表示为更具表现力的特征向量。 最简单的表示称为独热编码（one-hot encoding）</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">F<span class="token punctuation">.</span>one_hot<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>vocab<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>我们每次采样的小批量数据形状是二维张量： （批量大小，时间步数）。 <code>one_hot</code>函数将这样一个小批量数据转换成三维张量， 张量的最后一个维度等于词表大小 <code>len(vocab)</code></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">X <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>F<span class="token punctuation">.</span>one_hot<span class="token punctuation">(</span>X<span class="token punctuation">.</span>T<span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token comment"># torch.Size([5, 2, 28])</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="预测-1"><a href="#预测-1" class="headerlink" title="预测"></a>预测</h3><p>让我们首先定义预测函数来生成 <code>prefix</code> 之后的新字符， 其中的 <code>prefix</code> 是一个用户提供的包含多个字符的字符串。 在循环遍历 <code>prefix</code> 中的开始字符时， 我们不断地将隐状态传递到下一个时间步，但是不生成任何输出。 这被称为预热（warm-up）期， 因为在此期间模型会自我更新（例如，更新隐状态）， 但不会进行预测。 预热期结束后，隐状态的值通常比刚开始的初始值更适合预测， 从而预测字符并输出它们</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">predict_ch8</span><span class="token punctuation">(</span>prefix<span class="token punctuation">,</span> num_preds<span class="token punctuation">,</span> net<span class="token punctuation">,</span> vocab<span class="token punctuation">,</span> device<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment">#@save</span>    <span class="token triple-quoted-string string">"""在prefix后面生成新字符"""</span>    state <span class="token operator">=</span> net<span class="token punctuation">.</span>begin_state<span class="token punctuation">(</span>batch_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> ctx<span class="token operator">=</span>device<span class="token punctuation">)</span>    outputs <span class="token operator">=</span> <span class="token punctuation">[</span>vocab<span class="token punctuation">[</span>prefix<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span>    get_input <span class="token operator">=</span> <span class="token keyword">lambda</span><span class="token punctuation">:</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span>outputs<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> ctx<span class="token operator">=</span>device<span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> y <span class="token keyword">in</span> prefix<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">:</span>  <span class="token comment"># 预热期</span>        _<span class="token punctuation">,</span> state <span class="token operator">=</span> net<span class="token punctuation">(</span>get_input<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> state<span class="token punctuation">)</span><span class="token comment"># 不关心输出，只关心隐状态</span>        outputs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>vocab<span class="token punctuation">[</span>y<span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_preds<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># 预测num_preds步</span>        y<span class="token punctuation">,</span> state <span class="token operator">=</span> net<span class="token punctuation">(</span>get_input<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> state<span class="token punctuation">)</span>        outputs<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">(</span>y<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> <span class="token string">''</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token punctuation">[</span>vocab<span class="token punctuation">.</span>idx_to_token<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> outputs<span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="梯度剪裁"><a href="#梯度剪裁" class="headerlink" title="梯度剪裁"></a>梯度剪裁</h3><p>对于长度为 T 的序列，我们在迭代中计算这 T 个时间步上的梯度， 将会在反向传播过程中产生长度为 O(T) 的矩阵乘法链，当 T 较大时，它可能导致数值不稳定， 例如可能导致梯度爆炸或梯度消失。对于梯度爆炸， 一个流行的替代方案是通过将梯度gg投影回给定半径 （例如 θ）的球来裁剪梯度 g。 如下式</p><script type="math/tex; mode=display">\mathbf{g} \leftarrow \min \left(1, \frac{\theta}{\|\mathbf{g}\|}\right) \mathbf{g}</script><h3 id="训练-1"><a href="#训练-1" class="headerlink" title="训练"></a>训练</h3><p>循环神经网络的训练与普通的神经网络训练有几点不同：</p><ol><li>序列数据的不同采样方法（随机采样和顺序分区）将导致隐状态初始化的差异</li><li>我们在更新模型参数之前裁剪梯度。 这样的操作的目的是：即使训练过程中某个点上发生了梯度爆炸，也能保证模型不会发散</li><li>我们用困惑度来评价模型</li></ol><p>需要注意的是隐状态的传递会导致梯度链的增长，这带来的好处是历史信息的传递，带来的坏处是过长的计算图使得梯度计算变得复杂，下面是教材中的原话：</p><blockquote><p>具体来说，当使用顺序分区时， 我们只在每个迭代周期（epoch）的开始位置初始化隐状态。 由于下一个小批量数据中的第 i 个子序列样本与当前第 i 个子序列样本相邻， 因此当前小批量数据最后一个样本的隐状态， 将用于初始化下一个小批量数据第一个样本的隐状态。 这样，存储在隐状态中的序列的历史信息可以在一个迭代周期内流经相邻的子序列。 然而，在任何一点隐状态的计算， 都依赖于同一迭代周期中前面所有的小批量数据， 这使得梯度计算变得复杂。 为了降低计算量，在处理任何一个小批量数据之前（iteration）， 我们先分离梯度，使得隐状态的梯度计算总是限制在一个小批量数据的时间步内</p></blockquote><p>解决方式就是在每个 iteration 前，把隐状态作从计算图中分离 detach_，也就是将其看作一个常数输入，下面是训练的代码</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#@save</span><span class="token keyword">def</span> <span class="token function">train_epoch_ch8</span><span class="token punctuation">(</span>net<span class="token punctuation">,</span> train_iter<span class="token punctuation">,</span> loss<span class="token punctuation">,</span> updater<span class="token punctuation">,</span> device<span class="token punctuation">,</span> use_random_iter<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""训练网络一个迭代周期（定义见第8章）"""</span>    state<span class="token punctuation">,</span> timer <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span> d2l<span class="token punctuation">.</span>Timer<span class="token punctuation">(</span><span class="token punctuation">)</span>    metric <span class="token operator">=</span> d2l<span class="token punctuation">.</span>Accumulator<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>  <span class="token comment"># 训练损失之和,词元数量</span>    <span class="token keyword">for</span> X<span class="token punctuation">,</span> Y <span class="token keyword">in</span> train_iter<span class="token punctuation">:</span>        <span class="token keyword">if</span> state <span class="token keyword">is</span> <span class="token boolean">None</span> <span class="token keyword">or</span> use_random_iter<span class="token punctuation">:</span>            <span class="token comment"># 在第一次迭代或使用随机抽样时初始化state</span>            state <span class="token operator">=</span> net<span class="token punctuation">.</span>begin_state<span class="token punctuation">(</span>batch_size<span class="token operator">=</span>X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>net<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span> <span class="token keyword">and</span> <span class="token keyword">not</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>state<span class="token punctuation">,</span> <span class="token builtin">tuple</span><span class="token punctuation">)</span><span class="token punctuation">:</span>                <span class="token comment"># state对于nn.GRU是个张量</span>                state<span class="token punctuation">.</span>detach_<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token keyword">else</span><span class="token punctuation">:</span>                <span class="token comment"># state对于nn.LSTM或对于我们从零开始实现的模型是个元组</span>                <span class="token keyword">for</span> s <span class="token keyword">in</span> state<span class="token punctuation">:</span>                    s<span class="token punctuation">.</span>detach_<span class="token punctuation">(</span><span class="token punctuation">)</span>        y <span class="token operator">=</span> Y<span class="token punctuation">.</span>T<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>        X<span class="token punctuation">,</span> y <span class="token operator">=</span> X<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>        y_hat<span class="token punctuation">,</span> state <span class="token operator">=</span> net<span class="token punctuation">(</span>X<span class="token punctuation">,</span> state<span class="token punctuation">)</span>        l <span class="token operator">=</span> loss<span class="token punctuation">(</span>y_hat<span class="token punctuation">,</span> y<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>updater<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Optimizer<span class="token punctuation">)</span><span class="token punctuation">:</span>            updater<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>            l<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>            grad_clipping<span class="token punctuation">(</span>net<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>            updater<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            l<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>            grad_clipping<span class="token punctuation">(</span>net<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>            <span class="token comment"># 因为已经调用了mean函数</span>            updater<span class="token punctuation">(</span>batch_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        metric<span class="token punctuation">.</span>add<span class="token punctuation">(</span>l <span class="token operator">*</span> y<span class="token punctuation">.</span>numel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>numel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> math<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>metric<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">/</span> metric<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> metric<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">/</span> timer<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="循环神经网络的简洁实现"><a href="#循环神经网络的简洁实现" class="headerlink" title="循环神经网络的简洁实现"></a>循环神经网络的简洁实现</h2><h3 id="定义模型"><a href="#定义模型" class="headerlink" title="定义模型"></a>定义模型</h3><p>高级API提供了循环神经网络的实现。 我们构造一个具有256个隐藏单元的单隐藏层的循环神经网络层 <code>rnn_layer</code>。 事实上，我们还没有讨论多层循环神经网络的意义</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> functional <span class="token keyword">as</span> F<span class="token keyword">from</span> d2l <span class="token keyword">import</span> torch <span class="token keyword">as</span> d2lbatch_size<span class="token punctuation">,</span> num_steps <span class="token operator">=</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">35</span>train_iter<span class="token punctuation">,</span> vocab <span class="token operator">=</span> d2l<span class="token punctuation">.</span>load_data_time_machine<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> num_steps<span class="token punctuation">)</span>num_hiddens <span class="token operator">=</span> <span class="token number">256</span><span class="token comment"># 可以看到 rnn_layer 的定义是不需要时间步的，应该是在输入数据上进行定义</span><span class="token comment"># 这里应该能体会到“循环”的感觉了，即数据不断地流入流出同一个网络</span>rnn_layer <span class="token operator">=</span> nn<span class="token punctuation">.</span>RNN<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>vocab<span class="token punctuation">)</span><span class="token punctuation">,</span> num_hiddens<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>我们使用张量来初始化隐状态，它的形状是（隐藏层数，批量大小，隐藏单元数）</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">state <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> num_hiddens<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># [1, 32, 256]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>通过一个隐状态和一个输入，我们就可以用更新后的隐状态计算输出。 需要强调的是，<code>rnn_layer</code>的“输出”（<code>Y</code>）不涉及输出层的计算： 它是指每个时间步的隐状态，这些隐状态可以用作后续输出层的输入</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 区别于卷积神经网络把 batch_size 的维度放在第一个，rnn 的输入将时间步维度放在第一个</span>X <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">(</span>num_steps<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>vocab<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>Y<span class="token punctuation">,</span> state_new <span class="token operator">=</span> rnn_layer<span class="token punctuation">(</span>X<span class="token punctuation">,</span> state<span class="token punctuation">)</span><span class="token comment"># Y.shape = [35, 32, 256]</span><span class="token comment"># state_new.shape = [1, 32, 256] 是 Y 的组后一个输出，即：Y[34] or Y[num_steps-1]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>rnn_layer</code>只包含隐藏的循环层，我们还需要创建一个单独的输出层，这里用 <code>nn.Linear(num_hidden, len(vocab))</code> 实现，下面完整实现</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#@save</span><span class="token keyword">class</span> <span class="token class-name">RNNModel</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""循环神经网络模型"""</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> rnn_layer<span class="token punctuation">,</span> vocab_size<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>RNNModel<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>rnn <span class="token operator">=</span> rnn_layer        self<span class="token punctuation">.</span>vocab_size <span class="token operator">=</span> vocab_size        self<span class="token punctuation">.</span>num_hiddens <span class="token operator">=</span> self<span class="token punctuation">.</span>rnn<span class="token punctuation">.</span>hidden_size        <span class="token comment"># 如果RNN是双向的（之后将介绍），num_directions应该是2，否则应该是1</span>        <span class="token keyword">if</span> <span class="token keyword">not</span> self<span class="token punctuation">.</span>rnn<span class="token punctuation">.</span>bidirectional<span class="token punctuation">:</span>            self<span class="token punctuation">.</span>num_directions <span class="token operator">=</span> <span class="token number">1</span>            self<span class="token punctuation">.</span>linear <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_hiddens<span class="token punctuation">,</span> self<span class="token punctuation">.</span>vocab_size<span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            self<span class="token punctuation">.</span>num_directions <span class="token operator">=</span> <span class="token number">2</span>            self<span class="token punctuation">.</span>linear <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_hiddens <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>vocab_size<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs<span class="token punctuation">,</span> state<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># input.shape = (batch_size, num_steps) 需要转置一下并生成 onehot 特征</span>        X <span class="token operator">=</span> F<span class="token punctuation">.</span>one_hot<span class="token punctuation">(</span>inputs<span class="token punctuation">.</span>T<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>vocab_size<span class="token punctuation">)</span>        X <span class="token operator">=</span> X<span class="token punctuation">.</span>to<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>        Y<span class="token punctuation">,</span> state <span class="token operator">=</span> self<span class="token punctuation">.</span>rnn<span class="token punctuation">(</span>X<span class="token punctuation">,</span> state<span class="token punctuation">)</span>        <span class="token comment"># 全连接层首先将Y的形状改为(时间步数*批量大小,隐藏单元数)</span>        <span class="token comment"># 它的输出形状是(时间步数*批量大小,词表大小)。</span>        output <span class="token operator">=</span> self<span class="token punctuation">.</span>linear<span class="token punctuation">(</span>Y<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> Y<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> output<span class="token punctuation">,</span> state    <span class="token keyword">def</span> <span class="token function">begin_state</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> device<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> <span class="token keyword">not</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>rnn<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>LSTM<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token comment"># nn.GRU以张量作为隐状态</span>            <span class="token keyword">return</span>  torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_directions <span class="token operator">*</span> self<span class="token punctuation">.</span>rnn<span class="token punctuation">.</span>num_layers<span class="token punctuation">,</span>                                 batch_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_hiddens<span class="token punctuation">)</span><span class="token punctuation">,</span>                                device<span class="token operator">=</span>device<span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            <span class="token comment"># nn.LSTM以元组作为隐状态</span>            <span class="token keyword">return</span> <span class="token punctuation">(</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>                self<span class="token punctuation">.</span>num_directions <span class="token operator">*</span> self<span class="token punctuation">.</span>rnn<span class="token punctuation">.</span>num_layers<span class="token punctuation">,</span>                batch_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_hiddens<span class="token punctuation">)</span><span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span>                    torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>                        self<span class="token punctuation">.</span>num_directions <span class="token operator">*</span> self<span class="token punctuation">.</span>rnn<span class="token punctuation">.</span>num_layers<span class="token punctuation">,</span>                        batch_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_hiddens<span class="token punctuation">)</span><span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="通过时间反向传播"><a href="#通过时间反向传播" class="headerlink" title="通过时间反向传播"></a>通过时间反向传播</h2><p>这一节详细为了计算循环神经网络的梯度，向我们展示了循环神经网络中存在的梯度数值不稳定</p><h3 id="梯度策略"><a href="#梯度策略" class="headerlink" title="梯度策略"></a>梯度策略</h3><p>教材提到了三种策略：随机阶段，常规截断，完整计算</p><p><img src="/archives/a67a203a/image-20211209164325936.png" style="zoom:80%;"></p><ul><li>第一行采用随机截断，方法是将文本划分为不同长度的片断</li><li>第二行采用常规截断，方法是将文本分解为相同长度的子序列。 这也是教材在循环神经网络实验中一直在做的，具体来说就是使用 <code>detach_()</code> 方法将每一个 iteration 输入的初始隐状态从计算图中分离开</li><li>第三行采用通过时间的完全反向传播，结果是产生了在计算上不可行的表达式（迭代链很长，计算复杂）</li></ul><p>遗憾的是，虽然随机截断在理论上具有吸引力， 但很可能是由于多种因素在实践中并不比常规截断更好</p><h3 id="反向传播细节"><a href="#反向传播细节" class="headerlink" title="反向传播细节"></a>反向传播细节</h3><p>首先写每个时间步的方程</p><script type="math/tex; mode=display">\begin{array}{l}\mathbf{h}_{t}=\mathbf{W}_{h x} \mathbf{x}_{t}+\mathbf{W}_{h h} \mathbf{h}_{t-1}, \\\mathbf{o}_{t}=\mathbf{W}_{q h} \mathbf{h}_{t},\end{array}</script><p>写出损失函数</p><script type="math/tex; mode=display">L=\frac{1}{T} \sum_{t=1}^{T} l\left(\mathbf{o}_{t}, y_{t}\right)</script><p>画出计算图</p><p><img src="/archives/a67a203a/image-20211209171043562.png" style="zoom:80%;"></p><p>在任意时间步tt， 目标函数关于模型输出的微分计算是相当简单的</p><script type="math/tex; mode=display">\frac{\partial L}{\partial \mathbf{o}_{t}}=\frac{\partial l\left(\mathbf{o}_{t}, y_{t}\right)}{T \cdot \partial \mathbf{o}_{t}} \in \mathbb{R}^{q}</script><p>现在，我们可以计算目标函数关于输出层中参数 $W_{qh}$ 的梯度</p><script type="math/tex; mode=display">\frac{\partial L}{\partial \mathbf{W}_{q h}}=\sum_{t=1}^{T} \operatorname{prod}\left(\frac{\partial L}{\partial \mathbf{o}_{t}}, \frac{\partial \mathbf{o}_{t}}{\partial \mathbf{W}_{q h}}\right)=\sum_{t=1}^{T} \frac{\partial L}{\partial \mathbf{o}_{t}} \mathbf{h}_{t}^{\top},</script><p>根据计算图，要计算关于隐状态的梯度。我们不能够同时得到所有时间步的梯度，而是从最后一个时间步 T 倒推</p><script type="math/tex; mode=display">\frac{\partial L}{\partial \mathbf{h}_{T}}=\operatorname{prod}\left(\frac{\partial L}{\partial \mathbf{o}_{T}}, \frac{\partial \mathbf{o}_{T}}{\partial \mathbf{h}_{T}}\right)=\mathbf{W}_{q h}^{\top} \frac{\partial L}{\partial \mathbf{o}_{T}}</script><p>进行迭代计算，最终得到所有时间步的表达式</p><script type="math/tex; mode=display">\frac{\partial L}{\partial \mathbf{h}_{t}}=\operatorname{prod}\left(\frac{\partial L}{\partial \mathbf{h}_{t+1}}, \frac{\partial \mathbf{h}_{t+1}}{\partial \mathbf{h}_{t}}\right)+\operatorname{prod}\left(\frac{\partial L}{\partial \mathbf{o}_{t}}, \frac{\partial \mathbf{o}_{t}}{\partial \mathbf{h}_{t}}\right)=\mathbf{W}_{h h}^{\top} \frac{\partial L}{\partial \mathbf{h}_{t+1}}+\mathbf{W}_{q h}^{\top} \frac{\partial L}{\partial \mathbf{o}_{t}}</script><p>为了进行分析，对于任何时间步 1≤t≤T 展开递归计算得</p><script type="math/tex; mode=display">\frac{\partial L}{\partial \mathbf{h}_{t}}=\sum_{i=t}^{T}\left(\mathbf{W}_{h h}^{\top}\right)^{T-i} \mathbf{W}_{q h}^{\top} \frac{\partial L}{\partial \mathbf{o}_{T+t-i}}</script><p>这个简单的线性例子已经展现了长序列模型的一些关键问题： 由于连续矩阵相乘，它可能陷入到潜在的非常大的幂。 这在数值上是不稳定的，表现形式为梯度消失或梯度爆炸，解决方法通常为梯度截断，或者使用（在之后学习的）更复杂的序列模型，如：LSTM/GRU</p><p>最后我们得到权重矩阵的梯度</p><script type="math/tex; mode=display">\begin{array}{c}\frac{\partial L}{\partial \mathbf{W}_{h x}}=\sum_{t=1}^{T} \operatorname{prod}\left(\frac{\partial L}{\partial \mathbf{h}_{t}}, \frac{\partial \mathbf{h}_{t}}{\partial \mathbf{W}_{h x}}\right)=\sum_{t=1}^{T} \frac{\partial L}{\partial \mathbf{h}_{t}} \mathbf{x}_{t}^{\top}, \\\frac{\partial L}{\partial \mathbf{W}_{h h}}=\sum_{t=1}^{T} \operatorname{prod}\left(\frac{\partial L}{\partial \mathbf{h}_{t}}, \frac{\partial \mathbf{h}_{t}}{\partial \mathbf{W}_{h h}}\right)=\sum_{t=1}^{T} \frac{\partial L}{\partial \mathbf{h}_{t}} \mathbf{h}_{t-1}^{\top},\end{array}</script>]]></content>
      
      
      <categories>
          
          <category> 课程 </category>
          
          <category> Dive into deep learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Dive into deep learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>D2L 07 现代卷积神经网络</title>
      <link href="/archives/d08db5b4.html"/>
      <url>/archives/d08db5b4.html</url>
      
        <content type="html"><![CDATA[<h1 id="D2L-07-现代卷积神经网络"><a href="#D2L-07-现代卷积神经网络" class="headerlink" title="D2L 07 现代卷积神经网络"></a>D2L 07 现代卷积神经网络</h1><p>虽然深度神经网络的概念非常简单——将神经网络堆叠在一起。但由于不同的网络结构和超参数选择，这些神经网络的性能会发生很大变化。 本章介绍的神经网络是将人类直觉和相关数学见解结合后，经过大量研究试错后的结晶。 我们会按时间顺序介绍这些模型，<strong>在追寻历史的脉络的同时，帮助你培养对该领域发展的直觉</strong>。这将有助于你研究开发自己的结构。 例如，本章介绍的批量归一化（batch normalization）和残差网络（ResNet）为设计和训练深度神经网络提供了重要思想指导</p><h2 id="一点历史"><a href="#一点历史" class="headerlink" title="一点历史"></a>一点历史</h2><p>在传统机器学习方法中，计算机视觉流水线是由经过人的手工精心设计的特征流水线组成的（SIFT, SURF, HOG）。将提取的特征放到最喜欢的分类器中（例如线性模型或其它核方法），以训练分类器</p><p>对于这些传统方法，大部分的进展都来自于对特征有了更聪明的想法，并且学习到的算法往往归于事后的解释</p><p>机器学习是一个正在蓬勃发展、严谨且非常有用的领域。然而，如果你和计算机视觉研究人员交谈，<strong>他们会告诉你图像识别的诡异事实——推动领域进步的是数据特征，而不是学习算法</strong>。计算机视觉研究人员相信，从对最终模型精度的影响来说，更大或更干净的数据集、或是稍微改进的特征提取，比任何学习算法带来的进步要大得多</p><p>一组研究人员，包括 Yann LeCun, Geoff Hinton, Yoshua Bengio, Andrew Ng, Shun ichi Amari 和 Juergen Schmidhuber，他们认为特征本身应该被学习</p><p>深度卷积神经网络的突破出现在2012年。突破可归因于两个关键因素：</p><ol><li>数据：包含许多特征的深度模型需要大量的有标签数据，才能显著优于基于凸优化的传统方法</li><li>GPU：并行计算以及高内存带宽实现快速卷积运算</li></ol><h2 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h2><p>2012年，AlexNet 横空出世。它首次证明了学习到的特征可以超越手工设计的特征。AlexNet 使用了8层卷积神经网络，并以很大的优势赢得了2012年 ImageNet (224x224) 图像识别挑战赛</p><p>有趣的是，在网络的最底层，AlexNet 学习到了一些类似于传统滤波器的特征抽取器。AlexNet 的更高层建立在这些底层表示的基础上，以表示更大的特征</p><p>尽管一直有一群执着的研究者不断钻研，试图学习视觉数据的逐级表征，然而很长一段时间里这些尝试都未有突破</p><h3 id="AlexNet-amp-LeNet"><a href="#AlexNet-amp-LeNet" class="headerlink" title="AlexNet &amp; LeNet"></a>AlexNet &amp; LeNet</h3><p><img src="/archives/d08db5b4/image-20211128151502022.png" style="zoom:80%;"></p><p>AlexNet和LeNet的设计理念非常相似，但也存在一些差异，除了层数更深，通道更多，其他关键的改变还有：</p><ol><li>激活函数从 sigmoid 改为 ReLU</li><li>使用了 dropout 正则化</li><li>使用了数据增强</li></ol><p>下面看看模型的代码</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">from</span> torch <span class="token keyword">import</span> nnnet <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>    <span class="token comment"># 这里，我们使用一个11*11的更大窗口来捕捉对象。</span>    <span class="token comment"># 同时，步幅为4，以减少输出的高度和宽度。</span>    <span class="token comment"># 另外，输出通道的数目远大于LeNet</span>    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">96</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">11</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token comment"># 减小卷积窗口，使用填充为2来使得输入与输出的高和宽一致，且增大输出通道数</span>    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">96</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token comment"># 使用三个连续的卷积层和较小的卷积窗口。</span>    <span class="token comment"># 除了最后的卷积层，输出通道的数量进一步增加。</span>    <span class="token comment"># 在前两个卷积层之后，汇聚层不用于减少输入的高度和宽度</span>    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">384</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">384</span><span class="token punctuation">,</span> <span class="token number">384</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">384</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token comment"># 这里，全连接层的输出数量是LeNet中的好几倍。使用dropout层来减轻过度拟合</span>    nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">6400</span><span class="token punctuation">,</span> <span class="token number">4096</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>p<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">4096</span><span class="token punctuation">,</span> <span class="token number">4096</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>p<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token comment"># 最后是输出层。由于这里使用Fashion-MNIST，所以用类别数为10，而非论文中的1000</span>    nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">4096</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>今天，AlexNet已经被更有效的结构所超越，但它是从浅层网络到深层网络的关键一步。尽管AlexNet的代码只比LeNet多出几行，但学术界花了很多年才接受深度学习这一概念，并应用其出色的实验结果</p><h2 id="VGG"><a href="#VGG" class="headerlink" title="VGG"></a>VGG</h2><p>VGG 让网络的结构更加模块化，下面我们定义一个 vgg_block 来实现一个组合：Convolution + Activation + Pooling</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token keyword">def</span> <span class="token function">vgg_block</span><span class="token punctuation">(</span>num_convs<span class="token punctuation">,</span> in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">)</span><span class="token punctuation">:</span>    layers <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_convs<span class="token punctuation">)</span><span class="token punctuation">:</span>        layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span>                                kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        in_channels <span class="token operator">=</span> out_channels    layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span>layers<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>利用定义好的模块和各种超参数，搭建 VGG 网络</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 定义 (num_conv, out_channels)</span>conv_arch <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">vgg</span><span class="token punctuation">(</span>conv_arch<span class="token punctuation">)</span><span class="token punctuation">:</span>    conv_blks <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    in_channels <span class="token operator">=</span> <span class="token number">1</span>    <span class="token comment"># 卷积层部分</span>    <span class="token keyword">for</span> <span class="token punctuation">(</span>num_convs<span class="token punctuation">,</span> out_channels<span class="token punctuation">)</span> <span class="token keyword">in</span> conv_arch<span class="token punctuation">:</span>        conv_blks<span class="token punctuation">.</span>append<span class="token punctuation">(</span>vgg_block<span class="token punctuation">(</span>num_convs<span class="token punctuation">,</span> in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">)</span><span class="token punctuation">)</span>        in_channels <span class="token operator">=</span> out_channels    <span class="token keyword">return</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>        <span class="token operator">*</span>conv_blks<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token comment"># 全连接层部分</span>        nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>out_channels <span class="token operator">*</span> <span class="token number">7</span> <span class="token operator">*</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">4096</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">4096</span><span class="token punctuation">,</span> <span class="token number">4096</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">4096</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>net <span class="token operator">=</span> vgg<span class="token punctuation">(</span>conv_arch<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在 VGG 论文中，Simonyan 和 Ziserman 尝试了各种架构。特别是他们发现深层且窄的卷积（即3×3）比较浅层且宽的卷积更有效</p><h2 id="NiN"><a href="#NiN" class="headerlink" title="NiN"></a>NiN</h2><p>全连接层的输入和输出通常是分别对应于样本和特征的二维张量，这个参数数量相比卷积核是非常大的，NiN 和 AlexNet 之间的一个显著区别是 NiN 完全取消了全连接层。NiN 的想法是在每个像素位置（针对每个高度和宽度）应用一个 1x1 的卷积（可视为像素级全连接层）以替代全连接层，下面直接上图示和代码</p><p><img src="/archives/d08db5b4/image-20211128165154091.png" style="zoom:80%;"></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token keyword">def</span> <span class="token function">nin_block</span><span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> kernel_size<span class="token punctuation">,</span> strides<span class="token punctuation">,</span> padding<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>        nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> kernel_size<span class="token punctuation">,</span> strides<span class="token punctuation">,</span> padding<span class="token punctuation">)</span><span class="token punctuation">,</span>        nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>out_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>out_channels<span class="token punctuation">,</span> out_channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>    nin_block<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">96</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">11</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nin_block<span class="token punctuation">(</span><span class="token number">96</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nin_block<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">384</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token comment"># 标签类别数是10</span>    nin_block<span class="token punctuation">(</span><span class="token number">384</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token comment"># 最后放一个 全局平均汇聚层（global average pooling layer），生成一个多元逻辑向量（logits）</span>    <span class="token comment"># 将四维的输出转成二维的输出，其形状为(批量大小, 10)</span>    nn<span class="token punctuation">.</span>AdaptiveAvgPool2d<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>NiN 设计的优点是，它显著减少了模型所需参数的数量，这也减少了过拟合。然而，在实践中，这种设计有时会增加训练模型的时间</p><h2 id="GoogLeNet"><a href="#GoogLeNet" class="headerlink" title="GoogLeNet"></a>GoogLeNet</h2><p>在 GoogLeNet 中，基本的卷积块被称为 Inception 块（Inception block）论文的一个观点是，有时使用不同大小的卷积核组合是有利的。其中 Google 中的 L 为大写，以致敬 LeNet </p><p><img src="/archives/d08db5b4/image-20211128173254328.png" style="zoom:80%;"></p><p>这四条路径都使用合适的填充来使输入与输出的高和宽一致，最后我们将每条线路的输出在通道维度上连结，并构成 Inception 块的输出。在 Inception 块中，通常调整的超参数是每层输出通道的数量（很难调，这也是 GoogLeNet 难以复现的原因之一）。下面是  Inception 块的代码</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> functional <span class="token keyword">as</span> F<span class="token keyword">class</span> <span class="token class-name">Inception</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># `c1`--`c4` 是每条路径的输出通道数</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_channels<span class="token punctuation">,</span> c1<span class="token punctuation">,</span> c2<span class="token punctuation">,</span> c3<span class="token punctuation">,</span> c4<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span>Inception<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span>        <span class="token comment"># 线路1，单1 x 1卷积层</span>        self<span class="token punctuation">.</span>p1_1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> c1<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        <span class="token comment"># 线路2，1 x 1卷积层后接3 x 3卷积层</span>        self<span class="token punctuation">.</span>p2_1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> c2<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>p2_2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>c2<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c2<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        <span class="token comment"># 线路3，1 x 1卷积层后接5 x 5卷积层</span>        self<span class="token punctuation">.</span>p3_1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> c3<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>p3_2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>c3<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c3<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>        <span class="token comment"># 线路4，3 x 3最大汇聚层后接1 x 1卷积层</span>        self<span class="token punctuation">.</span>p4_1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>p4_2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token punctuation">,</span> c4<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        p1 <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>p1_1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>        p2 <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>p2_2<span class="token punctuation">(</span>F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>p2_1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        p3 <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>p3_2<span class="token punctuation">(</span>F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>p3_1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        p4 <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>p4_2<span class="token punctuation">(</span>self<span class="token punctuation">.</span>p4_1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment"># 在通道维度上连结输出</span>        <span class="token keyword">return</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>p1<span class="token punctuation">,</span> p2<span class="token punctuation">,</span> p3<span class="token punctuation">,</span> p4<span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>整个模型图示</p><p><img src="/archives/d08db5b4/image-20211128173520258.png" style="zoom:80%;"></p><p>Inception 块之间的最大汇聚层可降低维度，1x1 卷积块的作用之一就是维度转换，这样可以通过减少通道数降低网络参数</p><h2 id="Batch-Normalization"><a href="#Batch-Normalization" class="headerlink" title="Batch Normalization"></a>Batch Normalization</h2><p><strong>这是一种流行且有效的技术，可持续加速深层网络的收敛速度</strong>，直观形式是：控制每一层的输出分布。现在具体来看批量归一化（batch normalization）的形式，用 $x∈\mathcal B$ 表示一个来自小批量的输入</p><script type="math/tex; mode=display">\mathrm{BN}(\mathbf{x})=\gamma \odot \frac{\mathbf{x}-\hat{\boldsymbol{\mu}}_{\mathcal{B}}}{\hat{\boldsymbol{\sigma}}_{\mathcal{B}}}+\boldsymbol{\beta}\\\begin{aligned}\hat{\boldsymbol{\mu}}_{\mathcal{B}} &=\frac{1}{|\mathcal{B}|} \sum_{\mathbf{x} \in \mathcal{B}} \mathbf{x} \\\hat{\boldsymbol{\sigma}}_{\mathcal{B}}^{2} &=\frac{1}{|\mathcal{B}|} \sum_{\mathbf{x} \in \mathcal{B}}\left(\mathbf{x}-\hat{\boldsymbol{\mu}}_{\mathcal{B}}\right)^{2}+\epsilon\end{aligned}</script><p>应用标准化后，生成的小批量的平均值为0和单位方差为1，$\gamma, \beta$ 是需要学习的参数，通常被认为是拉伸参数和偏移参数，$\epsilon$ 为一个小量以确保不除以零</p><h3 id="批量归一化层"><a href="#批量归一化层" class="headerlink" title="批量归一化层"></a>批量归一化层</h3><p>批量归一化是一种线性变换，通常作用在输出和激活函数之间，对于全连接层和卷积层的批量归一化略有不同（<a href="https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html">BatchNorm1d</a>-&gt;<a href="https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html#torch.nn.BatchNorm2d">BatchNorm2d</a>）</p><p>批量归一化也可以看作一种正则化技术，它在训练和测试阶段的表现是不一样的。通常在预测阶段，通过移动平均估算整个训练数据集的样本均值和方差，并在预测时使用它们以替代训练过程中的小批量均值和方差</p><h3 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h3><p>教材给出了一个从零实现版本</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token keyword">def</span> <span class="token function">batch_norm</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> gamma<span class="token punctuation">,</span> beta<span class="token punctuation">,</span> moving_mean<span class="token punctuation">,</span> moving_var<span class="token punctuation">,</span> eps<span class="token punctuation">,</span> momentum<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># 通过 `is_grad_enabled` 来判断当前模式是训练模式还是预测模式</span>    <span class="token keyword">if</span> <span class="token keyword">not</span> torch<span class="token punctuation">.</span>is_grad_enabled<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># 如果是在预测模式下，直接使用传入的移动平均所得的均值和方差</span>        X_hat <span class="token operator">=</span> <span class="token punctuation">(</span>X <span class="token operator">-</span> moving_mean<span class="token punctuation">)</span> <span class="token operator">/</span> torch<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>moving_var <span class="token operator">+</span> eps<span class="token punctuation">)</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        <span class="token keyword">assert</span> <span class="token builtin">len</span><span class="token punctuation">(</span>X<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>X<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">2</span><span class="token punctuation">:</span>            <span class="token comment"># 使用全连接层的情况，计算特征维上的均值和方差</span>            mean <span class="token operator">=</span> X<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>            var <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>X <span class="token operator">-</span> mean<span class="token punctuation">)</span> <span class="token operator">**</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            <span class="token comment"># 使用二维卷积层的情况，计算通道维上（axis=1）的均值和方差。</span>            <span class="token comment"># 这里我们需要保持X的形状以便后面可以做广播运算</span>            mean <span class="token operator">=</span> X<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>            var <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>X <span class="token operator">-</span> mean<span class="token punctuation">)</span> <span class="token operator">**</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>        <span class="token comment"># 训练模式下，用当前的均值和方差做标准化</span>        X_hat <span class="token operator">=</span> <span class="token punctuation">(</span>X <span class="token operator">-</span> mean<span class="token punctuation">)</span> <span class="token operator">/</span> torch<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>var <span class="token operator">+</span> eps<span class="token punctuation">)</span>        <span class="token comment"># 更新移动平均的均值和方差</span>        moving_mean <span class="token operator">=</span> momentum <span class="token operator">*</span> moving_mean <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">1.0</span> <span class="token operator">-</span> momentum<span class="token punctuation">)</span> <span class="token operator">*</span> mean        moving_var <span class="token operator">=</span> momentum <span class="token operator">*</span> moving_var <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">1.0</span> <span class="token operator">-</span> momentum<span class="token punctuation">)</span> <span class="token operator">*</span> var    Y <span class="token operator">=</span> gamma <span class="token operator">*</span> X_hat <span class="token operator">+</span> beta  <span class="token comment"># 缩放和移位</span>    <span class="token keyword">return</span> Y<span class="token punctuation">,</span> moving_mean<span class="token punctuation">.</span>data<span class="token punctuation">,</span> moving_var<span class="token punctuation">.</span>data<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>上面仅实现了核心功能，如果要结合到 pytorch 模块中还需要用 Module 类来包装一下，这里就不记录了。直接使用 pytorch 的 API 只需要指定输入的 channel 数即可，下面是在原始的 LeNet 上使用 batch normalization 的代码</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">120</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span><span class="token number">120</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">120</span><span class="token punctuation">,</span> <span class="token number">84</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span><span class="token number">84</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">84</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="批量归一化做了什么"><a href="#批量归一化做了什么" class="headerlink" title="批量归一化做了什么"></a>批量归一化做了什么</h3><ol><li>固定小批量中的均值和方差，维护数值的相对稳定，能加速收敛，减缓了梯度消失/爆炸的情况，但一般不改变模型精度</li><li>固定小批量中的均值和方差，引入了噪声，起到了正则化的作用。这是一个意想不到的“副作用”</li></ol><p>实际上对于批量归一化的原理并没有一个明确的答案，原论文提到的“减少内部协变量偏移”的动机似乎不是一个有效的解释。如果非要给这个问题给出自己的胡乱理解，我认为是控制输出分布能够让数值更稳定，在一个统一标准下的空间超平面的分割分会更好，或许这种数值稳定对于梯度爆炸和梯度消失也有一定作用</p><h2 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h2><p>加深网络一定能提升模型的表现吗？答案不是肯定的，下面这张图形象地展示原因</p><p><img src="/archives/d08db5b4/image-20211128194609417.png" style="zoom:80%;"></p><p>只有当较复杂的函数类包含较小的函数类时，我们才能确保增大搜索范围时，搜索得到的结果能更接近最优解。对于深度神经网络，如果我们能将新添加的层训练成恒等映射（identity function）$f(x)=x$，新模型和原模型将同样有效</p><p>针对这一问题，何恺明等人提出了残差网络（ResNet），它在2015年的 ImageNet 图像识别挑战赛夺魁，<strong>并深刻影响了后来的深度神经网络的设计</strong></p><h3 id="残差块"><a href="#残差块" class="headerlink" title="残差块"></a>残差块</h3><p>假设我们的原始输入为 $x$ ，而希望学出的理想映射为 $f(x)$，普通的块和残差块的表现形式如下</p><p> <img src="/archives/d08db5b4/image-20211128200154146.png" style="zoom:80%;"></p><p>重点关注右侧的结构，在该结构下，虚线框内所学到的映射将是一个残差 $g(x) = f(x) - x$（假设我们能够学到理想映射），所以取名为残差块。这样的模块将很容易学习恒等变换，只需要将所有的权重置零即可</p><p>为了让输出和输入能够相加，显然要求输入和输出是具有相同形状和相同通道数，这个问题可以使用 1x1 卷积层解决。ResNet 中的残差块图示如下</p><p><img src="/archives/d08db5b4/image-20211128202426360.png" style="zoom:80%;"></p><p>代码将更清晰地展示其中的细节</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> functional <span class="token keyword">as</span> F<span class="token keyword">class</span> <span class="token class-name">Residual</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment">#@save</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_channels<span class="token punctuation">,</span> num_channels<span class="token punctuation">,</span>                 use_1x1conv<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>input_channels<span class="token punctuation">,</span> num_channels<span class="token punctuation">,</span>                               kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> stride<span class="token operator">=</span>strides<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>num_channels<span class="token punctuation">,</span> num_channels<span class="token punctuation">,</span>                               kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> use_1x1conv<span class="token punctuation">:</span>            self<span class="token punctuation">.</span>conv3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>input_channels<span class="token punctuation">,</span> num_channels<span class="token punctuation">,</span>                                   kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> stride<span class="token operator">=</span>strides<span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            self<span class="token punctuation">.</span>conv3 <span class="token operator">=</span> <span class="token boolean">None</span>        self<span class="token punctuation">.</span>bn1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>num_channels<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>bn2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>num_channels<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>relu <span class="token operator">=</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">)</span><span class="token punctuation">:</span>        Y <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>bn1<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        Y <span class="token operator">=</span> self<span class="token punctuation">.</span>bn2<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>Y<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>conv3<span class="token punctuation">:</span>            X <span class="token operator">=</span> self<span class="token punctuation">.</span>conv3<span class="token punctuation">(</span>X<span class="token punctuation">)</span>        Y <span class="token operator">+=</span> X        <span class="token keyword">return</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>Y<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="ResNet-模型"><a href="#ResNet-模型" class="headerlink" title="ResNet 模型"></a>ResNet 模型</h3><p>ResNet 的前两层跟之前介绍的 GoogLeNet 中的一样，不同之处在于 ResNet 每个卷积层后增加了<strong>批量归一化层</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">b1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">7</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                   nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                   nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>GoogLeNet 在后面接了 4 个由Inception块组成的模块。 ResNet 则使用 4 个由残差块组成的模块，每个模块使用若干个同样输出通道数的残差块，定义由残差块组成的 <code>resnet_block</code></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">resnet_block</span><span class="token punctuation">(</span>input_channels<span class="token punctuation">,</span> num_channels<span class="token punctuation">,</span> num_residuals<span class="token punctuation">,</span>                 first_block<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    blk <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_residuals<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># 对第一个模块做特别处理，不需要对维度进行转换</span>        <span class="token keyword">if</span> i <span class="token operator">==</span> <span class="token number">0</span> <span class="token keyword">and</span> <span class="token keyword">not</span> first_block<span class="token punctuation">:</span>            blk<span class="token punctuation">.</span>append<span class="token punctuation">(</span>Residual<span class="token punctuation">(</span>input_channels<span class="token punctuation">,</span> num_channels<span class="token punctuation">,</span>                                use_1x1conv<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">else</span><span class="token punctuation">:</span>            blk<span class="token punctuation">.</span>append<span class="token punctuation">(</span>Residual<span class="token punctuation">(</span>num_channels<span class="token punctuation">,</span> num_channels<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> blk<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>现在在 ResNet 中加入所有残差块，这里每个模块使用 2 个残差块</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">b2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span>resnet_block<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> first_block<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span>b3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span>resnet_block<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>b4 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span>resnet_block<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>b5 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span>resnet_block<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>最后，与 GoogLeNet 一样，在 ResNet 中加入全局平均汇聚层，以及全连接层输出</p><pre class="line-numbers language-pyt" data-language="pyt"><code class="language-pyt">net = nn.Sequential(b1, b2, b3, b4, b5,                    nn.AdaptiveAvgPool2d((1,1)),                    nn.Flatten(), nn.Linear(512, 10))<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>每个模块有 4 个卷积层（不包括恒等映射的 1×1 卷积层）。 加上第一个 7×7 卷积层和最后一个全连接层，共有 18 层。 因此，这种模型通常被称为 ResNet-18。虽然 ResNet 的主体结构跟 GoogLeNet类似，但 ResNet 结构更简单，修改也更方便。这些因素都导致了 ResNet 迅速被广泛使用</p><p><img src="/archives/d08db5b4/image-20211128204626861.png" style="zoom:80%;"></p>]]></content>
      
      
      <categories>
          
          <category> 课程 </category>
          
          <category> Dive into deep learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Dive into deep learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>D2L 06 卷积神经网络</title>
      <link href="/archives/59b56001.html"/>
      <url>/archives/59b56001.html</url>
      
        <content type="html"><![CDATA[<h1 id="D2L-06-卷积神经网络"><a href="#D2L-06-卷积神经网络" class="headerlink" title="D2L 06 卷积神经网络"></a>D2L 06 卷积神经网络</h1><p>本章介绍的卷积神经网络（convolutional neural network，CNN）是一类强大的、为处理图像数据而设计的神经网络。 基于卷积神经网络结构的模型在计算机视觉领域中已经占主导地位，当今几乎所有的图像识别、对象检测或语义分割相关的学术竞赛和商业应用都以这种方法为基础</p><h2 id="从全连接层到卷积"><a href="#从全连接层到卷积" class="headerlink" title="从全连接层到卷积"></a>从全连接层到卷积</h2><p>MLP 的需要将数据展开到一维，这将带来大量的参数开销，以及忽略数据之间的结构信息。CNN 是机器学习利用自然图像中一些已知结构的创造性方法</p><p>为了让网络能够适合于计算机视觉，需要有两个特征：</p><ol><li>平移不变性：对相同的图像区域具有相似的反应</li><li>局部性：只探索输入图像中的局部区域，而不过度在意图像中相隔较远区域的关系</li></ol><p>教材用了几个公式的转变来完成这两个特征</p><ol><li>全连接层公式表达，$H,U,W\ or \ V,X$ 分别表示输出（隐藏层），偏置，权重，输入。下标表示图形长宽</li></ol><p><img src="/archives/59b56001/image-20211125150600004.png"></p><ol><li>加入平移不变性</li></ol><p><img src="/archives/59b56001/image-20211125150750073.png"></p><ol><li>加入局部性</li></ol><p><img src="/archives/59b56001/image-20211125150811529.png"></p><p>​    上面就是一个基本的卷积层，$V$ 为卷积核（convolution kernel）或者滤波器（filter）</p><ol><li>加入通道</li></ol><p><img src="/archives/59b56001/image-20211125150903545.png"></p><p>教材还介绍了一下数学上的卷积操作，与我们实际使用的卷积操作是不一样的，图像卷积操作在数学上叫做互相关（cross-correlation），该操作是卷积的“未翻转”版本。为了与深度学习文献中的标准术语保持一致，我们将继续把“互相关运算”称为卷积运算</p><h2 id="图像卷积"><a href="#图像卷积" class="headerlink" title="图像卷积"></a>图像卷积</h2><p>互相关/卷积运算图解</p><p><img src="/archives/59b56001/image-20211125152613227.png" style="zoom:80%;"></p><p>注意，输出大小略小于输入大小。这是因为卷积核的宽度和高度大于1， 而卷积核只与图像中每个大小完全适合的位置进行互相关运算。下面简单实现一个自己的卷积层</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token keyword">def</span> <span class="token function">corr2d</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> K<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment">#@save</span>    <span class="token triple-quoted-string string">"""计算二维互相关运算。"""</span>    h<span class="token punctuation">,</span> w <span class="token operator">=</span> K<span class="token punctuation">.</span>shape    Y <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">-</span> h <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">-</span> w <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>Y<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>Y<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            Y<span class="token punctuation">[</span>i<span class="token punctuation">,</span> j<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">(</span>X<span class="token punctuation">[</span>i<span class="token punctuation">:</span>i <span class="token operator">+</span> h<span class="token punctuation">,</span> j<span class="token punctuation">:</span>j <span class="token operator">+</span> w<span class="token punctuation">]</span> <span class="token operator">*</span> K<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> Y<span class="token keyword">class</span> <span class="token class-name">Conv2D</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> kernel_size<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>weight <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span>kernel_size<span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>bias <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> corr2d<span class="token punctuation">(</span>x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>weight<span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>bias<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="学习卷积核"><a href="#学习卷积核" class="headerlink" title="学习卷积核"></a>学习卷积核</h3><p>教材举了一个例子：能够用一个 <code>[1, -1]</code> 的简单卷积核来检测横向边缘。但是不可能所有卷积核是人工构造的，好消息是我们可以像之前的 MLP 一样使用优化算法估计出一个卷积核来达到期望的效果。最终通过梯度下降法学习到的权重为 <code>[0.9895, -0.9873]</code> 与人工设计卷积核十分接近</p><p>实际上可能存在各种各样的卷积核，这些卷积核能够提取不同的特征，例如：图像边缘，服饰膨胀，二阶求导等。如果要去人工设计这么多功能的卷积核，就回到了传统计算机视觉，另一个选择就是设计一个网络，然后使用优化算法去学习，但是学习到的卷积核可解释性就不强了</p><h3 id="特征映射和感受野"><a href="#特征映射和感受野" class="headerlink" title="特征映射和感受野"></a>特征映射和感受野</h3><p>教材说到：卷积层有时被称为特征映射（Feature Map）。由于 Map 的意义在英文里有多个，也可以被翻译为地图，Feature Map 也常被翻译为特征图谱，而教材应该就是想表述为“映射”，以表示 CNN 对于特征的提取作用</p><h2 id="填充和步幅"><a href="#填充和步幅" class="headerlink" title="填充和步幅"></a>填充和步幅</h2><p>填充和步幅可用于有效地调整数据的维度</p><h3 id="填充"><a href="#填充" class="headerlink" title="填充"></a>填充</h3><p>在应用多层卷积时，我们常常丢失边缘像素。在许多情况下，我们需要设置 $p_h=k_h−1$ 和 $p_w=k_w−1$ 去填充（padding）图像周围，使输入和输出具有相同的高度和宽度。如果 kernel size 为奇数就能在左右上下均匀得填充了</p><h3 id="步幅"><a href="#步幅" class="headerlink" title="步幅"></a>步幅</h3><p>有时候为了高效计算或是缩减采样次数，卷积窗口可以跳过中间位置，每次滑动多个元素。我们将每次滑动元素的数量称为步幅（stride）</p><h2 id="多输入多输出通道"><a href="#多输入多输出通道" class="headerlink" title="多输入多输出通道"></a>多输入多输出通道</h2><h3 id="多输入通道"><a href="#多输入通道" class="headerlink" title="多输入通道"></a>多输入通道</h3><p>当输入包含多个通道时，需要构造一个与输入数据具有相同输入通道数目的卷积核，以便与输入数据进行互相关运算。我们演示了一个具有两个输入通道的二维互相关运算的示例</p><p><img src="/archives/59b56001/image-20211125162435643.png" style="zoom:80%;"></p><h3 id="多输出通道"><a href="#多输出通道" class="headerlink" title="多输出通道"></a>多输出通道</h3><p>每一层有多个输出通道是至关重要的。在最流行的神经网络架构中，随着神经网络层数的加深，我们常会增加输出通道的维数，通过减少空间分辨率以获得更大的通道深度。直观地说，我们可以将每个通道看作是对不同特征的响应</p><h3 id="1x1-卷积层"><a href="#1x1-卷积层" class="headerlink" title="1x1 卷积层"></a>1x1 卷积层</h3><p>1x1 卷积看起来似乎没有多大意义。 毕竟，卷积的本质是有效提取相邻像素间的相关特征，但是这样的操作实际上非常常见</p><p>我们可以将 1x1 卷积层看作是在每个像素位置应用的全连接层。这里输入和输出具有相同的高度和宽度，输出中的每个元素都是从输入图像中同一位置的元素的线性组合</p><p><img src="/archives/59b56001/image-20211125163401472.png" style="zoom:80%;"></p><p>注意：在后面的图示和代码当中，很少能看到 bias 出现，但实际上如果没有特殊指定，默认都是存在 bias，其数量与卷积核数量相同</p><h2 id="汇聚层"><a href="#汇聚层" class="headerlink" title="汇聚层"></a>汇聚层</h2><p>也通常叫做池化层（pooling layer），它通常具有两个目的：</p><ol><li>降低卷积层对位置的敏感性</li><li>对输出进行降采样</li></ol><p>对于“敏感性”的说法，我觉得不太好理解，在吴恩达的视频里提到：池化层能提高所提取特征的鲁棒性。这让我联想到了自己看的 PointNet：使用了 maxpooling 来将所有点的特征提取为 global 特征，我认为这里有着相似的作用。因为 maxpooling 是一个对称函数，对于一些位置的变换（噪声）其输出是不会有改变的。我们将窗口中最大的数作为整个窗口的“代表”，忽略其他较小的值，以整体把握</p><h3 id="最大池化和平均池化"><a href="#最大池化和平均池化" class="headerlink" title="最大池化和平均池化"></a>最大池化和平均池化</h3><p>与卷积层类似，汇聚层运算符由一个固定形状的窗口组成，该窗口根据其步幅大小在输入的所有区域上滑动。在池化窗口到达的每个位置，它计算该窗口中输入子张量的最大值或平均值</p><p>在处理多通道输入数据时，汇聚层在每个输入通道上单独运算，而不是像卷积层一样在通道上对输入进行汇总</p><h3 id="胡思乱想😅"><a href="#胡思乱想😅" class="headerlink" title="胡思乱想😅"></a>胡思乱想😅</h3><p>是否可以直接通过卷积操作替代池化层？因为卷积也能够降低图谱的分辨率，显然平均池化是可以被替代的，但最大池化呢？看到一个 <a href="(https://www.zhihu.com/question/270777218">知乎</a> 链接 [卷积神经网络中的pooling层能否用相同stride的convolution层替代]) 有所讨论，其中有人评论：max pooling 是动态的，而 strided convolution 是静态的，二者不可一概而论</p><p>现在正在证明一件事：可以使用神经网络实现最大值分类/回归问题，下面介绍一下我的实验结果：</p><ol><li>实验数据为1000个数对，从 (0， 20000) 中进行采样</li><li>ReLU 需要输入大多数为正数，负数太多梯度会迅速消失，当然数据的归一化也有很不错的效果</li><li>通过一个简单网络，我可以很好的训练出一个最大最小值分类模型，但是对于回归模型仍然需要更多努力</li><li><del>显然原始数据对于最大值回归问题是很重要的，或许对于其他的回归问题也很重要</del>。如果得到了最大最小值的分类，只需要将分类结果与原始数据相乘即可得到最大值。按照这个思路我也得到期望的结果，但是学习率非常非常小大概到了 1e-8 次方级别，最终损失在 5 左右</li><li>即使不使用“相乘”操作，实际上我也能人工构造出一个网络，得到不错的结果，按照我的想法，网络没办法通过优化算法获得我所设计的参数，但是这个问题很快在<strong>更宽更多</strong>的网络层下被解决，实际的 loss 在 0.05 左右，我认为这是一个相当不错的结果</li><li>使用 SGD 无法得到优化结果，只能使用 Adam，对于稀疏数据/模型可能需要自适应的学习率，可以先用 Adam 快速收敛再用 SGD 调整</li><li>使用 mini-batch 无法得到优化结果，batch size 只能等于一，batch size 越大越容易搜索到 sharp minimum，参考 <a href="https://zhuanlan.zhihu.com/p/64864995">知乎</a></li></ol><p>根据以上实验，我认为 strided convolution 具有替代 max pooling 的能力，另一些笼统的感受是：</p><ol><li>分类任务想比回归任务更加简单</li><li>可能对于有<strong>高精度</strong>的（回归）任务深度学习是需要一定辅助的，但在大量复杂数据的情景下，深度学习相比人类具有无法比拟的优势</li><li>一开始认为需要使用原始数据进行回归，尝试了 ResNet，但实际上并不需要，普通的全连接层即可完成</li></ol><h2 id="LeNet"><a href="#LeNet" class="headerlink" title="LeNet"></a>LeNet</h2><p>当时， LeNet 取得了与支持向量机（support vector machines）性能相媲美的成果，成为监督学习的主流方法。直接上图和代码就能够清楚其结构</p><p><img src="/archives/59b56001/image-20211127204926151.png" style="zoom:80%;"></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token keyword">class</span> <span class="token class-name">Reshape</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">)</span>net <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>    Reshape<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>AvgPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>AvgPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">16</span> <span class="token operator">*</span> <span class="token number">5</span> <span class="token operator">*</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">120</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">120</span><span class="token punctuation">,</span> <span class="token number">84</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">84</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>为了凸显简单，教材直接使用一个 <code>nn.Sequential</code> 将所有的模块连接起来，并请注意，虽然 ReLU 和最大汇聚层更有效，但它们在20世纪90年代还没有出现</p>]]></content>
      
      
      <categories>
          
          <category> 课程 </category>
          
          <category> Dive into deep learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Dive into deep learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>D2L 05 深度学习计算</title>
      <link href="/archives/53554dbc.html"/>
      <url>/archives/53554dbc.html</url>
      
        <content type="html"><![CDATA[<h1 id="D2L-05-深度学习计算"><a href="#D2L-05-深度学习计算" class="headerlink" title="D2L 05 深度学习计算"></a>D2L 05 深度学习计算</h1><p>在本章中，我们开始深入探索深度学习计算的关键组件，即模型构建、参数访问与初始化、设计自定义层和块、将模型读写到磁盘，以及利用GPU实现显著的加速。这些知识将使你从基础用户变为高级用户。虽然本章不介绍任何新的模型或数据集，但后面的高级模型章节在很大程度上依赖于本章的知识</p><h2 id="层和块"><a href="#层和块" class="headerlink" title="层和块"></a>层和块</h2><p>为了实现这些复杂的网络，我们引入了神经网络块的概念。块可以描述单个层、由多个层组成的组件或整个模型本身</p><h3 id="自定义块"><a href="#自定义块" class="headerlink" title="自定义块"></a>自定义块</h3><p>简要总结一下每个块必须提供的基本功能：</p><ol><li>将输入数据作为其正向传播函数的参数，并通过正向传播函数来生成输出</li><li>计算其输出关于输入的梯度，可通过其反向传播函数进行访问。通常这是自动发生的</li><li>存储和访问正向传播计算所需的参数，并能根据需要初始化模型参数</li></ol><p>下面写一个简单的线性模块</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">MyLinear</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_units<span class="token punctuation">,</span> units<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>weight <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>in_units<span class="token punctuation">,</span> units<span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>bias <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>units<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">)</span><span class="token punctuation">:</span>        linear <span class="token operator">=</span> torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>X<span class="token punctuation">,</span> self<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>data<span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>bias<span class="token punctuation">.</span>data        <span class="token keyword">return</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>linear<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>除了自定义带参数的层外，还可以自定义不带参数的模块，这样可以更轻松地加入到其他模块当中，例如可以将损失函数写为一个模块加入到 <code>nn.Sequential</code> 中</p><h3 id="顺序块"><a href="#顺序块" class="headerlink" title="顺序块"></a>顺序块</h3><p><code>nn.Sequential</code> 提供了两个功能：</p><ol><li>将块逐个追加到列表中，在之后能够通过 index 访问，一般的模块不能通过 index 访问其子模块，而是通过属性的方式访问子模块</li><li>在正向传播时，将输入按顺序传递给块组成链条</li></ol><p>教材中的简易实现</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">MySequential</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">for</span> block <span class="token keyword">in</span> args<span class="token punctuation">:</span>            <span class="token comment"># 这里，`block`是`Module`子类的一个实例。我们把它保存在'Module'类的成员变量</span>            <span class="token comment"># `_modules` 中。`block`的类型是OrderedDict。</span>            self<span class="token punctuation">.</span>_modules<span class="token punctuation">[</span>block<span class="token punctuation">]</span> <span class="token operator">=</span> block    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># OrderedDict保证了按照成员添加的顺序遍历它们</span>        <span class="token keyword">for</span> block <span class="token keyword">in</span> self<span class="token punctuation">.</span>_modules<span class="token punctuation">.</span>values<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            X <span class="token operator">=</span> block<span class="token punctuation">(</span>X<span class="token punctuation">)</span>        <span class="token keyword">return</span> X<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在最后的练习中有提问：如果把 <code>self._modules</code> 换为普通的 python 列表有什么问题？回答：使用 <code>self._modules</code> 将会把这些子模块注册到模块中，这是 <code>nn.Module</code> 的重要属性之一。当在其他模块使用该 <code>MySequential</code> 时，这些子模块同样也会被识别，并递归地注册到该模块中。而普通的 python list 类无法做到</p><h3 id="嵌套块"><a href="#嵌套块" class="headerlink" title="嵌套块"></a>嵌套块</h3><p>可以直接通过 <code>add_module(key, module)</code> 方法加入子模块，所有添加子模块的本质都是向 <code>self._module</code> OrderedDict 中注册新的 name: module pair</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">block1</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                         nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">block2</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># 在这里嵌套</span>        net<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'block </span><span class="token interpolation"><span class="token punctuation">{</span>i<span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">,</span> block1<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> netrgnet <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>block2<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="在正向传播函数中执行代码"><a href="#在正向传播函数中执行代码" class="headerlink" title="在正向传播函数中执行代码"></a>在正向传播函数中执行代码</h3><p>可以在 <code>forward()</code> 函数中任意执行你希望的过程。在反向传播的过程中只会更新模块中的参数，如下面的 <code>self.rand_weight</code> 就不会被更新</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">FixedHiddenMLP</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment"># 不计算梯度的随机权重参数。因此其在训练期间保持不变。</span>        self<span class="token punctuation">.</span>rand_weight <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>linear <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> X<span class="token punctuation">)</span><span class="token punctuation">:</span>        X <span class="token operator">=</span> self<span class="token punctuation">.</span>linear<span class="token punctuation">(</span>X<span class="token punctuation">)</span>        <span class="token comment"># 使用创建的常量参数以及`relu`和`dot`函数。</span>        X <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>mm<span class="token punctuation">(</span>X<span class="token punctuation">,</span> self<span class="token punctuation">.</span>rand_weight<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span>        <span class="token comment"># 复用全连接层。这相当于两个全连接层共享参数。</span>        X <span class="token operator">=</span> self<span class="token punctuation">.</span>linear<span class="token punctuation">(</span>X<span class="token punctuation">)</span>        <span class="token keyword">return</span> X<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="参数管理"><a href="#参数管理" class="headerlink" title="参数管理"></a>参数管理</h2><p>在本节中，我们将介绍以下内容：</p><ul><li>访问参数，用于调试、诊断和可视化</li><li>参数初始化</li><li>在不同模型组件间共享参数</li></ul><h3 id="参数访问"><a href="#参数访问" class="headerlink" title="参数访问"></a>参数访问</h3><p>通过 <code>state_dict()</code> 查看网络层参数的 <code>OrderedDict</code></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">from</span> torch <span class="token keyword">import</span> nnnet <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>X <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>net<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># OrderedDict([('weight', tensor([[-0.1280,  0.3443,  0.0572, -0.1925,  0.3084, -0.2585,  0.1038,  0.0608]])), ('bias', tensor([0.1917]))])</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>通过类属性访问参数，并进一步访问该参数的值</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">.</span>bias<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">.</span>bias<span class="token punctuation">.</span>data<span class="token punctuation">)</span><span class="token comment"># tensor([-0.1373], requires_grad=True)</span><span class="token comment"># tensor([-0.1373])</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>通过 <code>named_parameters()</code> 也可以访问所有参数的名字和参数，返回的是一个生成器，通过循环可遍历所有参数，以 <code>(name, param)</code> 元组形式为返回值</p><h3 id="参数初始化"><a href="#参数初始化" class="headerlink" title="参数初始化"></a>参数初始化</h3><p>默认情况下，PyTorch会根据一个范围均匀地初始化权重和偏置矩阵，这个范围是根据输入和输出维度计算出的。PyTorch的 <code>nn.init</code> 模块提供了多种预置初始化方法，其本质是对 <code>module.weight</code> 进行赋值</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">xavier</span><span class="token punctuation">(</span>m<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> <span class="token builtin">type</span><span class="token punctuation">(</span>m<span class="token punctuation">)</span> <span class="token operator">==</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">:</span>        nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>xavier_uniform_<span class="token punctuation">(</span>m<span class="token punctuation">.</span>weight<span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">init_42</span><span class="token punctuation">(</span>m<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> <span class="token builtin">type</span><span class="token punctuation">(</span>m<span class="token punctuation">)</span> <span class="token operator">==</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">:</span>        nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>m<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> <span class="token number">42</span><span class="token punctuation">)</span>net<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span>xavier<span class="token punctuation">)</span>net<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span>init_42<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>weight<span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>net<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">.</span>weight<span class="token punctuation">.</span>data<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="参数绑定"><a href="#参数绑定" class="headerlink" title="参数绑定"></a>参数绑定</h3><p>有时我们希望在多个层间共享参数。让我们看看如何优雅地做这件事</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 我们需要给共享层一个名称，以便可以引用它的参数。</span>shared <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span>net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                    shared<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                    shared<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                    nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>net<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在反向传播时，这两个隐藏层的梯度将会加在一起</p><h2 id="读写文件"><a href="#读写文件" class="headerlink" title="读写文件"></a>读写文件</h2><p>现在是时候学习如何加载和存储权重向量和整个模型</p><h3 id="加载和保存张量"><a href="#加载和保存张量" class="headerlink" title="加载和保存张量"></a>加载和保存张量</h3><p>可以直接调用 <code>load</code> 和 <code>save</code> 函数，以读写各种数据类型，包括 Pytorch 模型（模型包含 <code>state_dict</code> 即参数）</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> functional <span class="token keyword">as</span> Fx <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token string">'x-file'</span><span class="token punctuation">)</span>x2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'x-file'</span><span class="token punctuation">)</span><span class="token comment"># 可以存储各种的数据类型</span>y <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token punctuation">[</span>x<span class="token punctuation">,</span> y<span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token string">'x-files'</span><span class="token punctuation">)</span>x2<span class="token punctuation">,</span> y2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'x-files'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="加载和保存模型参数"><a href="#加载和保存模型参数" class="headerlink" title="加载和保存模型参数"></a>加载和保存模型参数</h3><p>仅仅保存参数，并将保存的参数加载到新建的模型中</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 假设定义了一个模型</span><span class="token keyword">class</span> <span class="token class-name">MLP</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">pass</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">pass</span>net <span class="token operator">=</span> MLP<span class="token punctuation">(</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>net<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'mlp.params'</span><span class="token punctuation">)</span><span class="token comment"># 新建模型并加载参数</span>clone <span class="token operator">=</span> MLP<span class="token punctuation">(</span><span class="token punctuation">)</span>clone<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'mlp.params'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="GPU"><a href="#GPU" class="headerlink" title="GPU"></a>GPU</h2><p>我们可以指定用于存储和计算的设备，如CPU和GPU。默认情况下，张量是在内存中创建的，然后使用CPU计算它，pytorch 中与 GPU 相关的包为 <code>torch.cuda</code></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token comment"># 获得 GPU 设备，返回值为字符串 'cpu' or 'cuda' or f'cuda:{idx}'</span>torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">'cpu'</span><span class="token punctuation">)</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">'cuda'</span><span class="token punctuation">)</span><span class="token comment"># equals torch.device('cuda:0')</span>torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">'cuda:1'</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>device_count<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># GPU 数量</span>torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># GPU 是否可用</span>torch<span class="token punctuation">.</span>version<span class="token punctuation">.</span>cuda<span class="token comment"># cuda 版本</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>查看张量所在设备，并更改所在设备</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>device<span class="token punctuation">)</span><span class="token comment"># cpu</span><span class="token comment"># 将 x 移到 GPU 上</span>x <span class="token operator">=</span> x<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">'cuda'</span><span class="token punctuation">)</span><span class="token comment"># equals x = x.cuda()</span><span class="token comment"># net 是一个 Module，将其参数移动到 GPU 上</span>net<span class="token punctuation">.</span>to<span class="token punctuation">(</span>x<span class="token punctuation">.</span>device<span class="token punctuation">)</span><span class="token comment"># net.cuda()</span><span class="token comment"># 查看网络的参数是否在 GPU 上</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">next</span><span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>device<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>注意：</p><ol><li>计算需要在同一个设备上进行，即模型和数据需要在同一个 GPU 或者 CPU 上进行计算</li><li><code>to(device)</code> 对于张量不是一个 inplace 操作，而对于模型来说是一个 inplace 操作，也就是说对于张量需要使用 <code>x = x.to()</code> 来使改变真正生效</li></ol>]]></content>
      
      
      <categories>
          
          <category> 课程 </category>
          
          <category> Dive into deep learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Dive into deep learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>D2L 04 多层感知机</title>
      <link href="/archives/fc6001ca.html"/>
      <url>/archives/fc6001ca.html</url>
      
        <content type="html"><![CDATA[<h1 id="D2L-04-多层感知机"><a href="#D2L-04-多层感知机" class="headerlink" title="D2L 04 多层感知机"></a>D2L 04 多层感知机</h1><h2 id="多层感知机"><a href="#多层感知机" class="headerlink" title="多层感知机"></a>多层感知机</h2><p>线性模型的表示能力是有限的，如果加入隐藏层和非线性运算，模型的表示能力将大大增加。事实上如果隐藏层的节点足够多，模型将能够拟合任意的连续函数 $f(·)$，这就是万能/通用近似 universal approximation</p><p>参考链接：<a href="https://www.bilibili.com/video/BV1Hh411Q7p4">bilibili</a> <a href="http://neuralnetworksanddeeplearning.com/chap4.html">link</a> 直观简述了为什么 hidden layer + ReLU 能够拟合任意连续函数，看完就有感觉了</p><h3 id="Pytorch-实现"><a href="#Pytorch-实现" class="headerlink" title="Pytorch 实现"></a>Pytorch 实现</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>dataloader <span class="token keyword">import</span> DataLoader<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>sampler <span class="token keyword">import</span> SubsetRandomSampler<span class="token keyword">from</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">import</span> SGD<span class="token keyword">from</span> utils <span class="token keyword">import</span> get_dataset<span class="token punctuation">,</span> traintrain_dataset <span class="token operator">=</span> get_dataset<span class="token punctuation">(</span>train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>test_dataset <span class="token operator">=</span> get_dataset<span class="token punctuation">(</span>train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>data <span class="token operator">=</span> train_dataset<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>  MLP <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>    nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">28</span><span class="token operator">*</span><span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>batch_size<span class="token punctuation">,</span> lr<span class="token punctuation">,</span> num_epochs <span class="token operator">=</span> <span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">10</span>loss <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>optim <span class="token operator">=</span> SGD<span class="token punctuation">(</span>MLP<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>lr<span class="token punctuation">)</span>NUM <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_dataset<span class="token punctuation">)</span>sampler <span class="token operator">=</span> SubsetRandomSampler<span class="token punctuation">(</span>np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>NUM<span class="token punctuation">)</span><span class="token punctuation">)</span>train_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>train_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span> sampler<span class="token operator">=</span>sampler<span class="token punctuation">)</span>train<span class="token punctuation">(</span>MLP<span class="token punctuation">,</span> train_loader<span class="token punctuation">,</span> num_epochs<span class="token punctuation">,</span> optim<span class="token punctuation">,</span> loss<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>其中我自己写了一个 utils 文件，包含一些常规功能，这里不贴出来了</p><h2 id="模型选择、欠拟合和过拟合"><a href="#模型选择、欠拟合和过拟合" class="headerlink" title="模型选择、欠拟合和过拟合"></a>模型选择、欠拟合和过拟合</h2><h3 id="训练误差和泛化误差"><a href="#训练误差和泛化误差" class="headerlink" title="训练误差和泛化误差"></a>训练误差和泛化误差</h3><p>将模型在训练数据上拟合得比在潜在分布中更接近的现象称为过拟合（overfitting），用于对抗过拟合的技术称为正则化（regularization）</p><p>为了进一步讨论这一现象，我们需要了解训练误差和泛化误差。训练误差（training error）是指，我们的模型在训练数据集上计算得到的误差。泛化误差（generalization error）是指，当我们将模型应用在同样从原始样本的分布中抽取的无限多的数据样本时，我们模型误差的期望</p><p>在实际中，我们只能通过将模型应用于一个独立的测试集来估计泛化误差，该测试集由随机选取的、未曾在训练集中出现的数据样本构成</p><h3 id="过拟合和欠拟合"><a href="#过拟合和欠拟合" class="headerlink" title="过拟合和欠拟合"></a>过拟合和欠拟合</h3><p>欠拟合是指模型无法继续减少训练误差。过拟合是指训练误差远小于验证误差</p><p>一般来讲模型越复杂，训练集越简单，越容易过拟合。教材使用了多项式回归来简要说明了这一现象：使用更高阶的多项式，通过参数调整，很容易（过）拟合一个函数</p><h3 id="利用验证集进行模型选择"><a href="#利用验证集进行模型选择" class="headerlink" title="利用验证集进行模型选择"></a>利用验证集进行模型选择</h3><p>为了确定候选模型中的最佳模型，我们通常会使用验证集。这个问题的一个流行的解决方案是采用 K 折交叉验证。通过对 K 次实验的结果取平均来估计训练和验证误差</p><h2 id="权重衰减"><a href="#权重衰减" class="headerlink" title="权重衰减"></a>权重衰减</h2><h3 id="L2-正则化"><a href="#L2-正则化" class="headerlink" title="L2 正则化"></a>L2 正则化</h3><p>权重衰减（通常称为 L2 正则化）是最广泛使用的正则化的技术之一</p><p>要保证权重”范围”比较小，最常用方法是将其范数作为惩罚项加到最小化损失的问题中。原来的训练目标最小化训练标签上的预测损失，调整为最小化预测损失和惩罚项之和</p><p>我们通过正则化常数 λ 来描述这种权衡，这是一个非负超参数，下面是 L2 正则化下的损失函数</p><p><img src="/archives/fc6001ca/image-20211122191124428.png" style="zoom:80%;"></p><p>如上形式的正则化有几个好处：</p><ol><li><p>便于计算，没有根号</p></li><li><p>使得优化算法偏向于生成在大量特征上均匀分布权重的模型，考虑下面的优化问题，可以简单理解什么是“均匀分布”</p><script type="math/tex; mode=display">min \ \sum w_i^2 \\s.t. \sum w_i = const</script></li></ol><p>在实例化优化器时直接通过 <code>weight_decay</code> 指定 weight decay 超参数。默认情况下，PyTorch 同时衰减权重和偏移。这里我们只为权重设置了 <code>weight_decay</code>，所以 bias 参数不会衰减</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">num_inputs <span class="token operator">=</span> <span class="token number">784</span>net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>num_inputs<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">for</span> param <span class="token keyword">in</span> net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    param<span class="token punctuation">.</span>data<span class="token punctuation">.</span>normal_<span class="token punctuation">(</span><span class="token punctuation">)</span>    loss <span class="token operator">=</span> nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>num_epochs<span class="token punctuation">,</span> lr <span class="token operator">=</span> <span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">0.003</span>wd <span class="token operator">=</span> <span class="token number">3</span><span class="token comment"># 偏置参数没有衰减。</span>trainer <span class="token operator">=</span> SGD<span class="token punctuation">(</span><span class="token punctuation">[</span>    <span class="token punctuation">{</span><span class="token string">"params"</span><span class="token punctuation">:</span>net<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>weight<span class="token punctuation">,</span><span class="token string">'weight_decay'</span><span class="token punctuation">:</span> wd<span class="token punctuation">}</span><span class="token punctuation">,</span>    <span class="token punctuation">{</span><span class="token string">"params"</span><span class="token punctuation">:</span>net<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>bias<span class="token punctuation">}</span><span class="token punctuation">]</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>lr<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'w的L2范数：'</span><span class="token punctuation">,</span> net<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>weight<span class="token punctuation">.</span>norm<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>学习点：</p><ol><li>Pytorch 优化器可以对模型中指定参数进行权重衰减，使用一个字典组成的列表即可 <a href="https://pytorch.org/docs/stable/optim.html">torch.optim</a></li></ol><h3 id="补充：L1-正则化与稀疏参数"><a href="#补充：L1-正则化与稀疏参数" class="headerlink" title="补充：L1 正则化与稀疏参数"></a>补充：L1 正则化与稀疏参数</h3><p>从凸优化的角度来看，在强对偶条件下，给定最优的正则化超参 λ*，在原函数加入惩罚项和给参数加约束是等价的</p><script type="math/tex; mode=display">min\ f(x) \ s.t. \ m(x) \le 0\\\Leftrightarrow min \ L(x, \lambda^*)</script><h2 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h2><p>这一部分的教材讲的得比较模糊…不说了直接去 <a href="https://www.bilibili.com/video/BV1Y5411c7aY?p=1&amp;t=692">bilibili</a> 看大佬讲课！总结来说：</p><ol><li>Dropout 被看作一项正则化技术，给模型加入噪声</li><li>Dropout 将一些输出项随机置0，常作用在 MLP 的隐藏层输出上，其中丢弃概率 p 为超参</li><li>教材选择在 Dropout 输出的时候除以 (1 - p) 以保证期望不变。在 cs231n 课程中是选择在测试的时候对输出乘以 (1 - p) 以保持期望不变，二者应该是等价的</li></ol><p>注意：Dropout 和权重衰减都是正则化技术，他们仅在训练时使用，在测试时是不使用 or 不一样的，包括之后会介绍的 batch normalization 也是一样的</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">dropout1<span class="token punctuation">,</span> dropout2 <span class="token operator">=</span> <span class="token number">0.2</span><span class="token punctuation">,</span> <span class="token number">0.5</span>net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">784</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token comment"># 在第一个全连接层之后添加一个dropout层</span>        nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>dropout1<span class="token punctuation">)</span><span class="token punctuation">,</span>        nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token comment"># 在第二个全连接层之后添加一个dropout层</span>        nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>dropout2<span class="token punctuation">)</span><span class="token punctuation">,</span>        nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="正向传播、反向传播和计算图"><a href="#正向传播、反向传播和计算图" class="headerlink" title="正向传播、反向传播和计算图"></a>正向传播、反向传播和计算图</h2><p>对于这一部分，我认为需要更扎实的矩阵论的知识，尤其是对于矩阵/张量求导的表示，看在之后能不能填上这部分</p><p>当然简单的结论是能够帮助我们快速前进的，下面给出矩阵乘法的反向传播结论（分子式）</p><script type="math/tex; mode=display">y \in \mathbb{R}^M, x \in \mathbb{R}^N, W \in \mathbb{R}^{M\times N} \\y=W·x, \frac{\partial{L}}{\partial y} = d_y^T\\\text{we have } \frac{\partial L}{\partial W}=xd_y^T\\\text{and } \frac{\partial L}{\partial x}=d_y^TW</script><p>其实除了矩阵乘法的求导比较陌生，其他运算的求导以及链式法则应该都相对熟悉，与初高中遇到的问题是相似的</p><p>几个关于矩阵求导的参考链接：<a href="https://www.bilibili.com/video/BV1xk4y1B7RQ?p=4&amp;t=0">bilibili</a> <a href="https://blog.csdn.net/nomadlx53/article/details/50849941#commentBox">CSDN</a> <a href="https://en.wikipedia.org/wiki/Matrix_calculus#Scalar-by-matrix">wiki Matrix calculus</a></p><p>这里总结几个基本法则：</p><ol><li>在求导之前一定要确定是分子式还是分母式，看个人选择，推荐分子式，更符合平时求导的直觉</li><li>最重要的定律莫过于乘法求导法则 <a href="https://en.wikipedia.org/wiki/Product_rule">product rule</a> 以及链式求导法则 <a href="https://en.wikipedia.org/wiki/Chain_rule">chain rule</a>。如果习惯按照分母式求导，那么链式求导时顺序要倒过来，并且常数在提出来时应该放在后面并且转置  </li><li>再来看上面得出的结论，对于 x 的求导变得相对容易，但对于 W 的求导还是有点复杂，因为是对于矩阵求导。其中会遇到 vector by matrix 的情况，这该怎么处理？事实上，这种情况需要将 upper gradient or unit 1 vector 与需要求导的 vector 相乘 $\frac{\partial (d_y^TWx)}{\partial W}$，将其转换为 scalar by matrix</li></ol><p>之后可以结合 cs231n 中对 batch normalization 的反向传播练习以及 RNN 中的反向传播练习来加深熟练度，虽然他们都很难！</p><p>经过多次的总结，关于机器学习中常用的矩阵求导规律（依然使用分子式）：</p><ol><li>数乘法则<script type="math/tex; mode=display">\text{vector by vector}\\\frac{\partial \mathbf{A} \mathbf{u}}{\partial \mathbf{x}}= \mathbf A \frac{\partial \mathbf u}{\partial \mathbf x}\\\frac{\partial u \mathbf{a}}{\partial \mathbf{x}}= \mathbf a \frac{\partial u}{\partial \mathbf x}\\\\\text{scalar by vector}\\\frac{\partial \mathbf a^T \mathbf{u}}{\partial \mathbf{x}}= \mathbf a^T \frac{\partial \mathbf u}{\partial \mathbf x}</script></li></ol><ol><li><p><strong>乘法法则</strong></p><script type="math/tex; mode=display">\text{vector by vector}\\\frac{\partial v \mathbf{u}}{\partial \mathbf{x}}=\quad v \frac{\partial \mathbf{u}}{\partial \mathbf{x}}+\mathbf{u} \frac{\partial v}{\partial \mathbf{x}}\\\\\text{scalar by vector}\\\frac{\partial \mathbf{u}^{\top} \mathbf{v}}{\partial \mathbf{x}}=\mathbf{u}^{\top} \frac{\partial \mathbf{v}}{\partial \mathbf{x}}+\mathbf{v}^{\top} \frac{\partial \mathbf{u}}{\partial \mathbf{x}}</script></li></ol><ol><li>链式法则。<script type="math/tex; mode=display">\text{vector by vector}\\\frac{\partial \mathbf{f}(\mathbf{g}(\mathbf{u}))}{\partial \mathbf{x}}=\frac{\partial \mathbf{f}(\mathbf{g})}{\partial \mathbf{g}} \frac{\partial \mathbf{g}(\mathbf{u})}{\partial \mathbf{u}} \frac{\partial \mathbf{u}}{\partial \mathbf{x}}\\\\\text{scalar by vector}\\\frac{\partial f(g(u))}{\partial \mathbf{x}}=\frac{\partial f(g)}{\partial g} \frac{\partial g(u)}{\partial u} \frac{\partial u}{\partial \mathbf{x}}</script></li></ol><ol><li>向量函数为逐元素计算，求导后变为对角矩阵<script type="math/tex; mode=display">\frac{\partial f(\mathbf x)}{\partial \mathbf x} = diag(f'(\mathbf x))</script></li></ol><ol><li>Scalar by matrix，仅给出下面一种形式，更高阶的将不再进行讨论<script type="math/tex; mode=display">\frac{\partial \mathbf{a}^{\top} \mathbf{X} \mathbf{b}}{\partial \mathbf{X}}=\mathbf{b a}^{\top}</script></li></ol><p>更加完善的矩阵求导体系可以参考 <a href="https://zhuanlan.zhihu.com/p/24709748">矩阵求导术</a>，当然我又是在挖坑了🤣，以后再来整理吧！</p><h2 id="数值稳定性和模型初始化"><a href="#数值稳定性和模型初始化" class="headerlink" title="数值稳定性和模型初始化"></a>数值稳定性和模型初始化</h2><p>在 MLP 的模型下，加入所有隐藏变量和输入都是向量，那么求解其中任一参数 W 的梯度将面临如下的过程（注意下面表达式 $W^t$ 其实不需要转置）</p><p><img src="/archives/fc6001ca/image-20211123190427465.png" alt="image-20211123190427465" style="zoom: 50%;"></p><p><img src="/archives/fc6001ca/image-20211123190439856.png" alt="image-20211123190439856" style="zoom: 50%;"></p><p>也就是说会有多个矩阵进行连续的相乘，如果没有一个很好的初始化，那么我们将会面临梯度爆炸或者梯度消失的情况。当然这也跟激活函数相关，ReLU 的设计将减缓部分梯度消失情况</p><h2 id="参数初始化"><a href="#参数初始化" class="headerlink" title="参数初始化"></a>参数初始化</h2><p>初始参数过大、过小会引起梯度爆炸/消失，初始参数全部取相同值也会导致优化时所有参数更新的值都是一样的（MLP 模型下）</p><p>使用正态分布来初始化权重值，对于中等规模的问题通常很有效。教材还介绍了另一种初始化方法 Xavier 初始化，可以参考 <a href="https://zhuanlan.zhihu.com/p/40175178#:~:text=Xavier%E5%88%9D%E5%A7%8B,%E5%85%8D%E6%A2%AF%E5%BA%A6%E5%BC%A5%E6%95%A3%E6%83%85%E5%86%B5%E3%80%82">知乎</a></p><h2 id="环境和分布偏移"><a href="#环境和分布偏移" class="headerlink" title="环境和分布偏移"></a>环境和分布偏移</h2><p>机器学习的许多应用中都存在类似的问题：通过将基于模型的决策引入环境，我们可能会破坏模型</p><h3 id="分布偏移的类型"><a href="#分布偏移的类型" class="headerlink" title="分布偏移的类型"></a>分布偏移的类型</h3><h4 id="协变量偏移"><a href="#协变量偏移" class="headerlink" title="协变量偏移"></a>协变量偏移</h4><p>在分布偏移的分类中，协变量偏移可能是研究的最广泛的。这里我们假设，虽然输入的分布可能随时间而改变，但标签函数，即条件分布 $P(y∣x)$ 没有改变。教材举了一个猫狗的例子</p><p><img src="/archives/fc6001ca/image-20211124125337960.png" style="zoom:50%;"></p><p><img src="/archives/fc6001ca/image-20211124125348173.png" style="zoom:50%;"></p><p>测试时的数据相比训练时发生了变化，但是标签的并没有改变</p><h4 id="标签偏移"><a href="#标签偏移" class="headerlink" title="标签偏移"></a>标签偏移</h4><p>标签偏移描述了与协变量偏移相反的问题。标签边缘概率 $P(y)$ 可以改变，但是类别条件分布 $P(x∣y)$ 在不同的领域之间保持不变。简单的理解就是样本标签/类别不均衡的问题</p><h4 id="概念偏移"><a href="#概念偏移" class="headerlink" title="概念偏移"></a>概念偏移</h4><p>当标签的定义发生变化时，就会出现这种问题，通俗一点说是说我们可以指猫为”狗“。从数学上来说，是输入的边缘分布相同，标签的边缘分布也相同：$p_s(x)=p_t(x),p_s(y)=p_t(y)$，但是条件分布不同：$p_s(y|x)≠p_t(y|x)$</p><h3 id="分布偏移纠正"><a href="#分布偏移纠正" class="headerlink" title="分布偏移纠正"></a>分布偏移纠正</h3><p>主要是通过纠正损失函数的偏移来解决这个问题，具体来说就是给损失函数加权，这就要使用测试集中的样本分布了。而且教材也提到：不耐烦的读者可以继续下一节，因为这些内容不是后续概念的先修内容，而我就是不耐烦的那一批😁</p><p><img src="/archives/fc6001ca/image-20211124143457101.png" style="zoom:80%;"></p><h3 id="机器学习中的公平、责任和透明度"><a href="#机器学习中的公平、责任和透明度" class="headerlink" title="机器学习中的公平、责任和透明度"></a>机器学习中的公平、责任和透明度</h3><p>这部分讲了一些道德伦理困境。教材原文：通常，在建模纠正过程中，模型的预测与训练数据耦合的各种机制都没有得到解释。这可能导致研究人员称之为“失控反馈循环”的现象</p><p>就像一个正反馈机制一样，比如在一个推荐系统中，你会被推荐越来越多相似的内容；而在一个犯罪预警系统中，某一个社区或者某一类人将会被越来越针对</p>]]></content>
      
      
      <categories>
          
          <category> 课程 </category>
          
          <category> Dive into deep learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Dive into deep learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>D2L 03 线性神经网络</title>
      <link href="/archives/56c94983.html"/>
      <url>/archives/56c94983.html</url>
      
        <content type="html"><![CDATA[<h1 id="D2L-03-线性神经网络"><a href="#D2L-03-线性神经网络" class="headerlink" title="D2L 03 线性神经网络"></a>D2L 03 线性神经网络</h1><p>在本章中，我们将介绍神经网络的整个训练过程，包括：定义简单的神经网络架构、数据处理、指定损失函数和如何训练模型</p><p>经典统计学习技术中的线性回归和softmax回归可以视为线性神经网络</p><h2 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h2><p>几个基本的概念</p><ul><li>数据集 $X \in \mathbb R^{n\times d}$</li><li>样本，特征/协变量</li><li>标签/目标 $y \in R^n$</li></ul><h3 id="线性模型"><a href="#线性模型" class="headerlink" title="线性模型"></a>线性模型</h3><p>使用仿射变换得到预测值 $\hat{\bold y}$</p><script type="math/tex; mode=display">\hat{\bold y} = \bold X\bold w+b</script><p>$\bold w\in R^d$，$b$ 是一个标量</p><h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p>MSE（Mean Square Error）</p><script type="math/tex; mode=display">L(\mathbf{w}, b)=\frac{1}{n} \sum_{i=1}^{n} l^{(i)}(\mathbf{w}, b)=\frac{1}{n} \sum_{i=1}^{n} \frac{1}{2}\left(\mathbf{w}^{\top} \mathbf{x}^{(i)}+b-y^{(i)}\right)^{2}</script><p>希望寻找一组参数使得损失函数最小</p><script type="math/tex; mode=display">\mathbf{w}^{*}, b^{*}=\underset{\mathbf{w}, b}{\operatorname{argmin}} L(\mathbf{w}, b)</script><p>简单的线性问题可以有解析解，但一般深度学习的问题中很难找到解析解</p><h3 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h3><p>小批量随机梯度下降</p><p>学到这里，我已经感受到大部分深度学习教材的数学都没有进行深入的挖掘，其核心在于”动手”，通过简单的叙述和代码，让人们入门深度学习，有一个整体的认识，知道深度学习能够干什么</p><p>但是真正的深入：概率论，信息论，线性代数（矩阵求导），机器学习等所有的核心知识，都有所欠缺，所以现在改变策略，将不进行细致的整理，仅记录我认为有用的部分，并进行适当扩充。主要目的为编程练习</p><h3 id="正态分布与平方损失"><a href="#正态分布与平方损失" class="headerlink" title="正态分布与平方损失"></a>正态分布与平方损失</h3><p>在高斯噪声的假设下，最小化均方误差等价于对线性模型的最大似然估计</p><p><img src="/archives/56c94983/image-20211116151118056.png" style="zoom: 80%;"></p><h3 id="线性回归-pytorch-实现"><a href="#线性回归-pytorch-实现" class="headerlink" title="线性回归 pytorch 实现"></a>线性回归 pytorch 实现</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> torch<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils <span class="token keyword">import</span> data<span class="token comment"># 定义随机种子</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">synthetic_data</span><span class="token punctuation">(</span>w<span class="token punctuation">,</span> b<span class="token punctuation">,</span> num_examples<span class="token punctuation">)</span><span class="token punctuation">:</span>    X <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>num_examples<span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>w<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    y <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>X<span class="token punctuation">,</span> w<span class="token punctuation">)</span> <span class="token operator">+</span> b    y <span class="token operator">+=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0.01</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>    X<span class="token punctuation">,</span> y <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>    <span class="token keyword">return</span> X<span class="token punctuation">,</span> y<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>true_w <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">3.4</span><span class="token punctuation">]</span><span class="token punctuation">)</span>true_b <span class="token operator">=</span> <span class="token number">4.2</span>features<span class="token punctuation">,</span> labels <span class="token operator">=</span> synthetic_data<span class="token punctuation">(</span>true_w<span class="token punctuation">,</span> true_b<span class="token punctuation">,</span> <span class="token number">1000</span><span class="token punctuation">)</span><span class="token comment"># 读取数据集</span><span class="token keyword">def</span> <span class="token function">load_array</span><span class="token punctuation">(</span>data_arrays<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> is_train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment">#@save</span>    <span class="token triple-quoted-string string">"""构造一个PyTorch数据迭代器。"""</span>    dataset <span class="token operator">=</span> data<span class="token punctuation">.</span>TensorDataset<span class="token punctuation">(</span><span class="token operator">*</span>data_arrays<span class="token punctuation">)</span>    <span class="token keyword">return</span> data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> shuffle<span class="token operator">=</span>is_train<span class="token punctuation">)</span>batch_size <span class="token operator">=</span> <span class="token number">10</span>data_iter <span class="token operator">=</span> load_array<span class="token punctuation">(</span><span class="token punctuation">(</span>features<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span><span class="token comment"># 定义模型</span><span class="token keyword">from</span> torch <span class="token keyword">import</span> nnnet <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># 初始化参数</span>net<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>weight<span class="token punctuation">.</span>data<span class="token punctuation">.</span>normal_<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0.01</span><span class="token punctuation">)</span>net<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>bias<span class="token punctuation">.</span>data<span class="token punctuation">.</span>fill_<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token comment"># 定义损失函数</span>loss <span class="token operator">=</span> nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># 定义优化算法</span>trainer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.03</span><span class="token punctuation">)</span><span class="token comment"># 训练</span>num_epochs <span class="token operator">=</span> <span class="token number">3</span><span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">for</span> X<span class="token punctuation">,</span> y <span class="token keyword">in</span> data_iter<span class="token punctuation">:</span>        l <span class="token operator">=</span> loss<span class="token punctuation">(</span>net<span class="token punctuation">(</span>X<span class="token punctuation">)</span> <span class="token punctuation">,</span>y<span class="token punctuation">)</span>        trainer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>        l<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        trainer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>    l <span class="token operator">=</span> loss<span class="token punctuation">(</span>net<span class="token punctuation">(</span>features<span class="token punctuation">)</span><span class="token punctuation">,</span> labels<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'epoch </span><span class="token interpolation"><span class="token punctuation">{</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">}</span></span><span class="token string">, loss </span><span class="token interpolation"><span class="token punctuation">{</span>l<span class="token punctuation">:</span><span class="token format-spec">f</span><span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>学习点：</p><ol><li><code>torch.Tensor.to(torch.float32)</code> <a href="https://pytorch.org/docs/stable/generated/torch.Tensor.to.html">doc</a> 既可以转换类型，又可以转换 cpu/gpu 设备</li><li><p>可以通过序号 <code>net[idx].weight</code> 访问 <code>nn.Sequential</code> 中指定网络层的参数</p></li><li><p>关于 <a href="https://pytorch.org/tutorials/beginner/nn_tutorial.html">torch.nn</a></p></li></ol><h2 id="Softmax-回归"><a href="#Softmax-回归" class="headerlink" title="Softmax 回归"></a>Softmax 回归</h2><h3 id="One-hot-编码"><a href="#One-hot-编码" class="headerlink" title="One-hot 编码"></a>One-hot 编码</h3><p>编码是一个向量，它的分量和类别一样多。类别对应的分量设置为1，其他所有分量设置为0</p><h3 id="Softmax-运算"><a href="#Softmax-运算" class="headerlink" title="Softmax 运算"></a>Softmax 运算</h3><p>假设有一个样本，输入为 o，分类数量为 q，预测值为 y</p><p><img src="/archives/56c94983/image-20211116170343558.png" style="zoom:80%;"></p><p>尽管 softmax 是一个非线性函数，但 softmax 回归的输出仍然由输入特征的仿射变换决定。因此，softmax 回归是一个线性模型</p><h3 id="损失函数-1"><a href="#损失函数-1" class="headerlink" title="损失函数"></a>损失函数</h3><p><img src="/archives/56c94983/image-20211116170647087.png" style="zoom:80%;"></p><p>以上为似然函数，也被常称为（多分类）交叉熵损失。交叉熵是一个衡量两个概率分布之间差异的很好的度量。它测量给定模型编码数据所需的比特数</p><h4 id="Softmax-及其导数"><a href="#Softmax-及其导数" class="headerlink" title="Softmax 及其导数"></a>Softmax 及其导数</h4><p>将 softmax 的公式带入到损失函数中并求导</p><p><img src="/archives/56c94983/image-20211116172439239.png" style="zoom:80%;"></p><p>导数是我们模型分配的概率（由 softmax 得到）与实际发生的情况（由独热标签向量表示）之间的差异。从这个意义上讲，与我们在回归中看到的非常相似</p><h3 id="Fashion-MNIST-数据集"><a href="#Fashion-MNIST-数据集" class="headerlink" title="Fashion-MNIST 数据集"></a>Fashion-MNIST 数据集</h3><p>这一小节介绍了如何从 pytorch api 加载该数据集</p><h3 id="Softmax-Pytorch-实现"><a href="#Softmax-Pytorch-实现" class="headerlink" title="Softmax Pytorch 实现"></a>Softmax Pytorch 实现</h3><h4 id="上溢下溢问题"><a href="#上溢下溢问题" class="headerlink" title="上溢下溢问题"></a>上溢下溢问题</h4><p>如何解决 exp 上溢和 log 下溢问题？</p><ol><li>softmax 上下同时除以 exp(max(x)) 可以解决上溢问题。但当 exp(max(x)) 比较大 (&gt;1000) 时，softmax 会直接返回 0，再进入 log 函数就会产生下溢</li><li>解决方法是直接输入 logits 输出交叉熵，即不经过 softmax 运算。因为 log 和 exp 是一对反函数，它们可以相互抵消，log(exp(x)) = x</li></ol><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>dataloader <span class="token keyword">import</span> DataLoader<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>sampler <span class="token keyword">import</span> SubsetRandomSampler<span class="token keyword">from</span>  torchvision <span class="token keyword">import</span> datasets<span class="token keyword">from</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">import</span> SGD<span class="token keyword">from</span> torchvision<span class="token punctuation">.</span>transforms <span class="token keyword">import</span> ToTensor<span class="token keyword">import</span> timetraining_data <span class="token operator">=</span> datasets<span class="token punctuation">.</span>FashionMNIST<span class="token punctuation">(</span>    root<span class="token operator">=</span><span class="token string">"./data"</span><span class="token punctuation">,</span>    train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>    download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>    transform<span class="token operator">=</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>test_data <span class="token operator">=</span> datasets<span class="token punctuation">.</span>FashionMNIST<span class="token punctuation">(</span>    root<span class="token operator">=</span><span class="token string">"./data"</span><span class="token punctuation">,</span>    train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>    download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>    transform<span class="token operator">=</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">'cuda'</span><span class="token punctuation">)</span>batch_size <span class="token operator">=</span> <span class="token number">256</span>NUM_TRAIN <span class="token operator">=</span> <span class="token number">1000</span>sampler <span class="token operator">=</span> SubsetRandomSampler<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span>NUM_TRAIN<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># 暂时先不用 sampler</span>train_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>training_data<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">)</span><span class="token comment"># PyTorch不会隐式地调整输入的形状。因此，</span><span class="token comment"># 我们在线性层前定义了展平层（flatten），来调整网络输入的形状</span>net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">784</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>net<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">init_weights</span><span class="token punctuation">(</span>m<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">if</span> <span class="token builtin">type</span><span class="token punctuation">(</span>m<span class="token punctuation">)</span> <span class="token operator">==</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">:</span>        nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>normal_<span class="token punctuation">(</span>m<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> std<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>net<span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span>init_weights<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment"># 损失函数并移动到 GPU</span><span class="token comment"># input is logits, i.e. raw scores</span>loss <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>loss<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>optim <span class="token operator">=</span> SGD<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">eval</span><span class="token punctuation">(</span>output<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">,</span> label<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">)</span><span class="token punctuation">:</span>    pred <span class="token operator">=</span> output<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>    acc_num <span class="token operator">=</span> <span class="token punctuation">(</span>pred<span class="token punctuation">.</span>to<span class="token punctuation">(</span>label<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span> <span class="token operator">==</span> label<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">return</span> acc_num <span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>model<span class="token punctuation">:</span> nn<span class="token punctuation">.</span>Module<span class="token punctuation">,</span> train_loader<span class="token punctuation">,</span> epochs<span class="token punctuation">,</span> optim<span class="token punctuation">:</span> SGD<span class="token punctuation">,</span> loss_fn<span class="token punctuation">)</span><span class="token punctuation">:</span>    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>        start <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>        loss <span class="token operator">=</span> <span class="token number">0</span>        acc_num <span class="token operator">=</span> <span class="token number">0</span>        <span class="token keyword">for</span> data<span class="token punctuation">,</span> label <span class="token keyword">in</span> train_loader<span class="token punctuation">:</span>            <span class="token comment"># 将 data 移入 GPU</span>            data <span class="token operator">=</span> data<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>            label <span class="token operator">=</span> label<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>            output <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">)</span>            loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>output<span class="token punctuation">,</span> label<span class="token punctuation">)</span>            optim<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>            loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>            optim<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>            acc_num <span class="token operator">+=</span> <span class="token builtin">eval</span><span class="token punctuation">(</span>output<span class="token punctuation">,</span> label<span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'epoch: </span><span class="token interpolation"><span class="token punctuation">{</span>epoch<span class="token punctuation">}</span></span><span class="token string">, loss: </span><span class="token interpolation"><span class="token punctuation">{</span>loss<span class="token punctuation">:</span><span class="token format-spec">.4f</span><span class="token punctuation">}</span></span><span class="token string">, train_acc: </span><span class="token interpolation"><span class="token punctuation">{</span>acc_num <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>training_data<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">.2f</span><span class="token punctuation">}</span></span><span class="token string">, time:</span><span class="token interpolation"><span class="token punctuation">{</span>time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span>start<span class="token punctuation">:</span><span class="token format-spec">.2f</span><span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>train<span class="token punctuation">(</span>net<span class="token punctuation">,</span> train_loader<span class="token punctuation">,</span> epochs<span class="token operator">=</span><span class="token number">80</span><span class="token punctuation">,</span> optim<span class="token operator">=</span>optim<span class="token punctuation">,</span> loss_fn<span class="token operator">=</span>loss<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>自己写一个 softmax 实现，最终结果与官方差不多，以下结果来自自己，图像来自官方</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">epoch: <span class="token number">0</span>, loss: <span class="token number">0.983296</span>, train_acc: <span class="token number">0.64</span>, time:4.58epoch: <span class="token number">1</span>, loss: <span class="token number">0.797371</span>, train_acc: <span class="token number">0.72</span>, time:4.47epoch: <span class="token number">2</span>, loss: <span class="token number">0.712272</span>, train_acc: <span class="token number">0.75</span>, time:4.44epoch: <span class="token number">3</span>, loss: <span class="token number">0.660301</span>, train_acc: <span class="token number">0.77</span>, time:4.40epoch: <span class="token number">4</span>, loss: <span class="token number">0.624506</span>, train_acc: <span class="token number">0.78</span>, time:4.49epoch: <span class="token number">5</span>, loss: <span class="token number">0.598148</span>, train_acc: <span class="token number">0.79</span>, time:4.52epoch: <span class="token number">6</span>, loss: <span class="token number">0.577858</span>, train_acc: <span class="token number">0.80</span>, time:4.58epoch: <span class="token number">7</span>, loss: <span class="token number">0.561719</span>, train_acc: <span class="token number">0.80</span>, time:4.59epoch: <span class="token number">8</span>, loss: <span class="token number">0.548546</span>, train_acc: <span class="token number">0.80</span>, time:4.45epoch: <span class="token number">9</span>, loss: <span class="token number">0.537567</span>, train_acc: <span class="token number">0.81</span>, time:4.43epoch: <span class="token number">10</span>, loss: <span class="token number">0.528253</span>, train_acc: <span class="token number">0.81</span>, time:4.50<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/archives/56c94983/output_softmax-regression-concise_75d138_51_0.svg" style="zoom:80%;"></p><p>学习点：</p><ol><li>在实现过程中发现了 <code>add_module</code> 的作用，相当于在 <code>__init__</code> 中使用了 <code>self.module_name = nn.xxx</code>，即把一个模块注册到当前模型中，成为该模型的 children / 子模块。在之后的训练中将会更新这个模块的参数，并且该模块也能作为属性被模型访问 <code>model.module_name</code></li><li>通过 <code>nn.init</code> 模块可以对模型参数进行初始化</li><li>通过 <code>nn.apply(fn)</code> 循环地对所有子模型 <code>model.children()</code> 进行操作</li><li>需要将模型和数据都转移到相同的设备上才能进行运算，如果损失函数也是 <code>nn.Module</code> 的子类，则也需要转移</li></ol><h3 id="补充：为什么使用-CE-进行分类而不使用-MSE"><a href="#补充：为什么使用-CE-进行分类而不使用-MSE" class="headerlink" title="补充：为什么使用 CE 进行分类而不使用 MSE"></a>补充：为什么使用 CE 进行分类而不使用 MSE</h3><ol><li><p>从梯度角度来看。分类问题的输出通常经过 sigmoid or softmax 函数，以 sigmoid 函数为例，函数的两端会非常非常的平缓，这就会导致梯度消失，网络无法进一步优化</p></li><li><p>交叉熵就是用于衡量两个分布之间的相似度。这里又要提一句 KL 散度和交叉熵之间的关系与区别：<strong>KL 散度可以被用于计算两个分布的差异，而在特定情况下最小化 KL 散度等价于最小化交叉熵。而交叉熵的运算更简单，所以用交叉熵来当做代价</strong>。再贴几个公式</p><script type="math/tex; mode=display">S(v)=-\sum_{i} p\left(v_{i}\right) \log p\left(v_{i}\right)\\D_{K L}(A \| B)=\sum_{i} p_{A}\left(v_{i}\right) \log p_{A}\left(v_{i}\right)-p_{A}\left(v_{i}\right) \log p_{B}\left(v_{i}\right)\\H(A, B)=-\sum_{i} p_{A}\left(v_{i}\right) \log p_{B}\left(v_{i}\right)\\H(A, B)=D_{K L}(A \| B)+S_{A}</script><p>当 $S_A$ 为常数时，优化交叉熵等价于优化 KL 散度。最后提一句通过 Jensen 不等式可证明 KL 散度大于0</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 课程 </category>
          
          <category> Dive into deep learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Dive into deep learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Matplotlib 拓展</title>
      <link href="/archives/ea21061e.html"/>
      <url>/archives/ea21061e.html</url>
      
        <content type="html"><![CDATA[<h1 id="Matplotlib-拓展"><a href="#Matplotlib-拓展" class="headerlink" title="Matplotlib 拓展"></a>Matplotlib 拓展</h1><p><a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.html#module-matplotlib.pyplot">pyplot api doc</a> 放一个 api 链接，便于查找 api</p><h2 id="Axis-limit"><a href="#Axis-limit" class="headerlink" title="Axis limit"></a>Axis limit</h2><p>有两个推荐的方法</p><ol><li><code>plt.xlim(left, right)</code>，<a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.xlim.html?highlight=pyplot%20xlim#matplotlib.pyplot.xlim">xlim doc</a></li><li><code>plt.axis([xmin, xmax, ymin, ymax])</code>，<a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.axis.html#matplotlib.pyplot.axis">axis doc</a>，通过 <code>plt.axis(False)</code> 也可以不显示坐标轴及其标签</li></ol><p>axis 除了范围可以设置，其 tick 也可设置，<code>plt.xticks(ticks=, labels=)</code> <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.xticks.html#matplotlib.pyplot.xticks">xticks doc</a></p><p>补充：将 y 轴进行反转 <code>plt.gca().invert_yaxis()</code></p><h2 id="Text"><a href="#Text" class="headerlink" title="Text"></a>Text</h2><div class="table-container"><table><thead><tr><th><a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.html#module-matplotlib.pyplot"><code>pyplot</code></a> API</th><th>OO API</th><th>description</th></tr></thead><tbody><tr><td><a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.text.html#matplotlib.pyplot.text"><code>text</code></a></td><td><a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.text.html#matplotlib.axes.Axes.text"><code>text</code></a></td><td>Add text at an arbitrary location of the <a href="https://matplotlib.org/stable/api/axes_api.html#matplotlib.axes.Axes"><code>Axes</code></a>.</td></tr><tr><td><a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.annotate.html#matplotlib.pyplot.annotate"><code>annotate</code></a></td><td><a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.annotate.html#matplotlib.axes.Axes.annotate"><code>annotate</code></a></td><td>Add an annotation, with an optional arrow, at an arbitrary location of the <a href="https://matplotlib.org/stable/api/axes_api.html#matplotlib.axes.Axes"><code>Axes</code></a>.</td></tr><tr><td><a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.xlabel.html#matplotlib.pyplot.xlabel"><code>xlabel</code></a></td><td><a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.set_xlabel.html#matplotlib.axes.Axes.set_xlabel"><code>set_xlabel</code></a></td><td>Add a label to the <a href="https://matplotlib.org/stable/api/axes_api.html#matplotlib.axes.Axes"><code>Axes</code></a>‘s x-axis.</td></tr><tr><td><a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.ylabel.html#matplotlib.pyplot.ylabel"><code>ylabel</code></a></td><td><a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.set_ylabel.html#matplotlib.axes.Axes.set_ylabel"><code>set_ylabel</code></a></td><td>Add a label to the <a href="https://matplotlib.org/stable/api/axes_api.html#matplotlib.axes.Axes"><code>Axes</code></a>‘s y-axis.</td></tr><tr><td><a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.title.html#matplotlib.pyplot.title"><code>title</code></a></td><td><a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.set_title.html#matplotlib.axes.Axes.set_title"><code>set_title</code></a></td><td>Add a title to the <a href="https://matplotlib.org/stable/api/axes_api.html#matplotlib.axes.Axes"><code>Axes</code></a>.</td></tr><tr><td><a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.figtext.html#matplotlib.pyplot.figtext"><code>figtext</code></a></td><td><a href="https://matplotlib.org/stable/api/figure_api.html#matplotlib.figure.Figure.text"><code>text</code></a></td><td>Add text at an arbitrary location of the <a href="https://matplotlib.org/stable/api/figure_api.html#matplotlib.figure.Figure"><code>Figure</code></a>.</td></tr><tr><td><a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.suptitle.html#matplotlib.pyplot.suptitle"><code>suptitle</code></a></td><td><a href="https://matplotlib.org/stable/api/figure_api.html#matplotlib.figure.Figure.suptitle"><code>suptitle</code></a></td><td>Add a title to the <a href="https://matplotlib.org/stable/api/figure_api.html#matplotlib.figure.Figure"><code>Figure</code></a>.</td></tr></tbody></table></div><p>这些应该都返回一个 <code>Text</code> 文字对象，当然也拥有 <code>Text</code> 对象的各个属性，下面列举一些常用的属性</p><ol><li><code>color</code></li><li><code>fontsize</code></li><li><code>fontweight</code> 调整字体粗细 ‘ultralight’, ‘light’, ‘normal’, ‘regular’, ‘bold’, ‘extra bold’, ‘black’</li><li><code>fontfamily</code> 规定字体家族，可以更改字体</li><li><code>fontstyle</code> 可以使用斜体 <code>italic</code></li><li><code>alpha</code> 透明度，0~1之间，1为完全不透明</li><li><code>bbox</code> 给文字增加外框，其值为一个字典，常用 <code>dict(boxstyle='', facecolor='', edgecolor='')</code>，其中 <code>boxstyle</code> 取值请参考 <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.patches.FancyBboxPatch.html#matplotlib-patches-fancybboxpatch">link</a>，默认为 square 也常用 round</li></ol><p>下面看看这些 API 有哪些必要参数，通过一个例子了解</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> matplotlib<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> pltfig <span class="token operator">=</span> plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># Set titles for the figure and the subplot respectively</span>plt<span class="token punctuation">.</span>suptitle<span class="token punctuation">(</span><span class="token string">'bold figure suptitle'</span><span class="token punctuation">,</span> fontsize<span class="token operator">=</span><span class="token number">14</span><span class="token punctuation">,</span> fontweight<span class="token operator">=</span><span class="token string">'bold'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'pltes title'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'xlabel'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'ylabel'</span><span class="token punctuation">)</span><span class="token comment"># Set both x- and y-pltis limits to [0, 10] instead of default [0, 1]</span>plt<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>text<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token string">'boxed italics text in data coords'</span><span class="token punctuation">,</span> style<span class="token operator">=</span><span class="token string">'italic'</span><span class="token punctuation">,</span>        bbox<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">'facecolor'</span><span class="token punctuation">:</span> <span class="token string">'red'</span><span class="token punctuation">,</span> <span class="token string">'alpha'</span><span class="token punctuation">:</span> <span class="token number">0.5</span><span class="token punctuation">}</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>text<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token string">r'an equation: $E=mc^2$'</span><span class="token punctuation">,</span> fontsize<span class="token operator">=</span><span class="token number">15</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>text<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token string">'unicode: Institut für Festkörperphysik'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/archives/ea21061e/image-20211115155638742.png" style="zoom:67%;"></p><h2 id="Legend-amp-annotate"><a href="#Legend-amp-annotate" class="headerlink" title="Legend &amp; annotate"></a>Legend &amp; annotate</h2><p><code>label</code> 其实是各个 <code>Artist</code> 对象都拥有的属性，在使用 <code>plt.plot()</code> 类似的方法来绘图的时候，可以直接在参数里使用 <code>label=</code> 以创造该绘图对象的标签。而 <code>legend</code> 可以用于将 <code>label</code> 以图例形式加入到 figure 当中，参考 <a href="https://zhuanlan.zhihu.com/p/111108841">知乎</a>, <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.legend.html#matplotlib.pyplot.legend">legend doc</a>,  <a href="https://matplotlib.org/stable/tutorials/introductory/customizing.html#matplotlib-rcparams">about matplotlib.rcParams</a></p><p>也可以对图像中的某些点进行标记，使用 <code>annotate()</code> 方法即可，<a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.annotate.html#matplotlib.pyplot.annotate">annotate doc</a></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token comment"># 设置默认字体以显示中文</span>plt<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">'font.family'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'HarmonyOS Sans SC'</span><span class="token punctuation">]</span>n <span class="token operator">=</span> np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">)</span>m1 <span class="token operator">=</span> <span class="token number">3</span> <span class="token operator">*</span> n <span class="token operator">+</span> <span class="token number">2</span>m2 <span class="token operator">=</span> n <span class="token operator">**</span> <span class="token number">2</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'时间'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'心情'</span><span class="token punctuation">)</span>line1<span class="token punctuation">,</span> <span class="token operator">=</span> plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>n<span class="token punctuation">,</span> m1<span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'r'</span><span class="token punctuation">,</span> linewidth<span class="token operator">=</span><span class="token number">1.5</span><span class="token punctuation">,</span> linestyle<span class="token operator">=</span><span class="token string">'-'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'女生购物欲望'</span><span class="token punctuation">)</span>line2<span class="token punctuation">,</span> <span class="token operator">=</span> plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>n<span class="token punctuation">,</span> m2<span class="token punctuation">,</span> <span class="token string">'b'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'男生购物欲望'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span>handles<span class="token operator">=</span><span class="token punctuation">[</span>line1<span class="token punctuation">,</span> line2<span class="token punctuation">]</span><span class="token punctuation">,</span> labels<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'girl购物欲望'</span><span class="token punctuation">,</span><span class="token string">'boy购物欲望'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> loc<span class="token operator">=</span><span class="token string">'best'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>annotate<span class="token punctuation">(</span><span class="token string">'bottom'</span><span class="token punctuation">,</span> xy<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> xytext<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> arrowprops<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>color<span class="token operator">=</span><span class="token string">'black'</span><span class="token punctuation">,</span> shrink<span class="token operator">=</span><span class="token number">0.05</span><span class="token punctuation">)</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/archives/ea21061e/image-20211115163146776.png" style="zoom:67%;"></p><h2 id="Image"><a href="#Image" class="headerlink" title="Image"></a>Image</h2><p>在目标检测中，经常使用 bbox 对目标进行框选，并进行类别标注，这些都是可以通过 matplotlib 做到的。一般的图像在计算机视觉中，被处理为一个 (H, W, C) 的三维张量，其中 C 通常为 3，在 matplotlib 中可以使用 <code>matplotlib.image</code> 包处理图像，然后使用 <code>plt.imshow()</code> 绘制图像，<a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.imshow.html#matplotlib.pyplot.imshow">imshow doc</a></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>image <span class="token keyword">as</span> mpimgimg <span class="token operator">=</span> mpimg<span class="token punctuation">.</span>imread<span class="token punctuation">(</span><span class="token string">'test.png'</span><span class="token punctuation">)</span><span class="token comment"># img = plt.imread('test.png')</span>plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>img<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># 修改原点</span>plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>img<span class="token punctuation">,</span> origin<span class="token operator">=</span><span class="token string">'lower'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># 修改透明度</span>plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>img<span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token comment"># 在 img 上绘图</span>x <span class="token operator">=</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>img<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>k <span class="token operator">=</span> img<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">/</span> img<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>y <span class="token operator">=</span> k <span class="token operator">*</span> xplt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'red'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/archives/ea21061e/image-20211115174301946.png" style="zoom: 67%;"></p><p>除了绘制函数，一般的几何图形也能够绘制，一般使用 patches 对象，具体操作可参考 <a href="https://www.jianshu.com/p/8d14238d402a">简书</a></p>]]></content>
      
      
      <categories>
          
          <category> 编程 </category>
          
          <category> Python </category>
          
          <category> Package </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Matplotlib </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Matplotlib</title>
      <link href="/archives/d1e3c468.html"/>
      <url>/archives/d1e3c468.html</url>
      
        <content type="html"><![CDATA[<h1 id="Matplotlib"><a href="#Matplotlib" class="headerlink" title="Matplotlib"></a>Matplotlib</h1><p>不多解释，python 超强的可视化工具，学就完事儿了，参考 <a href="https://matplotlib.org/stable/tutorials/index.html">official tutorial</a></p><h2 id="Usage-Guide"><a href="#Usage-Guide" class="headerlink" title="Usage Guide"></a>Usage Guide</h2><h3 id="A-simple-example"><a href="#A-simple-example" class="headerlink" title="A simple example"></a>A simple example</h3><p>Matplotlib 的图都是在 <a href="https://matplotlib.org/stable/api/figure_api.html##matplotlib.figure.Figure"><code>Figure</code></a>s 上绘制的，每个 Figure 都可以包含一个或多个 <a href="https://matplotlib.org/stable/api/axes_api.html##matplotlib.axes.Axes"><code>Axes</code></a>。然后我们可以使用 <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.plot.html##matplotlib.axes.Axes.plot"><code>Axes.plot</code></a> 在轴上绘制一些数据，使用 axes 创建图形的最简单方法是使用<a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.subplots.html##matplotlib.pyplot.subplots"><code>pyplot.subplots</code></a> （Axes 概念比较抽象，这里就把它们当作一个个的子图好了，subfigure）</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token keyword">import</span> numpy <span class="token keyword">as</span> npfig<span class="token punctuation">,</span> ax <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment">## Create a figure containing a single axes.</span>ax<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment">## Plot some data on the axes.</span><span class="token comment"># plt.show()</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这种方式取名叫 <code>object-oriented style or OO-style</code></p><p><img src="/archives/d1e3c468/sphx_glr_usage_001.png" style="zoom:50%;"></p><p>除了使用 Axes 绘图以外，matplotlib 还可以使用 <code>plt.plot()</code> 进行绘图，它会在“当前” Axes 上执行该绘图，如果它们不存在则创建该 Axes，所以上面的图像可以用下面的代码</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment">## Matplotlib plot.</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>为这种方式取名叫 <code>pyplot-style</code> 目前比较流行这种方式，同时现在也不推荐使用 <code>pylab</code> 进行绘图</p><h3 id="Matplotlib-basic-concept"><a href="#Matplotlib-basic-concept" class="headerlink" title="Matplotlib basic concept"></a>Matplotlib basic concept</h3><ol><li><p>Figure</p><p>可以把 figure 当成一个画布，这个画布可以画任意数量的 Axes</p></li><li><p>Axes</p><p>把 Axes 当成一个小画布</p></li><li><p>Axis</p><p>可以理解为图像里的坐标轴，确定函数取值范围</p></li><li><p>Artist</p><p>基本上任何你看到的东西都是 artist 类，包括 Text objects, Axes, Line2D objects…所有的 artist 都会被画到画布中</p></li></ol><p>最好使用 numpy.array 作为函数的输入，其他类型的变量可能不能很好地处理</p><h3 id="Interactive-mode"><a href="#Interactive-mode" class="headerlink" title="Interactive mode"></a>Interactive mode</h3><p>可以使用交互模式，看到每一个画图的效果，可以使用 ipython 进行交互</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> pltplt<span class="token punctuation">.</span>ion<span class="token punctuation">(</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1.6</span><span class="token punctuation">,</span> <span class="token number">2.7</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment">## a window should show</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"interactive test"</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">"index"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>如果是没有指明交互模式，则需要使用 <code>plt.show()</code> 让绘制的图像显示</p><h3 id="Performance"><a href="#Performance" class="headerlink" title="Performance"></a>Performance</h3><p>如果感觉渲染得很慢的话，可以是使用 fast style</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>style <span class="token keyword">as</span> mplstylemplstyle<span class="token punctuation">.</span>use<span class="token punctuation">(</span><span class="token string">'fast'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>如果有多个 style 的话，确保 fast style 在最后，以保证不被其他 style 修改</p><h2 id="Pyplot-tutorial"><a href="#Pyplot-tutorial" class="headerlink" title="Pyplot tutorial"></a>Pyplot tutorial</h2><p><code>matplotlib.pyplot</code> 包含了各种各样的接口，能够让用户轻松地绘图，下面引用一下官方文档</p><blockquote><p>Each <code>pyplot</code> function makes some change to a figure: e.g., creates a figure, creates a plotting area in a figure, plots some lines in a plotting area, decorates the plot with labels, etc.</p><p> It keeps track of things like the current figure and plotting area, and the plotting functions are directed to the current axes.</p></blockquote><h3 id="Intro-to-pyplot"><a href="#Intro-to-pyplot" class="headerlink" title="Intro to pyplot"></a>Intro to pyplot</h3><p>绘制简单映射函数 $y = f(x)$ 图像可以使用 <code>plt.plot</code>，详细内容推荐 <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.plot.html#matplotlib.pyplot.plot">plot doc</a> </p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> pltplt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'some numbers'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/archives/d1e3c468/sphx_glr_pyplot_001.png" style="zoom: 67%;"></p><p>只传入一个参数，自动使用其 index 作为 x 轴，常用公式为如下</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token operator">=</span><span class="token punctuation">,</span> y<span class="token operator">=</span><span class="token punctuation">,</span> fmt<span class="token operator">=</span><span class="token string">'b-'</span><span class="token punctuation">)</span><span class="token comment"># fmt 代表 format 'b-' 代表蓝色直线，为默认值，其它 format 如 'ro' 代表红色圆点</span><span class="token comment"># x, y 可以是二维的，这样将绘画多个函数图像</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h4 id="Formatting-the-style-of-your-plot"><a href="#Formatting-the-style-of-your-plot" class="headerlink" title="Formatting the style of your plot"></a>Formatting the style of your plot</h4><p>实际上 <code>plt.plot</code> 可以接受任意多的参数，以绘画任意多个函数图像</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token comment"># evenly sampled time at 200ms intervals</span>t <span class="token operator">=</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">)</span><span class="token comment"># red dashes, blue squares and green triangles</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>t<span class="token punctuation">,</span> t<span class="token punctuation">,</span> <span class="token string">'r--'</span><span class="token punctuation">,</span> t<span class="token punctuation">,</span> t<span class="token operator">**</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token string">'bs'</span><span class="token punctuation">,</span> t<span class="token punctuation">,</span> t<span class="token operator">**</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token string">'g^'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/archives/d1e3c468/sphx_glr_pyplot_004.png" style="zoom: 67%;"></p><h3 id="Plotting-with-keyword-strings"><a href="#Plotting-with-keyword-strings" class="headerlink" title="Plotting with keyword strings"></a>Plotting with keyword strings</h3><p>如果有 <code>data_dict</code> 存放着数据，则可以直接通过 <code>data_dict</code> 和其中的关键字绘图，下面使用了 <code>plt.scatter</code> 来绘制一个散点图，<a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.scatter.html?highlight=scatter#matplotlib.pyplot.scatter">scatter doc</a></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">data <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'a'</span><span class="token punctuation">:</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">50</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token string">'c'</span><span class="token punctuation">:</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">50</span><span class="token punctuation">,</span> <span class="token number">50</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token string">'d'</span><span class="token punctuation">:</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">50</span><span class="token punctuation">)</span><span class="token punctuation">}</span>data<span class="token punctuation">[</span><span class="token string">'b'</span><span class="token punctuation">]</span> <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token string">'a'</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token number">10</span> <span class="token operator">*</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">50</span><span class="token punctuation">)</span>data<span class="token punctuation">[</span><span class="token string">'d'</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token builtin">abs</span><span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token string">'d'</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">100</span>plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span><span class="token string">'a'</span><span class="token punctuation">,</span> <span class="token string">'b'</span><span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">'c'</span><span class="token punctuation">,</span> s<span class="token operator">=</span><span class="token string">'d'</span><span class="token punctuation">,</span> data<span class="token operator">=</span>data<span class="token punctuation">)</span><span class="token comment"># [c]olor, [s]ize</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'entry a'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'entry b'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>图像如下，可以看到散点的颜色和大小也是由 <code>data</code> 字典中的 <code>c &amp; d</code> 决定的</p><p><img src="/archives/d1e3c468/sphx_glr_pyplot_005.png" style="zoom:67%;"></p><h3 id="Working-with-multiple-figures-and-axes"><a href="#Working-with-multiple-figures-and-axes" class="headerlink" title="Working with multiple figures and axes"></a>Working with multiple figures and axes</h3><p><code>pyplot</code> 有一个 current figure/axes 概念，也就是当前在哪个画布上绘制哪个图像，下面就展示如何绘制两个子图</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">f</span><span class="token punctuation">(</span>t<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token operator">-</span>t<span class="token punctuation">)</span> <span class="token operator">*</span> np<span class="token punctuation">.</span>cos<span class="token punctuation">(</span><span class="token number">2</span><span class="token operator">*</span>np<span class="token punctuation">.</span>pi<span class="token operator">*</span>t<span class="token punctuation">)</span>t1 <span class="token operator">=</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">5.0</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">)</span>t2 <span class="token operator">=</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">5.0</span><span class="token punctuation">,</span> <span class="token number">0.02</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># 创建 figure，optional，创建子图的时候也会自动创建</span>plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">211</span><span class="token punctuation">)</span><span class="token comment"># 指向子图 (2, 1, 1)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>t1<span class="token punctuation">,</span> f<span class="token punctuation">(</span>t1<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'bo'</span><span class="token punctuation">,</span> t2<span class="token punctuation">,</span> f<span class="token punctuation">(</span>t2<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'k'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">212</span><span class="token punctuation">)</span><span class="token comment"># 创建子图 (2, 1, 2)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>t2<span class="token punctuation">,</span> np<span class="token punctuation">.</span>cos<span class="token punctuation">(</span><span class="token number">2</span><span class="token operator">*</span>np<span class="token punctuation">.</span>pi<span class="token operator">*</span>t2<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'r--'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>我们可以把 <code>plt</code> 看作一个指针或者画笔，它将指向你将绘图的地方</p><p><img src="/archives/d1e3c468/sphx_glr_pyplot_007.png" style="zoom: 67%;"></p><p>其中的 <code>211 &amp; 212</code> 代表什么呢？这其实是 (2, 1, 1) 的简写，<code>subplot(2, 1, 1)</code> 也是一样的效果，三个数字分别表示：num_rows, num_cols, plot_number，其中 plot_number 是一个范围为 1~num_rows * num cols 的数字，能够定位在哪个子图上绘画</p><p>下面的代码展示了绘画多个 figure &amp; subplot</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> pltplt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>                <span class="token comment"># the first figure</span>plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">211</span><span class="token punctuation">)</span>             <span class="token comment"># the first subplot in the first figure</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">212</span><span class="token punctuation">)</span>             <span class="token comment"># the second subplot in the first figure</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>                <span class="token comment"># a second figure</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">)</span>          <span class="token comment"># creates a subplot() by default</span>plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>                <span class="token comment"># figure 1 current; subplot(212) still current</span>plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">211</span><span class="token punctuation">)</span>             <span class="token comment"># make subplot(211) in figure1 current</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Easy as 1, 2, 3'</span><span class="token punctuation">)</span> <span class="token comment"># subplot 211 title</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/archives/d1e3c468/image-20211114194402180.png" style="zoom:50%;"></p><p>还有一个常用的操作 <code>plt.gca()</code> 代表获得当前 axes (get current axes)</p><h3 id="Plotting-with-categorical-variables"><a href="#Plotting-with-categorical-variables" class="headerlink" title="Plotting with categorical variables"></a>Plotting with categorical variables</h3><p>x 轴不仅可以是 number 还可以是字符串序列 names</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">names <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'group_a'</span><span class="token punctuation">,</span> <span class="token string">'group_b'</span><span class="token punctuation">,</span> <span class="token string">'group_c'</span><span class="token punctuation">]</span>values <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">]</span>plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># 画布大小</span>plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">131</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>bar<span class="token punctuation">(</span>names<span class="token punctuation">,</span> values<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">132</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>names<span class="token punctuation">,</span> values<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">133</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>names<span class="token punctuation">,</span> values<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>suptitle<span class="token punctuation">(</span><span class="token string">'Categorical Plotting'</span><span class="token punctuation">)</span><span class="token comment"># 给 Figure 添加标题</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/archives/d1e3c468/sphx_glr_pyplot_006.png" style="zoom:67%;"></p><h3 id="Controlling-line-properties"><a href="#Controlling-line-properties" class="headerlink" title="Controlling line properties"></a>Controlling line properties</h3><p>可以对 plot 出来的线条的属性进行设置，例如通过 <code>plt.setp()</code> 方法。实际上 <code>plt.plot()</code> 返回的是一个 <code>Line2D</code> 对象组成的列表，本质上是对 <code>Line2D</code> 对象的属性进行更改 <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.lines.Line2D.html#matplotlib.lines.Line2D">Line2D doc</a></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 直接在 plot 方法中进行修改</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> linewidth<span class="token operator">=</span><span class="token number">2.0</span><span class="token punctuation">)</span><span class="token comment"># 使用 plt.step()</span>line_1<span class="token punctuation">,</span> line_2 <span class="token operator">=</span> plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x1<span class="token punctuation">,</span> y1<span class="token punctuation">,</span> x2<span class="token punctuation">,</span> y2<span class="token punctuation">)</span><span class="token comment"># use keyword args</span>plt<span class="token punctuation">.</span>setp<span class="token punctuation">(</span>lines<span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'r'</span><span class="token punctuation">,</span> linewidth<span class="token operator">=</span><span class="token number">2.0</span><span class="token punctuation">)</span><span class="token comment"># or MATLAB style string value pairs</span>plt<span class="token punctuation">.</span>setp<span class="token punctuation">(</span>line_1<span class="token punctuation">,</span> <span class="token string">'color'</span><span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> <span class="token string">'linewidth'</span><span class="token punctuation">,</span> <span class="token number">2.0</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Working-with-text"><a href="#Working-with-text" class="headerlink" title="Working with text"></a>Working with text</h3><p>通过 <code>text</code> 方法可以为 figure 添加文字，通过 <code>xlabel, ylable, title</code> 等方法可以给 figure 添加坐标轴标签以及标题，<a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.text.html#matplotlib.pyplot.text">text doc</a> <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.xlabel.html#matplotlib.pyplot.xlabel">xlabel doc</a>, <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.ylabel.html#matplotlib.pyplot.ylabel">ylabel doc</a> and <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.title.html#matplotlib.pyplot.title">title doc</a></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">mu<span class="token punctuation">,</span> sigma <span class="token operator">=</span> <span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">15</span>x <span class="token operator">=</span> mu <span class="token operator">+</span> sigma <span class="token operator">*</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">10000</span><span class="token punctuation">)</span><span class="token comment"># the histogram of the data</span>n<span class="token punctuation">,</span> bins<span class="token punctuation">,</span> patches <span class="token operator">=</span> plt<span class="token punctuation">.</span>hist<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">50</span><span class="token punctuation">,</span> density<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> facecolor<span class="token operator">=</span><span class="token string">'g'</span><span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.75</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'Smarts'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'Probability'</span><span class="token punctuation">)</span><span class="token comment"># 给 Axes 设置标题，区别于 plt.title()</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Histogram of IQ'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>text<span class="token punctuation">(</span><span class="token number">60</span><span class="token punctuation">,</span> <span class="token number">.025</span><span class="token punctuation">,</span> <span class="token string">r'$\mu=100,\ \sigma=15$'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">40</span><span class="token punctuation">,</span> <span class="token number">160</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0.03</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment"># 对轴进行设置</span>plt<span class="token punctuation">.</span>grid<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment"># 格点设置</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/archives/d1e3c468/sphx_glr_pyplot_008.png" style="zoom:67%;"></p><ol><li><p>所有的文字对象都可以像 <code>Line2D</code> 一样进行属性设置</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">t <span class="token operator">=</span> plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'my data'</span><span class="token punctuation">,</span> fontsize<span class="token operator">=</span><span class="token number">14</span><span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'red'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li><p>可以使用 Latex 语法进行数学公式的书写</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">r'$\sigma_i=15$'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li></ol><h4 id="Annotating-text"><a href="#Annotating-text" class="headerlink" title="Annotating text"></a>Annotating text</h4><p>通过 <code>plt.annotate</code> 对图像中的某个点进行标记</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">ax <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token punctuation">)</span>t <span class="token operator">=</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">5.0</span><span class="token punctuation">,</span> <span class="token number">0.01</span><span class="token punctuation">)</span>s <span class="token operator">=</span> np<span class="token punctuation">.</span>cos<span class="token punctuation">(</span><span class="token number">2</span><span class="token operator">*</span>np<span class="token punctuation">.</span>pi<span class="token operator">*</span>t<span class="token punctuation">)</span>line<span class="token punctuation">,</span> <span class="token operator">=</span> plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>t<span class="token punctuation">,</span> s<span class="token punctuation">,</span> lw<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>annotate<span class="token punctuation">(</span><span class="token string">'local max'</span><span class="token punctuation">,</span> xy<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> xytext<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>             arrowprops<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>facecolor<span class="token operator">=</span><span class="token string">'black'</span><span class="token punctuation">,</span> shrink<span class="token operator">=</span><span class="token number">0.05</span><span class="token punctuation">)</span><span class="token punctuation">,</span>             <span class="token punctuation">)</span>plt<span class="token punctuation">.</span>ylim<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/archives/d1e3c468/sphx_glr_pyplot_009.png" style="zoom:67%;"></p><h3 id="Nonlinear-axes"><a href="#Nonlinear-axes" class="headerlink" title="Nonlinear axes"></a>Nonlinear axes</h3><p>可以对坐标轴进行缩放，例如对数缩放 <code>plt.xscale('log')</code> 更多就不再叙述了，可以直接参考 <a href="https://matplotlib.org/stable/tutorials/introductory/pyplot.html#logarithmic-and-other-nonlinear-axes">tutorial</a></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>以上就是一些 matplotlib.pyplot 中的基础概念，掌握了基本逻辑过后，就可以通过查询文档进行更多的操作了，放两个参考链接</p><ol><li><p><a href="https://github.com/matplotlib/cheatsheets/">Matplotlib Cheat Sheet</a>，查看一些代号很方便</p></li><li><p><a href="https://matplotlib.org/stable/tutorials/introductory/sample_plots.html#sphx-glr-tutorials-introductory-sample-plots-py">Example Gallery</a></p></li></ol><h2 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h2><p>整理一些常用的 api 操作</p>]]></content>
      
      
      <categories>
          
          <category> 编程 </category>
          
          <category> Python </category>
          
          <category> Package </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Matplotlib </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>D2L 02 预备知识</title>
      <link href="/archives/ca9aa429.html"/>
      <url>/archives/ca9aa429.html</url>
      
        <content type="html"><![CDATA[<p>官方：<a href="https://zh-v2.d2l.ai/chapter_preliminaries/index.html">预备知识</a></p><h1 id="D2L-02-预备知识"><a href="#D2L-02-预备知识" class="headerlink" title="D2L 02 预备知识"></a>D2L 02 预备知识</h1><ol><li>所有机器学习方法都涉及从数据中提取信息，因此，我们先学习一些关于<strong>数据的实用技能，包括存储、操作和预处理数据</strong></li><li>深度学习是关于<strong>优化</strong>的。我们有一个带有参数的模型，想要找到其中能拟合数据的最好模型。在算法的每个步骤中，决定以何种方式调整参数需要一点微积分知识。本节将简要介绍这些知识</li><li>机器学习还涉及如何做出<strong>预测</strong>：给定我们观察到的信息，某些未知属性可能的值是多少？要在不确定的情况下进行严格的推理，我们需要借用概率语言</li></ol><h2 id="2-1-数据操作"><a href="#2-1-数据操作" class="headerlink" title="2.1 数据操作"></a>2.1 数据操作</h2><h3 id="Numpy-amp-Pytorch-基础"><a href="#Numpy-amp-Pytorch-基础" class="headerlink" title="Numpy &amp; Pytorch 基础"></a>Numpy &amp; Pytorch 基础</h3><p>根据 <a href="https://github.com/juliangaal/python-cheat-sheet">github 项目</a> 和自己的一些经验，整理了 Numpy Cheat Sheet，在博客内搜索即可。学习该教材也需要一定的 pytorch 基础（如果你选择 pytorch 作为工具的话），这里就不赘述了</p><h3 id="节省内存"><a href="#节省内存" class="headerlink" title="节省内存"></a>节省内存</h3><p>为了节省内存，可以使用索引进行原地操作</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">Z <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros_like<span class="token punctuation">(</span>Y<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'id(Z):'</span><span class="token punctuation">,</span> <span class="token builtin">id</span><span class="token punctuation">(</span>Z<span class="token punctuation">)</span><span class="token punctuation">)</span>Z<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> X <span class="token operator">+</span> Y<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'id(Z):'</span><span class="token punctuation">,</span> <span class="token builtin">id</span><span class="token punctuation">(</span>Z<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># id is the same</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="2-2-数据预处理"><a href="#2-2-数据预处理" class="headerlink" title="2.2 数据预处理"></a>2.2 数据预处理</h2><p>我们将简要介绍使用<code>pandas</code>预处理原始数据并将原始数据转换为张量格式的步骤。假设 csv 数据如下</p><pre class="line-numbers language-csv" data-language="csv"><code class="language-csv"><span class="token value">   NumRooms Alley   Price</span><span class="token value">0       NaN  Pave  127500</span><span class="token value">1       2.0   NaN  106000</span><span class="token value">2       4.0   NaN  178100</span><span class="token value">3       NaN   NaN  140000</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>使用 pandas 读取 csv 文档，并对 NaN 值进行处理</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd<span class="token comment"># read_csv</span>data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>data_file<span class="token punctuation">)</span><span class="token comment"># iloc</span>inputs<span class="token punctuation">,</span> outputs <span class="token operator">=</span> data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token comment"># fillna</span>inputs <span class="token operator">=</span> inputs<span class="token punctuation">.</span>fillna<span class="token punctuation">(</span>inputs<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>转换为 Tensor</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">X<span class="token punctuation">,</span> y <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>inputs<span class="token punctuation">.</span>values<span class="token punctuation">)</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>values<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>更多有关 pandas 的处理后续再进行总结</p><h2 id="2-3-线性代数"><a href="#2-3-线性代数" class="headerlink" title="2.3 线性代数"></a>2.3 线性代数</h2><p>这里仅记录一些自己觉得该注意的点，更基础的数学和编程知识就不介绍了</p><h3 id="一些注意的点"><a href="#一些注意的点" class="headerlink" title="一些注意的点"></a>一些注意的点</h3><ol><li><p><strong>向量与张量的维度</strong></p><p>维度（dimension）这个词在不同上下文时往往会有不同的含义，向量的维度和张量的维度经常会使人感到困惑。为了清楚起见，我们在此明确一下：</p><ol><li>向量或轴的维度被用来表示向量或轴的长度，即向量或轴的元素数量</li><li>张量的<strong>维度</strong>用来表示张量具有的轴数。在这个意义上，张量的某个轴的<strong>维数</strong>就是这个轴的长度</li></ol><p>两个矩阵的按元素乘法称为<strong>哈达玛积（Hadamard product）</strong>（数学符号⊙）</p></li><li><p><strong>非降维求和</strong></p><p>有时在调用函数来计算总和或均值时保持轴数不变会很有用</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">sum_A <span class="token operator">=</span> A<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> keepdims<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li><p><strong>哈达玛积（Hadamard product）</strong></p><p>两个矩阵的按元素乘法称为哈达玛积（Hadamard product）（数学符号⊙）</p></li><li><p>范数计算</p><pre class="line-numbers language-PYTHON" data-language="PYTHON"><code class="language-PYTHON"># L2 or Frobenius normu = torch.tensor([3.0, -4.0])torch.norm(u)# L1torch.abs(u).sum()<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ol><h3 id="线性代数与机器学习"><a href="#线性代数与机器学习" class="headerlink" title="线性代数与机器学习"></a>线性代数与机器学习</h3><blockquote><p>仅用一节，我们就教会了你所需的，用以理解大量的现代深度学习的全部线性代数。 线性代数还有很多，其中很多数学对于机器学习非常有用。例如，矩阵可以分解为因子，这些分解可以显示真实世界数据集中的低维结构。机器学习的整个子领域都侧重于使用矩阵分解及其向高阶张量的泛化来发现数据集中的结构并解决预测问题。但这本书的重点是深度学习。我们相信，一旦你开始动手尝试并在真实数据集上应用了有效的机器学习模型，你会更倾向于学习更多数学。因此，虽然我们保留在后面介绍更多数学知识的权利，但我们这一节到此结束。</p></blockquote><p>这最后的小结非常有意思，说明了机器学习需要更多的数学知识，但深度学习所需要的线性代数知识就到此为止了…可以说数学门槛是相当低了，不过机器学习给人更扎实的感受，以后有时间再整理一下机器学习领域的知识吧😀</p><h2 id="2-4-微分"><a href="#2-4-微分" class="headerlink" title="2.4 微分"></a>2.4 微分</h2><p>重要概念：导数，微分，偏微分，梯度，链式法则。当扩展到张量阶段的时候，需要参考工程矩阵中的知识，下面贴一个梯度的公式</p><script type="math/tex; mode=display">\nabla_{\mathbf{x}} f(\mathbf{x})=\left[\frac{\partial f(\mathbf{x})}{\partial x_{1}}, \frac{\partial f(\mathbf{x})}{\partial x_{2}}, \ldots, \frac{\partial f(\mathbf{x})}{\partial x_{n}}\right]^{\top}</script><h2 id="2-5-自动微分"><a href="#2-5-自动微分" class="headerlink" title="2.5 自动微分"></a>2.5 自动微分</h2><p>关于自动微分，可以查看博客中的 <a href="https://hongkun.space/archives/6c437432.html#toc-heading-17">pytorch tutorial</a> 里面更详细地介绍了自动微分操作。当加入了张量运算后自动微分会变得不那么显然，可以自行推导一下矩阵相乘时的一般结论，以及 sigmoid 函数的自动微分情况</p><h2 id="2-6-概率"><a href="#2-6-概率" class="headerlink" title="2.6 概率"></a>2.6 概率</h2><p>重要概念：概率论基本公式，随机变量，联合概率，条件概率，贝叶斯定理，边际概率，独立性，期望，方差，协方差…</p><p>概率论和矩阵论都是我非常薄弱的环节😭，希望有时间一定要好好重新学过！！！</p><h1 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h1><ol><li>完成 matplotlib 整理</li><li>完成概率论，线性代数的深入学习</li></ol>]]></content>
      
      
      <categories>
          
          <category> 课程 </category>
          
          <category> Dive into deep learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Dive into deep learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MMDetection3D &amp; OpenPCDet Installation</title>
      <link href="/archives/93e5b117.html"/>
      <url>/archives/93e5b117.html</url>
      
        <content type="html"><![CDATA[<h1 id="MMDetection3D-amp-OpenPCDet"><a href="#MMDetection3D-amp-OpenPCDet" class="headerlink" title="MMDetection3D &amp; OpenPCDet"></a>MMDetection3D &amp; OpenPCDet</h1><h2 id="Install-mmdet3d"><a href="#Install-mmdet3d" class="headerlink" title="Install mmdet3d"></a>Install mmdet3d</h2><p>可以参考 <a href="https://mmdetection3d.readthedocs.io/en/latest/getting_started.html#">官方 doc</a> 进行下载。其中提供了如何使用 conda 从零下载，但是环境不仅仅包含 conda 环境，还有 GCC, CUDA 等编译环境。所以更好的选择是使用 docker 进行安装，这样能够一步解决所有环境问题，专注于代码</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token comment"># build an image with PyTorch 1.6, CUDA 10.1</span>docker build -t mmdetection3d docker/docker run --gpus all --shm-size<span class="token operator">=</span>8g -it -v <span class="token punctuation">{</span>DATA_DIR<span class="token punctuation">}</span>:/mmdetection3d/data mmdetection3d<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>由于每次启动 docker 都要传入很多参数，所以在这里记录启动容器的命令，以后直接复制粘贴</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">docker run --gpus all --shm-size<span class="token operator">=</span>8g -it -v /home/chk/data:/shared -v /home/chk/.Xauthority:/root/.Xauthority -e <span class="token environment constant">DISPLAY</span> --net<span class="token operator">=</span>host --name<span class="token comment"># 其中 -e 和 --net 是为了设置图形化操作，在之后详细介绍</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>在安装的过程中出现了两个问题</p><ol><li><p>clone MMDetection3D 时网络出了问题，clone 失败了。再次尝试 <code>docker build</code> 后成功</p></li><li><p>其中有个小报错 <code>ERROR: nbconvert 5.6.0 has requirement traitlets&gt;=4.2, but you'll have traitlets 4.1.0 which is inco</code></p><p>但是最终显示是成功安装，查了一下这个库，是用于将 notebooks 转为其他格式的，先暂时忽略。如遇到报错则尝试使用 pip 升级以符合条件</p></li></ol><h3 id="Nvidia-Docker"><a href="#Nvidia-Docker" class="headerlink" title="Nvidia-Docker"></a>Nvidia-Docker</h3><p>为了让容器能够使用 GPU，需要安装 Nvidia-docker，过程也比较简单，具体可以参考这篇 <a href="https://zhuanlan.zhihu.com/p/361934132">知乎</a></p><h2 id="Verify"><a href="#Verify" class="headerlink" title="Verify"></a>Verify</h2><p>来运行官方 <a href="https://mmdetection3d.readthedocs.io/en/latest/demo.html">demo</a> 验证是否安装成功</p><p>下载好 SECOND 模型，然后运行脚本</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">python demo/pcd_demo.py demo/data/kitti/kitti_000008.bin configs/second/hv_second_secfpn_6x8_80e_kitti-3d-car.py checkpoints/hv_second_secfpn_6x8_80e_kitti-3d-car_20200620_230238-393f000c.pth<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>最后得到报错</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">Traceback <span class="token punctuation">(</span>most recent call last<span class="token punctuation">)</span>:  File <span class="token string">"demo/pcd_demo.py"</span>, line <span class="token number">4</span>, <span class="token keyword">in</span> <span class="token operator">&lt;</span>module<span class="token operator">&gt;</span>    from mmdet3d.apis <span class="token function">import</span> inference_detector, init_model, show_result_meshlab  File <span class="token string">"/mmdetection3d/mmdet3d/__init__.py"</span>, line <span class="token number">5</span>, <span class="token keyword">in</span> <span class="token operator">&lt;</span>module<span class="token operator">&gt;</span>    <span class="token function">import</span> mmseg  File <span class="token string">"/opt/conda/lib/python3.7/site-packages/mmseg/__init__.py"</span>, line <span class="token number">59</span>, <span class="token keyword">in</span> <span class="token operator">&lt;</span>module<span class="token operator">&gt;</span>    f<span class="token string">'MMCV=={mmcv.__version__} is used but incompatible. '</span> <span class="token punctuation">\</span>AssertionError: <span class="token assign-left variable">MMCV</span><span class="token operator">==</span><span class="token number">1.3</span>.8 is used but incompatible. Please <span class="token function">install</span> mmcv<span class="token operator">&gt;=</span><span class="token punctuation">(</span><span class="token number">1</span>, <span class="token number">3</span>, <span class="token number">13</span>, <span class="token number">0</span>, <span class="token number">0</span>, <span class="token number">0</span><span class="token punctuation">)</span>, <span class="token operator">&lt;=</span><span class="token punctuation">(</span><span class="token number">1</span>, <span class="token number">4</span>, <span class="token number">0</span>, <span class="token number">0</span>, <span class="token number">0</span>, <span class="token number">0</span><span class="token punctuation">)</span>.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>现在尝试升级 MMCV 以解决。修改 dockerfile 中的 mmcv 版本为 1.3.13，重新生成镜像和对应容器。由于目前实验室的 GPU 有其他人在跑项目，所以验证的时候发生错误 <a href="https://github.com/open-mmlab/mmdetection3d/issues/21">github issue</a></p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">RuntimeError: /mmdetection3d/mmdet3d/ops/spconv/src/indice_cuda.cu <span class="token number">124</span>cuda execution failed with error <span class="token number">2</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>应该是由于显存不足导致的，于是选择了一个较小的模型 PointNet++ 进行了验证，最终 demo 能够运行，故以上升级是有效的。在 MeshLab 中进行可视化查看 PointNet++ 分割效果</p><p><img src="/archives/93e5b117/image-20211028172827565.png" style="zoom:50%;"></p><p>等服务器空闲了，测试了 SECOND，也可以运行</p><p><img src="/archives/93e5b117/image-20211029132630612.png" style="zoom: 67%;"></p><h2 id="Work-with-VSCode"><a href="#Work-with-VSCode" class="headerlink" title="Work with VSCode"></a>Work with VSCode</h2><h3 id="VSCode-with-container"><a href="#VSCode-with-container" class="headerlink" title="VSCode with container"></a>VSCode with container</h3><p>想要 vscode 编辑 docker 容器中的文件，可以按照以下方法 </p><ol><li><p>下载 docker 和 remote-container 插件</p></li><li><p>在 side bar 中可以看到 docker 工具栏，可以轻松启动容器</p><p><img src="/archives/93e5b117/image-20211028115235998.png"></p></li><li><p>启动容器后，选择 <code>Attach Visual Studio Code</code> 就可以打开新的窗口，新窗口的界面就像 vscode 在容器中运行一样</p><p><img src="/archives/93e5b117/image-20211028115404905.png"></p></li></ol><p>如果在 Linux 上遇到连接问题 <code>error "connect EACCES /var/run/docker.sock"</code> 这是由于 docker 权限造成，可以按照 <a href="https://github.com/microsoft/vscode-docker/wiki/Troubleshooting">官方提示</a>  可以尝试解决。如果还不能解决，直接通过修改 <code>docker.sock</code> 文件的权限一步到位</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">sudo</span> <span class="token function">chmod</span> <span class="token number">666</span> /var/run/docker.sock<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="VSCode-免密登录"><a href="#VSCode-免密登录" class="headerlink" title="VSCode 免密登录"></a>VSCode 免密登录</h3><p>完成以下步骤即可：</p><ol><li><p>生成本地 ssh-key，和 git 操作是一样的</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">ssh-keygen -t rsa<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li><p>将 <code>id_rsa.pub</code> 复制到服务器主机 <code>~/.ssh</code> 文件夹下，将 <code>id_rsa.pub</code> 的内容加入到 <code>authorized_keys</code> 中</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">cat</span> id_rsa.pub <span class="token operator">&gt;&gt;</span> authorized_keys<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li><p>重启 ssh 服务 <code>service sshd restart</code></p></li></ol><p>其他操作和一般 remote-ssh 是一样的，按默认填写配置文件即可，不需要配置 <code>IdentityFile</code> 关键字</p><pre class="line-numbers language-config" data-language="config"><code class="language-config">Host Arbitrary_Nane  HostName Host_ip  User User_Name<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="VSCode-X11-forward"><a href="#VSCode-X11-forward" class="headerlink" title="VSCode X11 forward"></a>VSCode X11 forward</h3><p>使用 X server 解决无法可视化图形界面的问题。一般来讲使用 ssh 连接到服务器后是不能使用图形化界面服务的，例如使用  firefox 浏览器。一些软件自带 X server，例如 MobaXterm，当连接上服务器后，可以直接在命令行输入 <code>firefox</code>，然后就能弹出浏览器窗口。如果电脑上没有 X server 则需要自行安装，或者直接把 MobaXterm 挂在旁边即可。更多科普内容参考 <a href="https://www.jianshu.com/p/1a296191a122">博客</a></p><p>现在在 VSCode Remote-SSH 上也支持了 X11 forwarding，可以通过以下步骤完成</p><p>首先修改配置 vscode <code>settings.json</code> 中 <code>terminal.integrated.env.windows</code> 字段，添加本地显示变量</p><pre class="line-numbers language-json" data-language="json"><code class="language-json">   <span class="token property">"terminal.integrated.env.windows"</span><span class="token operator">:</span> <span class="token punctuation">{</span>       <span class="token property">"DISPLAY"</span><span class="token operator">:</span> <span class="token string">"127.0.0.1:0.0"</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>然后在 ssh 配置文件中加入相关字段</p><pre class="line-numbers language-config" data-language="config"><code class="language-config">Host Arbitrary_Nane  HostName Host_ip  User User_Name  ForwardAgent yes  ForwardX11 yes  ForwardX11Trusted yes<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>最后在服务器上指定 <code>DISPLAY</code> 环境变量</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token builtin class-name">export</span> <span class="token assign-left variable"><span class="token environment constant">DISPLAY</span></span><span class="token operator">=</span><span class="token string">"localhost:10.0"</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>注意，10.0 这个数字是根据 .Xauthority 文件确定，可以通过 xauth list 命令查看。得到列表可能会比较长，我对这一块不是很了解…经验来看，关注的是最后一行，或者 unix:index 最小的那一行</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">user@linux xauth listlinux/unix:12  MIT-MAGIC-COOKIE-1  78cbc********************c64<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>这里看到 <code>unix:12</code> 所以我们配置 <code>DISPLAY</code> 变量时应该为 <code>export DISPLAY="localhost:12.0"</code></p><p>使用 <code>xeyes</code> 测试一下，如果看到一个眼睛窗口就成功了😎</p><h3 id="Docker-with-GUI"><a href="#Docker-with-GUI" class="headerlink" title="Docker with GUI"></a>Docker with GUI</h3><p>如果能够在 Docker 中使用 GUI app 岂不是美滋滋？既然能够在 VSCode 中通过 X11 forward 协议运行图形界面，那么理论上 Docker 也是可以的！根据这两个博客：<a href="https://www.cnblogs.com/larva-zhh/p/10531824.html">Link-1</a> <a href="https://medium.com/@SaravSun/running-gui-applications-inside-docker-containers-83d65c0db110">Link-2</a> 进行配置，意想不到地成功了，说明博客中的原理是正确的，只要将 Host 中的 X11 服务器分享给 Docker 就可以，具体步骤如下：</p><ol><li><p>Share the Host’s XServer with the Container by creating a volume</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">--volume<span class="token operator">=</span><span class="token string">"<span class="token environment constant">$HOME</span>/.Xauthority:/root/.Xauthority:rw"</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>需要注意的是，每次登录的时 Host <code>.Xauthority</code> 是不一样的，如果直接复制该文件的话，要每次更新</p></li><li><p>share the Host’s <strong>DISPLAY</strong> environment variable to the Container</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">--env<span class="token operator">=</span><span class="token string">"DISPLAY"</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li><p>Run container with <strong>host</strong> network driver with</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">--net<span class="token operator">=</span>host<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li></ol><h2 id="KITTI"><a href="#KITTI" class="headerlink" title="KITTI"></a>KITTI</h2><p>使用 KITTI 数据集进行实验，下载通过 <a href="https://gas.graviti.cn/dataset/data-decorators/KITTIObject">GRAVITI</a></p><p><img src="/archives/93e5b117/image-20211028134043307.png" style="zoom:80%;"></p><p>将数据集放在一个文件夹下，全部解压</p><h2 id="SECOND-on-MMDetection3D"><a href="#SECOND-on-MMDetection3D" class="headerlink" title="SECOND on MMDetection3D"></a>SECOND on MMDetection3D</h2><p>先尝试测试一下经典的 backbone SECOND 能不能运行</p><h3 id="Test-SECOND"><a href="#Test-SECOND" class="headerlink" title="Test SECOND"></a>Test SECOND</h3><ol><li><p>下载 <a href="https://github.com/open-mmlab/mmdetection3d/blob/master/configs/second/README.md">SECOND</a> 模型</p></li><li><p>根据 <a href="https://mmdetection3d.readthedocs.io/en/latest/datasets/kitti_det.html">doc</a> 生成数据集，其中生成了一些 pkl 文件用于存储数据集每个样本的相关信息，关于 pkl 文件可以参考 <a href="https://blog.csdn.net/Ving_x/article/details/114488844">CSDN</a>。下面是程序运行中最后的输出</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">load <span class="token number">2207</span> Pedestrian database infosload <span class="token number">14357</span> Car database infosload <span class="token number">734</span> Cyclist database infosload <span class="token number">1297</span> Van database infosload <span class="token number">488</span> Truck database infosload <span class="token number">224</span> Tram database infosload <span class="token number">337</span> Misc database infosload <span class="token number">56</span> Person_sitting database infos<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>Test SECOND on KITTI val，其中 <code>AP@0.5 0.5 0.5</code> 代表 bbox, bev, 3d 任务的 IoU 阈值分别为 0.5, 0.5, 0.5，列出 Car 相关的部分</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">Result is saved to /tmp/tmp50avi_bh/results.pkl.Car AP@0.70, <span class="token number">0.70</span>, <span class="token number">0.70</span>:bbox AP:98.1839, <span class="token number">89.7606</span>, <span class="token number">88.7837</span>bev  AP:89.6905, <span class="token number">87.4570</span>, <span class="token number">85.4865</span>3d   AP:87.4561, <span class="token number">76.7570</span>, <span class="token number">74.1302</span>aos  AP:97.70, <span class="token number">88.73</span>, <span class="token number">87.34</span>Car AP@0.70, <span class="token number">0.50</span>, <span class="token number">0.50</span>:bbox AP:98.1839, <span class="token number">89.7606</span>, <span class="token number">88.7837</span>bev  AP:98.4400, <span class="token number">90.1218</span>, <span class="token number">89.6270</span>3d   AP:98.3329, <span class="token number">90.0209</span>, <span class="token number">89.4035</span>aos  AP:97.70, <span class="token number">88.73</span>, <span class="token number">87.34</span>Overall AP@easy, moderate, hard:bbox AP:84.0061, <span class="token number">75.7857</span>, <span class="token number">73.6821</span>bev  AP:80.2144, <span class="token number">72.7919</span>, <span class="token number">69.1538</span>3d   AP:76.7926, <span class="token number">66.6667</span>, <span class="token number">62.3905</span>aos  AP:80.79, <span class="token number">72.30</span>, <span class="token number">70.19</span><span class="token punctuation">{</span><span class="token string">'KITTI/Car_3D_easy_strict'</span><span class="token builtin class-name">:</span> <span class="token number">87.45610724795893</span>, <span class="token string">'KITTI/Car_BEV_easy_strict'</span><span class="token builtin class-name">:</span> <span class="token number">89.69046011671303</span>, <span class="token string">'KITTI/Car_2D_easy_strict'</span><span class="token builtin class-name">:</span> <span class="token number">98.18389028596552</span>, <span class="token string">'KITTI/Car_3D_moderate_strict'</span><span class="token builtin class-name">:</span> <span class="token number">76.75701107649772</span>, <span class="token string">'KITTI/Car_BEV_moderate_strict'</span><span class="token builtin class-name">:</span> <span class="token number">87.45702960861706</span>, <span class="token string">'KITTI/Car_2D_moderate_strict'</span><span class="token builtin class-name">:</span> <span class="token number">89.76058109581083</span>, <span class="token string">'KITTI/Car_3D_hard_strict'</span><span class="token builtin class-name">:</span> <span class="token number">74.13015065869207</span>, <span class="token string">'KITTI/Car_BEV_hard_strict'</span><span class="token builtin class-name">:</span> <span class="token number">85.4865455582404</span>, <span class="token string">'KITTI/Car_2D_hard_strict'</span><span class="token builtin class-name">:</span> <span class="token number">88.78373491728972</span>, <span class="token string">'KITTI/Car_3D_easy_loose'</span><span class="token builtin class-name">:</span> <span class="token number">98.33288257217502</span>, <span class="token string">'KITTI/Car_BEV_easy_loose'</span><span class="token builtin class-name">:</span> <span class="token number">98.4400221898542</span>, <span class="token string">'KITTI/Car_2D_easy_loose'</span><span class="token builtin class-name">:</span> <span class="token number">98.18389028596552</span>, <span class="token string">'KITTI/Car_3D_moderate_loose'</span><span class="token builtin class-name">:</span> <span class="token number">90.02090501786836</span>, <span class="token string">'KITTI/Car_BEV_moderate_loose'</span><span class="token builtin class-name">:</span> <span class="token number">90.12184507731126</span>, <span class="token string">'KITTI/Car_2D_moderate_loose'</span><span class="token builtin class-name">:</span> <span class="token number">89.76058109581083</span>, <span class="token string">'KITTI/Car_3D_hard_loose'</span><span class="token builtin class-name">:</span> <span class="token number">89.40349529357029</span>, <span class="token string">'KITTI/Car_BEV_hard_loose'</span><span class="token builtin class-name">:</span> <span class="token number">89.62702775979791</span>, <span class="token string">'KITTI/Car_2D_hard_loose'</span><span class="token builtin class-name">:</span> <span class="token number">88.78373491728972</span>, <span class="token string">'KITTI/Overall_3D_easy'</span><span class="token builtin class-name">:</span> <span class="token number">76.79258397928281</span>, <span class="token string">'KITTI/Overall_BEV_easy'</span><span class="token builtin class-name">:</span> <span class="token number">80.21439732105783</span>, <span class="token string">'KITTI/Overall_2D_easy'</span><span class="token builtin class-name">:</span> <span class="token number">84.00606839712997</span>, <span class="token string">'KITTI/Overall_3D_moderate'</span><span class="token builtin class-name">:</span> <span class="token number">66.6666643647041</span>, <span class="token string">'KITTI/Overall_BEV_moderate'</span><span class="token builtin class-name">:</span> <span class="token number">72.7919003517221</span>, <span class="token string">'KITTI/Overall_2D_moderate'</span><span class="token builtin class-name">:</span> <span class="token number">75.78568527747004</span>, <span class="token string">'KITTI/Overall_3D_hard'</span><span class="token builtin class-name">:</span> <span class="token number">62.39046573028369</span>, <span class="token string">'KITTI/Overall_BEV_hard'</span><span class="token builtin class-name">:</span> <span class="token number">69.15381069261458</span>, <span class="token string">'KITTI/Overall_2D_hard'</span><span class="token builtin class-name">:</span> <span class="token number">73.68210872556001</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ol><p>但是想要的预测结果 <code>pred.obj</code> 以及 <code>result.pkl</code> 好像并没有保存，并且查看了输出中的路径 <code>/tmp/tmp50avi_bh/results.pkl</code> 甚至都找不到这个路径 ，再次查看了官方文档，有以下描述</p><blockquote><ul><li><code>--show</code>: If specified, detection results will be plotted in the silient mode. It is only applicable to single GPU testing and used for debugging and visualization. This should be used with <code>--show-dir</code>.</li></ul></blockquote><p>因为我在运行的时候只指定了 <code>--show-dir</code>，而  <code>--show</code> 和 <code>--show-dir</code> 需要一起使用。而没有看到 <code>result.pkl</code> 是因为我传入 <code>--out</code> 的参数为文件夹，应该传入一个文件。对于 <code>--show</code> 的使用，需要安装 open3d，<code>pip install open3d</code> 即可，我在安装的过程中遇到了一些错误，这里列出来</p><ol><li><p>遇到错误 <code>AttributeError: 'NoneType' object has no attribute 'point_size'</code>，原因可能是由于 open3d 版本问题，可以尝试更换版本 <code>pip install open3d==0.11</code>，参考  <a href="https://github.com/open-mmlab/mmdetection3d/issues/344">github issue</a> </p></li><li><p>使用 open3d==0.11 后遇到错误 <code>OSError: libc++.so.1: cannot open shared object file: No such file or directory</code>，原因在于环境变量没有设置，参考 <a href="https://github.com/isl-org/Open3D/issues/2518">github issue</a> 加入对应环境变量即可</p></li><li><p>如果以上问题都解决了，但你的测试环境为远程服务器，没有图形界面 GUI，那么还可能遇到报错 <code>RuntimeError: [Open3D ERROR] GLFW Error: X11: The DISPLAY environment variable is missing</code>，可以参考 <a href="https://github.com/open-mmlab/mmdetection3d/issues/851">github issue</a> 对 <code>if show</code> 部分的代码进行注释，或者如前文提到的方法，配置好 GUI 环境</p></li></ol><h3 id="Train-SECOND"><a href="#Train-SECOND" class="headerlink" title="Train SECOND"></a>Train SECOND</h3><p>只能跑1个 batch_size </p><p><img src="/archives/93e5b117/image-20211030195600143-16359966282161.png"></p><p>我认为我应该转战一下 <a href="https://github.com/open-mmlab/OpenPCDet">OpenPCDet</a> 项目，根据 PV-RCNN 论文</p><blockquote><p>Our PV-RCNN framework is trained from scratch in an end-to-end manner with the ADAM optimizer. For the KITTI dataset, we train the entire network with the batch size 24, learning rate 0.01 for 80 epochs on 8 GTX 1080 Ti GPUs, which takes around 5 hours.</p></blockquote><p>使用8个 1080Ti GPU 也能够跑24个 batch size，说明实验室的 2080Ti 至少每个能跑3个 batch size。然而 MMDetection3D 只能跑一个，确实太少了。现在需要对 OpenPCDet 进行更进一步的研究</p><h2 id="———————————————"><a href="#———————————————" class="headerlink" title="———————————————-"></a>———————————————-</h2><h2 id="OpenPCDet-amp-spconv"><a href="#OpenPCDet-amp-spconv" class="headerlink" title="OpenPCDet &amp; spconv"></a>OpenPCDet &amp; spconv</h2><p>首先面临的难题就是安装  <a href="https://github.com/open-mmlab/OpenPCDet">OpenPCDet</a>，最先想到的就是使用 docker 安装，也有人发布了 <a href="https://hub.docker.com/r/xfbs/openpcdet">openpcdet-docker</a> 但我下载下来后，感觉不太好用，最基本的 pip 命令都没有，当然也可能是我打开方式不对。尝试现成的 docker 失败后，只有自己逐步搭建了</p><h3 id="Install-spconv-v1-2-1"><a href="#Install-spconv-v1-2-1" class="headerlink" title="Install spconv v1.2.1"></a>Install spconv v1.2.1</h3><p>安装 OpenPCDet 首先需要安装 spconv，这个部分也是花费了不少精力，到处都是困难啊😥而且由于 OpenPCDet 项目更新速度并不快，但是 spconv 已经更新到了 2.0 版本，老版本几乎已经停止更新了，所以想要安装老版本 <a href="https://github.com/traveller59/spconv/tree/v1.2.1">spconv v1.2.1</a> 也比有一些难度</p><h4 id="Install-by-docker-deprecate"><a href="#Install-by-docker-deprecate" class="headerlink" title="Install by docker (deprecate)"></a>Install by docker (deprecate)</h4><p>首先想要通过 docker 来下载 spconv，但是由于 spconv 的镜像从不打 tag，如果根据原 Dockerfile 会默认拉取最新的镜像，所以 CUDA 版本并不是我想要下载的 10.1。而且实验室 Ubuntu 的 Nvidia Driver 版本不够新，所以更高版本的 CUDA 镜像是没办法启动的。于是就尝试根据 github 中最晚的更新时间，下载老版本的镜像，这里我安装的 tag 是</p><p><img src="/archives/93e5b117/image-20211031204629220.png" style="zoom:80%;"></p><p>下载好该镜像后就能正常运行 CUDA 镜像了，然后就根据 OpenPCDet 官方 <a href="https://github.com/open-mmlab/OpenPCDet/blob/master/docs/INSTALL.md">Install</a> 文档进行安装</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">git</span> clone https://github.com/open-mmlab/OpenPCDet.gitpip <span class="token function">install</span> -r requirements.txt python setup.py develop<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>但之后在安装 mayavi 库的时候出现了问题，因为需要使用 python3.7，而镜像是 python3.8，并且镜像没有 conda 命令，个人不是很习惯，于是打算放弃通过 spconv docker 安装。考虑使用 mmdetection3d 提供的镜像，作为基础镜像从零开始安装，因为该镜像的功能更多一些，环境更完整，其部分 Dockerfile 如下</p><pre class="line-numbers language-dockerfile" data-language="dockerfile"><code class="language-dockerfile">ARG PYTORCH="1.6.0"ARG CUDA="10.1"ARG CUDNN="7"FROM pytorch/pytorch:${PYTORCH}-cuda${CUDA}-cudnn${CUDNN}-develENV TORCH_CUDA_ARCH_LIST="6.0 6.1 7.0+PTX"ENV TORCH_NVCC_FLAGS="-Xfatbin -compress-all"ENV CMAKE_PREFIX_PATH="$(dirname $(which conda))/../"RUN apt-get update &amp;&amp; apt-get install -y ffmpeg libsm6 libxext6 git ninja-build libglib2.0-0 libsm6 libxrender-dev libxext6 \    &amp;&amp; apt-get clean \    &amp;&amp; rm -rf /var/lib/apt/lists/*<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="Install-cmake"><a href="#Install-cmake" class="headerlink" title="Install cmake"></a>Install cmake</h4><p>首先遇到的难题是安装 cmake，发现原来通过 pip 安装才是最快的方式，而且版本很新，参考 <a href="https://stackoverflow.com/questions/49859457/how-to-reinstall-the-latest-cmake-version">stackoverflow</a></p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token punctuation">(</span>base<span class="token punctuation">)</span> root@fb873089e53c:/spconv<span class="token comment"># cmake --version</span>cmake version <span class="token number">3.21</span>.3CMake suite maintained and supported by Kitware <span class="token punctuation">(</span>kitware.com/cmake<span class="token punctuation">)</span>.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h4 id="Git-clone"><a href="#Git-clone" class="headerlink" title="Git clone"></a>Git clone</h4><p>一定要使用 <code>git clone ... --recursive</code> 命令来 clone 该项目，<code>--recursive</code> 命令意思是这个项目还有一些子项目也需要 clone。并且需要加上 <code>-b</code> 参数指定 clone 的 branch，不然会默认 clone master 分支，而不是我需要的 v1.2.1 版本。整个下载的过程可能会很慢，强烈建议使用国内的镜像源，可以参考我的 <a href="https://hongkun.space/archives/2121b11b.html#toc-heading-1">git 笔记</a>（题外话，自己就是因为 clone 操作没有弄对，在安装的时候除了好多错…心态爆炸）</p><h4 id="Setup-py"><a href="#Setup-py" class="headerlink" title="Setup.py"></a>Setup.py</h4><p>运行 <code>setup.py</code> 进行编译，然后进入 <code>./dist</code> 文件夹下载 <code>xxx.whl</code> 不同版本的 spconv 会有不同的 <code>.whl</code> 文件 </p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">python setup.py bdist_wheel<span class="token builtin class-name">cd</span> ./distpython xxx.whl<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="Install-OpenPCDet"><a href="#Install-OpenPCDet" class="headerlink" title="Install OpenPCDet"></a>Install OpenPCDet</h3><p>下载好了 spconv 继续前往 OpenPCDet 项目继续安装吧</p><h4 id="Install-requirements"><a href="#Install-requirements" class="headerlink" title="Install requirements"></a>Install requirements</h4><p><code>git clone https://github.com/open-mmlab/OpenPCDet.git</code> 下载项目，然后安装环境</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">pip <span class="token function">install</span> -r requirements.txt <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在下载 requirements 的时候发现莫名其妙地下载了最新版的 torch==1.10.0 替换了原来的 torch==1.6.0，<code>requirements.txt</code> 部分内容如下</p><pre class="line-numbers language-txt" data-language="txt"><code class="language-txt">torch&gt;=1.1kornia<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>一般情况下 pip 是不会自动替换已经满足要求的包的，我使用了另一个 docker 也没有复现出这个错误过程，所以就暂时不要担心这个操作了。在 torch==1.10.0 的情况下运行 <code>setup.py</code> 可能遇到如下报错，更换对应的 torch 版本就好</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">RuntimeError:The detected CUDA version <span class="token punctuation">(</span><span class="token number">10.1</span><span class="token punctuation">)</span> mismatches the version that was used to compilePyTorch <span class="token punctuation">(</span><span class="token number">10.2</span><span class="token punctuation">)</span>. Please <span class="token function">make</span> sure to use the same CUDA versions.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>并且由于 kornia 对于 Pytorch 低版本兼容性问题，根据 <a href="https://github.com/open-mmlab/OpenPCDet/issues/544">github issue</a> 选择下载 <code>kornia==0.5</code> 版本，如果你不需要使用 CaDNN 也可以选择不下载 kornia。现在重新安装 torch==1.6.0 &amp; kornia==0.5</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">pip <span class="token function">install</span> <span class="token assign-left variable">torch</span><span class="token operator">==</span><span class="token number">1.6</span>.0+cu101 <span class="token assign-left variable">torchvision</span><span class="token operator">==</span><span class="token number">0.7</span>.0+cu101 -f https://download.pytorch.org/whl/torch_stable.htmlpip <span class="token function">install</span> <span class="token assign-left variable">kornia</span><span class="token operator">==</span><span class="token number">0.5</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h4 id="Setup-py-1"><a href="#Setup-py-1" class="headerlink" title="Setup.py"></a>Setup.py</h4><p>运行 <code>setup.py</code> 进行编译</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">python setup.py develop<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="Install-mayavi"><a href="#Install-mayavi" class="headerlink" title="Install mayavi"></a>Install mayavi</h3><p>这个库是用于可视化的，其安装也有一些注意事项的，列举如下：</p><ol><li><p><code>mayavi</code> 是需要图形化界面 GUI 的，到了这一步我不得不想办法让 docker 能够运行 GUI app，还好找到了方法，参照前文即可完成</p></li><li><p>根据 <a href="https://zhuanlan.zhihu.com/p/373668000">知乎</a> 下载 <code>vtk==8.1.2</code>，自动安装的为 <code>vtk==9.0.x</code>，<a href="https://blog.csdn.net/weixin_43978293/article/details/118731248">据说</a> 在 python3.8 环境中似乎会出问题</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">pip <span class="token function">install</span> <span class="token assign-left variable">vtk</span><span class="token operator">==</span><span class="token number">8.1</span>.2 <span class="token comment"># 自动安装的vtk是9，会产生冲突</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li><p>还需要下载 <code>PyQt5</code> 以进行可视化</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">pip <span class="token function">install</span> PyQt5<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>之后遇到了一个与之相关的报错，也是困扰我很久，<a href="https://www.jianshu.com/p/b51008566134">博客</a> 解释是少了一些依赖库，可能是因为 docker 是一个精简的 ubuntu，没有完整的依赖库</p><p>通过 <code>apt install python3-pyqt5</code> 下载了其相关的依赖库 </p></li></ol><p>通过不断地尝试不断地折腾可算是安装好了😀先来进行测试吧！</p><h2 id="Demo-on-OpenPCDet"><a href="#Demo-on-OpenPCDet" class="headerlink" title="Demo on OpenPCDet"></a>Demo on OpenPCDet</h2><h3 id="Demo"><a href="#Demo" class="headerlink" title="Demo"></a>Demo</h3><p>先将原来的 KITTI 数据集放到 data 目录下，已经使用 MMDetection3d 生成了基本数据，但 OpenPCDet 暂时还不需要生成，Demo 只需要原始数据集就可以了。准备好模型和数据集后，运行以下命令测试一下 SECOND</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">import</span> osCONFIG_FILE <span class="token operator">=</span> <span class="token string">'/OpenPCDet/tools/cfgs/kitti_models/second.yaml'</span>CKPT <span class="token operator">=</span> <span class="token string">'/OpenPCDet/checkpoints/second_7862.pth'</span>POINT_CLOUD_DATA <span class="token operator">=</span> <span class="token string">'/OpenPCDet/data/kitti/training/velodyne/000007.bin'</span>os.system<span class="token punctuation">(</span>f<span class="token string">'python demo.py --cfg_file {CONFIG_FILE} \    --ckpt {CKPT} \    --data_path {POINT_CLOUD_DATA}'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>运行 <code>Demo.py</code> 后获得了如下预测结果，看上去还挺不错的</p><p><img src="/archives/93e5b117/image-20211102173223643.png" style="zoom:80%;"></p><h3 id="Test"><a href="#Test" class="headerlink" title="Test"></a>Test</h3><p>直接测试 SECOND 在 KITTI 验证集上的结果，列出 Car 相关的部分</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">Car AP@0.70, <span class="token number">0.70</span>, <span class="token number">0.70</span>:bbox AP:90.7803, <span class="token number">89.8999</span>, <span class="token number">89.0433</span>bev  AP:90.0097, <span class="token number">87.9282</span>, <span class="token number">86.4528</span>3d   AP:88.6137, <span class="token number">78.6245</span>, <span class="token number">77.2243</span>aos  AP:90.76, <span class="token number">89.77</span>, <span class="token number">88.82</span>Car AP_R40@0.70, <span class="token number">0.70</span>, <span class="token number">0.70</span>:bbox AP:95.6261, <span class="token number">94.1728</span>, <span class="token number">91.7683</span>bev  AP:92.4184, <span class="token number">88.5586</span>, <span class="token number">87.6479</span>3d   AP:88.6137, <span class="token number">78.6245</span>, <span class="token number">77.2243</span>aos  AP:95.59, <span class="token number">94.01</span>, <span class="token number">91.52</span>Car AP@0.70, <span class="token number">0.50</span>, <span class="token number">0.50</span>:bbox AP:90.7803, <span class="token number">89.8999</span>, <span class="token number">89.0433</span>bev  AP:90.7940, <span class="token number">90.1441</span>, <span class="token number">89.5173</span>3d   AP:90.7940, <span class="token number">90.0886</span>, <span class="token number">89.4014</span>aos  AP:90.76, <span class="token number">89.77</span>, <span class="token number">88.82</span>Car AP_R40@0.70, <span class="token number">0.50</span>, <span class="token number">0.50</span>:bbox AP:95.6261, <span class="token number">94.1728</span>, <span class="token number">91.7683</span>bev  AP:95.6751, <span class="token number">94.8476</span>, <span class="token number">94.2478</span>3d   AP:95.6623, <span class="token number">94.7450</span>, <span class="token number">94.0537</span>aos  AP:95.59, <span class="token number">94.01</span>, <span class="token number">91.52</span><span class="token punctuation">..</span>.<span class="token number">2021</span>-11-01 <span class="token number">11</span>:48:15,756   INFO  Result is save to /OpenPCDet/output/OpenPCDet/tools/cfgs/kitti_models/second/default/eval/epoch_7862/val/default<span class="token number">2021</span>-11-01 <span class="token number">11</span>:48:15,756   INFO  ****************Evaluation done.*****************<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>与 MMDetection3D 的结果进行对比，整体上来看还是相近的</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token comment"># OpenPCDet</span>Car AP@0.50, <span class="token number">0.70</span>3d   AP:90.7940, <span class="token number">90.0886</span>, <span class="token number">89.4014</span>3d   AP:88.6137, <span class="token number">78.6245</span>, <span class="token number">77.2243</span>Car AP_R40@0.50, <span class="token number">0.70</span>3d   AP:95.6623, <span class="token number">94.7450</span>, <span class="token number">94.0537</span>3d   AP:88.6137, <span class="token number">78.6245</span>, <span class="token number">77.2243</span><span class="token comment"># MMDetection3d</span>Car AP@0.50, <span class="token number">0.70</span>3d   AP:98.3329, <span class="token number">90.0209</span>, <span class="token number">89.4035</span>3d   AP:87.4561, <span class="token number">76.7570</span>, <span class="token number">74.1302</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Train"><a href="#Train" class="headerlink" title="Train"></a>Train</h3><p>查看一下 SECOND 训练的基本情况，这里改了一个配置：USE_ROAD_PLANE: False</p><p><img src="/archives/93e5b117/image-20211102184034692.png"></p><p>训练速度还是不错的，此时的 batch size per GPU = 4 比 MMDetection3D 效率更高，下面是 GPU 使用情况</p><p><img src="/archives/93e5b117/image-20211102184056522.png"></p><h2 id="CenterPoint-on-MMDetection3D"><a href="#CenterPoint-on-MMDetection3D" class="headerlink" title="CenterPoint on MMDetection3D"></a>CenterPoint on MMDetection3D</h2><p>现在尝试一下用 MMDetection3D 运行 CenterPoint，想要看一看 KITTI 数据集的结果，毕竟原论文中没有在 KITTI 上进行测试。有人在 <a href="https://github.com/open-mmlab/mmdetection3d/issues/871">github issue</a> 也进行了一些尝试，原文作者也有项目 <a href="https://github.com/tianweiy/CenterPoint-KITTI">CenterPoint-KITTI</a>，从实验结果来看，单阶段与 SECOND 效果差不多，并没有非常亮眼的表现，可能还需要进一步的微调</p><p>尝试在 MMDetection3D 上简单运行一下，然而似乎是显存不够的原因，没能够跑起来，后续再进一步研究吧</p>]]></content>
      
      
      <categories>
          
          <category> 编程 </category>
          
          <category> OpenMMLab </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MMDetection3D </tag>
            
            <tag> OpenPCDet </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Voxel R-CNN</title>
      <link href="/archives/de63c30e.html"/>
      <url>/archives/de63c30e.html</url>
      
        <content type="html"><![CDATA[<h1 id="Voxel-R-CNN"><a href="#Voxel-R-CNN" class="headerlink" title="Voxel R-CNN"></a>Voxel R-CNN</h1><hr><p>Deng, Jiajun, Shaoshuai Shi, Peiwei Li, Wengang Zhou, Yanyong Zhang, and Houqiang Li. “Voxel R-CNN: Towards High Performance Voxel-Based 3D Object Detection.” <em>ArXiv:2012.15712 [Cs]</em>, February 5, 2021. <a href="http://arxiv.org/abs/2012.15712">http://arxiv.org/abs/2012.15712</a>.</p><p>Comment: AAAI2021</p><hr><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>这篇论文是 PV-RCNN 的一个后续研究，为了解决 PV-RCNN 中的推理速度问题，在改进之后速度能够达到 25 fps 的实时推理速度（on NVIDIA 2080 Ti），相比于前作的 8.9 fps（论文提供数据）提升了接近2倍。同时在准度上也超越了前作，虽然超越得不多，但是本论文的整个框架非常干净，几乎没有使用任何其他的技巧，后续提升空间非常大</p><p>许多现有的高性能 3D 探测器都是基于点 point-based，因为这种结构可以更好地保留精确的空间信息。然而由于无序存储，point-wise 特征会导致高计算开销。相比之下，基于体素 voxel-based 的结构更适合于特征提取，但是准确度不高。<strong>而这篇论文就打破了这个观念——即使是粗粒度的体素块也能很好地提供空间信息，精确的点云信息并不是高性能的关键点</strong>。之前 voxel-based 方法之所以效果不佳，是因为将三维体素特征图谱 3D voxel feature map 重塑为 2D BEV feature map 过后不再利用原来的三维体素特征了，而重塑的过程中就损失了空间信息</p><p>论文的核心重点为使用了 voxel RoI pooling 操作，通过提取 RoI 中的特征对选框进行细化，其中 RoI 特征来源于 backbone 中提取的 3D feature（这里我叫它体素化特征 voxel-wise feature），而非 PV-RCNN 中的点类特征 point-wise feature。去除了计算量庞大的点类特征提取，使得 Voxel R-CNN 推理速度大大增加，同时保持了优异的准确率</p><h2 id="Voxel-R-CNN-Architecture"><a href="#Voxel-R-CNN-Architecture" class="headerlink" title="Voxel R-CNN Architecture"></a>Voxel R-CNN Architecture</h2><p><img src="/archives/de63c30e/image-20211019154543934.png"></p><p>可以说这个示意图展示出来的结构非常干净，没有多余的技巧，就是 RCNN 框架的三部曲：</p><ol><li>3D backbone特征提取</li><li>RPN 提出选框</li><li>2-Stage 细化选框</li></ol><h3 id="3D-backbone-amp-RPN"><a href="#3D-backbone-amp-RPN" class="headerlink" title="3D backbone &amp; RPN"></a>3D backbone &amp; RPN</h3><p>直接使用 SECOND 作为其 backbone 网络提取特征，将得到的 3D 特征沿 Z 轴进行堆叠，重塑为 2D 俯视特征图谱 BEV feature map 作为 RPN 的输入。论文在第三节就这样一句带过 3D backbone，该 backbone 有4个阶段，每个阶段的频道数分别为 16, 32, 48, 64</p><p>RPN 设计由两部分组成：</p><ol><li>top-down 特征提取网络，使用2个卷积块</li><li>对尺度特征融合结构，将不同分辨率的特征图谱进行上采样并连接起来，得到最终的特征图谱</li></ol><p>最后时候该特征图谱去做分类任务和回归任务，这部分与 VoxelNet 中的 RPN 结构也是类似的，这里贴一下 VoxelNet 中 RPN 的示意图</p><p><img src="/archives/de63c30e/image-20211019161506601.png" style="zoom: 67%;"></p><p>损失函数使用 focal loss 和 Huber loss，数学表示如下</p><script type="math/tex; mode=display">\mathcal{L}_{\mathrm{RPN}}=\frac{1}{N_{\mathrm{fg}}}\left[\sum_{i} \mathcal{L}_{\text {cls }}\left(p_{i}^{a}, c_{i}^{*}\right)+\mathbb{1}\left(c_{i}^{*} \geq 1\right) \sum_{i} \mathcal{L}_{\text {reg }}\left(\delta_{i}^{a}, t_{i}^{*}\right)\right]</script><p>其中 Huber loss 与通常使用的 smooth L1 loss 也是相似的，目的是为了减小奇异点的损失，其具体公式如下</p><script type="math/tex; mode=display">L_{\delta}(y, f(x))=\left\{\begin{array}{ll}\frac{1}{2}(y-f(x))^{2}, & \text { for }|y-f(x)| \leq \delta \\\delta \cdot\left(|y-f(x)|-\frac{1}{2} \delta\right), & \text { otherwise. }\end{array}\right.</script><p><img src="/archives/de63c30e/1182370-20180928094214405-164664611.gif" style="zoom:50%;"></p><h3 id="Voxel-RoI-pooling"><a href="#Voxel-RoI-pooling" class="headerlink" title="Voxel RoI pooling"></a>Voxel RoI pooling</h3><p>接下来就是论文核心操作了，即如何对提取出的体素化特征 voxel-wise feature 进行 RoI pooling</p><h4 id="Voxel-volumes-as-points"><a href="#Voxel-volumes-as-points" class="headerlink" title="Voxel volumes as points"></a>Voxel volumes as points</h4><p>将每一个体素块 voxel volume 视作为一个点，该点的坐标为体素中心的坐标</p><script type="math/tex; mode=display">\{v_i=x_i,y_i,z_i\}_{i=1}^N\\\{\phi_i\}_{i=1}^N</script><p>其中 $\phi_i$ 表示该体素的特征</p><h4 id="Voxel-query"><a href="#Voxel-query" class="headerlink" title="Voxel query"></a>Voxel query</h4><p>该操作为寻找某个体素附近的非空体素。由于体素的规范表达，两个体素之间的位置可以由他们的坐标 index 迅速计算，论文采用曼哈顿距离 Manhattan distance 表示两个体素 $\alpha,\beta$ 的距离</p><script type="math/tex; mode=display">\alpha = (i_\alpha, j_\alpha, k_\alpha),\ \beta = (i_\beta, j_\beta, k_\beta)\\D_{m}(\alpha, \beta)=\left|i_{\alpha}-i_{\beta}\right|+\left|j_{\alpha}-j_{\beta}\right|+\left|k_{\alpha}-k_{\beta}\right|</script><p>论文使用球搜索 ball query 来寻找附近的体素，时间复杂度为 $O(K)$，其中 $K$ 是（最大）邻居数。但这个 ball query 算法具体怎么实现的暂时还不理解…给自己留个坑吧，以后补机器学习和数据结构的时候看能不能填上！</p><p><img src="/archives/de63c30e/image-20211019170427837.png" style="zoom: 50%;"></p><h4 id="Voxel-RoI-pooling-1"><a href="#Voxel-RoI-pooling-1" class="headerlink" title="Voxel RoI pooling"></a>Voxel RoI pooling</h4><p>首先将提议选框 proposal 平均分成 $G\times G\times G$ 个子体素块，将子体素块的中心点作为采样栅格点 $g_i$，用于进一步聚集体素特征。对于每一个采样栅格点，使用 voxel query，得到其邻居集合 $\Gamma_i = \{v_i^1,…,v_i^K\}$ 然后使用 PointNet 模块进行特征提取</p><script type="math/tex; mode=display">\boldsymbol{\eta}_{i}=\max _{k=1,2, \cdots, K}\left\{\Psi\left(\left[\boldsymbol{v}_{i}^{k}-\boldsymbol{g}_{i} ; \boldsymbol{\phi}_{i}^{k}\right]\right)\right\}</script><p>在真正实施该 pooling 操作时，其 pooling 对象其实不是初始的体素化点云，而是 3D backbone 中最后两个阶段的 3D voxel-wise feature。并且对于每个阶段，设置了多个曼哈顿距离阈值以进行对尺度聚集 grouping，最后将不同阶段不同尺度的聚集特征进行连接得到最终的特征集</p><h4 id="Accelerated-local-aggregation"><a href="#Accelerated-local-aggregation" class="headerlink" title="Accelerated local aggregation"></a>Accelerated local aggregation</h4><p>论文使用了加速版本的 PointNet，区别与原始版本先做邻居搜索再进行特征提取，加速版本的 PointNet 将体素块的位置 $(x,y,z)$ 和特征 feature 进行分别处理，图示如下</p><p><img src="/archives/de63c30e/image-20211019171951879.png" style="zoom:80%;"></p><p>如果按照 PV-RCNN 中的方法进行点云特征聚合，则要先寻找附近的点 grouping，然后再对附近的点使用 MLP 做特征提取，这一过程的复杂度为 $(O(M × K × (C + 3) × C’ ))$，其中 $M=r\times G^3$ 为格点数 grid points，$r$ 为 RoI 数量，$K$ 为（最大）邻居数，$C+3$ 为输入特征维数，$C’$ 为输出特征维数</p><p>而论文将相对坐标与体素特征分离。给定权重为$ W ∈ \mathbb R^{C’ ,C+3}$ 的全连接层，论文将其分为 $ W_F ∈ \mathbb R^{C’ ,C}$  和  $ W_C ∈ \mathbb R^{C’ ,3}$。由于体素特征与网格点无关，因此在执行 voxel query 搜索之前，直接在体素特征上应用了权重为 $W_F$ 的全连接层。然后，在 voxel query 之后，我们只将分组的相对坐标乘以 $W_C$，得到相对位置特征，并将它们添加到分组的体素特征中</p><p>加速 PointNet 模块的 FLOP 为 $O(N ×C ×C’ +M ×K × 3×C’)$，由于分组体素的数量 $M ×K$ 比 $N$ 高一个数量级，因此加速的 PointNet 模块比原始模块更高效。更直观地来讲，这样减少了很多由于重叠的邻居产生的特征提取操作</p><p>这部分内容引起了我对于 FC/MLP 作用的思考：MLP 将原始特征通过<strong>简单的</strong>非线性变换映射到新的特征空间中，其中伴随的维度变换是最直观的体现。以上方法做特征聚集竟然可以将输入分开来看待，这样做竟然不会影响表现，那为什么不对相对坐标也采用同样的操作，这样复杂度为 $O(N ×(C+3) ×C’)$ 会变得更小</p><h3 id="Detection-head"><a href="#Detection-head" class="headerlink" title="Detection head"></a>Detection head</h3><p>经过 voxel RoI pooling 过后每一个选框都有对应的特征向量集来表示，接下来就使用这些特征对选框进行细化。具体来讲，使用一个 shared 2-layer MLP 将 RoI 特征进一步做特征提取，将这些特征用于置信度预测和回归预测两个任务。回归分支预测从 3D 预测选框 proposals 到真实框的残差，置信度分支预测与 IoU 相关的分数。这些都是很常规的操作了，与 PV-RCNN 中是一致的，使用 binary cross entropy loss 和 smooth L1 loss，数学表示如下</p><script type="math/tex; mode=display">\begin{aligned}\mathcal{L}_{\text {head }}=& \frac{1}{N_{s}}\left[\sum_{i} \mathcal{L}_{\text {cls }}\left(p_{i}, l_{i}^{*}\left(\operatorname{IoU}_{i}\right)\right)\right.\\&\left.+\mathbb{1}\left(\operatorname{Io} U_{i} \geq \theta_{\text {reg }}\right) \sum_{i} \mathcal{L}_{\text {reg }}\left(\delta_{i}, t_{i}^{*}\right)\right]\end{aligned}</script><script type="math/tex; mode=display">l_{i}^{*}\left(\mathrm{IoU}_{i}\right)=\left\{\begin{array}{ll}0 & \mathrm{IoU}_{i}<\theta_{L} \\\frac{\mathrm{loU}_{i}-\theta_{L}}{\theta_{H}-\theta_{L}} & \theta_{L} \leq \mathrm{IoU}_{i}<\theta_{H} \\1 & \mathrm{IoU}_{i}>\theta_{H}\end{array}\right.</script><h2 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a>Experiment</h2><h3 id="SECOND-amp-PV-RCNN"><a href="#SECOND-amp-PV-RCNN" class="headerlink" title="SECOND &amp; PV-RCNN"></a>SECOND &amp; PV-RCNN</h3><p><img src="/archives/de63c30e/image-20211020194545864.png"></p><p>论文对 SECOND 和 PV-RCNN 进行了实验，两张图分别说明了：</p><ol><li>2-Stage 的细化是有效果的，前作 PV-RCNN 的表现是相当不错的</li><li>PV-RCNN 中花费了大量时间（超过一般）用于 voxel set abstraction (VSA) 操作，逐点操作 point-wise operation 计算量很大</li></ol><h3 id="KITTI"><a href="#KITTI" class="headerlink" title="KITTI"></a>KITTI</h3><h4 id="val-set"><a href="#val-set" class="headerlink" title="val set"></a>val set</h4><p><img src="/archives/de63c30e/image-20220129123000757.png" alt="image-20220129123000757" style="zoom: 50%;"></p><h4 id="test-set"><a href="#test-set" class="headerlink" title="test set"></a>test set</h4><p><img src="/archives/de63c30e/image-20211020195023758.png"></p><p>对标 SA-SSD，在准度和速度上均实现了超越</p><h3 id="Waymo"><a href="#Waymo" class="headerlink" title="Waymo"></a>Waymo</h3><p><img src="/archives/de63c30e/image-20211020195307759.png"></p><h3 id="Ablation-study"><a href="#Ablation-study" class="headerlink" title="Ablation study"></a>Ablation study</h3><p><img src="/archives/de63c30e/image-20211020200856394.png"></p><p>其中不使用 voxel query 则使用 ball query 替代，区别请参考 voxel query 一节 Figure 3。可以看出 voxel query 稍微加快了速度也稍微提升了准确率，对于速度提升最大的是 accelerated PointNet 操作。对于准度提升最大的则是 2-Stage detection head，但同时也让速度下降一半多</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>这一篇论文的中心思想很明确，就是直接使用 voxel-wise feature 对预测选框进行细化，然后加速了 PointNet 特征提取操作，二者的结合形成了本文的核心 voxel RoI pooling。Voxel R-CNN 在速度和准度上全面超越了前作 PV-RCNN，重点在于其网络结构非常干净，没有使用过多的辅助技巧，如果将其他论文中的提升技巧结合到本论文中（例如语义分割），应该会有更多的提升，期待之后的发展</p>]]></content>
      
      
      <categories>
          
          <category> papers </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Voxel R-CNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker</title>
      <link href="/archives/f5f9fa9b.html"/>
      <url>/archives/f5f9fa9b.html</url>
      
        <content type="html"><![CDATA[<h1 id="Docker"><a href="#Docker" class="headerlink" title="Docker"></a>Docker</h1><p>很早之间就听说 docker 了，最近在 bilibili 上还看到了这么一个视频：<a href="https://www.bilibili.com/video/BV163411C7jE">为什么我不用 Docker？</a> 着实把我笑拉了。而且在看 MMDetection3D 的时候发现可以通过 docker 安装，那么就尝试一下这个工具吧！也许又打开了新世界大门呢？更多关于科普的知识可以看这篇 <a href="https://zhuanlan.zhihu.com/p/187505981">知乎</a>，这里引用其中一句话</p><blockquote><p>docker是一个用Go语言实现的开源项目，可以让我们方便的创建和使用容器，docker将程序以及程序所有的依赖都打包到docker container，这样你的程序可以在任何环境都会有一致的表现，这里程序运行的依赖也就是容器就好比集装箱，容器所处的操作系统环境就好比货船或港口，<strong>程序的表现只和集装箱有关系(容器)，和集装箱放在哪个货船或者哪个港口(操作系统)没有关系</strong>。</p></blockquote><p>整个笔记参考 <a href="https://www.bilibili.com/video/BV1og4y1q7M4">狂神说 Docker</a>，打算整理一些基本逻辑和命令，方便之后复习与查看</p><p>Link: <a href="https://dockerlabs.collabnix.com/docker/cheatsheet/">Docker Cheat Sheet</a></p><h2 id="安装-Docker"><a href="#安装-Docker" class="headerlink" title="安装 Docker"></a>安装 Docker</h2><p>这一步就不多说了，直接上 <a href="https://www.docker.com/">官网</a> 下载，也可以根据上面提到的视频教程进行下载。如果下载很慢的话依旧考虑镜像安装，这里贴一个自家镜像关于 docker 的帮助文档：<a href="https://mirror.nju.edu.cn/help/docker-ce">NJU Mirror</a>，同时官方也提供了卸载 docker 的操作，可以放心下载了！现在我是在 windows 上熟悉 docker 操作，直接傻瓜式下载了 docker desktop，其中 Windows 安装可能遇到报错 <code>WSL 2 installation is incomplete</code>，根据提示下载 <a href="https://wslstorestorage.blob.core.windows.net/wslblob/wsl_update_x64.msi">WLS_update_x64.msi</a> 安装即可</p><h2 id="Docker-基本组成"><a href="#Docker-基本组成" class="headerlink" title="Docker 基本组成"></a>Docker 基本组成</h2><ol><li><p>镜像（image）</p><blockquote><p>When running a container, it uses an isolated filesystem. This custom filesystem is provided by a <strong>container image</strong>. Since the image contains the container’s filesystem, it must contain everything needed to run an application - all dependencies, configuration, scripts, binaries, etc. The image also contains other configuration for the container, such as environment variables, a default command to run, and other metadata.</p></blockquote></li><li><p>容器（container）</p><blockquote><p>A container is a sandboxed process on your machine that is isolated from all other processes on the host machine. </p></blockquote><p>一种形象的说法时，镜像是类 class，容器是类的实例 object</p></li><li><p>仓库（repository）</p><p>就像 github 一样，仓库 dockerhub 可以存放各种开源镜像以供大家下载，如果下载 dockerhub 的速度慢，依然可以使用国内镜像源进行下载，<a href="https://mirror.nju.edu.cn/help/docker-hub">NJU Mirror</a></p></li></ol><h2 id="Docker-的常用命令"><a href="#Docker-的常用命令" class="headerlink" title="Docker 的常用命令"></a>Docker 的常用命令</h2><p><a href="https://docs.docker.com/reference/">官方参考文档</a></p><h3 id="Basic"><a href="#Basic" class="headerlink" title="Basic"></a>Basic</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">docker version<span class="token comment"># 查看版本信息</span>docker info<span class="token comment"># 显示 docker 的系统信息，包括镜像和容器的数量</span>docker <span class="token punctuation">[</span>command<span class="token punctuation">]</span> --help<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="Image"><a href="#Image" class="headerlink" title="Image"></a>Image</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token comment"># 查看镜像</span>docker images<span class="token comment"># 查看 images</span>docker images -aq<span class="token comment"># 查看所有 images id.</span><span class="token comment"># a for all, q for quiet</span><span class="token comment"># 搜索镜像</span>docker search img_name<span class="token comment"># 搜索镜像</span>docker search -f<span class="token comment"># filter</span><span class="token comment"># 下载镜像</span>docker pull name:tag<span class="token comment"># 下载镜像，可以指定标签/版本</span><span class="token comment"># 删除镜像</span>docker rmi img_name<span class="token comment"># 移除镜像</span>docker rmi -f img_name<span class="token comment"># 强制删除镜像</span>docker rmi -f <span class="token variable"><span class="token variable">$(</span>docker images -aq<span class="token variable">)</span></span><span class="token comment"># 强制删除全部镜像</span>docker image prune -a<span class="token comment"># 清理没有使用的镜像</span><span class="token comment"># 给镜像打标签</span>docker tag src_img dst_img:tag<span class="token comment"># 创造新的镜像及新标签</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Container"><a href="#Container" class="headerlink" title="Container"></a>Container</h3><p>有了镜像 image 过后才能创建容器 container，这一部分的命令是最核心的也是最多的</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token comment"># 创建容器</span>docker run <span class="token punctuation">[</span>opt<span class="token punctuation">]</span> img<span class="token comment"># 常用参数</span>--name string<span class="token comment"># 给容器命名</span>-d, --detached<span class="token comment"># 后台运行</span>-it<span class="token comment"># 交互终端 interactive terminal</span>-p host_port:ctn_port<span class="token comment"># 指定暴露端口</span>--rm<span class="token comment"># 退出后删除容器</span>--hostname name<span class="token comment"># 指定主机名</span><span class="token comment"># 查看容器</span>docker <span class="token function">ps</span><span class="token comment"># 查看运行中的容器</span>docker <span class="token function">ps</span> -a<span class="token comment"># 查看所有容器</span>docker <span class="token function">ps</span> -q<span class="token comment"># 查看运行中的容器id</span>docker <span class="token function">ps</span> -n int<span class="token comment"># 限制显示数量</span>docker logs --tail <span class="token number">10</span> ctn_id<span class="token comment"># 查看容器操作日志</span>docker <span class="token function">top</span> ctn_id<span class="token comment"># 查看容器进程</span>docker inspect ctn_id<span class="token comment"># 查看容器元数据</span><span class="token comment"># 退出容器</span><span class="token builtin class-name">exit</span><span class="token comment"># 完全退出</span>ctrl + P + Q<span class="token comment"># 容器在后台仍运行</span><span class="token comment"># 启动和停止容器</span>docker start ctn_iddocker start -ai ctn_id<span class="token comment"># 启动并进入容器交互</span>docker restart ctn_iddocker stop ctn_iddocker <span class="token function">kill</span> ctn_id<span class="token comment"># 强制停止</span><span class="token comment"># 进入运行中的容器</span>docker <span class="token builtin class-name">exec</span> -it ctn_id<span class="token comment"># 进入容器并开启新终端</span>docker attach ctn_id<span class="token comment"># 进入正在执行的终端</span><span class="token comment"># 删除容器</span>docker <span class="token function">rm</span> ctn_id<span class="token comment"># 删除指定容器</span>docker <span class="token function">rm</span> -f <span class="token variable"><span class="token variable">$(</span>docker <span class="token function">ps</span> -aq<span class="token variable">)</span></span><span class="token comment"># 强制删除所有容器</span><span class="token comment"># 拷贝容器文件至主机</span>docker <span class="token function">cp</span> ctn_id:src_path dst_path<span class="token comment"># 之后使用卷技术 -v 可以实现文件共享</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>以上的 <code>ctn_id</code> 指的时容器 id，也可以用容器名替代，如果有的话</p><p>补充：自己担心下载的镜像太多了会占用 C 盘，所以使用目录连接，将 docker appdata 移到了 D 盘</p><pre class="line-numbers language-cmd" data-language="cmd"><code class="language-cmd"># 管理员权限mklink /j Docker D:\AppData\Dockermklink /j target source<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h2 id="Docker-镜像讲解"><a href="#Docker-镜像讲解" class="headerlink" title="Docker 镜像讲解"></a>Docker 镜像讲解</h2><h3 id="镜像加载原理"><a href="#镜像加载原理" class="headerlink" title="镜像加载原理"></a>镜像加载原理</h3><p>UnionFS 是一种分层、轻量级并且高性能的文件系统。支持对文件系统的修改作为一次提交来一层层的叠加，同时可以将不同目录挂载到同一个虚拟文件系统下。在这种层级结构下，如果有涉及到相同的文件，那么层与层间就可以共用了，极大节省资源</p><p>docker 的镜像实际上由一层一层的文件系统组成，这种层级文件系统就是上述的 UnionFS。接着，在内部又分为2部分：</p><ul><li>boot file system （bootfs）：docker镜像的最底层是bootfs，主要包含 bootloader（加载器）和 kernel（内核）。bootloader 主要是引导加载 kernel。注意 kernel 是与宿主机共享的，而且不用像虚拟机一样模拟硬件，所以 docker 加载很快，是秒级的</li><li>root file system （rootfs）：包含典型的目录结构，包括 /dev, /proc, /bin, /etc, /lib, /usr, and /tmp 等再加上要运行用户应用所需要的所有配置文件，二进制文件和库文件。这个文件系统在不同的Linux 发行版（Ubuntu, CentOS…）中是不同的。而且用户可以对这个文件进行修改，对比之下，用户就不会修改 bootfs</li></ul><p><img src="/archives/f5f9fa9b/image-20220129171824126.png" alt="image-20220129171824126" style="zoom: 50%;"></p><p>Docker 镜像都是只读的，当启动容器时，一个新的可写层被加载到镜像的顶部，这一层就是通常说的容器层，容器之下的都叫镜像层</p><h3 id="Commit-image"><a href="#Commit-image" class="headerlink" title="Commit image"></a>Commit image</h3><p>当你在容器中完成了你的应用，想要将该容器生成镜像，就可以使用 <code>docker commit</code> 命令。本质上就是把你的容器层变为镜像层，加入到原来的镜像层中（root file system）再打包保存起来。因为是分层文件管理系统，所以这样的操作很方便</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">docker commit -a <span class="token string">"author"</span> -m <span class="token string">"message"</span> ctn_id img_name:tag<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这样就可以打造自己的个性化镜像了，但之后还会有更高级的方法 Dockerfile 来创造镜像</p><h3 id="Save-amp-load-image"><a href="#Save-amp-load-image" class="headerlink" title="Save &amp; load image"></a>Save &amp; load image</h3><p>有时候不希望从网络下载镜像，可以使用 <code>docker save</code> 命令打包镜像，然后把镜像传输给需要的人，别人再用 <code>docker load</code> 将镜像加载即可</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">docker save -o xxx.tar imgdocker save -i xxx.tar <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h2 id="容器数据卷"><a href="#容器数据卷" class="headerlink" title="容器数据卷"></a>容器数据卷</h2><p>这是一种将<strong>数据持久化/共享数据</strong>的技术。数据卷可以将容器与宿主机，容器与容器之间连接一个通道，进行数据共享，可同步修改。并且删掉其中一个容器的数据（不是修改），其他容器的共享数据并不会损坏，这就达到了持久化的效果</p><h3 id="使用数据卷"><a href="#使用数据卷" class="headerlink" title="使用数据卷"></a>使用数据卷</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token comment"># 在创建容器时通过参数 -v 挂载</span>-v, --volume<span class="token operator">=</span><span class="token punctuation">[</span>host-src:<span class="token punctuation">]</span>container-dest<span class="token punctuation">[</span>:<span class="token operator">&lt;</span>options<span class="token operator">&gt;</span><span class="token punctuation">]</span><span class="token comment"># The 'host-src' is an absolute path or a name value.</span><span class="token comment"># 通过多次 -v 参数挂载多个卷</span><span class="token comment"># 指定路径挂载</span><span class="token comment"># 如果不存在路径则自动创造</span>docker run -v host_dir:ctn_dir ctn_id<span class="token comment"># 匿名挂载</span><span class="token comment"># 仅传入容器内路径</span>docker run -v ctn_dir ctn_id<span class="token comment"># 具名挂载</span><span class="token comment"># 给卷添加名字，注意这区别于指定路径挂载</span>docker run -v name:ctn_dir ctn_id <span class="token comment"># 指定读写权限，如 ro 指容器只能读卷</span>docker run -v ctn_dir:ro ctn_iddocekr run -v ctn_dir:rw ctn_id<span class="token comment"># 容器之间的共享卷</span><span class="token comment"># 可以其他容器的卷挂载到当前容器下</span>docker run --volumes-from ctn_list ctn_id<span class="token comment"># 查看所有卷的情况</span>docker volume <span class="token function">ls</span>docker volume inspect volume_id<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>”挂载“的本质是在宿主机创造了一个数据卷 volume（如果实现没有该 volume 的话），可以把这个卷看作为一个共享文件夹，通过指定命令大家都可以来访问和修改</p><p>数据卷还可以使用 <code>docker inspect ctn_id</code> 查看详情，在 <code>Mount</code> 字段下记录有 <code>Source &amp; Destination</code> 分别对应宿主机和容器内目录</p><p>除了通过 <code>-v</code> 命令挂载卷之外，还可以使用 Dockerfile 进行挂载，通过指定 VOLUME 字段，确定容器内挂载路径</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">VOLUME <span class="token punctuation">[</span><span class="token string">"DIR_1"</span>,<span class="token string">"DIR_2"</span>,<span class="token punctuation">..</span>.<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>以上的操作都是在创建容器时挂载卷，如果在创建好容器之后想要挂载卷应该怎么办呢？事实上也没有一个优雅的办法能解决，可以选择将该容器 commit 为镜像，然后再进行创建</p><h2 id="Dockerfile"><a href="#Dockerfile" class="headerlink" title="Dockerfile"></a>Dockerfile</h2><p>在上一节首次提到了使用 dockerfile 挂载卷。Dockerfile 是用来构建 docker 镜像的文件，本质为一个命令参数脚本。先来看看一些官方的 dockerfile 是怎么写的😀</p><pre class="line-numbers language-dockerfile" data-language="dockerfile"><code class="language-dockerfile">FROM scratchADD ubuntu-focal-oci-amd64-root.tar.gz /# 假设该压缩文件已经预先下载到后面指定的目录CMD ["bash"]<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>这三行就创建了一个 Ubuntu 20.04 dockerfile，一般官方所给的都是最基础的，很多功能都没有，所以有时候需要自己创建 dockerfile 以及对应的镜像。简单介绍一下基础知识：</p><ol><li>所有命令都是大写</li><li>命令按照顺序从上到下执行</li><li>注释使用井号 #</li><li>每个命令都会形成一个新的镜像层</li></ol><h3 id="Dockerfile-命令"><a href="#Dockerfile-命令" class="headerlink" title="Dockerfile 命令"></a>Dockerfile 命令</h3><p>Dockerfile 的常用命令及其作用</p><ul><li>FROM：基于哪个基础镜像</li><li>WORKDIR：指定shell命令运行在哪个目录下。为后续的 RUN、CMD、COPY、ADD 等命令配置工作目录。接下来的 COPY 和 ADD 命令中的相对路径就是相对于 WORKDIR 指定的路径</li><li>COPY：将当前宿主机的文件拷贝到镜像中去（<strong>copy的文件必须在build命令最后指定的路径内</strong>）</li><li>ADD：和COPY一样，并且还可以解压缩，或者从 url 拷贝文件到镜像中。<strong>COPY 和 ADD 命令具有相同的特点：只复制目录中的内容而不包含目录自身</strong>。</li><li>RUN：构建镜像时运行的shell命令</li><li>CMD：容器运行时执行的shell命令（<strong>多个CMD只有最后一个生效，要想都执行可以使用&amp;&amp;连接多个命令</strong>）（<strong>如果容器run时，后面指定了shell版本，Dockerfile中的CMD也会被覆盖</strong>）</li><li>ENTRYPOINT：和CMD一样，但是可以追加（必须使用exec格式，即：ENTRYPOINT [./entrypoint.sh，参数1，参数2……]）</li><li>EXPOSE：指定镜像暴露出来的端口</li><li>VOLUMU：数据容器卷，指定映射文件，用于数据持久化</li><li>ENV：指定环境变量</li><li>LABEL：指定容器运行时标示</li><li>SHELL：指定shell</li><li>MAINTAINER：镜像维护者的姓名和邮箱地址</li><li>ONBUILD：当构建一个父镜像时，父镜像被子镜像继承时，ONBUILD被触发</li></ul><p>这里贴一个 mmdetection 3D 写的 dockerfile</p><pre class="line-numbers language-dockerfile" data-language="dockerfile"><code class="language-dockerfile">ARG PYTORCH="1.6.0"ARG CUDA="10.1"ARG CUDNN="7"FROM pytorch/pytorch:${PYTORCH}-cuda${CUDA}-cudnn${CUDNN}-devel# 如果预先没有下载该镜像，猜测会自动装，类似 docker runENV TORCH_CUDA_ARCH_LIST="6.0 6.1 7.0+PTX"ENV TORCH_NVCC_FLAGS="-Xfatbin -compress-all"ENV CMAKE_PREFIX_PATH="$(dirname $(which conda))/../"RUN apt-get update &amp;&amp; apt-get install -y ffmpeg libsm6 libxext6 git ninja-build libglib2.0-0 libsm6 libxrender-dev libxext6 \    &amp;&amp; apt-get clean \    &amp;&amp; rm -rf /var/lib/apt/lists/*# Install MMCV, MMDetection and MMSegmentationRUN pip install mmcv-full==1.3.8 -f https://download.openmmlab.com/mmcv/dist/cu101/torch1.6.0/index.htmlRUN pip install mmdet==2.17.0RUN pip install mmsegmentation==0.18.0# Install MMDetection3DRUN conda clean --allRUN git clone https://github.com/open-mmlab/mmdetection3d.git /mmdetection3dWORKDIR /mmdetection3dENV FORCE_CUDA="1"RUN pip install -r requirements/build.txtRUN pip install --no-cache-dir -e .<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>使用 dockerfile 生成镜像的常用命令</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">docker build -t name:tag -f dockerfile_name FILE_PATH<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="发布镜像"><a href="#发布镜像" class="headerlink" title="发布镜像"></a>发布镜像</h2><h3 id="DockerHub"><a href="#DockerHub" class="headerlink" title="DockerHub"></a>DockerHub</h3><ol><li><p>注册 dockerhub 账户</p></li><li><p>登录，直接输入 <code>docker login</code> 就会提示进程，也可以带参数</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">docker login -u username<span class="token comment"># Password:</span>docker <span class="token builtin class-name">logout</span><span class="token comment"># 退出登录</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>发布镜像 <code>docker push img:tag</code></p></li></ol><p>也可以选择国内仓库进行发布，例如阿里云，这里不过多介绍了</p><h2 id="以图片小结-Docker"><a href="#以图片小结-Docker" class="headerlink" title="以图片小结 Docker"></a>以图片小结 Docker</h2><p><img src="/archives/f5f9fa9b/format,png.png"></p>]]></content>
      
      
      <categories>
          
          <category> 编程 </category>
          
          <category> Tools </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker </tag>
            
            <tag> 教程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>VoxelNet &amp; SECOND</title>
      <link href="/archives/4486189f.html"/>
      <url>/archives/4486189f.html</url>
      
        <content type="html"><![CDATA[<h1 id="VoxelNet-amp-SECOND"><a href="#VoxelNet-amp-SECOND" class="headerlink" title="VoxelNet &amp; SECOND"></a>VoxelNet &amp; SECOND</h1><hr><p>Zhou, Yin, and Oncel Tuzel. “VoxelNet: End-to-End Learning for Point Cloud Based 3D Object Detection.” <em>ArXiv:1711.06396 [Cs]</em>, November 16, 2017. <a href="http://arxiv.org/abs/1711.06396">http://arxiv.org/abs/1711.06396</a>.</p><p>Yan, Yan, Yuxing Mao, and Bo Li. “SECOND: Sparsely Embedded Convolutional Detection.” <em>Sensors</em> 18, no. 10 (October 6, 2018): 3337. <a href="https://doi.org/10.3390/s18103337">https://doi.org/10.3390/s18103337</a>.</p><hr><h2 id="VoxelNet"><a href="#VoxelNet" class="headerlink" title="VoxelNet"></a>VoxelNet</h2><h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>VoxelNet 作为体素化处理点云的奠基之作，其地位也是相当高的。该论文为之后的体素化框架提供了通用的思路：该网络将点云分割为均匀的 3D 体素块，并将每一个体素内的点使用统一的特征表示。然后再将 3D 特征图谱转化为 BEV 特征图谱进行选框预测</p><p>在当时对于点云特征提取还处于起步阶段，PointNet 刚刚问世，对于特征提取不再使用人工设计特征，多视角融合的方法也逐渐被超越。但是 PointNet 庞大的运算量是一个亟需解决的问题，为了有效地利用点云，将其进行体素化表示不失为一个好方向，规则化的数据结构一般是更利于存储与学习的，VoxelNet 应运而生 </p><h3 id="VoxelNet-Architecture"><a href="#VoxelNet-Architecture" class="headerlink" title="VoxelNet Architecture"></a>VoxelNet Architecture</h3><p><img src="/archives/4486189f/image-20211018182525929.png"></p><h4 id="Feature-Learning-Network"><a href="#Feature-Learning-Network" class="headerlink" title="Feature Learning Network"></a>Feature Learning Network</h4><p>这一部分是整个网络的核心，详细地描述了如何将点云编码为体素化特征图谱。首先是将网络分割为均匀的体素块，最终可以使用 $(D,H,W)$ 形状的矩阵来表示该体素化点云。由于点云中能够包含 ~100k 数量级的点，所以对每个体素块 $(d,h,w)$ 中的点的数量进行限制，最多不超过 $T$ 个点，这样的限制能够很好的节约计算，平衡每个体素块内的点云数量</p><p>接下来就是使用多个体素特征编码模块 voxel feature encoding (VFE) 对每个体素块内的点云进行特征提取，下面对 VFE 模块进行详细了解。其中<strong>一个</strong>非空体素块特征表示为如下公式</p><script type="math/tex; mode=display">\mathbf{V}=\left\{\mathbf{p}_{i}=\left[x_{i}, y_{i}, z_{i}, r_{i}\right]^{T} \in \mathbb{R}^{4}\right\}_{i=1 \ldots t}</script><p>即该体素块中所有的点，其中 $r_i$ 为反射强度。将该特征进行增强，加入每个点距离该体素中心的偏移量</p><script type="math/tex; mode=display">\mathbf{V_in}=\left\{\hat{\mathbf{p}}_{i}=\left[x_{i}, y_{i}, z_{i}, r_{i}, x_i-v_x, y_i-v_y, z_i-v_z\right]^{T} \in \mathbb{R}^{4}\right\}_{i=1 \ldots t}</script><p>将该特征送入网络（FCN + BN + ReLU）得到每一个点的特征 $\mathbf{f}_i \in \mathbb{R}^m$，然后再使用 MaxPooling 获得该体素的整体特征 $\tilde{\mathbf{f}}_i \in \mathbb{R}^m$ 。（其实这个结构与 PointNet 是相似的，只不过论文中名称叫 FCN/MLP 而不是 shared MLP，但实际上 FCN 的权重是所有非空体素共享的）</p><p>将体素的特征与逐点的特征 point-wise feature 连接起来</p><script type="math/tex; mode=display">\mathbf{f}_{i}^{o u t}=\left[\mathbf{f}_{i}^{T}, \tilde{\mathbf{f}}^{T}\right]^{T} \in \mathbb{R}^{2 m}</script><p>该操作是为了给每个点增加其所在体素的信息。以上就是第一个 VFE 模块的操作过程，将体素中的点云编码为统一形状的特征向量，图示如下</p><p><img src="/archives/4486189f/image-20211018193130912.png" style="zoom: 80%;"></p><p>论文使用多个这样的 VFE 模块，不断地对点云进行特征提取操作，最后一个 VFE 模块在使用 MaxPooling 后，不再将其连接到逐点的特征上，即最终得到了一个逐体素的特征图谱 voxel-wise feature，每个体素的特征维数记为 $C$，整个点云的特征图谱表示为 $(C, D, H, W)$ 形状的矩阵</p><h4 id="Convolutional-middle-layers"><a href="#Convolutional-middle-layers" class="headerlink" title="Convolutional middle layers"></a>Convolutional middle layers</h4><p>这部分论文以少量的文字描述略过。就是对提取出来的体素特征进行卷积操作，表示为 Conv3D(C_in, C_out, kernel_size, stride, padding)。这一结构的逐渐聚集体素特征，缩小特征图谱分辨率，不断提升图谱中每个像素的感受野</p><h4 id="Region-Proposal-Network"><a href="#Region-Proposal-Network" class="headerlink" title="Region Proposal Network"></a>Region Proposal Network</h4><p>首先将 3D 的特征图谱沿着 z 轴，重塑 reshape 为 2D 的 BEV 俯视特征图谱。转换到二维过后就是熟悉的领域了，先使用多个二维卷积模块 Conv2D 进行特征提取，然后将不同分辨率的特征图谱进行上采样或者叫反卷积 upsampling/deconvolution。经过上采样后，得到多个分辨率相同的特征图谱，然后将它们连接起来，使用 anchor-based detector 进行分类任务和回归任务。整个 RPN 网络的结构如下图所示    </p><p><img src="/archives/4486189f/image-20211018193754367.png"></p><p>对于 anchor 的设置不像二维一样有很多个尺度的 anchor，论文仅使用了一个 anchor size 和两个旋转角度（水平和垂直）作为预定义选框</p><h4 id="Loss-function"><a href="#Loss-function" class="headerlink" title="Loss function"></a>Loss function</h4><p>关于回归任务使用的是对数大小 logarithmic size 的残差值作为拟合对象/标签，而不是直接使用真实的残差值，具体这么做的原因我不太清楚，可能对数函数能够让标签更加平滑，并且从图像上来看，log 函数能够稍微降低惩罚</p><script type="math/tex; mode=display">\begin{array}{l}\Delta x=\frac{x_{c}^{g}-x_{c}^{a}}{d^{a}}, \Delta y=\frac{y_{c}^{g}-y_{c}^{a}}{d^{a}}, \Delta z=\frac{z_{c}^{g}-z_{c}^{a}}{h^{a}} \\\Delta l=\log \left(\frac{l^{g}}{l^{a}}\right), \Delta w=\log \left(\frac{w^{g}}{w^{a}}\right), \Delta h=\log \left(\frac{h^{g}}{h^{a}}\right) \\\Delta \theta=\theta^{g}-\theta^{a}\end{array}\\</script><script type="math/tex; mode=display">where \ d^{a}=\sqrt{\left(l^{a}\right)^{2}+\left(w^{a}\right)^{2}}</script><p>回归任务的损失函数为 smooth L1 loss，分类任务使用交叉熵损失 cross entropy loss（这个时候 focal loss 还没诞生，在之后其升级框架 SECOND 中使用了）</p><p><img src="/archives/4486189f/image-20211018195534649.png" style="zoom: 80%;"></p><p>由于是 anchor-based RPN 依然是要对预定义选框 pre-defined anchors 进行正负分类的，而且回归损失对 positive anchor 所预测的选框计算损失</p><h4 id="Data-structure"><a href="#Data-structure" class="headerlink" title="Data structure"></a>Data structure</h4><p>既然使用了体素化表示，必定带来数据结构上的表示优势。由于点云的稀疏性，有大量的体素内部是没有点云的，此时使用哈希表能够快速地查找体素阵中的非空体素。假设非空的体素块最多有 $K$ 个，初始化一个 $(K,T,7)$ 形状的矩阵以存储每个体素及其内部点云的特征，其中 $T$ 代表一个体素内最多有 $T$ 个点，$7$ 代表原始点云的特征。以每个体素的坐标作为 hash key 制作 hash table，通过遍历所有的点，就能够将每个点分配到对应体素中，最终给出体素的坐标，就能够迅速查找出该体素内所有采样点的信息。以上构造哈希表+特征提取的过程可以用下图表示</p><p><img src="/archives/4486189f/image-20211018203646922.png"></p><h2 id="SECOND"><a href="#SECOND" class="headerlink" title="SECOND"></a>SECOND</h2><p>SECOND 可以说就是 VoxelNet 的升级版本，更快更准，其整个 SSD 检测框架可以说已经成为 Voxel-based SSD 的主流，是现在经常使用的 backbone 之一，能够非常有效地将点云体素化并进行三维卷积操作。这一部分仅介绍一下 SECOND 网络为什么更快，这也是该论文的重点贡献之一，使用了稀疏卷积/子流形卷积 sparse convolution/submanifold convolution 改进了原来的三维卷积操作，省去了大量对空体素的卷积操作（点云的稀疏性导致大量体素块为空），从而加速计算。下面留两个参考链接，</p><ol><li><p>知乎：<a href="https://zhuanlan.zhihu.com/p/382365889">Link1</a> <a href="https://zhuanlan.zhihu.com/p/383299678">Link2</a>（两个链接内容相似，讲解稀疏卷积/子流形卷积）</p></li><li><p>子流形卷积定义：<a href="https://paperswithcode.com/method/submanifold-convolutions">Link3</a></p></li></ol><p>其核心思想也是和 hash table 类似，创建一个 RuleBook 记录下每个体素块的输入位置在哪里、输出位置在哪里、对应相乘的卷积核权重在哪里。通过遍历这个 RuleBook 即可完成三维卷积操作</p><p>下面仅留一张示意图以便快速复习（如果没看过参考链接应该是很难看懂）</p><p><img src="/archives/4486189f/v2-80514738ec783b83d56a2506a0a2150b_r.jpg"></p><p>个人再重新总结一下：</p><ol><li>构建稀疏向量 sparse tensor</li><li>通过稀疏向量构建 RuleBook (hash in table &amp; hash out table 包括其中)，从逻辑上理解：该 RuleBook 记录了输入的稀疏向量位置和对应<strong>卷积核位置</strong> $(i, j)$ 以及其输出稀疏向量的位置，但实际上是以卷积核位置 $(i, j)$ 为主导建立的</li><li>同时并行计算所有的输入稀疏向量，并获得输出稀疏向量</li></ol><p>为什么要引入子流形卷积？因为普通的稀疏卷积会让感受野迅速增加，许多 inactive 的点经过卷积过后变得 active，而子流形卷积则保证了 active 点的个数不变，参考 <a href="https://github.com/facebookresearch/SparseConvNet">github</a></p><p><img src="/archives/4486189f/i.gif" alt="sparse convolution"></p><p><img src="/archives/4486189f/img.gif" alt="submanifold convolution"></p><p>除了稀疏卷积的内容之外，SECOND 还贡献有两个重要贡献：</p><ol><li><p>对于方向损失函数的改进</p><script type="math/tex; mode=display">L_{\theta}=\operatorname{SmoothL1}\left(\sin \left(\theta_{p}-\theta_{t}\right)\right)</script><p>使用正弦 L1 loss 再加上方向二元分类损失，以达到精确的方向定位</p></li><li><p>对于数据增强的改进</p><ol><li>从标签池中随机采样 Sample Ground Truths from the Database</li><li>对每个标签随机旋转 Object Noise</li><li>对整个点云随机旋转和随机缩放  Global Rotation and Scaling</li></ol></li></ol><h2 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a>Experiment</h2><p><img src="/archives/4486189f/image-20211018213219777.png" alt="image-20211018213219777"></p><p>SECOND 在速度上相比于 VoxelNet 提升了接近5倍，已经能够达到实时检测的标准（20+ fps），这在速度上是完全的碾压，而且在准确率上也远远领先</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>以上则是对 VoxelNet 和 SECOND 的总结，这两篇已经是好几年前的文章了，也是三维点云体素化方向的奠基之作。在很多论文中都将到了这两篇的身影，所以了解一下其中的实现细节，能够帮助更好地理解其他论文的结构</p>]]></content>
      
      
      <categories>
          
          <category> papers </category>
          
      </categories>
      
      
        <tags>
            
            <tag> VoxelNet </tag>
            
            <tag> SECOND </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SE-SSD</title>
      <link href="/archives/774e60d7.html"/>
      <url>/archives/774e60d7.html</url>
      
        <content type="html"><![CDATA[<h1 id="SE-SSD"><a href="#SE-SSD" class="headerlink" title="SE-SSD"></a>SE-SSD</h1><hr><p>Zheng, Wu, Weiliang Tang, Li Jiang, and Chi-Wing Fu. “SE-SSD: Self-Ensembling Single-Stage Object Detector From Point Cloud.” <em>ArXiv:2104.09804 [Cs]</em>, April 20, 2021. <a href="http://arxiv.org/abs/2104.09804">http://arxiv.org/abs/2104.09804</a>.</p><hr><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>本论文的核心为使用知识蒸馏 <strong>Knowledge Distill</strong> + <strong>Mean Teacher</strong>的思想，加入软目标 soft target 对网络的预测结果进行监督学习。生成该 soft target 不是使用原始方法，将不同模型的 prediction 进行集成，而是先将模型进行集成，再使用集成模型进行预测 prediction。集成模型结构 ensemble model 与原始网络相同，称为 Teacher-SSD，而原始网络称为 Student-SSD，其中 Teacher-SSD 的参数为 Student-SSD 参数的集成，这也是为什么模型名叫自嵌入 SSD (self-embedding)</p><h3 id="Why-soft-target"><a href="#Why-soft-target" class="headerlink" title="Why soft target"></a>Why soft target</h3><p>手动注释的硬目标（即标签 hard target/label）相比，软目标通常具有更高的熵，从而为学生提供更多信息以供学习，弥补了监督信号的不足。并且论文的软目标来自于自身模型的集成，所以与自身的预测结果比较相似，避免了梯度的剧烈变化。而所谓更高的熵该如何去理解？参考 <a href="https://zhuanlan.zhihu.com/p/390167950">知乎</a></p><p>展开分析一下软目标的作用，以分类任务为例，总结如下：</p><ol><li>分类标签为 one hot 向量，仅为一个点，也即该目标所属类别。而使用 teacher model 对于每个样本输出一个连续的 label 分布，这样可以利用的监督信息就远比 one hot 的多了</li><li>软目标还提供了其他分类的得分/可能性，含有了类别与类别之间的信息</li><li>（在本论文中）将学习曲线变得更加平滑，减少了梯度方差，帮助更好的微调</li></ol><p>除了该核心思想外，论文还提出了新的数据增强的方式和新的损失函数以提升网络表现：</p><ol><li>Shape-aware data augmentation</li><li>Consistency loss for soft target</li><li>Orientation-aware distance-IoU loss for hard target </li></ol><h2 id="SE-SSD-Architecture"><a href="#SE-SSD-Architecture" class="headerlink" title="SE-SSD Architecture"></a>SE-SSD Architecture</h2><p><img src="/archives/774e60d7/image-20211014170119221.png"></p><p>SE-SSD 的整体结构非常的简洁。网络的计算有两条路线，teacher 路线 &amp; student 路线</p><ol><li><p>Teacher 路线（图中标以蓝色箭头）：将原始点云输入到 Teacher SSD 中产生预测结果 predictions，对预测选框进行全局变换 global transformation (including a random translation, flipping, and scaling) 生成软目标 soft target</p></li><li><p>Student 路线（途中标以绿色箭头）：将原始点云进行全局变换 global transformation，然后进行数据增强 shape aware data augmentation，生成增强过后的输入和硬目标。将增强后的数据输入 Student SSD 做多任务：回归任务和分类任务，最终得到预测结果 student predictions。该预测结果将与硬目标和软目标同时输入损失函数，进行计算并优化网络参数</p></li></ol><p>以上就是整体的流程，下面需要对 Student SSD，数据增强方法以及损失函数进行详细的了解</p><h3 id="Architecture-of-Student-SSD"><a href="#Architecture-of-Student-SSD" class="headerlink" title="Architecture of Student SSD"></a>Architecture of Student SSD</h3><p>SSD 的结构与作者的前作文章 CIA-SSD 是一致的。该网络为一个轻量型结构，但是推理效果依然很好。按理来讲 SA-SSD 已经很快了，但是该模型比其更快更好。论文中解释了速度的原因：CIA-SSD 使用的 channel 数大部分都是 SA-SSD 的一半，但是将语义和空间信息的学习移到了主干网络中，综合之下胜出。还有一篇论文 Voxel R-CNN 的表现也非常优秀，都在速度和准确率上超越了 SA-SSD。这些结果是否意味着辅助网络的彻底失败呢？</p><p>我认为辅助网络提供了一种可能性：即使是小模型也能够使用更好的参数达到一流的效果。并且辅助网络的思想很简单，能够轻松地加入到大部分的结构当中，而不需要花费大量的时间进行结构设计</p><p>下面对 CIA-SSD 的重要结构进行简要的介绍</p><p><img src="/archives/774e60d7/image-20211016161605882.png" style="zoom: 80%;"></p><ol><li>使用稀疏卷积将体素化点云进行编码，并转化为 BEV 特征图谱</li><li>使用 SSFA 模块对 BEV 特征图谱进行进一步特征提取：<ol><li>保持原 BEV 特征图谱的形状，进行多次卷积继续提取小尺度的空间特征 spatial group，假设最终得到空间特征图谱 $F_{spatial}$</li><li>将 $F_{spatial}$ 作为输入，进一步提取高级/感受野更大的语义特征 semantic group，假设最终得到语义特征图谱 $F_{semantic}$</li><li>将语义特征进行上采样/反卷积 upsampling/deconvolution 达到和空间特征一样的形状，以准备融合</li><li>融合阶段，将两个特征图谱的通道数压缩为1，并使用 sigmoid 函数映射至 0-1 区间，得到两个新的权重特征图谱。然后将权重特征图谱与原来的特征图谱逐元素相乘，得到最终用于多任务的特征图谱 $F$</li></ol></li><li>进行多任务预测：分类任务、IoU 预测任务、box 回归预测任务、方向分类任务</li></ol><p>CIA-SSD 中提到了一些 trick 在本论文之中均没有使用，个人觉得比较复杂，不太好理解，就不继续深入研究了，而且如是好 trick 的话本论文应该会沿用。总体来看 CIA-SSD 的结构依然是加强对多尺度信息的提取并进行融合</p><h3 id="Shape-aware-data-augmentation"><a href="#Shape-aware-data-augmentation" class="headerlink" title="Shape-aware data augmentation"></a>Shape-aware data augmentation</h3><p>由于点云数据的不规则性，很多物体表面上的点都没有被采集到，这是物理层面的原因。为了模拟这种数据缺失并增加样本多样性，论文采取了下图所示的做法</p><p><img src="/archives/774e60d7/image-20211016165328812.png" style="zoom: 80%;"></p><p>用语言简要叙述：</p><ol><li>在进行操作前先对数据集进行基本的数据增强 global transformation (including a random translation, flipping, and scaling)</li><li>将每个3D选框分为6个子区域，方法为将选框顶点与选框中心相连接，形成六个四棱锥</li><li>对每个3D选框，在6个子区域中随机选择一个剔除，以模拟采集时点云丢失的情况</li><li>将不同3D选框之间的子区域进行交换，子区域的相对位置是一样的，例如将两个选框的右侧的四棱锥进行交换。该操作增加样本的多样性</li><li>对每个3D选框，随机选择一个子区域进行下采样，使其更加稀疏。采样方法为 farthest point sampling (FPS)</li></ol><h3 id="Consistency-loss"><a href="#Consistency-loss" class="headerlink" title="Consistency loss"></a>Consistency loss</h3><p>为了让软目标不会对预测选框进行错误引导，需要先对软目标和预测选框同时进行筛选：</p><ol><li>去掉置信度低于阈值 $\tau_c$ 的软目标和预测选框</li><li>仅匹配 IoU 高的软目标和预测选框，二者 IoU 低于阈值 $\tau_I$ 的不进行损失函数 consistency loss 计算</li></ol><p>数学表现形式如下：</p><script type="math/tex; mode=display">\begin{array}{c}\mathcal{L}_{b o x}^{c}=\frac{1}{N^{\prime}} \sum_{i=1}^{N} \mathbb{1}\left(I o U_{i}>\tau_{I}\right) \sum_{e} \frac{1}{7} \mathcal{L}_{\delta_{e}}^{c} \\\\\delta_{e}=\left\{\begin{array}{ll}\left|e_{s}-e_{t}\right| & \text { if } e \in\{x, y, z, w, l, h\} \\\left|\sin \left(e_{s}-e_{t}\right)\right| & \text { if } e \in\{r\}\end{array}\right.\end{array}</script><p>$\mathcal{L}_{\delta_e}^c$ 为 smooth L1 loss，$N$ 和 $N’$ 为起始预测选框数和筛选后的选框数。对于分类也使用类似的损失函数</p><script type="math/tex; mode=display">\mathcal{L}_{c l s}^{c}=\frac{1}{N^{\prime}} \sum_{i=1}^{N} \mathbb{1}\left(I o U_{i}>\tau_{I}\right) \mathcal{L}_{\delta_{c}}^{c}\\\delta_{c}=\left|\sigma\left(c_{s}\right)-\sigma\left(c_{t}\right)\right|</script><h3 id="Orientation-aware-distance-IoU-loss"><a href="#Orientation-aware-distance-IoU-loss" class="headerlink" title="Orientation-aware distance-IoU loss"></a>Orientation-aware distance-IoU loss</h3><p>为了让预测选框的几何参数更关注目标中心和旋转方向，论文设计了相关的损失函数，引导选框与硬目标对齐</p><script type="math/tex; mode=display">\mathcal{L}_{b o x}^{s}=1-\operatorname{IoU}\left(B_{p}, B_{g}\right)+\frac{c^{2}}{d^{2}}+\gamma(1-|\cos (\Delta r)|)</script><p>$B_p$ 和 $B_g$ 代表预测选框和硬目标/标签，$c$ 代表中心距离，$d$ 代表包围两个选框的最小长方体的对角线，$\Delta r$ 代表两个选框 BEV 相差的角度，$\gamma$ 为超参数，图示如下</p><p><img src="/archives/774e60d7/image-20211016191827057.png"></p><p>论文画出了 $(1-|cos(\Delta r)|)$ 的图像，方向差别越大损失函数越大</p><p><img src="/archives/774e60d7/image-20211016193642630.png" style="zoom: 80%;"></p><p>除了回归任务，还有选框的分类任务，以及选框朝向的分类任务，两个任务的损失函数分别为 focal loss 和 binary cross entropy loss。故整个网络的全部损失函数写为</p><script type="math/tex; mode=display">\mathcal{L}_{\text {student }}=\mathcal{L}_{\text {cls }}^{s}+\omega_{1} \mathcal{L}_{\text {box }}^{s}+\omega_{2} \mathcal{L}_{\text {dir }}^{s}+\mu_{t}\left(\mathcal{L}_{\text {cls }}^{c}+\mathcal{L}_{\text {box }}^{c}\right)</script><p>前三项为预测选框与硬目标的损失函数，分别对应：选框分类任务，选框 $(x, y ,z ,w, l, h, \theta)$ 回归任务，选框朝向分类任务</p><p>后两项为预测选框与软目标的损失函数 consistency loss，分别对应：分类一致损失，选框一致损失。其余参数为权重超参数，其中 $\mu_t$ 随时间从0增长至1</p><h2 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a>Experiment</h2><h3 id="KITTI"><a href="#KITTI" class="headerlink" title="KITTI"></a>KITTI</h3><p><img src="/archives/774e60d7/image-20211016200424581.png" style="zoom: 80%;"></p><p>目前（2021/10/16） SE-SSD 依旧在 KITTI 榜单上排名顶尖 $9^{th}$</p><h3 id="Ablation-study"><a href="#Ablation-study" class="headerlink" title="Ablation study"></a>Ablation study</h3><p><img src="/archives/774e60d7/image-20211016202758864.png"></p><p>论文中的三个重要结构，在验证集上 Easy 难度提升是最小的，因为已经比较准了，而在 Moderate 和 Hard 难度中都提升了 3% 左右。其中可以看到单独作用最大的结构为 consistency loss，而且在该结构的加持下， ODIoU loss 的效果似乎也变得更好</p><p>对于 ODIoU 不能直接去掉，论文使用的是 smooth L1 loss 代替</p><h3 id="Consistency-loss-1"><a href="#Consistency-loss-1" class="headerlink" title="Consistency loss"></a>Consistency loss</h3><p><img src="/archives/774e60d7/image-20211016203125284.png" style="zoom:80%;"></p><p>两个表分别说明了：</p><ol><li><p>分类和回归，两个任务的预测结果同时对齐软目标时效果最好</p></li><li><p>并且对软目标进行筛选时，基于 IoU 策略的筛选能够保留更多的信息。其中 nms filter 代表的是使用 NMS 策略对软目标进行筛选， gt filter 代表的是剔除与 ground truth 标签重叠的软目标</p></li></ol><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>SE-SSD 的表现可以说是非常的惊艳，所使用的 Teacher-SSD &amp; Student-SSD &amp; soft target 思想简单且有效，或许在之后能够成为一种常用的提升网络效果的手段。论文设计的数据增强和损失函数也在一定程度上增加了网络准确率，这也说明了除了网络结构本身，<strong>其他的信息（标签、样本）以及评估模型的方式</strong>也是相当重要的。在阅读期间也有一些疑问和想法产生</p><p><strong>Q:</strong> 同时软目标相对于预先设定的 anchor，具有更精确的边界框和置信度，这里是否可以借鉴 2-Stage 中的思想，对于软目标进一步的利用，将其作为更高级的注意力机制</p><p><strong>Q:</strong> 对于软目标是否一定要来自于自身的集成，使用其他模型的效果会如何。对于集成模型的参数更新方式不一定使用 EWA，可否借鉴强化学习中的方法。对于 consistency loss 能否进一步改进，比如增加 IoU 相关损失</p><p><strong>Q:</strong> （与 SA-SSD 联动）辅助任务与软目标的异步进行，先使用辅助函数进行基础学习，再使用软目标进行知识蒸馏</p>]]></content>
      
      
      <categories>
          
          <category> papers </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SE-SSD </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SA-SSD</title>
      <link href="/archives/82cec617.html"/>
      <url>/archives/82cec617.html</url>
      
        <content type="html"><![CDATA[<h1 id="SA-SSD"><a href="#SA-SSD" class="headerlink" title="SA-SSD"></a>SA-SSD</h1><hr><p>He, Chenhang, Hui Zeng, Jianqiang Huang, Xian-Sheng Hua, and Lei Zhang. “Structure Aware Single-Stage 3D Object Detection From Point Cloud.” In <em>2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 11870–79. Seattle, WA, USA: IEEE, 2020. <a href="https://doi.org/10.1109/CVPR42600.2020.01189">https://doi.org/10.1109/CVPR42600.2020.01189</a>.</p><hr><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>现阶段点云目标检测常用 SSD 方法为，使用卷积网络逐步缩小 feature map 形状，同时感受野也在逐渐提高，最终使用 downscale 的特征图谱去做选框的预测。这个过程中不可避免地会丢失空间信息：</p><ol><li>在将点云进行体素化时会丢失原始点云的空间信息</li><li>在进行卷积操作时，虽然进一步提取了局部特征，但同时也会丢失细节信息</li></ol><p>为了解决信息丢失问题，可以使用 2-Stage 目标检测网络。在第二阶段可以利用更精细的空间信息，重点关注第一阶段提出的 RoI，从而预测更加精准，这揭示了利用点云的细粒度 fine-grained 空间信息的重要性。然而，对每个点进行操作并为每个 RoI 重新提取特征会大大增加计算成本，使得两阶段方法难以达到实时速度</p><p>使用辅助任务来提升主任务的表现，在目标检测网络中也是非常常见的方法。例如在 PV-RCNN 中则进行了前景点任务，并利用该任务对不同点的特征进行权重分配，前景点将获得更大的权重。</p><p>论文使用可分离辅助网络来补偿损失的空间信息。辅助网络的输入为 backbone 中不同分辨率的 feature map，将特征图谱的栅格化特征表示，使用特征传播 feature propagation 转化为逐点的特征表示，然后使用逐点的特征去做两个辅助任务：前景点分离和中心预测。在训练过程中辅助网络与主干网络进行联合优化，所以主干网络的 backbone 参数中将具有原始点云的语义信息。而在进行推理的时候，辅助网络将从主干网络中分离，故不增加任何的计算</p><p><a href="https://blog.csdn.net/qq_39732684/article/details/105147497">CSDN</a> 上对于这篇论文的代码解读，该网络的代码构建是基于 MMDetection 和 SECOND</p><h3 id="疑问"><a href="#疑问" class="headerlink" title="疑问"></a>疑问</h3><p>在网络中间插入辅助任务的做法，我在二维目标检测中的一篇文章（Hourglass Networks）中也看到过类似的结构。但在 Hourglass 中这种做法叫做中间监督 intermediate supervision，但该结构在推理中并没有被分离，其中的特征图谱经过转化过后再一次加入到了主干网络中</p><p>如果将 SA-SSD 辅助网络中学习的特征再次送入主干网络之中效果会更好吗？事实上，这样就回到了 2-Stage 目标检测网络结构。例如 PV-RCNN 也是将 voxel-wise 特征转化为 point-wise 特征，再使用 point-wise 特征根据 RoI 做选框细化。所以需要提出的问题为：什么样的辅助网络结构，能够让主干网络有效提取精细的空间信息。<strong>这个问题将又引申出两个疑问：如果辅助网络的对特征的转换过于复杂，那么更新到主干网络中的参数是否还有意义？如果采用与主干网络相似的结构作为辅助网络的结构，这种相似结构是否会帮助特征学习？</strong></p><h2 id="SA-SSD-Architecture"><a href="#SA-SSD-Architecture" class="headerlink" title="SA-SSD Architecture"></a>SA-SSD Architecture</h2><p><img src="/archives/82cec617/image-20211012145648239.png"></p><h3 id="Input-pre-process"><a href="#Input-pre-process" class="headerlink" title="Input pre-process"></a>Input pre-process</h3><p>论文采用了简单 floor 操作，将所有点的坐标映射到栅格点上。这样的预处理与 SECOND 相比，使用时间非常短，在最后的实验部分有图表</p><script type="math/tex; mode=display">\overline{p_i} = (⌊ \frac{x_i}{d_x} ⌋, ⌊ \frac{y_i}{d_y} ⌋, ⌊ \frac{z_i}{d_z} ⌋)</script><h3 id="Backbone-network"><a href="#Backbone-network" class="headerlink" title="Backbone network"></a>Backbone network</h3><p>主干网络的结构比较简单，主要是基于 VoxelNet/SECOND 网络结构，使用 3D 稀疏卷积 sparse convolution 进行特征提取。将得到的 3D 特征图谱重塑 reshape 为二维 BEV 特征图谱表示，即将 z 轴方向的特征连接起来。最终使用该 BEV 特征图谱分为头，做选框预测任务和分类任务</p><h3 id="Detachable-auxiliary-network"><a href="#Detachable-auxiliary-network" class="headerlink" title="Detachable auxiliary network"></a>Detachable auxiliary network</h3><p>辅助网络的目标是帮助主干网络感知 3D 点云的结构信息。下面详细地介绍辅助网络的使用动机</p><h4 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h4><p>在主干网络提取点云特征的过程中，会不断地进行卷积操作，该操作也是一个下采样操作，将不可避免地丢失准确的空间信息。当仅使用部分点（由于下采样的原因）对 3D 选框进行预测时，如果添加一些其他信息进行辅助，能够更好地帮助预测结果，比如：每个点的是否为前景点、每个点的选框中心在何处。有了这些辅助信息，能够让预测的选框更加准确</p><p><img src="/archives/82cec617/image-20211012165858427.png"></p><p>受此启发，最简单操作为，直接使用更多的网络来完成对于辅助信息的预测，然后再将这些辅助特征、信息与主干网络的特征相连接，进行最终的预测。但是这些网络将会使用更多的计算资源，本论文则希望在不增加计算资源的同时获得这些辅助任务的特征与信息，基于此提出了可分离辅助网络。该辅助网络在训练时与主干网络联合优化，而在推理时将从主干网络中分离，也即在训练时由于辅助网络的引进会增加更多的计算，但在推理时没有其他多余的计算，保持主干网络的高效率</p><h3 id="Point-wise-feature-representation"><a href="#Point-wise-feature-representation" class="headerlink" title="Point-wise feature representation"></a>Point-wise feature representation</h3><p>为解决以上提出的问题，论文的解决方案为：构建一个具有点级 point-level 监督的辅助网络，以引导主干网络在不分辨率的特征图谱去学习更细粒度的结构。该引导为隐性的引导，在训练过程中通过辅助任务和反向转播去调整主干网络中的参数，使得主干网络获得更细节的特征信息。具体方法如下：</p><ol><li><p>使用特征传播 feature propagation，将不同分辨率下的 voxel-level 特征转化为 point-level 特征，该操作与 PointNet++ 中的特征传播是一致的，是基于空间距离的插值操作 inverse distance weighted average </p><script type="math/tex; mode=display">f^{(j)}(x)=\frac{\sum_{i=1}^{k} w_{i}(x) f_{i}^{(j)}}{\sum_{i=1}^{k} w_{i}(x)} \quad \text { where } \quad w_{i}(x)=\frac{1}{d\left(x, x_{i}\right)^{p}}, j=1, \ldots, C</script><p>而这些插值点的来源论文中并没有提及，但是每一个 voxel-level 特征所转换出来的 point-level 特征应该都是相同形状的</p></li><li><p>将不同分辨率下得到的 point-level 特征连接起来使用 shared MLP 进行编码（在论文的代码中并没有体现）</p></li><li>将编码得到的特征，使用 MLP 去预测两个结果：每个点的属于前景点的概率，前景点到目标中心的偏移量。这里的 unit point convolutions 应该还是</li></ol><p>两个任务的损失函数也是常规的 focal loss 和 smooth L1 loss，且 L1 loss 仅针对于前景点</p><script type="math/tex; mode=display">\mathcal{L}_{\mathrm{seg}}=\frac{1}{N_{\text {pos }}} \sum_{i}^{N}-\alpha\left(1-\hat{s}_{i}\right)^{\gamma} \log \left(\hat{s}_{i}\right)\\where \ \hat{s}_{i}=\left\{\begin{array}{ll}\tilde{s}_{i} & \text { if } s_{i}=1 \\1-\tilde{s}_{i} & \text { otherwise. }\end{array}\right.</script><script type="math/tex; mode=display">\mathcal{L}_{\mathrm{ctr}}=\frac{1}{N_{\text {pos }}} \sum_{i}^{N} \text { Smooth- } l_{1}(\Delta \tilde{\mathbf{p}}-\Delta \mathbf{p}) \cdot \mathbb{1}\left[s_{i}=1\right]</script><h3 id="Part-sensitive-warping"><a href="#Part-sensitive-warping" class="headerlink" title="Part-sensitive warping"></a>Part-sensitive warping</h3><p>如果使用 anchor-based 方法进行目标检测，例如：Faster RCNN，会出现预测选框与分类置信度之间并不匹配。分类置信度的特征来源是由预先设值的 anchor 决定的，而不是来自所预测的选框。为解决这一问题，论文提出了 part-sensitive warping operation (PSWarp) 用于矫正这一不匹配现象，其中心思想为：让预测选框的分类置信度，来自于预测选框对应的分类特征图谱区域。具体操作更加复杂一点</p><ol><li><p>将分类特征图谱改变维度，从 $(W, L, F)$ 至 $(W,L,C, K)$ 其中 C 表示类别数量，K 表示将预测选框的俯视图平均分成了 K 份（论文将选框分为了 4x7=28 份），K 个维度里的每一个维度代表该点为选框某个部分的得分。例如当 K = 4 时，维度 (0, 1, 2, 3) 代表预测选框的 (左上，右上，左下，右下) 的得分</p></li><li><p>将预测选框的俯视图平均分为 K 份后，取每一个部分的中心点作为采样点，再使用双线性插值 bilinear interpolation 获得<strong>采样点在分类图谱中的特征值</strong>。为了更具体的说明插值过程，将这 K 个采样点进行编号 $\{S_k: k=1, 2,…,K\}$，假设第 i 个采样点 $S_i$ 其插值参考的特征图谱 feature map $\mathcal{X}$ 也为第 i 个，即 $(W,L,C,i)$ 记为 $\mathcal{X^i}$。代数过程如下</p><script type="math/tex; mode=display">\mathcal{C}_{p}=\frac{1}{K} \sum_{k=1}^{K} \sum_{i\in\{\lfloor{u^k}\rfloor ,\lfloor{u^k+1}\rfloor\}\atop  j\in\{\lfloor{v^k}\rfloor ,\lfloor{v^k+1}\rfloor\}} \mathcal{X_{ij}^k}\times b(i,j,u^k,v^k)</script><p>代码可以参考 <a href="https://blog.csdn.net/themasterbi/article/details/106913582">CSDN</a>，这篇博客的所写的源代码注释，是众多博客中让我唯一理解的注释，不然通过论文中的文字很难理解 PSWarp 操作。最终获得输出 $(K, 1, N, 1)$，其中 $N$ 为该场景中预测选框的数量。图示如下</p><p><img src="/archives/82cec617/image-20211013182126400.png" style="zoom:80%;"></p></li><li><p>K 个采样点将会得到的 K 个得分，它们的平均值作为最终分类得分，最后使用 sigmoid 函数获得分类置信度</p></li></ol><p>将辅助任务和主任务的损失函数乘以权重超参数，相加后得到整个网络的损失函数</p><script type="math/tex; mode=display">\mathcal{L}=\mathcal{L}_{\text {cls }}+\omega \mathcal{L}_{\text {box }}+\mu \mathcal{L}_{\text {seg }}+\lambda \mathcal{L}_{\text {ctr }}</script><p>前两项即为主任务的分类任务和预测选框任务，后两项为辅助任务的分割任务和预测中心任务。所有的分类任务和回归任务都是 focal loss 和 smooth L1 loss</p><p>损失函数没有使用到 IoU 相关的部分，IoU 其实是一个非常有效的综合评估标准，包含了不少的信息。之后可以考虑加入预测 IoU 的任务，该任务或许对原网络有不错的优化</p><h2 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a>Experiment</h2><h3 id="Train"><a href="#Train" class="headerlink" title="Train"></a>Train</h3><p>在 RPN 网络训练过程中，由于 anchor-based 属性，需要提供 anchor 的 positive/negative 属性以进行分类任务的训练，其 IoU 阈值分别为0.6和0.45。在推理阶段使用阈值为0.1的 NMS 操作 </p><h3 id="KITTI"><a href="#KITTI" class="headerlink" title="KITTI"></a>KITTI</h3><p><img src="/archives/82cec617/image-20211013184635247.png"></p><h3 id="Weight-selection-of-auxiliary-tasks"><a href="#Weight-selection-of-auxiliary-tasks" class="headerlink" title="Weight selection of auxiliary tasks"></a>Weight selection of auxiliary tasks</h3><p><img src="/archives/82cec617/image-20211013184733794.png"></p><p>论文采用 $\mu=0.9,\lambda=2$</p><h3 id="Ablation-study-amp-compare"><a href="#Ablation-study-amp-compare" class="headerlink" title="Ablation study &amp; compare"></a>Ablation study &amp; compare</h3><p><img src="/archives/82cec617/image-20211013185112410.png"></p><p>可以看出3个特殊设计各有0.5%左右的提升，最终提供了接近1.5%的提升，同时网络速度也保持得相当不错</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>论文创新性地使用了可分离辅助网络，在推理时不增加额外计算量，同时提升了最终的表现。可以感觉该思想是一个不错的突破口，但是这背后留下了更多的疑问：辅助网络的具体结构应该如何设计，是该简单，还是该复杂，或者都不是；该方法是否能称为一种主流的方法，将整个目标检测的框架带到一个新的台阶上；细粒度信息应该以怎样的表示方法加入到其中，尤其与 2-Stage 方法做比较，直接的特征加入和间接的特征引导学习，两者该怎么衡量…</p><p>PSWarp 方法想要解决的困难是真实存在的，也就是置信度与选框不匹配问题。但该方法是否为解决该问题最好的，或许其他论文有更优雅的解决方案，还有待继续学习</p>]]></content>
      
      
      <categories>
          
          <category> papers </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SA-SSD </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CenterPoint</title>
      <link href="/archives/807a20df.html"/>
      <url>/archives/807a20df.html</url>
      
        <content type="html"><![CDATA[<h1 id="CenterPoint"><a href="#CenterPoint" class="headerlink" title="CenterPoint"></a>CenterPoint</h1><hr><p>Yin, Tianwei, Xingyi Zhou, and Philipp Krähenbühl. “Center-Based 3D Object Detection and Tracking.” <em>ArXiv:2006.11275 [Cs]</em>, January 6, 2021. <a href="http://arxiv.org/abs/2006.11275">http://arxiv.org/abs/2006.11275</a>.</p><hr><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><h3 id="三维目标检测难点"><a href="#三维目标检测难点" class="headerlink" title="三维目标检测难点"></a>三维目标检测难点</h3><p>与二维目标检测相比，三维目标检测有几个基本的难点</p><ol><li><p>点云数据的稀疏性，有大量的空间没有点云 </p></li><li><p><strong>选框的自由度高，不仅有更灵活的方向，还有更多的尺寸。Anchor-based RPN 难以满足这样的灵活性</strong> </p></li></ol><h3 id="Contribution"><a href="#Contribution" class="headerlink" title="Contribution"></a>Contribution</h3><p>CenterPoint 是一个 2-Stage 三维目标检测网络，是 center-based 系列思想在三维中的应用，其前作 CenterNet (Objects as Points) 在二维目标检测中有不错的效果，同时也在 CenterPoint 中发挥了重要作用。本论文提出的是一种基本框架，使用 center-based 思想能够不同程度提升 backbone 的表现（约 3-4 mAP）。再经过第二阶段的细化 refinement 还能够继续提升约 2 mAP 的表现，且牺牲的计算较少，控制在 10% 以内。下面简单介绍一下两个阶段的过程：</p><ol><li>首先使用 3D backbone 提取点云特征，该特征是以 map-view 的形式（俯视栅格）呈现。第一阶段 Stage-1 使用 map-view features 检测各个目标点的中心位置，然后使用中心位置的特征回归预测 3D 选框的其他属性，包括大小、方向、速度等</li><li>第二阶段 Stage-2 使用更多的相关点的特征来对选框进行细化</li></ol><h2 id="CenterPoint-Architecture"><a href="#CenterPoint-Architecture" class="headerlink" title="CenterPoint Architecture"></a>CenterPoint Architecture</h2><h3 id="3D-检测网络通用框架"><a href="#3D-检测网络通用框架" class="headerlink" title="3D 检测网络通用框架"></a>3D 检测网络通用框架</h3><p>论文里提了一下现代 3D detector 的常见处理过程。首先是使用一个 backbone 对点云数据进行特征提取，该 backbone 也可以叫做 encoder。backbone 的输出为一个 map-view feature map $M\in R^{W\times L\times F}$，其中 W &amp; L 为 width &amp; length 和三维场景的长宽相关，F 为特征维度的大小或者称为 channel number。论文中采用的 backbone 有两个 VoxelNet &amp; PointPillars（建议了解一下这两个网络），对这两个 backbone 做了实验和比较</p><p>然后常使用 bounding box detector 在该 feature map 上进行检测。这样的 detector 在二维当中有很多可以借鉴的网络，论文使用了 CenterNet 而不是常规的 anchor-based 网络。下图即为 CenterPoint 结构示意图，接下来详细了解一下两个阶段的细节</p><p><img src="/archives/807a20df/2f857fd4-fe6f-447b-9817-c1a9079d245e.png" style="zoom: 80%;"></p><h3 id="Stage-1"><a href="#Stage-1" class="headerlink" title="Stage-1"></a>Stage-1</h3><p>第一阶段基本上就是 CenterNet 思想的复刻，不管是中心预测，还是回归其他属性，所以细节部分请阅读 Objects as Points。这些预测都属于 dense prediction 也就是说每一个栅格 bin 都会有自己的预测结果，所有的第一阶段网络都是常见的卷积网络</p><h4 id="Center-heatmap-head"><a href="#Center-heatmap-head" class="headerlink" title="Center heatmap head"></a>Center heatmap head</h4><p>首先需要使用 feature map 预测各个目标的中心点在哪里。这里的过程和 CenterNet 是相似的，下面列出其中的关键部分：</p><ol><li><p>标签 label：将 ground truth 中心点的位置映射到 feature map 中形成中心点的 heatmap $Y\in [0,1]^{W\times L\times C}$，其中 C 为类别数量。这里为什么是一个 0~1 的区间，是由于该标签并不是硬标签，而是使用了高斯核，将该标签附近的栅格也作为了软目标中心，其计算形如下面的公式</p><script type="math/tex; mode=display">Y_{xyc}=\exp \left(-\frac{\left(x-\tilde{p}_{x}\right)^{2}+\left(y-\tilde{p}_{y}\right)^{2}}{2 \sigma_{p}^{2}}\right)</script></li><li><p>损失函数 loss function：focal loss</p></li></ol><p>以上两个操作都是基于点云的稀疏性、正负样本不均衡而设计。制作软标签的原因是在于中心点的范围实在太小，必须将其辐射出去；而使用 focal loss 也是因为背景点太多，而中心点太少</p><h4 id="Regression-heads"><a href="#Regression-heads" class="headerlink" title="Regression heads"></a>Regression heads</h4><p>为了预测选框，还需要预测其他的属性</p><ol><li><strong>栅格偏差</strong> offset，由于中心目标点是被映射到了栅格中，并不是精准的，所以需要预测一个偏差值进行修正 a sub-voxel location refinement $o \in R^2$ , The subvoxel location refinement o reduces the quantization error</li><li><strong>高度</strong> height-above-ground $h_g \in R$, The height-above-ground hg helps localize the object in 3D and adds the missing elevation information removed by the mapview projection</li><li><strong>选框大小</strong> the 3D size $s \in R^3$ </li><li><strong>选框方向</strong> and a yaw rotation angle $(sin(α), cos(α)) \in R^2$ </li></ol><p>损失函数对于中心 center 使用的一般 L1 loss，对于选框大小 size 实际预测的是对数大小 logarithmic size，然后再计算 L1 loss。使用对数大小，对于不同形状的选框更可能更有优势，损失函数的曲线会更平滑一些</p><p>还有一点需要注意的是，在第一阶段，所有的损失函数仅在标签位置 keypoint location 进行，这个思想和 PointRCNN, SECOND 等一致，仅对 positive proposals 做回归损失计算（以上为根据 CenterNet 的推测，原文似乎并未提及）</p><h3 id="Stage-2"><a href="#Stage-2" class="headerlink" title="Stage-2"></a>Stage-2</h3><p>第二阶段有两个任务，细化 refinement 和评分 score。我们从预测选框的每个面的中心提取一个点特征，这样就有6个特征点，但在俯视图中上下表面中心点重合，故只有5个特征点。对于每个点，使用双线性插值  <a href="https://www.cnblogs.com/xpvincent/archive/2013/03/15/2961448.html">bilinear interpolation</a> 从 feature map 中提取出各自的特征，然后将所有特征连接 concat 送入 MLP 中预测置信度 confidence score $I$ &amp; 3D bounding box</p><h4 id="置信度"><a href="#置信度" class="headerlink" title="置信度"></a>置信度</h4><p>其中的置信度 $I$ 与分类无关 class-agnostic，仅与 IoU 相关，计算公式如下</p><script type="math/tex; mode=display">I=\min \left(1, \max \left(0,2 \times I o U_{t}-0.5\right)\right)</script><p><img src="/archives/807a20df/image-20211007171708779.png" style="zoom: 67%;"></p><p>损失函数为二元交叉熵损失函数</p><script type="math/tex; mode=display">L_{\text {score }}=-I_{t} \log \left(\hat{I}_{t}\right)-\left(1-I_{t}\right) \log \left(1-\hat{I}_{t}\right)</script><p>最终的预测分数为如下公式</p><script type="math/tex; mode=display">\hat{Q}_{t}=\sqrt{\hat{Y}_{t} * \hat{I}_{t}}</script><h4 id="细化"><a href="#细化" class="headerlink" title="细化"></a>细化</h4><p>该细化工作是在第一阶段的提议 proposal 之上进行，即回归预测第一阶段所预测的选框与真实选框之间的残差。并且（在训练时）细化应该是仅对正样本进行，正负样本的标准判定为预测选框与标签 IoU 大于0.55，以 1:1 正负比例各采样128个</p><blockquote><p>During the training of two-stage CenterPoint, we randomly sample 128 boxes with 1:1 positive negative ratio [43] from the first stage predictions.</p></blockquote><p>在测试\推理时没有标签，则先使用 NMS 筛选出候选选框，然后选取得分最高的500个选框，最后再进行第二阶段的置信度预测和细化。NMS 的得分根据应该是 heatmap $Y$，毕竟此时置信度 $I$ 还没有计算出来</p><p>第一阶段和第二阶段的网络结构以及训练方法都介绍完了，一些更具体的基础结构可以参考下面的原文</p><blockquote><p>All first-stage outputs share a first 3 × 3 convolutional layer, Batch Normalization [25], and ReLU. Each output then uses its own branch of two 3×3 convolutions separated by a batch norm and ReLU. Our second-stage uses a shared two-layer MLP, with a batch norm, ReLU, and Dropout [22] with a drop rate of 0.3, followed by two branches of three fully-connected layers, one for confidence score and one for box regression prediction.</p></blockquote><h2 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a>Experiment</h2><h3 id="Waymo"><a href="#Waymo" class="headerlink" title="Waymo"></a>Waymo</h3><p><img src="/archives/807a20df/5a04d50f-941e-48ec-a14c-b65a2d6d46fc.png"></p><h3 id="nuScenes"><a href="#nuScenes" class="headerlink" title="nuScenes"></a>nuScenes</h3><p><img src="/archives/807a20df/e847f9af-5198-4628-9797-ae958aa73c63.png"></p><h3 id="Anchor-vs-center"><a href="#Anchor-vs-center" class="headerlink" title="Anchor vs. center"></a>Anchor vs. center</h3><p><img src="/archives/807a20df/bfeb0fb3-b716-4ac0-9f38-f1ecc1b6a683.png"></p><h3 id="One-stage-vs-Two-stage"><a href="#One-stage-vs-Two-stage" class="headerlink" title="One-stage vs. Two-stage"></a>One-stage vs. Two-stage</h3><p><img src="/archives/807a20df/5d0b419b-6226-40a5-8632-879a222a9da1.png"></p><blockquote><p>Two-stage refinement does not bring an improvement over the single-stage CenterPoint model on nuScenes in our experiments. Similar results have been observed in previous two-stage methods like PointRCNN [45] and PV-RCNN [44].</p></blockquote><p>nuScenes 对于 2-Stage 模型反馈并不好，原因可能在于其采样点较少，限制了进一步的精确细化</p><h3 id="Effects-of-different-feature-components"><a href="#Effects-of-different-feature-components" class="headerlink" title="Effects of different feature components"></a>Effects of different feature components</h3><p>对于第二阶段的细化，论文直接使用了双线性插值得到的 BEV 特征，实际上还有其他的方法得到各个采样点的特征。比如：</p><ol><li>PV-RCNN 中采用的 voxel set abstraction (VSA) 操作，也可以将周围 voxel 特征提取到采样点上</li><li>SA-SSD 中采用的基于空间距离的插值 inverse distance weighted average 也可以将 voxel 特征传播到采样点上</li></ol><p>论文将这两种方式在第二阶段的细化环节中与论文采用的 BEV 插值法进行对比实验，虽然效果不是最好，但差距不大，胜在用时</p><p><img src="/archives/807a20df/image-20211014212255839.png"></p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>CenterPoint 的结构其实相对简单，但取得了很好的效果，似乎在告诉我更多的参数就让网络自己去预测好了，或许当人为引入一些 anchor 相关的参数，反而让网络不好学习。并且由于其结构的简单，计算时间相对其他 2-Stage 网络来讲更少，不知道这种 center-based 思想有机会能否运用到更广泛的地方</p>]]></content>
      
      
      <categories>
          
          <category> papers </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CenterPoint </tag>
            
            <tag> Point Cloud </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>D2L 01 前言</title>
      <link href="/archives/786d359c.html"/>
      <url>/archives/786d359c.html</url>
      
        <content type="html"><![CDATA[<h1 id="Dive-into-deep-learning"><a href="#Dive-into-deep-learning" class="headerlink" title="Dive into deep learning"></a>Dive into deep learning</h1><p>中文教材（第二版）<a href="https://zh-v2.d2l.ai/">https://zh-v2.d2l.ai/</a> </p><p>英文教材：<a href="https://d2l.ai/">https://d2l.ai/</a> </p><p>中文教材只有部分内容，我选择先从中文开始看减少一些难度，没有的章节再去看英文部分。请先阅读 <a href="http://zh-v2.d2l.ai/chapter_installation/index.html">安装</a> <a href="http://zh-v2.d2l.ai/chapter_notation/index.html">符号</a> 两个章节，里面包含了如何下载该书的 notebook 以及讲解了该书使用的数学符号</p><h1 id="1-前言"><a href="#1-前言" class="headerlink" title="1. 前言"></a>1. 前言</h1><h2 id="关键组件"><a href="#关键组件" class="headerlink" title="关键组件"></a>关键组件</h2><h3 id="数据"><a href="#数据" class="headerlink" title="数据"></a>数据</h3><ol><li>数据的分布，一般假设为独立同分布。所以当分布出现偏差，模型也会相应地被影响</li><li>数据的维数，每一个样本都可以是一个固定维数的样本，例如每个样本为一个三维向量，记录人的身高、体重、性别。也可以不一样，例如样本为图片时，数据为三维张量 (width, height, 3)，维度的具体分量由其长宽决定。注意这里要区分一下，向量的维度和张量的维度不是同一个定义</li><li>数据的标签，需要有正确的数据来引导模型的学习</li></ol><h3 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h3><p>直接引用原文</p><blockquote><p><strong>大多数机器学习会涉及到数据的转换。 比如，我们建立一个“摄取照片并预测笑脸”的系统。再比如，我们摄取一组传感器读数，并预测读数的正常与异常程度。 虽然简单的模型能够解决如上简单的问题，但本书中关注的问题超出了经典方法的极限。 深度学习与经典方法的区别主要在于：前者关注的功能强大的模型，这些模型由神经网络错综复杂的交织在一起，包含层层数据转换，因此被称为<em>深度学习</em>（deep learning）。 在讨论深度模型的过程中，我们也将提及一些传统方法。</strong></p></blockquote><h3 id="目标函数"><a href="#目标函数" class="headerlink" title="目标函数"></a>目标函数</h3><p>在机器学习中，我们需要定义模型的优劣程度的度量，这个度量在大多数情况是“可优化”的，我们称之为<em>目标函数</em>（objective function）。 我们通常定义一个目标函数，并希望优化它到最低点。因为越低越好，所以这些函数有时被称为<em>损失函数</em>（loss function, 或cost function）</p><h3 id="优化算法"><a href="#优化算法" class="headerlink" title="优化算法"></a>优化算法</h3><p>深度学习中，大多流行的优化算法通常基于一种基本方法–<em>梯度下降</em>（gradient descent）</p><h2 id="各种机器学习问题"><a href="#各种机器学习问题" class="headerlink" title="各种机器学习问题"></a>各种机器学习问题</h2><h3 id="监督学习"><a href="#监督学习" class="headerlink" title="监督学习"></a>监督学习</h3><p>监督学习就比较经典了，有回归问题、分类问题、标记问题、搜索问题、推荐系统、序列学习。前两个问题比较常见了，提一下后面几个</p><ol><li>标记问题，可以是目标检测相关，也可以是描述样本 (image captioning) 相关</li><li>搜索问题，一大应用即为搜索引擎，在海量数据库中找到与搜索内容最匹配的选项</li><li>推荐系统，根据用户喜好对用户进行个性化推荐</li><li>序列学习，输入和输出都是可变长度的序列，可应用于机器翻译、文本语音转换等</li></ol><h3 id="无监督学习"><a href="#无监督学习" class="headerlink" title="无监督学习"></a>无监督学习</h3><p>只有样本，没有标签，意在学习数据之间的内部关系。聚类、主成分分析、因果关系和概率图模型、生成对抗网络都是无监督学习的例子，其中生成对抗网络是现在深度学习中非常重要和活跃的领域</p><h3 id="强化学习"><a href="#强化学习" class="headerlink" title="强化学习"></a>强化学习</h3><p>强化学习又是另一个庞大的框架，而且十分强大，强化学习的目标是产生一个策略，让策略的奖励达到最大。深度强化学习将深度学习应用于强化学习问题，也是非常热门的研究方向</p><h2 id="深度学习发展之路"><a href="#深度学习发展之路" class="headerlink" title="深度学习发展之路"></a>深度学习发展之路</h2><ol><li>算力的发展和数据集的发展是深度学习爆发的基础。且由于这两者的限制，许多优秀的算法和模型其实在很早的时候就被提出，如多层感知机、卷积网络，但无法施展更强大的威力</li><li>列举部分最近十年中的事件，帮助深度学习取得巨大成就：</li></ol><ul><li>新的容量控制方法，如 dropout，有助于减轻过拟合</li><li>提出注意力机制</li><li>生成对抗网络的发明</li><li>构建并行式和分布式训练算法</li><li>开源的深度学习框架</li></ul><h2 id="深度学习特点"><a href="#深度学习特点" class="headerlink" title="深度学习特点"></a>深度学习特点</h2><ol><li><p><strong>深度学习是“深度”的，模型学习许多转换的“层”，每一层提供一个层次的表示</strong>。 例如，靠近输入的层可以表示数据的低级细节，而接近分类输出的层可以表示用于区分的更抽象的概念。 由于表示学习的目的是寻找表示本身，因此深度学习可以称为“多级表示学习”</p></li><li><p>毋庸置疑，深度学习方法中最显著的共同点是使用<strong>端到端训练</strong>。 也就是说，与其基于单独调整的组件组装系统，不如构建系统，然后联合调整它们的性能。 例如，在计算机视觉中，科学家们习惯于将特征工程的过程与建立机器学习模型的过程分开。 Canny边缘检测器 <a href="https://zh-v2.d2l.ai/chapter_references/zreferences.html#canny-1987">[Canny, 1987]</a> 和SIFT特征提取器 <a href="https://zh-v2.d2l.ai/chapter_references/zreferences.html#lowe-2004">[Lowe, 2004]</a> 作为将图像映射到特征向量的算法，在过去的十年里占据了至高无上的地位。 在过去的日子里，将机器学习应用于这些问题的关键部分是提出人工设计的特征工程方法，将数据转换为某种适合于浅层模型的形式。 然而，与一个算法自动执行的数百万个选择相比，人类通过特征工程所能完成的事情很少。 当深度学习开始时，<strong>这些特征抽取器被自动调整的滤波器所取代，产生了更高的精确度</strong></p></li><li><p>此外，通过取代大部分特定领域的预处理，深度学习消除了以前分隔计算机视觉、语音识别、自然语言处理、医学信息学和其他应用领域的许多界限，<strong>为解决各种问题提供了一套统一的工具</strong></p></li><li><p><strong>除了端到端的训练，我们正在经历从参数统计描述到完全非参数模型的转变。</strong> 当数据稀缺时，人们需要依靠简化对现实的假设来获得有用的模型。 当数据丰富时，可以用更准确地拟合实际情况的非参数模型来代替。 在某种程度上，这反映了物理学在上个世纪中叶随着计算机的出现所经历的进步。 现在人们可以借助于相关偏微分方程的数值模拟，而不是用手来求解电子行为的参数近似。<strong>这导致了更精确的模型，尽管常常以牺牲可解释性为代价</strong></p></li><li><p><strong>与以前工作的另一个不同之处是接受次优解，处理非凸非线性优化问题，并且愿意在证明之前尝试</strong>。 这种在处理统计问题上新发现的经验主义，加上人才的迅速涌入，导致了实用算法的快速进步。 尽管在许多情况下，这是以修改和重新发明存在了数十年的工具为代价的。</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 课程 </category>
          
          <category> Dive into deep learning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> Dive into deep learning </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Numpy Cheat Sheet</title>
      <link href="/archives/19c6ccbf.html"/>
      <url>/archives/19c6ccbf.html</url>
      
        <content type="html"><![CDATA[<h1 id="Numpy-Cheat-Sheet"><a href="#Numpy-Cheat-Sheet" class="headerlink" title="Numpy Cheat Sheet"></a>Numpy Cheat Sheet</h1><h2 id="Basics-基础"><a href="#Basics-基础" class="headerlink" title="Basics 基础"></a>Basics 基础</h2><h3 id="简单创建"><a href="#简单创建" class="headerlink" title="简单创建"></a>简单创建</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python">np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>start<span class="token punctuation">,</span> stop<span class="token punctuation">,</span> step<span class="token punctuation">)</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="Placeholders-创建"><a href="#Placeholders-创建" class="headerlink" title="Placeholders 创建"></a>Placeholders 创建</h3><p>包括创建 linespace, zeros, ones, random, empty 数组</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">np<span class="token punctuation">.</span>linespace<span class="token punctuation">(</span>start<span class="token punctuation">,</span> stop<span class="token punctuation">,</span> num<span class="token punctuation">)</span>np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>shape<span class="token punctuation">)</span>np<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>shape<span class="token punctuation">)</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>random<span class="token punctuation">(</span>shape<span class="token punctuation">)</span><span class="token comment"># 0-1 uniform</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token operator">*</span>dimensions<span class="token punctuation">)</span><span class="token comment"># normal/gaussian</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span>low<span class="token punctuation">,</span> high<span class="token punctuation">,</span> shape<span class="token punctuation">)</span><span class="token comment"># high is exclusive</span>np<span class="token punctuation">.</span>empty<span class="token punctuation">(</span>shape<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="Array-数组"><a href="#Array-数组" class="headerlink" title="Array 数组"></a>Array 数组</h2><h3 id="Array-Properties-属性"><a href="#Array-Properties-属性" class="headerlink" title="Array Properties 属性"></a>Array Properties 属性</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python">array<span class="token punctuation">.</span>shapearray<span class="token punctuation">.</span>ndim<span class="token comment"># dimensions of array</span>array<span class="token punctuation">.</span>sizearray<span class="token punctuation">.</span>dtypearray<span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token builtin">type</span><span class="token punctuation">)</span><span class="token comment"># convert data type</span><span class="token builtin">len</span><span class="token punctuation">(</span>array<span class="token punctuation">)</span><span class="token builtin">type</span><span class="token punctuation">(</span>array<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Copy-复制"><a href="#Copy-复制" class="headerlink" title="Copy 复制"></a>Copy 复制</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python">np<span class="token punctuation">.</span>copy<span class="token punctuation">(</span>array<span class="token punctuation">)</span>other <span class="token operator">=</span> array<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="Sort-排序"><a href="#Sort-排序" class="headerlink" title="Sort 排序"></a>Sort 排序</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python">array<span class="token punctuation">.</span>sort<span class="token punctuation">(</span><span class="token punctuation">)</span>array<span class="token punctuation">.</span>sort<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h2 id="Array-Operations-数组操作"><a href="#Array-Operations-数组操作" class="headerlink" title="Array Operations 数组操作"></a>Array Operations 数组操作</h2><h3 id="Adding-amp-removing"><a href="#Adding-amp-removing" class="headerlink" title="Adding &amp; removing"></a>Adding &amp; removing</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python">np<span class="token punctuation">.</span>append<span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span>np<span class="token punctuation">.</span>insert<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># not common</span>np<span class="token punctuation">.</span>delete<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># not common</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="Combining"><a href="#Combining" class="headerlink" title="Combining"></a>Combining</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python">np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span>arrays<span class="token punctuation">,</span> axis<span class="token punctuation">)</span>np<span class="token punctuation">.</span>vstack<span class="token punctuation">(</span>arrays<span class="token punctuation">)</span>np<span class="token punctuation">.</span>hstack<span class="token punctuation">(</span>arrays<span class="token punctuation">)</span>np<span class="token punctuation">.</span>stack<span class="token punctuation">(</span>arrays<span class="token punctuation">,</span> axis<span class="token punctuation">)</span><span class="token comment"># This will create a new axis</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Shaping"><a href="#Shaping" class="headerlink" title="Shaping"></a>Shaping</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python">array<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>shape<span class="token punctuation">)</span>array<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span><span class="token punctuation">)</span>array<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># equals array.T</span>array<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span>axes<span class="token punctuation">)</span><span class="token comment"># permute axes</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h2 id="Math-数学"><a href="#Math-数学" class="headerlink" title="Math 数学"></a>Math 数学</h2><h3 id="Operations-基础运算"><a href="#Operations-基础运算" class="headerlink" title="Operations 基础运算"></a>Operations 基础运算</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># basic</span>np<span class="token punctuation">.</span>multiply<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token comment"># equals x @ y</span>np<span class="token punctuation">.</span>dop<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token comment"># dot product of 1D array</span>np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>x<span class="token punctuation">)</span>np<span class="token punctuation">.</span>sin<span class="token punctuation">(</span>x<span class="token punctuation">)</span>np<span class="token punctuation">.</span>cos<span class="token punctuation">(</span>x<span class="token punctuation">)</span>np<span class="token punctuation">.</span>log<span class="token punctuation">(</span>x<span class="token punctuation">)</span>np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>x<span class="token punctuation">)</span>np<span class="token punctuation">.</span>power<span class="token punctuation">(</span>x1<span class="token punctuation">,</span> x2<span class="token punctuation">)</span><span class="token comment"># x1 &amp; x2 have the same shape or x2 can broadcast</span>np<span class="token punctuation">.</span>ceil<span class="token punctuation">(</span>x<span class="token punctuation">)</span>np<span class="token punctuation">.</span>floor<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token comment"># preprocess</span>np<span class="token punctuation">.</span>isnan<span class="token punctuation">(</span>x<span class="token punctuation">)</span>np<span class="token punctuation">.</span>isinf<span class="token punctuation">(</span>x<span class="token punctuation">)</span>np<span class="token punctuation">.</span><span class="token builtin">round</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> ndigits<span class="token punctuation">)</span>np<span class="token punctuation">.</span>nan_to_num<span class="token punctuation">(</span>x<span class="token punctuation">,</span> nan<span class="token punctuation">)</span><span class="token comment"># Replace NaN with zero and infinity with large finite numbers (default behaviour) or with the numbers defined by the user using the nan, posinf and/or neginf keywords.</span>np<span class="token punctuation">.</span><span class="token builtin">all</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> axis<span class="token punctuation">)</span><span class="token comment"># test whether all be true along a axis</span>np<span class="token punctuation">.</span><span class="token builtin">any</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> axis<span class="token punctuation">)</span><span class="token comment"># compare</span>np<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> axis<span class="token punctuation">)</span>np<span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> axis<span class="token punctuation">)</span>np<span class="token punctuation">.</span>maximum<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token comment"># Element-wise maximum of array elements.</span>np<span class="token punctuation">.</span>minimum<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token comment"># cumulative</span>np<span class="token punctuation">.</span>cumsum<span class="token punctuation">(</span>x<span class="token punctuation">,</span> axis<span class="token punctuation">)</span><span class="token comment"># cumulative sum, if axis=None, flatten x</span>np<span class="token punctuation">.</span>diff<span class="token punctuation">(</span>x<span class="token punctuation">,</span> axis<span class="token punctuation">)</span><span class="token comment"># differences</span>np<span class="token punctuation">.</span>prod<span class="token punctuation">(</span>x<span class="token punctuation">,</span> axis<span class="token punctuation">)</span><span class="token comment"># product along given axis</span><span class="token comment"># arg-relative</span>np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>x<span class="token punctuation">,</span> axis<span class="token punctuation">)</span>np<span class="token punctuation">.</span>argsort<span class="token punctuation">(</span>x<span class="token punctuation">,</span> axis<span class="token punctuation">)</span>np<span class="token punctuation">.</span>bincount<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># Count number of occurrences of each value in array of non-negative ints.</span><span class="token comment"># linear algebra</span>np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>det<span class="token punctuation">(</span>x<span class="token punctuation">)</span>np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>inv<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token comment"># Statistics</span>np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> axis<span class="token punctuation">)</span>np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>x<span class="token punctuation">,</span> axis<span class="token punctuation">)</span>np<span class="token punctuation">.</span>std<span class="token punctuation">(</span>x<span class="token punctuation">,</span> axis<span class="token punctuation">)</span>np<span class="token punctuation">.</span>corrcoef<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="Slicing-切片"><a href="#Slicing-切片" class="headerlink" title="Slicing 切片"></a>Slicing 切片</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># n dimensions</span>array<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token comment"># upper bound is exclusive</span>array<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token comment"># reverse slicing</span>array<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token comment"># step is 2</span><span class="token comment"># bool</span>array<span class="token punctuation">[</span>array <span class="token operator">&gt;</span> <span class="token number">5</span><span class="token punctuation">]</span>array<span class="token punctuation">[</span><span class="token punctuation">(</span>array<span class="token operator">&gt;</span><span class="token number">5</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span> <span class="token punctuation">(</span>array<span class="token operator">%</span><span class="token number">2</span><span class="token operator">==</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token comment"># Fancy indexing</span>array<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token comment"># could be any iterable int array</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="Broadcast-广播"><a href="#Broadcast-广播" class="headerlink" title="Broadcast 广播"></a>Broadcast 广播</h2><p>广播数组维度需要满足以下要求任意一个：</p><ol><li><p>从后往前比，两个数组各个维度大小相同</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">A <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>B <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>C <span class="token operator">=</span> A <span class="token operator">+</span> B<span class="token comment"># B will broadcast to (2, 3, 4, 5)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li><li><p>两个数组存在维度大小不相等时，其中一个不相等维度大小为1</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">A <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>B <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>C <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>D <span class="token operator">=</span> A <span class="token operator">+</span> B <span class="token operator">+</span> A <span class="token operator">*</span> C<span class="token comment"># B &amp; C will broadcast to (2, 3, 4, 5)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li></ol><h2 id="存储为-bin"><a href="#存储为-bin" class="headerlink" title="存储为 .bin"></a>存储为 .bin</h2><p>使用 <code>tofile &amp; fromfile</code> 将 ndarray 存储为二进制文件</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">from</span> pathlib <span class="token keyword">import</span> Pathbin_file <span class="token operator">=</span> Path<span class="token punctuation">(</span><span class="token string">'./xxx.bin'</span><span class="token punctuation">)</span>a <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>binfile<span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'w'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>    a<span class="token punctuation">.</span>tofile<span class="token punctuation">(</span>f<span class="token punctuation">)</span>b <span class="token operator">=</span> np<span class="token punctuation">.</span>fromfile<span class="token punctuation">(</span>binfile<span class="token punctuation">,</span> dtype<span class="token operator">=</span>a<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>b<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 编程 </category>
          
          <category> Python </category>
          
          <category> Package </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Python </tag>
            
            <tag> Numpy </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PV-RCNN</title>
      <link href="/archives/b179cc3a.html"/>
      <url>/archives/b179cc3a.html</url>
      
        <content type="html"><![CDATA[<h1 id="PV-RCNN"><a href="#PV-RCNN" class="headerlink" title="PV-RCNN"></a>PV-RCNN</h1><hr><p>Shi, Shaoshuai, Chaoxu Guo, Li Jiang, Zhe Wang, Jianping Shi, Xiaogang Wang, and Hongsheng Li. “PV-RCNN: Point-Voxel Feature Set Abstraction for 3D Object Detection.” <em>ArXiv:1912.13192 [Cs, Eess]</em>, April 9, 2021. <a href="http://arxiv.org/abs/1912.13192">http://arxiv.org/abs/1912.13192</a>.</p><p>Comment: Accepted by CVPR 2020. arXiv admin note: substantial text overlap with arXiv:2102.00463</p><hr><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>大多数现有的 3D 检测方法在点云表示方面可以分为两类：</p><ol><li>基于体素化的表示，the grid-based methods (e.g. VoxelNet)</li><li>基于点的表示，the point-based methods (e.g. Point R-CNN)</li></ol><p>这两种方法各有优缺点：</p><ol><li>基于体素化的操作有效地编码多尺度特征 multi-scale feature representations，并可以生成高质量的 3D proposals</li><li>基于 PointNet 的 set abstraction 操作，保留了更准确的位置信息，并且可以有更加灵活的感受野</li></ol><p>而 PV-RCNN 就是受这两类表示的启发，将这两类方法有效结合起来，使得点云特征既有体素化的多尺度信息，又增加了 set abstraction 的精准度与灵活度</p><p>论文总结了4个贡献点：</p><ol><li>结合了两种点云表示的优点：基于体素的表示和基于点的表示</li><li>提出了 <strong>voxel-to-keypoint scene encoding scheme</strong>，将体素类的特征编码转化为点云类特征</li><li><p>提出了 <strong>multi-scale RoI feature abstraction layer</strong>，将 RoI 中的点云特征编码转化为栅格点特征 RoI-grid pooling via set abstraction</p></li><li><p>PV-RCNN 以显著的优势在当时的 KITTI &amp; Waymo 榜单上排名第一</p></li></ol><p>中间两点提得比较笼统，需要具体看看 PV-RCNN 的结构才能有一个形象的了解</p><h2 id="PV-RCNN-Architecture"><a href="#PV-RCNN-Architecture" class="headerlink" title="PV-RCNN Architecture"></a>PV-RCNN Architecture</h2><p><img src="/archives/b179cc3a/ee6744b0-bff5-448b-a317-1557749f9588.png"></p><h3 id="3D-voxel-CNN"><a href="#3D-voxel-CNN" class="headerlink" title="3D voxel CNN"></a>3D voxel CNN</h3><p>首先将输入点云 P 划分为空间分辨率为 $L × W × H$ 的小体素/栅格，其中非空体素的特征直接计算为所有内部点的逐点特征的平均值。常用的特征是 3D 坐标 coordinate 和反射强度 reflectance intensity。Voxel CNN 能够在多个下采样分辨率下 (1x, 2x, 4x, 8x) 进行特征提取，得到不同 level 的 voxel-wise feature vectors，这就是体素化方法的好处，可以直接采用成熟的卷积方法</p><p>但是使用 voxel CNN 也会有一定的局限性：</p><ol><li>这些特征通常为低分辨率的空间特征，损失了大量的空间信息，阻碍了对象的准确定位</li><li>即使通过上采样 upsample 这些特征图谱都会是比较稀疏的，传统的池化方法可能得到许多零特征向量</li></ol><h3 id="Proposal-generation"><a href="#Proposal-generation" class="headerlink" title="Proposal generation"></a>Proposal generation</h3><p>将提取的 3D 特征转换 reshape 为 2D 俯视特征图 bird-view feature maps，按照基于锚 anchor 的方法生成高质量的 3D proposal (e.g. PointPillars)。这里可以尝试使用其他的生成算法，例如将 anchor-based 换为 anchor-free，提升效率和准确率</p><h3 id="Voxel-to-keypoint-encoding"><a href="#Voxel-to-keypoint-encoding" class="headerlink" title="Voxel-to-keypoint encoding"></a>Voxel-to-keypoint encoding</h3><p>了解了 voxel CNN 的一些局限性，是否有方法去补偿损失的空间信息呢？这里论文将提出一种全新的 encoding 方法 <strong>voxel set abstraction (VSA)</strong>，来将整个场景的编码从 voxel-like 转换为 point-like，具体来说 voxel set abstraction 使用 PointNet++ 网络中的 set abstraction 思想，将 voxel 特征聚合到场景中的关键点集 $K$上，这些关键点由 FurthestPoint-Sampling (FPS) 算法采样得出。这一操作我认为是整个论文里最具创意的操作，将 set abstraction 的操作进行了更广的拓展，从原来的 point-to-point 特征聚合操作，到这里为 voxel-to-point。更详细的动机可以参考原作者在 <a href="https://zhuanlan.zhihu.com/p/148942116">知乎</a> 上的回答</p><p>现在以更加数学化的语言来表达 <strong>voxel set abstraction (VSA)</strong>。关键点集合 $K=\{p_1,…,p_n\}$，对于每个关键点 $p_i$ ，我们在多个半径 $r_k$ 内寻找其相邻的非空体素 $v_j^{(l_k)}$ 其对特征为 $f_j^{(l_k)}$，$l_k$ 代表的是在 voxel CNN 阶段中的不同分辨率阶段</p><script type="math/tex; mode=display">S_{i}^{\left(l_{k}\right)}=\left\{\left[f_{j}^{\left(l_{k}\right)} ; v_{j}^{\left(l_{k}\right)}-p_{i}\right]^{T}\middle|\ \ \begin{array}{ll}\left\|v_{j}^{\left(l_{k}\right)}-p_{i}\right\|^{2}<r_{k}, \\\forall v_{j}^{\left(l_{k}\right)} \in \mathcal{V}^{\left(l_{k}\right)} \\\forall f_{j}^{\left(l_{k}\right)} \in \mathcal{F}^{\left(l_{k}\right)}\end{array}\right\}</script><p>然后使用 PointNet++ 中的 set abstraction 操作，将这些特征聚合为一个特征向量</p><script type="math/tex; mode=display">f_{i}^{\left(p v_{k}\right)}=\max \left\{G\left(\mathcal{M}\left(S_{i}^{\left(l_{k}\right)}\right)\right)\right\}</script><p>其中 $M(·)$ 表示从相邻集合 $S^{(l_k)}_i$ 中随机采样最多 $T_k$ 个体素以节省计算，$G(·)$ 表示一个多层感知器网络 MLP（区别于 PoinNet 中的 Shared MLP）。将多个半径的特征向量连接起来就能得到多尺度的特征，类似于 PointNet++ 中的 multi-scale grouping (MSG)</p><p>现在将不同分辨率的特征连接起来，原论文有4个不同的分辨率</p><script type="math/tex; mode=display">f_{i}^{(p v)}=\left[f_{i}^{\left(p v_{1}\right)}, f_{i}^{\left(p v_{2}\right)}, f_{i}^{\left(p v_{3}\right)}, f_{i}^{\left(p v_{4}\right)}\right], \text { for } i=1, \cdots, n</script><p>再添加一些特征：原点云数据 raw point feature 和对应点的俯视图特征 bird-eye view feature，得到最终的整个点云的特征集合</p><script type="math/tex; mode=display">f_{i}^{(p)}=\left[f_{i}^{(p v)}, f_{i}^{(r a w)}, f_{i}^{(b e v)}\right], \text { for } i=1, \cdots, n</script><p>再进行一些权重调整，权重依据为该点是否为前景点，如果为背景点则权重降低，这将给模型带来更好的注意力机制。使用得到的点云特征，送入到三层的 MLP $A(·)$ 中去预测该点的权重，然后再与原特征相乘</p><script type="math/tex; mode=display">\tilde{f}_{i}^{(p)}=\mathcal{A}\left(f_{i}^{(p)}\right) \cdot f_{i}^{(p)}</script><p>这里的权重调整机制论文称为 <strong>predicted key weighting (PKW)</strong>，其图示如下</p><p><img src="/archives/b179cc3a/image-20211008181557465.png"></p><h3 id="Keypoint-to-grid-RoI-feature-abstraction"><a href="#Keypoint-to-grid-RoI-feature-abstraction" class="headerlink" title="Keypoint-to-grid RoI feature abstraction"></a>Keypoint-to-grid RoI feature abstraction</h3><p>给定每个 3D RoI/proposal，论文提出 RoI-grid pooling，将关键点特征聚合到具有多个感受野的 RoI-grid 点，特征聚合方法依旧类似于 PointNet++ MSG，图示如下，蓝色虚线是我自己画的，方便体现出 grid</p><p><img src="/archives/b179cc3a/image-20211008183015394.png" style="zoom: 50%;"></p><p>其数学表达也是类似的</p><script type="math/tex; mode=display">\begin{array}{l}\tilde{\Psi}=\left\{\left[\tilde{f}_{j}^{(p)} ; p_{j}-g_{i}\right]^{T} \Biggl|\ \begin{array}{l}\left\|p_{j}-g_{i}\right\|^{2}<\tilde{r}, \\\forall p_{j} \in \mathcal{K}, \forall \tilde{f}_{j}^{(p)} \in \tilde{\mathcal{F}}\end{array}\right\} \\\tilde{f}_{i}^{(g)}=\max \{G(\mathcal{M}(\tilde{\Psi}))\}\end{array}</script><p>为什么这里还要再次进行编码，而不是直接使用选框内的所有点进行聚合，得到一个全局的表达？一个重要原因是因为使用 roi pooling 能够将特征聚合到一个固定的形状，便于之后输入到 MLP。同时也可能是为了获得多尺度的特征</p><h3 id="Refinement-and-confidence-prediction"><a href="#Refinement-and-confidence-prediction" class="headerlink" title="Refinement and confidence prediction"></a>Refinement and confidence prediction</h3><p>采用2层 MLP，去做置信度预测和选框细化两个任务。采用 3D RoI/proposal 与其对应的真实选框 ground truth 之间的 3D IoU 作为训练目标，并采用二元交叉熵损失函数</p><script type="math/tex; mode=display">y_{k}=\min \left(1, \max \left(0,2 \mathrm{IoU}_{k}-0.5\right)\right)\\L_{\mathrm{iou}}=-y_{k} \log \left(\tilde{y}_{k}\right)-\left(1-y_{k}\right) \log \left(1-\tilde{y}_{k}\right)</script><p>这种  quality-aware 置信度预测策略比传统分类标签实现了更好的性能（这种损失函数是否还能进一步改进呢？比如通过简单的平滑过渡操作，使得学习曲线更平缓）对于细化 refinement 的目标和损失函数论文没有完整列出，整体思想是预测其残差，并使用 smooth-L1 loss，具体请参考 SECOND, Part-A^2</p><script type="math/tex; mode=display">L_{\mathrm{rcnn}}=L_{\mathrm{iou}}+\sum_{\mathrm{r} \in\{x, y, z, l, h, w, \theta\}} \mathcal{L}_{\text {smooth-L1 }}\left(\widehat{\Delta \mathrm{r}^{p}}, \Delta \mathrm{r}^{p}\right)</script><p>在 voxel CNN 阶段，region proposal 和 classification 的损失函数也没有完整列出，如下</p><script type="math/tex; mode=display">L_{\mathrm{rpn}}=L_{\mathrm{cls}}+\beta \sum_{\mathrm{r} \in\{x, y, z, l, h, w, \theta\}} \mathcal{L}_{\text {smooth-L1 }}\left(\widehat{\Delta \mathrm{r}^{a}}, \Delta \mathrm{r}^{a}\right)</script><p>其中分类任务和分割任务都使用的是 focal loss</p><h2 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a>Experiment</h2><h3 id="KITTI"><a href="#KITTI" class="headerlink" title="KITTI"></a>KITTI</h3><p>PV-RCNN 在 KITTI 数据集上的准确率和召回率</p><p><img src="/archives/b179cc3a/image-20211008205557923.png"></p><p><img src="/archives/b179cc3a/image-20211008210508478.png" style="zoom:80%;"></p><h3 id="Waymo"><a href="#Waymo" class="headerlink" title="Waymo"></a>Waymo</h3><p><img src="/archives/b179cc3a/image-20211008210829402.png"></p><h3 id="Ablation-study"><a href="#Ablation-study" class="headerlink" title="Ablation study"></a>Ablation study</h3><p><img src="/archives/b179cc3a/image-20211008211127226.png"></p><p>消融实验针对 voxel set abstraction, RoI-grid pooling, PKW, IoU-guided scoreing 进行深入研究，这些结构能将最终表现提升 1-3 mAP</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>PV-RCNN 中的一个巨大启发是对于特征的 aggregation 不需要被数据实际的形式给限制，结合多种数据提取特征的优势，创造其中的桥梁，能够更好地进行局部和全局的把控，又将点云表示带到了一个新的高度，即使接近两年过去了，该方法仍在 KITTI 榜单排名前50。该网络的推理速度在 80ms 左右，依旧还有提升的空间，项目开源在了 OpenMMLab，现在 OpenMMLab 又提出了新的网络 Voxel R-CNN，推理速度减少了一半，达到了 40ms 左右，而且准确度也上升了，可以进一步进行学习</p><h2 id="TO-READ"><a href="#TO-READ" class="headerlink" title="TO READ"></a>TO READ</h2><ol><li>SECOND</li><li>Part-A^2</li><li>Voxel R-CNN</li></ol>]]></content>
      
      
      <categories>
          
          <category> papers </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Point Cloud </tag>
            
            <tag> PV-RCNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Point-GNN</title>
      <link href="/archives/74da7df7.html"/>
      <url>/archives/74da7df7.html</url>
      
        <content type="html"><![CDATA[<h1 id="Point-GNN-note"><a href="#Point-GNN-note" class="headerlink" title="Point-GNN note"></a>Point-GNN note</h1><p>由于对于GNN没有过多的了解，并不能感受到GNN相对于CNN有极大的优势。相反的，在其中设计的很多结构，与使用CNN处理是相似的，最核心的观点就是捕捉到 (multi-scale) local feature，这篇笔记仅潦草记录一下</p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>构建图的方法：以点作为图的顶点，将每个点和附近的点相连形成边</p><p>We encode the point cloud natively in a graph by using the points as the graph vertices. The edges of the graph connect neighborhood points that lie within a fixed radius, which allows feature information to flow between neighbors.  </p><p>A graph neural network reuses the graph edges in every layer, and avoids grouping and sampling the points repeatedly.</p><p><strong>几个特点</strong>：</p><ol><li>Use a graph representation can <strong>preserve the irregularity</strong> of a point cloud</li><li>Unlike the techniques that sample and group the points into sets repeatedly, <strong>we construct the graph once</strong>. </li><li>The proposed Point-GNN then extracts features of the point cloud by <strong>iteratively updating vertex features</strong> on the same graph. Our work is a <strong>single-stage detection</strong> method.</li></ol><h2 id="Point-GNN-for-3D-Object-Detection-in-a-Point-Cloud"><a href="#Point-GNN-for-3D-Object-Detection-in-a-Point-Cloud" class="headerlink" title="Point-GNN for 3D Object Detection in a Point Cloud"></a>Point-GNN for 3D Object Detection in a Point Cloud</h2><p>our method contains three components:</p><p>(a) graph construction, </p><p>(b) a GNN of T iterations, and </p><p>(c) bounding box merging and scoring.</p><p><img src="/archives/74da7df7/image-20210615114208241.png" style="zoom:80%;"></p><h3 id="Graph-construction"><a href="#Graph-construction" class="headerlink" title="Graph construction"></a>Graph construction</h3><p>Formally, we define a point cloud of N points as a set $P = \{p_1, …, p_N \}$, where $p_i = (x_i, s_i)$</p><p>$x_i$是坐标，$s_i$为state value可以看作feature</p><p> we construct a graph G = (P, E) by using P as the vertices and connecting a point to its neighbors within a fixed radius r</p><p><img src="/archives/74da7df7/image-20210614174123691.png" style="zoom:80%;"></p><p>由于点太多了，需要下采样</p><p>we use a voxel downsampled point cloud $\hat{P}$ for the graph construction.</p><p>为了保留原点云的信息，先用PointNet将点云encode（文章说不用grouping and sampling其实到处都在用）</p><p>To preserve the information within the original point cloud, we encode the dense point cloud in the initial state value si of the vertex. More specifically, we search the raw points within a r0 radius of each vertex and use the neural network on sets to extract their features. </p><h3 id="Graph-Neural-Network-with-Auto-Registration"><a href="#Graph-Neural-Network-with-Auto-Registration" class="headerlink" title="Graph Neural Network with Auto-Registration"></a>Graph Neural Network with Auto-Registration</h3><p><strong>GNN一般迭代过程</strong></p><p>A typical graph neural network refines the vertex features by aggregating features along the edges.</p><p>在 $(t+1)^{th}$ 迭代中，顶点更新公式为</p><p><img src="/archives/74da7df7/image-20210614214253822.png" style="zoom:80%;"></p><p>where  $e^t$ and $v^t$ are the edge and vertex features from the $t^{th}$ iteration.</p><p>$f^t(·)$ 通过两个顶点的特征来更新边的特征</p><p>$\rho(·)$ 为一个集函数，将每个顶点的边的特征进行综合</p><p>$g^t(·)$ 更新顶点i的特征</p><p>在本文中，顶点的特征 $v_i$，就是之前所说的每个点的状态 $s_i$</p><p>在本文新的迭代更新方程被提出，但我不理解其中的意义，文章说这样的更新是为了增加translation invariance</p><p><img src="/archives/74da7df7/image-20210614215842089.png" style="zoom:50%;"></p><h3 id="LOSS"><a href="#LOSS" class="headerlink" title="LOSS"></a>LOSS</h3><p> We use the average cross-entropy loss as the classification loss.</p><p><img src="/archives/74da7df7/image-20210614220904072.png" style="zoom: 67%;"></p><p>We encode the bounding box with the vertex coordinates (xv, yv, zv) as follows:</p><p><img src="/archives/74da7df7/image-20210614220942233.png" style="zoom:67%;"></p><p>We then average the localization loss of all the vertices:</p><p><img src="/archives/74da7df7/image-20210614221044678.png" style="zoom:67%;"></p><p>To prevent over-fitting, we add L1 regularization to each MLP. The total loss is then:</p><p><img src="/archives/74da7df7/image-20210614221104990.png" style="zoom: 80%;"></p><h3 id="Box-Merging-and-Scoring"><a href="#Box-Merging-and-Scoring" class="headerlink" title="Box Merging and Scoring"></a>Box Merging and Scoring</h3><p>文章通过一些的方法来实现近似于（更好于）NMS的效果，我没有仔细看</p><h2 id="Eperiment"><a href="#Eperiment" class="headerlink" title="Eperiment"></a>Eperiment</h2><p>最终实验结果还是很不错的</p><p><img src="/archives/74da7df7/image-20210614221626269.png" style="zoom:80%;"></p><p><img src="/archives/74da7df7/image-20210614221800920.png" style="zoom:80%;"></p><p>感觉比较简单的设计但达到了较好的效果，也不清楚这个网络的表现好到底来源于哪一部分…</p><p>不作为今后延申的重点，持观望态度</p>]]></content>
      
      
      <categories>
          
          <category> papers </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Point Cloud </tag>
            
            <tag> Point-GNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PointNet &amp; PointNet++</title>
      <link href="/archives/63387d0d.html"/>
      <url>/archives/63387d0d.html</url>
      
        <content type="html"><![CDATA[<h1 id="PointNet-amp-PointNet"><a href="#PointNet-amp-PointNet" class="headerlink" title="PointNet &amp; PointNet++"></a>PointNet &amp; PointNet++</h1><hr><p>Qi, Charles R., Hao Su, Kaichun Mo, and Leonidas J. Guibas. “PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation.” <em>ArXiv:1612.00593 [Cs]</em>, April 10, 2017. <a href="http://arxiv.org/abs/1612.00593">http://arxiv.org/abs/1612.00593</a>.</p><p>Comment: CVPR 2017</p><p>Qi, Charles R., Li Yi, Hao Su, and Leonidas J. Guibas. “PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space.” <em>ArXiv:1706.02413 [Cs]</em>, June 7, 2017. <a href="http://arxiv.org/abs/1706.02413">http://arxiv.org/abs/1706.02413</a>.</p><p>From zotero</p><hr><p>PointNet 算是利用深度学习处理点云数据的开山之作。由于点云数据对比图片数据更加混乱和复杂，原有的二维处理方法面对点云数据并没有起到好的效果，但在 PointNet 提出后，处理三维点云数据有了新的思路，并且实验结果有了显著的提升。该笔记主要为了总结 PointNet 和 PointNet++ 中心思想，参考链接：<a href="https://blog.csdn.net/weixin_39373480/article/details/88878629">CSDN</a></p><h2 id="PointNet"><a href="#PointNet" class="headerlink" title="PointNet"></a>PointNet</h2><h3 id="三维表示"><a href="#三维表示" class="headerlink" title="三维表示"></a>三维表示</h3><p><img src="/archives/63387d0d/image-20211004162518323.png" style="zoom: 50%;"></p><p>三维数据的表述形式一般分为四种：</p><ol><li><p>点云：由 N 个 D 维的点组成，当这个 D = 3 的时候一般代表着 $(x, y, z)$ 的坐标，当然也可以包括一些法向量、强度等别的特征</p></li><li><p>Mesh：由三角面片和正方形面片组成</p></li><li><p>体素：由三维栅格将物体用0和1表征</p></li><li><p>多角度的RGB图像或者RGB-D图像</p></li></ol><p><strong>为什么使用点云数据？</strong></p><ol><li>点云更接近于设备的原始表征（即雷达扫描物体直接产生点云）</li><li>点云的表达方式更加简单，一个物体仅用一个 N × D 的矩阵表示</li></ol><h3 id="Properties-of-Point-Sets"><a href="#Properties-of-Point-Sets" class="headerlink" title="Properties of Point Sets"></a>Properties of Point Sets</h3><ul><li>Unordered，无序性</li><li>Interaction among points，点与点之间的作用</li><li>Invariance under transformations，空间不变性</li></ul><p>以上性质的前两点是区别于二维图像数据的，也是处理点云数据的难点。PointNet 核心的贡献有两点，一个是解决无序的点云输入，一个是解决空间不变性。但是对于处理空间不变性的结构，在现在看来似乎没有必要性。而且对于点与点之间的作用 PointNet 也没有深入考虑，但在之后的 PointNet++ 中提出了解决方法</p><h3 id="PointNet-Architecture"><a href="#PointNet-Architecture" class="headerlink" title="PointNet Architecture"></a>PointNet Architecture</h3><p>先看下图有个整体感受<img src="/archives/63387d0d/eef95113-fb3d-4ba8-b8a4-6c377d66d2bd.png" style="zoom: 50%;"></p><p>PointNet 能够处理分类任务和分割任务，分别对应着流程图的上下两个部分</p><p>input transform 和 feature transform 的设计初衷是为了让网络面对空间的旋转、缩放等有一定的鲁棒性，在论文中的方法是新引入了一个 <strong>T-Net</strong> 网络去学习点云的旋转，将物体校准，具体的结构在该笔记中不会详细介绍</p><p>Shared MLP 本质为一维的卷积 <a href="https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html">Conv1d</a>，可以参考链接 <a href="https://blog.csdn.net/Passersby__/article/details/104941591">CSDN</a> 进一步学习。Shared MLP + Max Pooling 操作实现了对无序性点云数据的对称处理，即当点云输入顺序改变时，输出结果不会因为输入顺序的改变而改变。注意 Max Pooling 是对不同的点而言的，而不是对于同一个点的特征向量操作的。下面我们将重点讨论为何使用 Shared MLP + Max Pooling</p><h3 id="Symmetry-Function-for-Unordered-Input"><a href="#Symmetry-Function-for-Unordered-Input" class="headerlink" title="Symmetry Function for Unordered Input"></a>Symmetry Function for Unordered Input</h3><p>点云实际上拥有<strong>置换不变性</strong>的特点，那么什么是置换不变性呢，简单地说就是点的排序不影响物体的性质。因此针对点云的置换不变性，其设计的网络必须是一个<strong>对称的函数</strong>，我们经常看到的 <strong>sum</strong> 和 <strong>max</strong> 等函数其实都是对称函数</p><p>文章的具体做法为：将点云数据使用 Shared MLP 升维（从3维最终升至1024维），然后使用 max pooling 操作，得到一个全局的特征向量 global feature。使用该 global feature 就可以进行点云的分类任务了，而如果是进行点云分割任务，则需要和每个点的局部特征结合起来，再进行计算</p><p>Q：升维（或者说多卷积核）在深度学习当中是非常常见的，该操作的本质意义是什么？个人猜测：对高维度的空间进行分割更简单，并对数据保留足够的特征</p><h3 id="Shared-MLP-Max-Pooling-的合理性"><a href="#Shared-MLP-Max-Pooling-的合理性" class="headerlink" title="Shared MLP + Max Pooling 的合理性"></a>Shared MLP + Max Pooling 的合理性</h3><p>该论文提出了如下的定理，该定理基于万能近似定理（Universal Approximate Theorem）</p><p><img src="/archives/63387d0d/3b3fa29d-44f5-4724-af23-8438e1961530.png" style="zoom: 67%;"></p><p>对于文章证明理解，有2个概念需要进一步了解，一个是 <a href="https://en.wikipedia.org/wiki/Hausdorff_distance">Hausdorff_distance</a> 一个是 <a href="https://en.wikipedia.org/wiki/Power_set">Power set</a>，前者表示了两个集合的距离，后者表示了一个集合的所有子集</p><p>该定理的结论是，论文提出的结构，能够拟合任意的连续集合函数。这个定理的结论，并没有什么特殊意义，因为万能近似定理告诉我们，足够多节点的 MLP 能够近似任何连续函数。重点在于论文的证明过程，给出了 Shared MLP + Max Pooling 的合理性，该合理性总结为如下</p><blockquote><p>The proof to this theorem can be found in our supplementary material. The key idea is that in the worst case the network can learn to convert a point cloud into a volumetric representation, by partitioning the space into equal-sized voxels. In practice, however, the network learns a much smarter strategy to probe the space, as we shall see in point function visualizations.</p></blockquote><p>这里的 worst case 的“最差”体现在何处我并不理解，但是证明过程中指出了网络的一条可能的学习路径。该学习路径描述为如下：</p><ol><li>将所有的点映射到其“附近”的栅格点中，这样得到一个新的点集，可以证明使用该栅格点集作为输入去替换原点集，并不会对输出造成太大的影响，所以该栅格点集就是对原点集的一个很好的近似。而这个映射就是由 Shared MLP + Max Pooling + MLP 完成</li><li>此时还需要使用新的 MLP 完成对原连续集函数的拟合。该 MLP 和第一步中的 MLP 可以叠加起来，作为一个整体的 MLP，在公式中即表示为 γ 函数</li></ol><p>通过人为设置的学习路径，解释了该结构的合理性。但通过网络自身的学习，能够获得更好的效果，剩下的就交给优化算法吧！</p><h4 id="更新：从升维的角度来看待-PointNet"><a href="#更新：从升维的角度来看待-PointNet" class="headerlink" title="更新：从升维的角度来看待 PointNet"></a>更新：从升维的角度来看待 PointNet</h4><p>为什么要将每一个点的位置使用全连接网络进行升维度？BTW，因为每一个点都共用一个全连接网络所以叫 shared MLP</p><p>这样的升维操作我在 one-hot 编码中看到过，即用一个多维的，由 {0,1} 组成的向量来表示属于某一个类，这里会不会是相同的道理？MLP 的权重实际上是空间中的多个向量，这些向量将空间分割成多个子空间，如果输入向量落在该子空间中，则输入向量与分隔向量的点积数值就会较大，此时可以把则该子空间看作为<strong>某种特征</strong>。之后使用 maxpooling 堆所有输入向量进行全局的特征提取，最后使用 MLP 进行各种下游任务 </p><p>这个思想（可能）起源于传统的滤波，也可能来自于看了马毅教授的一些说法：把滤波/卷积核看作是一个高维度向量，而卷积操作实际上是该部分数据与该向量的点积，也就是在该方向上的投影，寻找卷积核就是在寻找不同的高维向量，对高维空间进行分割，原始特征落在高维空间的不同区域，它们与高维向量的点积代表了它们在这些方向上的投影，如果方向相同那么投影值肯定会打，如果方向垂直或者相反投影值则会变小，这样落在不同区域的特征将会被识别出来（通过 ReLU or maxpooling），这些投影值可能就是我们常说的提取得到的“特征”</p><h2 id="PointNet-1"><a href="#PointNet-1" class="headerlink" title="PointNet++"></a>PointNet++</h2><p>PointNet++ 的提出源于 PointNet 的缺点——缺失局部特征。PointNet对于场景的分割效果十分一般，由于其网络直接暴力地将所有的点最大池化为了一个全局特征，因此局部点与点之间的联系并没有被网络学习到。PointNet++ 中主要借鉴了 CNN 的多层感受野的思想，增强了网络对于局部特征的提取能力</p><p>具体来讲就是：对于点云数据，将点云数据进行采样和分组，使用原 PointNet 对这些分组后的点云子集进行特征提取（而非之前的全局特征提取），得到了新的特征集合，对于新的特征集合，可以重复之前的采样、分组、提取过程，不断地迭代。随着迭代次数的增加，PointNet 的感受野也越来越大，下图为 PointNet++  (single scale grouping) 的结构图，能够有一个更加直观的感受</p><p><img src="/archives/63387d0d/a4bc72c1-997d-4536-b50a-78a1917af8d6.png" style="zoom: 67%;"></p><h3 id="PointNet-Architecture-1"><a href="#PointNet-Architecture-1" class="headerlink" title="PointNet++ Architecture"></a>PointNet++ Architecture</h3><p>和 PointNet 类似，整体依旧是 encoder-decoder 模式，可以处理分割任务和分类任务，但两个任务的 decoder 不相同</p><h4 id="Encoder"><a href="#Encoder" class="headerlink" title="Encoder"></a>Encoder</h4><p>Encoder 由多个 set abstraction 结构组成，其中 set abstraction 由3个重要部分组成：sampling 采样，grouping 分组，PointNet 使用 PointNet 采集特征，接下来进一步了解这三个部分</p><ol><li>Sampling：使用利用 FPS（最远点采样）随机采样点，参考链接 <a href="https://blog.csdn.net/minhuaQAQ/article/details/107280596">CSDN</a></li><li>Grouping：利用 Ball Query 划一个 R 为半径的圈，将每个圈里面的点云作为一簇</li><li>PointNet： 对 Sampling + Grouping 以后的点云进行特征提取，注意这里的 PointNet 和原 PointNet 相比，去掉了其中的 T-Net transform 的部分</li></ol><p>数据的形状变化为：</p><p>Input (N, d) -&gt; sampling (n, d) -&gt; grouping (n, K, d) -&gt; PointNet (n, C + d) -&gt; …</p><p>其中 d 应该为点的原始信息，会一直跟随着点存在，因为 sampling + grouping 将会使用</p><h4 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h4><p>分类任务的 decoder 也是比较简单，直接使用 PointNet 提取全局特征，然后送入 MLP 中进行分类</p><p>分割任务的 decoder 需要得到每一个点的特征向量，但是经过 encoder 我们只有少数一些点的特征，应该怎么办呢？论文采取的结构为 Point Feature Propagation，将少数点的特征逐层传播到每一个点，其本质为插值 interpolation。公式如下，由 <a href="https://www.latexlive.com/">latexlive</a> 从图片生成</p><script type="math/tex; mode=display">f^{(j)}(x)=\frac{\sum_{i=1}^{k} w_{i}(x) f_{i}^{(j)}}{\sum_{i=1}^{k} w_{i}(x)} \quad \text { where } \quad w_{i}(x)=\frac{1}{d\left(x, x_{i}\right)^{p}}, j=1, \ldots, C</script><p>简单来说，就是将该点周围的点的特征值进行加权平均，作为该点自己的特征，论文取 k = 3, p = 2，即 neighbor 有3个，距离为欧氏距离</p><p>除了对点进行插值，进行特征传播外，论文还将插值得到特征与 encoder 中对应层的相同点的特征连接起来 concatenate，使得特征的信息保留更多</p><h4 id="多尺度-MSG-amp-MRG"><a href="#多尺度-MSG-amp-MRG" class="headerlink" title="多尺度 MSG &amp; MRG"></a>多尺度 MSG &amp; MRG</h4><p>为了继续增加网络对于多尺度信息的提取，论文也提出了两种多尺度 grouping 方法，MSG &amp; MRG 如下图所示</p><p><img src="/archives/63387d0d/4c9a6b7b-e492-40fe-b552-5a63e7aab832.png" style="zoom:43%;"></p><ol><li>MSG：比较好理解，就是使用多个半径，去获取多个尺度的特征，然后将这些特征连接起来</li><li>MRG：MSG 的计算量相对比较大，尤其是在点比较多的时候。论文提出了 MRG，MRG 分为两个部分，左边特征为一般的 grouping 得到的特征，右边特征为该 grouping 范围在原始点云中的位置，对该位置范围内的原始点云做特征提取。由于 MRG 作者并为将其代码开源，所以可能理解并不深刻，所以请参考原文及其附录</li></ol><h4 id="数据预处理-Dropout"><a href="#数据预处理-Dropout" class="headerlink" title="数据预处理 Dropout"></a>数据预处理 Dropout</h4><p>多尺度训练的目的之一是为了更好应对点云密度的变化，对于密度低的点云，选取更大尺度范围的特征效果会更好。同时论文也采用了 dropout 操作，对训练数据点以 dropout ratio θ 进行随机剔除，而 θ 是从 0-0.95 中均匀采样得到，这样就能创建不同密度的点云数据了</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>PointNet 系列是点云分割网络最初的 baseline，一些网络也是通过以这两个网络为基础构造出来的。其优点非常的明显，就是<strong>参数量小</strong>；但其缺点就是对于<strong>局部的特征的抓取还不是特别的完善</strong>，这也是未来可以改进的地方</p>]]></content>
      
      
      <categories>
          
          <category> papers </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Point Cloud </tag>
            
            <tag> PointNet </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PointPillars</title>
      <link href="/archives/f3e8f95c.html"/>
      <url>/archives/f3e8f95c.html</url>
      
        <content type="html"><![CDATA[<h1 id="PointPillars-note"><a href="#PointPillars-note" class="headerlink" title="PointPillars note"></a>PointPillars note</h1><p>这篇文章也经常在其他文章中被提到，该网络特点就是具有非常快的推理速度。这篇文章的一个出发点之一，就是不想使用速度较慢的 3D convolution。这篇笔记比较潦草，但目的是梳理清楚模型的框架和流程</p><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>In this work we propose PointPillars, a novel encoder which <strong>utilizes PointNets to learn a representation of point clouds organized in vertical columns (pillars).</strong> While <strong>the encoded features can be used with any standard 2D convolutional detection architecture,</strong> we further propose a lean downstream network</p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>Recently SECOND  improved the inference speed of VoxelNet but the 3D convolutions remain a bottleneck. </p><p>In this work we use a single stage method</p><p>We show how all computations on pillars can be posed as dense 2D convolutions which enables <strong>inference at 62 Hz;</strong> a factor of 2-4 times faster than other methods</p><h2 id="PointPillars-Network"><a href="#PointPillars-Network" class="headerlink" title="PointPillars Network"></a>PointPillars Network</h2><p>It consists of three main stages (Figure 2): </p><p>(1) A feature encoder network that <strong>converts a point cloud to a sparse pseudoimage;</strong></p><p>(2) <strong>a 2D convolutional backbone</strong> to process the pseudo-image into high-level representation; and </p><p>(3) a detection head that <strong>detects and regresses 3D boxes.</strong></p><p><img src="/archives/f3e8f95c/image-20210615120459627.png" style="zoom:80%;"></p><h3 id="Pointcloud-to-Pseudo-Image"><a href="#Pointcloud-to-Pseudo-Image" class="headerlink" title="Pointcloud to Pseudo-Image"></a>Pointcloud to Pseudo-Image</h3><p>As a first step the point cloud is discretized into an evenly spaced grid in the x-y plane, creating a set of pillars P with |P| = B</p><p>The points in <strong>each pillar are then augmented with</strong> $x_c, y_c, z_c, x_p, y_p$ where the c subscript denotes distance to the arithmetic mean of all points in the pillar and the p subscript denotes the offset from the pillar x, y center. </p><p>The augmented lidar point l is now <strong>D = 9</strong> dimensional $(x, y, z, r, x_c, y_c, z_c, x_p, y_p)$ </p><p>The set of pillars will be mostly empty due to sparsity of the point cloud</p><p><strong>为了更近一步处理 sparsity，规定了每个 sample，最多有 P 个 non-empty Pillars，每个 pillar 最多有 N 个 points，多于就进行随机采样。最终得到 tensor of size (D, P, N)。之后使用 PointNet，将每个 Pillar 进行 aggreagte 得到 feature tensor (C, P)，再将这个 feature tensor 还原成为 feature map</strong></p><h3 id="Backbone"><a href="#Backbone" class="headerlink" title="Backbone"></a>Backbone</h3><p><strong>We use a similar backbone as VoxelNet</strong> and the structure is shown in Figure 2. The backbone has two sub-networks: one top-down network that produces features at increasingly small spatial resolution and a second network that performs upsampling and concatenation of the top-down features. </p><p><strong>The top-down backbone can be characterized by a series of blocks Block(S, L, F).</strong> Each block operates at stride S (measured relative to the original input pseudo-image). A block has L 3x3 2D conv-layers with F output channels, each followed by BatchNorm and a ReLU</p><h3 id="Detection-Head"><a href="#Detection-Head" class="headerlink" title="Detection Head"></a>Detection Head</h3><p>In this paper, we use the Single Shot Detector (SSD) [18] setup to perform 3D object detection. Similar to SSD, we match the priorboxes to the ground truth using 2D Intersection over Union (IoU)</p><h2 id="Loss"><a href="#Loss" class="headerlink" title="Loss"></a>Loss</h2><p>Ground truth boxes and anchors are defined by $(x, y, z, w, l, h, \theta)$. The localization regression residuals between ground truth and anchors are defined by:</p><p><img src="/archives/f3e8f95c/image-20210615124243246.png" style="zoom:67%;"></p><p>$d^a = \sqrt{(w^a)^2+(l^a)^2}$ ，the total localization loss is: </p><p><img src="/archives/f3e8f95c/image-20210615124445132.png" style="zoom:67%;"></p><p>For the object classification loss, we use the focal loss [16]:</p><p><img src="/archives/f3e8f95c/image-20210615124612144.png" style="zoom:67%;"></p><p>The total loss is therefore</p><p><img src="/archives/f3e8f95c/image-20210615124700683.png" style="zoom:67%;"></p><h2 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a>Experiment</h2><p><strong>Params:</strong> Unless explicitly varied in an experimental study, we use an xy resolution: 0.16 m, max number of pillars (P): 12000, and max number of points per pillar (N): 100.</p><p><img src="/archives/f3e8f95c/image-20210615124819976.png" style="zoom:80%;"></p><h3 id="Speed-v-s-resolution-amp-presicion"><a href="#Speed-v-s-resolution-amp-presicion" class="headerlink" title="Speed v.s. resolution &amp; presicion"></a>Speed v.s. resolution &amp; presicion</h3><p><img src="/archives/f3e8f95c/image-20210615124859420.png" style="zoom:80%;"></p>]]></content>
      
      
      <categories>
          
          <category> papers </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Point Cloud </tag>
            
            <tag> PointPillars </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PointRCNN</title>
      <link href="/archives/51543c70.html"/>
      <url>/archives/51543c70.html</url>
      
        <content type="html"><![CDATA[<h1 id="PointRCNN"><a href="#PointRCNN" class="headerlink" title="PointRCNN"></a>PointRCNN</h1><hr><p>Shi, Shaoshuai, Xiaogang Wang, and Hongsheng Li. “PointRCNN: 3D Object Proposal Generation and Detection from Point Cloud.” <em>ArXiv:1812.04244 [Cs]</em>, May 16, 2019. <a href="http://arxiv.org/abs/1812.04244">http://arxiv.org/abs/1812.04244</a>.</p><p>Comment: Accepted by CVPR 2019</p><hr><p>今后的论文整理应该遵循一个统一的框架：</p><ol><li>前言：主要为了提出问题，引入背景，引出论文。描述一下文章解决了什么问题，以及其重要亮点 Remark</li><li>结构：描述论文中的网络结构，及其核心思想</li><li>实验：论文的结果好坏</li><li>总结：写一些自己的想法，提出可能的方向</li></ol><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>PointRCNN 的一大特点是，该方法<strong>基于原始的点云数据直接进行特征提取和 RPN 操作</strong>。随着 PointNet 系列论文的出现，可以直接基于点云原始数据进行特征提取，而不需要进行体素化 (VoxelNet，SECOND) 或者对点云进行投影 (PointPillar) 再使用二维的一些方法。直接使用点云数据，最明显的好处就是减少了信息丢失 information loss</p><p>但在其他的文章当中，可以看到使用二维的处理方法并不是完全被排斥的 (CenterPoint)。因为 3D 选框有7维 $(x, y, z, w, h, l, \theta)$，最后一个维度代表的是角度，理论上来讲三维中物体的角度应该是有3个分量的，而这里仅有某一个平面（俯视）的角度，这里角度维度的确实本身就为二维方法提供了很好的入口</p><p>PointRCNN 提出的贡献：</p><ol><li>提出了 3D 选框生成算法，a bottom-up point cloud-based 3D bounding box proposal generation algorithm</li><li>提出了 bin-based losses，提升网络表现与收敛速度</li><li>使用规范变换 Canonical transformation</li></ol><p>后两个贡献<strong>似乎</strong>在指向两个方向：网络更倾向由易到难的学习，网络更擅于学习规范化的数据</p><h2 id="PointRCNN-Architecture"><a href="#PointRCNN-Architecture" class="headerlink" title="PointRCNN Architecture"></a>PointRCNN Architecture</h2><p><img src="/archives/51543c70/image-20211006164534924.png" style="zoom: 80%;"></p><p>PointRCNN 的学习分为两个阶段：</p><ol><li><p>3D 选框生成 proposal generation，使用 PointNet++ 提取每一个点的特征向量，使用这些向量预测前景点和背景点，并生成初步选框</p></li><li><p>3D 选框细化 box refinement，利用初步提取的选框，再对这些选框进行精细化处理</p></li></ol><h3 id="Stage-1-3D-选框生成"><a href="#Stage-1-3D-选框生成" class="headerlink" title="Stage-1: 3D 选框生成"></a>Stage-1: 3D 选框生成</h3><h4 id="前景点和背景点分割"><a href="#前景点和背景点分割" class="headerlink" title="前景点和背景点分割"></a>前景点和背景点分割</h4><p>论文使用 PointNet++ with multi-scale grouping 作为 backbone，提取每一个点的特征向量，每个点的特征向量是具有一定的感受野的，也就是包含了局部范围的信息。当然这个 backbone 也可以换成其他网络结构，可能效果会更好</p><p>现在获得了逐点的特征向量 point-wise feature vector，先使用这些特征向量做前景点和背景点的分类任务，其损失函数为 focal loss</p><script type="math/tex; mode=display">\mathcal{L}_{\text {focal }}\left(p_{t}\right)=-\alpha_{t}\left(1-p_{t}\right)^{\gamma} \log \left(p_{t}\right)\\\text{where }p_{t}=\left\{\begin{array}{ll}p & \text { for forground point } \\ 1-p & \text { otherwise }\end{array}\right.</script><p>focal loss 在三维目标检测中是一个很常见的损失函数，下图可以清楚地看到，在 γ 比较大时，大部分的loss值都是比较低的，除非网络的预测非常的离谱，惩罚才会急剧增加。可以说 focal loss 能够减轻惩罚，对于正负样本不均匀的数据来说会很有用</p><p><img src="/archives/51543c70/a8c1f242-8cf0-4310-bd10-a488658a3463-16335112903811.png" style="zoom: 80%;"></p><p>更详细的说明，<a href="https://zhuanlan.zhihu.com/p/122542747">知乎</a></p><h4 id="选框生成"><a href="#选框生成" class="headerlink" title="选框生成"></a>选框生成</h4><p>经过了前景点和背景点的二元分类任务，网络就要正式进行选框生成。需要注意的是，网络仅采用前景点来生成选框，尽管在网络训练之初，前景点和背景点的分类结果并不靠谱，但随着训练的深入会越来越准确</p><p>怎样通过前景点生成选框呢？一个简单的想法就是：每一个点都去回归预测该点所属的选框。论文在某些目标上采取了回归的思想，在一些重要目标上采用了分类+回归的预测方法，论文称这种思想为 bin-based。现在来看看在这一阶段网络想要预测的目标是什么，</p><script type="math/tex; mode=display">\begin{array}{l}\operatorname{bin}_{x}^{(p)}=\left\lfloor\frac{x^{p}-x^{(p)}+\mathcal{S}}{\delta}\right\rfloor, \operatorname{bin}_{z}^{(p)}=\left\lfloor\frac{z^{p}-z^{(p)}+\mathcal{S}}{\delta}\right\rfloor \\\operatorname{res}_{u \in\{x, z\}}^{(p)}=\frac{1}{\mathcal{C}}\left(u^{p}-u^{(p)}+\mathcal{S}-\left(\operatorname{bin}_{u}^{(p)} \cdot \delta+\frac{\delta}{2}\right)\right),(2) \\\operatorname{res}_{y}^{(p)}=y^{p}-y^{(p)}\end{array}</script><p>结合下面这张图来解释一下其中的变量</p><p><img src="/archives/51543c70/image-20211006172654158.png" style="zoom: 80%;"></p><p>$(x^{(p)}, y^{(p)}, z^{(p)})$ 代表的是前景点的坐标，$(x^{p}, y^{p}, z^{p})$ 代表的是目标中心点的坐标，其余量均为常量，如 S 为搜索范围，δ 为 bin 的长度，C 为归一化常量。在文章并没有明确指出，如果超出了搜索范围是否就不使用该点进行预测，所以不太理解这里搜索范围的意义</p><p>现在可以具体来看目标的含义，首先是 $(bin_x^{(p)}, bin_z^{(p)})$ 可以将其看作中心点相对于前景点的栅格坐标。然后是残差，对于 x, z 坐标计算了栅格坐标和实际坐标的残差，对于 y 坐标则直接计算中心点相对于前景点的差距</p><p>想要得到的选框有7个变量  $(x, y, z, w, h, l, \theta)$，上面仅提到了3个，剩余的四个中，角度 θ 采取和 x, z 类似的思路使用 bin-based 思想，将角度分为多个区域；而选框的长款高则采取和 y 类似的思路，直接预测其残差，其残差为该标签与整个数据集的平均值的差</p><p>如果得到了以上预测值：bin, res，那么通过简单的计算，就能够得到预测选框的所有参数。设置这样的预测目标意义在哪里呢？以下为个人理解：</p><ol><li>使用 bin-based 思想，将回归问题转化为分类问题，先去预测中心点落在哪个栅格中，然后再通过残差精细调整</li><li>使用残差，预测一个相对值是更容易的，预测一个绝对值需要更多的计算。从物理的角度上来说，就好像规定了一个零势能面，让计算变得有标准</li></ol><p>有了目标标签和网络预测的结果，就需要损失函数来衡量结果的好坏</p><script type="math/tex; mode=display">\begin{array}{l}\mathcal{L}_{\text {bin }}^{(p)}=\sum_{u \in\{x, z, \theta\}}\left(\mathcal{F}_{\mathrm{cls}}\left(\widehat{\mathrm{bin}}_{u}^{(p)}, \operatorname{bin}_{u}^{(p)}\right)+\mathcal{F}_{\text {reg }}\left(\widehat{\operatorname{res}}_{u}^{(p)}, \operatorname{res}_{u}^{(p)}\right)\right) \\\mathcal{L}_{\text {res }}^{(p)}=\sum_{v \in\{y, h, w, l\}} \mathcal{F}_{\text {reg }}\left(\widehat{\operatorname{res}}_{v}^{(p)}, \operatorname{res}_{v}^{(p)}\right) \\\mathcal{L}_{\text {reg }}=\frac{1}{N_{\text {pos }}} \sum_{p \in \text { pos }}\left(\mathcal{L}_{\text {bin }}^{(p)}+\mathcal{L}_{\text {res }}^{(p)}\right)\end{array}</script><p>分类任务采取的是 cross entropy classification loss，回归任务采取的是 smooth L1 loss</p><h4 id="NMS"><a href="#NMS" class="headerlink" title="NMS"></a>NMS</h4><p>使用 non-maximum suppression (NMS) 算法去除多余的选框，关于训练和推理时的具体参数请参考原文。筛选出来的选框，将进行下一步细化，NMS 几乎是筛选最终选框/细化选框必不可缺的，可能之后的总结里不会提，但不代表没有这一步骤</p><blockquote><p>For training, we use 0.85 as the bird’s view IoU threshold and after NMS we keep top 300 proposals for training the stage-2 sub-network. For inference, we use oriented NMS with IoU threshold 0.8, and only top 100 proposals are kept for the refinement of stage-2 sub-network.</p></blockquote><p>关于 NMS 的参考链接：<a href="https://www.cnblogs.com/makefile/p/nms.html">link</a></p><h3 id="Stage2-3D-选框细化"><a href="#Stage2-3D-选框细化" class="headerlink" title="Stage2: 3D 选框细化"></a>Stage2: 3D 选框细化</h3><p>选框细化 refinement 有4个主要步骤：</p><ol><li><p>增大选框 region pooling，稍微将初步得到的选框扩大一点，使得该选框包含更多的前景点，同时剔除选框中的背景点。这对 Stage-1 的分割任务有一定要求</p></li><li><p>规范变换 canonical transformation，对每个选框建立了一个以自己为中心的<strong>个体坐标系</strong>，如下图所示</p><p><img src="/archives/51543c70/4c790bdd-2912-45d4-ab7a-31de52926ed6-16335194333043.png" style="zoom: 80%;"></p></li><li><p>特征学习 feature learning</p></li><li><p>细化与分类 refinement &amp; classification</p></li></ol><p>现在对特征学习和重新细化进行详细地了解</p><h4 id="特征学习"><a href="#特征学习" class="headerlink" title="特征学习"></a>特征学习</h4><p>由于经过了规范变换丢失了深度信息，为每一个点加上人为构造的深度特征</p><script type="math/tex; mode=display">d^{(p)} = \sqrt{(x^{(p)})^2+ (y^{(p)})^2 + (z^{(p)})^2}</script><p>每个点除了深度特征外，还增加了反射强度特征 r 和分割面罩 m。将这些规范变换并且增强后的特征，送入到一个 MLP 中进行转换得到一个输出，将该输出与 PointNet++ 中学习的语义特征连接起来，进行最后的细化工作</p><p><img src="/archives/51543c70/image-20211006193601408.png" style="zoom: 80%;"></p><h4 id="细化与分类"><a href="#细化与分类" class="headerlink" title="细化与分类"></a>细化与分类</h4><p>这里的学习过程和 Stage-1 中的学习过程是相似的。预测目标依然使用是 bin-based 思想，不过是在规范变化后的坐标下进行，而且仅对在 Stage-1 产生的基础选框内的点进行计算。其具体预测目标值就不再赘述，论文里给出了规范变化后的 ground truth bounding box 如何计算</p><script type="math/tex; mode=display">\tilde{\mathbf{b}}_{i}^{\mathrm{gt}}=\left(x_{i}^{\mathrm{gt}}-x_{i}, y_{i}^{\mathrm{gt}}-y_{i}, z_{i}^{\mathrm{gt}}-z_{i}, h_{i}^{\mathrm{gt}}, w_{i}^{\mathrm{gt}}, l_{i}^{\mathrm{gt}}, \theta_{i}^{\mathrm{gt}}-\theta_{i}\right)</script><p>其中没有 gt 上标的值即为对应基础选框的参数。除了对选框进行进一步的精细化外，还要执行多分类任务，该多分类任务的网络论文并没有详细说明，应该可以参照 PointNet 系列。Region pooling 的方法是在选框中的点里随机采样512个，便于之后输入 MLP </p><p>最终将精细化任务和多分类任务的损失函数相加，得到最终的损失函数</p><script type="math/tex; mode=display">\begin{aligned}\mathcal{L}_{\text {refine }}=& \frac{1}{\| \mathcal{B}\|} \sum_{i \in \mathcal{B}} \mathcal{F}_{\text {cls }}\left(\operatorname{prob}_{i}, \text { label }_{i}\right) \\&+\frac{1}{\left\|\mathcal{B}_{\text {pos }}\right\|} \sum_{i \in \mathcal{B}_{\text {pos }}}\left(\tilde{\mathcal{L}}_{\text {bin }}^{(i)}+\tilde{\mathcal{L}}_{\text {res }}^{(i)}\right)\end{aligned}</script><p>其中 positive bounding box 定义为如下</p><blockquote><p>For training the box classification head, a proposal is considered as positive if its maximum 3D IoU with ground-truth boxes is above 0.6</p></blockquote><p>在测试\推理时为了选出最终得分最高的选框，还要再使用一次 NMS 算法</p><blockquote><p>We finally apply oriented NMS with bird’s view IoU threshold 0.01 to remove the overlapping bounding boxes</p></blockquote><h2 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a>Experiment</h2><p>需要注意的是 PointRCNN 两个阶段是分开训练的，而不是一个端到端的训练。分开训练和端对端训练有什么优势吗？</p><h3 id="KITTI"><a href="#KITTI" class="headerlink" title="KITTI"></a>KITTI</h3><p><img src="/archives/51543c70/image-20211006202449787.png"></p><p>关于 average precision (AP) 和 recall 参考链接：<a href="https://zhuanlan.zhihu.com/p/56961620">知乎</a></p><h3 id="Ablation-study"><a href="#Ablation-study" class="headerlink" title="Ablation study"></a>Ablation study</h3><p><img src="/archives/51543c70/image-20211006202739285.png"></p><p>可以看到规范变换的作用非常大，大得离谱</p><h3 id="Bin-based-loss-recall"><a href="#Bin-based-loss-recall" class="headerlink" title="Bin-based loss recall"></a>Bin-based loss recall</h3><p><img src="/archives/51543c70/image-20211006202846004.png"></p><p>蓝色曲线为论文中使用的损失函数，效果最好</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>PointRCNN 为 2-Stage 网络，提出的 bin-based 损失函数和规范变换 canonical transformation 提升了网络的性能。并且直接使用点云数据，减少了原始点云的信息损失。但是整体看下来感觉 trick 和细节挺多的，比如其 region pooling 和前景背景点分割等等，论文里并没有记录其推理速度，在其他文献中找到大约为 10 fps，或许今后需要在速度上进行更快的突破</p><h2 id="TO-READ"><a href="#TO-READ" class="headerlink" title="TO READ"></a>TO READ</h2><p>LiDAR R-CNN</p>]]></content>
      
      
      <categories>
          
          <category> papers </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Point Cloud </tag>
            
            <tag> PointRCNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MMDetection 项目</title>
      <link href="/archives/acef3112.html"/>
      <url>/archives/acef3112.html</url>
      
        <content type="html"><![CDATA[<h1 id="MMDetection-项目"><a href="#MMDetection-项目" class="headerlink" title="MMDetection 项目"></a>MMDetection 项目</h1><p>现在正式开始 MMDetection 项目！之前有一个想法，看看能不能用 MMDetection 来检测网球比赛中的网球球速，使用了 Faster-RCNN 模型试了下目标检测，发现对于网球这种小物体根本检测不出来，在视频中就是非常小的一个像素点。那么能不能使用自己标注的数据集来训练一个小目标检测（仅网球）的网络，来对网球视频进行检测？现在来进行具体的试验</p><h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>使用 Labelme 进行标注，并转化为 COCO 数据集。将数据集按照如下结构排列</p><pre class="line-numbers language-none"><code class="language-none">mmdetection├── data│   ├── coco│   │   ├── annotations│   │   ├── train2017│   │   ├── val2017│   │   ├── test2017<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>其中 annotations 放置 coco format json 文件，其他文件夹放置图片数据集</p><h2 id="准备-config-文件"><a href="#准备-config-文件" class="headerlink" title="准备 config 文件"></a>准备 config 文件</h2><p>由于标注文件是有做 segmentation 的，选择 Mask-RCNN 作为模型</p><ol><li><p>base config: <a href="https://github.com/open-mmlab/mmdetection/blob/master/configs/mask_rcnn/mask_rcnn_r101_fpn_mstrain-poly_3x_coco.py">Mask-RCNN-R101-FPN</a> </p></li><li><p>checkpoint: <a href="https://download.openmmlab.com/mmdetection/v2.0/mask_rcnn/mask_rcnn_r101_fpn_mstrain-poly_3x_coco/mask_rcnn_r101_fpn_mstrain-poly_3x_coco_20210524_200244-5675c317.pth">model</a></p></li></ol><p>放置在 <code>/mmdet/config/mask_rcnn</code> 下，具体 config 文件放在文末</p><h2 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h2><p>目前还是不能跑起来，预计是 config 文件和数据集 CLASSES 的原因，还有要注意 config 的继承关系！</p><ol><li><p>由于继承机制，使用了 <code>RepeatDataset</code> 不对原数据集类型进行修改，不然报错</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">TypeError<span class="token punctuation">:</span> CocoDataset<span class="token punctuation">:</span> __init__<span class="token punctuation">(</span><span class="token punctuation">)</span> got an unexpected keyword argument <span class="token string">'times'</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li><p>遇到报错</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">AssertionError<span class="token punctuation">:</span> The `num_classes` <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token keyword">in</span> Shared2FCBBoxHead of MMDataParallel does <span class="token keyword">not</span> matches the length of `CLASSES` <span class="token number">80</span><span class="token punctuation">)</span> <span class="token keyword">in</span> RepeatDataset<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>依旧是由于 <code>ReapeatDataset</code> 造成的，由于对这个类不够了解，所以频繁报错😅这里的逻辑是因为没有指定 <code>classes</code>，由于原 coco 数据集有80个类，自己的类别不一定是原 COCO 数据集相同。既然是 <code>RepeatDataset</code> 那么一定是重复了自己定义的数据集，那就看看定义的数据集中是否指定了 <code>classes</code>。结果一看，果然没有指定，加上就解决了</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">data <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>    samples_per_gpu<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>    workers_per_gpu<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>    train<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>        <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'RepeatDataset'</span><span class="token punctuation">,</span>        times<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>        dataset<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>            <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'CocoDataset'</span><span class="token punctuation">,</span>            ann_file<span class="token operator">=</span><span class="token string">'/home/chenhongkun/mmdetection/data/coco/annotations/train.json'</span><span class="token punctuation">,</span>            img_prefix<span class="token operator">=</span><span class="token string">'/home/chenhongkun/mmdetection/data/coco/train2017'</span><span class="token punctuation">,</span>            <span class="token comment"># classes=('tennis', ),</span>            pipeline<span class="token operator">=</span><span class="token punctuation">[</span>                <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'LoadImageFromFile'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                <span class="token builtin">dict</span><span class="token punctuation">(</span>                    <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'LoadAnnotations'</span><span class="token punctuation">,</span>                    with_bbox<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>                    with_mask<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>                    poly2mask<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                <span class="token builtin">dict</span><span class="token punctuation">(</span>                    <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'Resize'</span><span class="token punctuation">,</span>                    img_scale<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token number">1333</span><span class="token punctuation">,</span> <span class="token number">640</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1333</span><span class="token punctuation">,</span> <span class="token number">800</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                    multiscale_mode<span class="token operator">=</span><span class="token string">'range'</span><span class="token punctuation">,</span>                    keep_ratio<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'RandomFlip'</span><span class="token punctuation">,</span> flip_ratio<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                <span class="token builtin">dict</span><span class="token punctuation">(</span>                    <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'Normalize'</span><span class="token punctuation">,</span>                    mean<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">123.675</span><span class="token punctuation">,</span> <span class="token number">116.28</span><span class="token punctuation">,</span> <span class="token number">103.53</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                    std<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">58.395</span><span class="token punctuation">,</span> <span class="token number">57.12</span><span class="token punctuation">,</span> <span class="token number">57.375</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                    to_rgb<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'Pad'</span><span class="token punctuation">,</span> size_divisor<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'DefaultFormatBundle'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                <span class="token builtin">dict</span><span class="token punctuation">(</span>                    <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'Collect'</span><span class="token punctuation">,</span>                    keys<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'img'</span><span class="token punctuation">,</span> <span class="token string">'gt_bboxes'</span><span class="token punctuation">,</span> <span class="token string">'gt_labels'</span><span class="token punctuation">,</span> <span class="token string">'gt_masks'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>            <span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        classes<span class="token operator">=</span><span class="token punctuation">(</span><span class="token string">'tennis'</span><span class="token punctuation">,</span> <span class="token punctuation">)</span><span class="token punctuation">,</span>        ann_file<span class="token operator">=</span><span class="token string">'/home/chenhongkun/mmdetection/data/coco/annotations/train.json'</span><span class="token punctuation">,</span>        img_prefix<span class="token operator">=</span><span class="token string">'/home/chenhongkun/mmdetection/data/coco/train2017'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    val<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>    test<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ol><p>训练了一个 epoch 来看看结果，发现很难检测到小的物体。而且经过了70个 epoch 的训练，最后 Loss 没有持续下降，感觉优化停止了。现在尝试增加 batch 数量，下一个手段就是减少学习率。我也在思考会不会是 anchor 的问题，因为 anchor 太大了根本检测不到这么小的物体</p><p>现在修改了 anchor 大小效果不错，继续训练…最后可视化结果来看有许多重复的结果，NMS 的阈值需要再调一下，而且现在的预测值非常低，不知道为什么，不过位置还是可以接受</p><p><img src="/archives/acef3112/image-20210920231709443.png" style="zoom:50%;"></p><h2 id="工具箱"><a href="#工具箱" class="headerlink" title="工具箱"></a>工具箱</h2><ol><li><p><code>print_config.py</code>，打印完整 config 文件</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">python tools<span class="token operator">/</span>misc<span class="token operator">/</span>print_config<span class="token punctuation">.</span>py $<span class="token punctuation">{</span>CONFIG<span class="token punctuation">}</span> <span class="token punctuation">[</span><span class="token operator">-</span>h<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token operator">-</span>options $<span class="token punctuation">{</span>OPTIONS <span class="token punctuation">[</span>OPTIONS<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li><p><code>analyze_logs.py</code>，可以将日志中的记录值绘制成曲线图</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">python tools<span class="token operator">/</span>analysis_tools<span class="token operator">/</span>analyze_logs<span class="token punctuation">.</span>py plot_curve <span class="token punctuation">[</span><span class="token operator">-</span><span class="token operator">-</span>keys $<span class="token punctuation">{</span>KEYS<span class="token punctuation">}</span><span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token operator">-</span>title $<span class="token punctuation">{</span>TITLE<span class="token punctuation">}</span><span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token operator">-</span>legend $<span class="token punctuation">{</span>LEGEND<span class="token punctuation">}</span><span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token operator">-</span>backend $<span class="token punctuation">{</span>BACKEND<span class="token punctuation">}</span><span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token operator">-</span>style $<span class="token punctuation">{</span>STYLE<span class="token punctuation">}</span><span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token operator">-</span>out $<span class="token punctuation">{</span>OUT_FILE<span class="token punctuation">}</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><blockquote><p><code>tools/analysis_tools/analyze_results.py</code> calculates single image mAP and saves or shows the topk images with the highest and lowest scores based on prediction results. <a href="https://mmdetection.readthedocs.io/en/latest/useful_tools.html#result-analysis">link</a></p></blockquote><pre class="line-numbers language-python" data-language="python"><code class="language-python">python tools<span class="token operator">/</span>analysis_tools<span class="token operator">/</span>analyze_results<span class="token punctuation">.</span>py \      $<span class="token punctuation">{</span>CONFIG<span class="token punctuation">}</span> \      $<span class="token punctuation">{</span>PREDICTION_PATH<span class="token punctuation">}</span> \      $<span class="token punctuation">{</span>SHOW_DIR<span class="token punctuation">}</span> \      <span class="token punctuation">[</span><span class="token operator">-</span><span class="token operator">-</span>show<span class="token punctuation">]</span> \      <span class="token punctuation">[</span><span class="token operator">-</span><span class="token operator">-</span>wait<span class="token operator">-</span>time $<span class="token punctuation">{</span>WAIT_TIME<span class="token punctuation">}</span><span class="token punctuation">]</span> \      <span class="token punctuation">[</span><span class="token operator">-</span><span class="token operator">-</span>topk $<span class="token punctuation">{</span>TOPK<span class="token punctuation">}</span><span class="token punctuation">]</span> \      <span class="token punctuation">[</span><span class="token operator">-</span><span class="token operator">-</span>show<span class="token operator">-</span>score<span class="token operator">-</span>thr $<span class="token punctuation">{</span>SHOW_SCORE_THR<span class="token punctuation">}</span><span class="token punctuation">]</span> \      <span class="token punctuation">[</span><span class="token operator">-</span><span class="token operator">-</span>cfg<span class="token operator">-</span>options $<span class="token punctuation">{</span>CFG_OPTIONS<span class="token punctuation">}</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><code>dataset_converters</code> 工具箱能够将不同的数据集格式转为 coco format，比如使用 <code>image2coco.py</code> 能够将图片生成没有标签的 coco format json 文件</p></li><li><p><a href="https://github.com/Chien-Hung/DetVisGUI/tree/mmdetection">DetVisGUI project</a>，为一个可视化项目，能够将检测结果 <code>result.pkl</code> 可视化</p></li></ol><h2 id="完整-config-文件"><a href="#完整-config-文件" class="headerlink" title="完整 config 文件"></a>完整 config 文件</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python">checkpoint_config <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>interval<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>    <span class="token comment"># mark</span>log_config <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>interval<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">,</span> hooks<span class="token operator">=</span><span class="token punctuation">[</span><span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'TextLoggerHook'</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment"># mark</span>custom_hooks <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'NumClassCheckHook'</span><span class="token punctuation">)</span><span class="token punctuation">]</span>dist_params <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>backend<span class="token operator">=</span><span class="token string">'nccl'</span><span class="token punctuation">)</span>log_level <span class="token operator">=</span> <span class="token string">'INFO'</span>load_from <span class="token operator">=</span> <span class="token string">'/home/declan/vscode/mmlab_test/mmdetection/checkpoints/mask_rcnn_r101_fpn_mstrain-poly_3x_coco_20210524_200244-5675c317.pth'</span>resume_from <span class="token operator">=</span> <span class="token boolean">None</span>workflow <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">'train'</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span>dataset_type <span class="token operator">=</span> <span class="token string">'CocoDataset'</span>data_root <span class="token operator">=</span> <span class="token string">'data/coco/'</span>img_norm_cfg <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>    mean<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">123.675</span><span class="token punctuation">,</span> <span class="token number">116.28</span><span class="token punctuation">,</span> <span class="token number">103.53</span><span class="token punctuation">]</span><span class="token punctuation">,</span> std<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">58.395</span><span class="token punctuation">,</span> <span class="token number">57.12</span><span class="token punctuation">,</span> <span class="token number">57.375</span><span class="token punctuation">]</span><span class="token punctuation">,</span> to_rgb<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>train_pipeline <span class="token operator">=</span> <span class="token punctuation">[</span>    <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'LoadImageFromFile'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token builtin">dict</span><span class="token punctuation">(</span>        <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'LoadAnnotations'</span><span class="token punctuation">,</span>        with_bbox<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>        with_mask<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>        poly2mask<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token builtin">dict</span><span class="token punctuation">(</span>        <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'Resize'</span><span class="token punctuation">,</span>        img_scale<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token number">1333</span><span class="token punctuation">,</span> <span class="token number">640</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1333</span><span class="token punctuation">,</span> <span class="token number">800</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        multiscale_mode<span class="token operator">=</span><span class="token string">'range'</span><span class="token punctuation">,</span>        keep_ratio<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'RandomFlip'</span><span class="token punctuation">,</span> flip_ratio<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token builtin">dict</span><span class="token punctuation">(</span>        <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'Normalize'</span><span class="token punctuation">,</span>        mean<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">123.675</span><span class="token punctuation">,</span> <span class="token number">116.28</span><span class="token punctuation">,</span> <span class="token number">103.53</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        std<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">58.395</span><span class="token punctuation">,</span> <span class="token number">57.12</span><span class="token punctuation">,</span> <span class="token number">57.375</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        to_rgb<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'Pad'</span><span class="token punctuation">,</span> size_divisor<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'DefaultFormatBundle'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'Collect'</span><span class="token punctuation">,</span> keys<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'img'</span><span class="token punctuation">,</span> <span class="token string">'gt_bboxes'</span><span class="token punctuation">,</span> <span class="token string">'gt_labels'</span><span class="token punctuation">,</span> <span class="token string">'gt_masks'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span>test_pipeline <span class="token operator">=</span> <span class="token punctuation">[</span>    <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'LoadImageFromFile'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token builtin">dict</span><span class="token punctuation">(</span>        <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'MultiScaleFlipAug'</span><span class="token punctuation">,</span>        img_scale<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1333</span><span class="token punctuation">,</span> <span class="token number">800</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        flip<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>        transforms<span class="token operator">=</span><span class="token punctuation">[</span>            <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'Resize'</span><span class="token punctuation">,</span> keep_ratio<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'RandomFlip'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token builtin">dict</span><span class="token punctuation">(</span>                <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'Normalize'</span><span class="token punctuation">,</span>                mean<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">123.675</span><span class="token punctuation">,</span> <span class="token number">116.28</span><span class="token punctuation">,</span> <span class="token number">103.53</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                std<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">58.395</span><span class="token punctuation">,</span> <span class="token number">57.12</span><span class="token punctuation">,</span> <span class="token number">57.375</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                to_rgb<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'Pad'</span><span class="token punctuation">,</span> size_divisor<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'ImageToTensor'</span><span class="token punctuation">,</span> keys<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'img'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'Collect'</span><span class="token punctuation">,</span> keys<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'img'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span>data <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>    samples_per_gpu<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span>  <span class="token comment"># mark</span>    workers_per_gpu<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>    train<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>        <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'RepeatDataset'</span><span class="token punctuation">,</span>        times<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>        dataset<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>            <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'CocoDataset'</span><span class="token punctuation">,</span>            ann_file<span class="token operator">=</span><span class="token string">'/home/declan/vscode/mmlab_test/mmdetection/data/coco/annotations/train.json'</span><span class="token punctuation">,</span>            img_prefix<span class="token operator">=</span><span class="token string">'/home/declan/vscode/mmlab_test/mmdetection/data/coco/train2017'</span><span class="token punctuation">,</span>            classes<span class="token operator">=</span><span class="token punctuation">(</span><span class="token string">'tennis'</span><span class="token punctuation">,</span> <span class="token punctuation">)</span><span class="token punctuation">,</span>            pipeline<span class="token operator">=</span><span class="token punctuation">[</span>                <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'LoadImageFromFile'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                <span class="token builtin">dict</span><span class="token punctuation">(</span>                    <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'LoadAnnotations'</span><span class="token punctuation">,</span>                    with_bbox<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>                    with_mask<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>                    poly2mask<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                <span class="token builtin">dict</span><span class="token punctuation">(</span>                    <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'Resize'</span><span class="token punctuation">,</span>                    img_scale<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token number">1333</span><span class="token punctuation">,</span> <span class="token number">640</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1333</span><span class="token punctuation">,</span> <span class="token number">800</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                    multiscale_mode<span class="token operator">=</span><span class="token string">'range'</span><span class="token punctuation">,</span>                    keep_ratio<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'RandomFlip'</span><span class="token punctuation">,</span> flip_ratio<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                <span class="token builtin">dict</span><span class="token punctuation">(</span>                    <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'Normalize'</span><span class="token punctuation">,</span>                    mean<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">123.675</span><span class="token punctuation">,</span> <span class="token number">116.28</span><span class="token punctuation">,</span> <span class="token number">103.53</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                    std<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">58.395</span><span class="token punctuation">,</span> <span class="token number">57.12</span><span class="token punctuation">,</span> <span class="token number">57.375</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                    to_rgb<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'Pad'</span><span class="token punctuation">,</span> size_divisor<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'DefaultFormatBundle'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                <span class="token builtin">dict</span><span class="token punctuation">(</span>                    <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'Collect'</span><span class="token punctuation">,</span>                    keys<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'img'</span><span class="token punctuation">,</span> <span class="token string">'gt_bboxes'</span><span class="token punctuation">,</span> <span class="token string">'gt_labels'</span><span class="token punctuation">,</span> <span class="token string">'gt_masks'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>            <span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        classes<span class="token operator">=</span><span class="token punctuation">(</span><span class="token string">'tennis'</span><span class="token punctuation">,</span> <span class="token punctuation">)</span><span class="token punctuation">,</span>        ann_file<span class="token operator">=</span><span class="token string">'/home/declan/vscode/mmlab_test/mmdetection/data/coco/annotations/train.json'</span><span class="token punctuation">,</span>        img_prefix<span class="token operator">=</span><span class="token string">'/home/declan/vscode/mmlab_test/mmdetection/data/coco/train2017'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    val<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>        <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'CocoDataset'</span><span class="token punctuation">,</span>        ann_file<span class="token operator">=</span><span class="token string">'/home/declan/vscode/mmlab_test/mmdetection/data/coco/annotations/val.json'</span><span class="token punctuation">,</span>        img_prefix<span class="token operator">=</span><span class="token string">'/home/declan/vscode/mmlab_test/mmdetection/data/coco/val2017'</span><span class="token punctuation">,</span>        pipeline<span class="token operator">=</span><span class="token punctuation">[</span>            <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'LoadImageFromFile'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token builtin">dict</span><span class="token punctuation">(</span>                <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'MultiScaleFlipAug'</span><span class="token punctuation">,</span>                img_scale<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1333</span><span class="token punctuation">,</span> <span class="token number">800</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                flip<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>                transforms<span class="token operator">=</span><span class="token punctuation">[</span>                    <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'Resize'</span><span class="token punctuation">,</span> keep_ratio<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                    <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'RandomFlip'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                    <span class="token builtin">dict</span><span class="token punctuation">(</span>                        <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'Normalize'</span><span class="token punctuation">,</span>                        mean<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">123.675</span><span class="token punctuation">,</span> <span class="token number">116.28</span><span class="token punctuation">,</span> <span class="token number">103.53</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                        std<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">58.395</span><span class="token punctuation">,</span> <span class="token number">57.12</span><span class="token punctuation">,</span> <span class="token number">57.375</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                        to_rgb<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                    <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'Pad'</span><span class="token punctuation">,</span> size_divisor<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                    <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'ImageToTensor'</span><span class="token punctuation">,</span> keys<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'img'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                    <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'Collect'</span><span class="token punctuation">,</span> keys<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'img'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>                <span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token punctuation">]</span><span class="token punctuation">,</span>        classes<span class="token operator">=</span><span class="token punctuation">(</span><span class="token string">'tennis'</span><span class="token punctuation">,</span> <span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    test<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>        <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'CocoDataset'</span><span class="token punctuation">,</span>        ann_file<span class="token operator">=</span><span class="token string">'/home/declan/vscode/mmlab_test/mmdetection/data/coco/annotations/test2017.json'</span><span class="token punctuation">,</span>        img_prefix<span class="token operator">=</span><span class="token string">'/home/declan/vscode/mmlab_test/mmdetection/data/coco/test2017'</span><span class="token punctuation">,</span>        pipeline<span class="token operator">=</span><span class="token punctuation">[</span>            <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'LoadImageFromFile'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token builtin">dict</span><span class="token punctuation">(</span>                <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'MultiScaleFlipAug'</span><span class="token punctuation">,</span>                img_scale<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1333</span><span class="token punctuation">,</span> <span class="token number">800</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                flip<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>                transforms<span class="token operator">=</span><span class="token punctuation">[</span>                    <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'Resize'</span><span class="token punctuation">,</span> keep_ratio<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                    <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'RandomFlip'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                    <span class="token builtin">dict</span><span class="token punctuation">(</span>                        <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'Normalize'</span><span class="token punctuation">,</span>                        mean<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">123.675</span><span class="token punctuation">,</span> <span class="token number">116.28</span><span class="token punctuation">,</span> <span class="token number">103.53</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                        std<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">58.395</span><span class="token punctuation">,</span> <span class="token number">57.12</span><span class="token punctuation">,</span> <span class="token number">57.375</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                        to_rgb<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                    <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'Pad'</span><span class="token punctuation">,</span> size_divisor<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                    <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'ImageToTensor'</span><span class="token punctuation">,</span> keys<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'img'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                    <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'Collect'</span><span class="token punctuation">,</span> keys<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'img'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>                <span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token punctuation">]</span><span class="token punctuation">,</span>        classes<span class="token operator">=</span><span class="token punctuation">(</span><span class="token string">'tennis'</span><span class="token punctuation">,</span> <span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>evaluation <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>interval<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> metric<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'bbox'</span><span class="token punctuation">,</span> <span class="token string">'segm'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>optimizer <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'SGD'</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.00125</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">,</span> weight_decay<span class="token operator">=</span><span class="token number">0.0001</span><span class="token punctuation">)</span>optimizer_config <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>grad_clip<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span>lr_config <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>    policy<span class="token operator">=</span><span class="token string">'step'</span><span class="token punctuation">,</span>    warmup<span class="token operator">=</span><span class="token string">'linear'</span><span class="token punctuation">,</span>    warmup_iters<span class="token operator">=</span><span class="token number">500</span><span class="token punctuation">,</span>    warmup_ratio<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">,</span>    step<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">,</span> <span class="token number">40</span><span class="token punctuation">,</span> <span class="token number">50</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># mark try 70 epoch</span>runner <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'EpochBasedRunner'</span><span class="token punctuation">,</span> max_epochs<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span>model <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>    <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'MaskRCNN'</span><span class="token punctuation">,</span>    backbone<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>        <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'ResNet'</span><span class="token punctuation">,</span>        depth<span class="token operator">=</span><span class="token number">101</span><span class="token punctuation">,</span>        num_stages<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span>        out_indices<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        frozen_stages<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>        norm_cfg<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'BN'</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        norm_eval<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>        style<span class="token operator">=</span><span class="token string">'pytorch'</span><span class="token punctuation">,</span>        init_cfg<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'Pretrained'</span><span class="token punctuation">,</span>                      checkpoint<span class="token operator">=</span><span class="token string">'torchvision://resnet101'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    neck<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>        <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'FPN'</span><span class="token punctuation">,</span>        in_channels<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">,</span> <span class="token number">2048</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        out_channels<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span>        num_outs<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    rpn_head<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>        <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'RPNHead'</span><span class="token punctuation">,</span>        in_channels<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span>        feat_channels<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span>        anchor_generator<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>            <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'AnchorGenerator'</span><span class="token punctuation">,</span>            scales<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token comment"># mark important</span>            ratios<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">2.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>            strides<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        bbox_coder<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>            <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'DeltaXYWHBBoxCoder'</span><span class="token punctuation">,</span>            target_means<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>            target_stds<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        loss_cls<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>            <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'CrossEntropyLoss'</span><span class="token punctuation">,</span> use_sigmoid<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> loss_weight<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        loss_bbox<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'L1Loss'</span><span class="token punctuation">,</span> loss_weight<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    roi_head<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>        <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'StandardRoIHead'</span><span class="token punctuation">,</span>        bbox_roi_extractor<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>            <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'SingleRoIExtractor'</span><span class="token punctuation">,</span>            roi_layer<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'RoIAlign'</span><span class="token punctuation">,</span> output_size<span class="token operator">=</span><span class="token number">7</span><span class="token punctuation">,</span> sampling_ratio<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            out_channels<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span>            featmap_strides<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        bbox_head<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>            <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'Shared2FCBBoxHead'</span><span class="token punctuation">,</span>            in_channels<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span>            fc_out_channels<span class="token operator">=</span><span class="token number">1024</span><span class="token punctuation">,</span>            roi_feat_size<span class="token operator">=</span><span class="token number">7</span><span class="token punctuation">,</span>            num_classes<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>            bbox_coder<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>                <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'DeltaXYWHBBoxCoder'</span><span class="token punctuation">,</span>                target_means<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                target_stds<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            reg_class_agnostic<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>            loss_cls<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>                <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'CrossEntropyLoss'</span><span class="token punctuation">,</span> use_sigmoid<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> loss_weight<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            loss_bbox<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'L1Loss'</span><span class="token punctuation">,</span> loss_weight<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        mask_roi_extractor<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>            <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'SingleRoIExtractor'</span><span class="token punctuation">,</span>            roi_layer<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'RoIAlign'</span><span class="token punctuation">,</span> output_size<span class="token operator">=</span><span class="token number">14</span><span class="token punctuation">,</span> sampling_ratio<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            out_channels<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span>            featmap_strides<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        mask_head<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>            <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'FCNMaskHead'</span><span class="token punctuation">,</span>            num_convs<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span>            in_channels<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span>            conv_out_channels<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span>            num_classes<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>            loss_mask<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>                <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'CrossEntropyLoss'</span><span class="token punctuation">,</span> use_mask<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> loss_weight<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    train_cfg<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>        rpn<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>            assigner<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>                <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'MaxIoUAssigner'</span><span class="token punctuation">,</span>                pos_iou_thr<span class="token operator">=</span><span class="token number">0.7</span><span class="token punctuation">,</span>                neg_iou_thr<span class="token operator">=</span><span class="token number">0.3</span><span class="token punctuation">,</span>                min_pos_iou<span class="token operator">=</span><span class="token number">0.3</span><span class="token punctuation">,</span>                match_low_quality<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>                ignore_iof_thr<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            sampler<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>                <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'RandomSampler'</span><span class="token punctuation">,</span>                num<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span>                pos_fraction<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span>                neg_pos_ub<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span>                add_gt_as_proposals<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            allowed_border<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span>            pos_weight<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span>            debug<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        rpn_proposal<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>            nms_pre<span class="token operator">=</span><span class="token number">2000</span><span class="token punctuation">,</span>            max_per_img<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">,</span>            nms<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'nms'</span><span class="token punctuation">,</span> iou_threshold<span class="token operator">=</span><span class="token number">0.7</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            min_bbox_size<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        rcnn<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>            assigner<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>                <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'MaxIoUAssigner'</span><span class="token punctuation">,</span>                pos_iou_thr<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span>                neg_iou_thr<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span>                min_pos_iou<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span>                match_low_quality<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>                ignore_iof_thr<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            sampler<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>                <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'RandomSampler'</span><span class="token punctuation">,</span>                num<span class="token operator">=</span><span class="token number">512</span><span class="token punctuation">,</span>                pos_fraction<span class="token operator">=</span><span class="token number">0.25</span><span class="token punctuation">,</span>                neg_pos_ub<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span>                add_gt_as_proposals<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            mask_size<span class="token operator">=</span><span class="token number">28</span><span class="token punctuation">,</span>            pos_weight<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span>            debug<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    test_cfg<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>        rpn<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>            nms_pre<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">,</span>            max_per_img<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">,</span>            nms<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'nms'</span><span class="token punctuation">,</span> iou_threshold<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            min_bbox_size<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        rcnn<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>            score_thr<span class="token operator">=</span><span class="token number">0.05</span><span class="token punctuation">,</span>            nms<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'nms'</span><span class="token punctuation">,</span> iou_threshold<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            max_per_img<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span>            mask_thr_binary<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>classes <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token string">'tennis'</span><span class="token punctuation">,</span> <span class="token punctuation">)</span>work_dir <span class="token operator">=</span> <span class="token string">'./work_dirs/mask_rcnn'</span>gpu_ids <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 编程 </category>
          
          <category> OpenMMLab </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MMDetection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Labelme 标注工具</title>
      <link href="/archives/be6c9228.html"/>
      <url>/archives/be6c9228.html</url>
      
        <content type="html"><![CDATA[<h1 id="Labelme-标注工具"><a href="#Labelme-标注工具" class="headerlink" title="Labelme 标注工具"></a>Labelme 标注工具</h1><p><a href="https://github.com/wkentaro/labelme">labelme github</a></p><p>下载直接 <code>pip install labelme</code></p><p>参考 <a href="https://www.bilibili.com/video/BV1jV411U7zb">bilibili</a></p><h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><h3 id="简单设置"><a href="#简单设置" class="headerlink" title="简单设置"></a>简单设置</h3><p><img src="/archives/be6c9228/屏幕截图 2021-09-17 115035.png" style="zoom: 50%;"></p><ol><li>打开 Save Automatically</li><li>Change Output Dir，选定输出文件夹</li><li>Save With Image Data</li></ol><h3 id="开始标注"><a href="#开始标注" class="headerlink" title="开始标注"></a>开始标注</h3><p>选择图片所在文件夹即可开始标注，可以使用多边形逐步将物体包围，也可以使用一些简单的集合图形进行标注。标注完成后在当前文件夹即可发现 json 文件</p><h3 id="文件整理"><a href="#文件整理" class="headerlink" title="文件整理"></a>文件整理</h3><ol><li>对未标注的文件进行清理，因为自己没把所有图片都标注。对已标注的文件重新命名，使得数据集列表更连贯</li><li>修改 json 文件中的信息，以匹配修改的文件名，即修改 <code>imagePath</code> 字段</li></ol><h3 id="数据转化"><a href="#数据转化" class="headerlink" title="数据转化"></a>数据转化</h3><p>使用 <a href="https://github.com/Tony607">Tony607</a>/<strong><a href="https://github.com/Tony607/labelme2coco">labelme2coco</a></strong> 中的脚本进行转化，将所有的 json 文件转化为一个 coco format json 文件，非常方便</p><pre class="line-numbers language-cmd" data-language="cmd"><code class="language-cmd">python labelme2coco.py image_dir<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><code>image_dir</code> 为之前标注所在的文件夹。而且作者还提供了一个 <code>COCO_Image_Viewer.ipynb</code> 可以将结果可视化显示出来，只需要简单修改一下其中的文件夹路径即可</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">annotation_path <span class="token operator">=</span> <span class="token string">"trainval.json"</span>image_dir <span class="token operator">=</span> <span class="token string">"your_image_dir"</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h2 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h2><p>COCO api 学习</p>]]></content>
      
      
      <categories>
          
          <category> 编程 </category>
          
          <category> OpenMMLab </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Labelme </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MMCV tutorial</title>
      <link href="/archives/81012a8b.html"/>
      <url>/archives/81012a8b.html</url>
      
        <content type="html"><![CDATA[<h1 id="Understand-MMCV"><a href="#Understand-MMCV" class="headerlink" title="Understand MMCV"></a>Understand MMCV</h1><p>现在想要更深一步学习 mmdetection，于是必不可少地要来了解一下 MMCV 这个基础库。从之前的学习过程来看，一个思想就是一切皆为 class。配置文件有 Config class，管理模块有 Registry class，运行模型有 Runner class…下面来具体看看这些类的一些基础框架</p><h2 id="Config"><a href="#Config" class="headerlink" title="Config"></a>Config</h2><blockquote><p><code>Config</code> class is used for manipulating config and config files. It supports loading configs from multiple file formats including <strong>python</strong>, <strong>json</strong> and <strong>yaml</strong>. It provides dict-like apis to get and set values.</p></blockquote><p>从 mmdetection 代码来看，主要是从 python 文件创建 config class</p><h3 id="创建"><a href="#创建" class="headerlink" title="创建"></a>创建</h3><p>文档举了一个例子</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># test.py</span>a <span class="token operator">=</span> <span class="token number">1</span>b <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>b1<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> b2<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span>c <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>d <span class="token operator">=</span> <span class="token string">'string'</span>pre_defined <span class="token operator">=</span> <span class="token string">'{{ fileDirname }}'</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>从 <code>test.py</code> 创建 config class</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> mmcv<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>config <span class="token keyword">import</span> Configcfg <span class="token operator">=</span> Config<span class="token punctuation">.</span>fromfile<span class="token punctuation">(</span><span class="token string">'test.py'</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>cfg<span class="token punctuation">)</span><span class="token comment"># print result</span><span class="token comment"># Config (path: a.py): {'a': 1, 'b': {'b1': [0, 1, 2], 'b2': None}, 'c': (1, 2), 'd': 'string',</span><span class="token comment"># 'pre_defined': '/home/hongkun/mmdetection'}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>config class 也支持4个预先定义的变量 <code>{{ var }}</code></p><p><code>{{ fileDirname }}</code> : 当前文件路径</p><p><code>{{ fileBasename }}</code>: 当前文件名，如 <code>test.py</code></p><p><code>{{ fileBasenameNoExtension }}</code>:  当前文件名，无扩展名，如 <code>test</code></p><p><code>{{ fileExtname }}</code>: 当前文件扩展名，如 <code>.py</code></p><h3 id="继承-inheritance"><a href="#继承-inheritance" class="headerlink" title="继承 inheritance"></a>继承 inheritance</h3><p>想要使用其他配置文件中的内容，只需要添加继承关键字 <code>_base_ = file or list_of_file</code> 即可</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># inheritance.py</span>_base_ <span class="token operator">=</span> <span class="token string">'test.py'</span> <span class="token comment"># or a list like, ['config_1.py', 'config_2.py']</span>b <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>b2<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token comment"># b = dict(b3=1, _delete_=True)</span>e <span class="token operator">=</span> <span class="token string">'new config'</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>继承之后，<code>inheritance.py</code> 除了自身的配置，还会包含 <code>test.py</code> 中的所有配置</p><p>当遇到重复的关键字时，例如两个配置文件中都有 <code>b</code> 关键字，config class 也支持修改，此时情况分为：</p><ol><li>key 对应的 value 为字典，那么会将这个字典与需要继承的字典进行融合，如果想要忽略继承文件夹中的同名配置，则需要添加 <code>_delete_=True</code> 键值</li><li>key 对应的 value 为为其他类型，则将使用当前的 value</li></ol><h2 id="Registry"><a href="#Registry" class="headerlink" title="Registry"></a>Registry</h2><p>registry class 是整个 MMCV 的大管家，负责将<strong>类</strong>进行注册并配合 config 中的信息将类实例化，这个类可以是任何已实现的类：可以是模型，也可以是其他类比如 Runner, Datasets…本质上 registry 完成的是一个映射： string —&gt; class，这里的 string 通常在 config 中对应着 <code>type</code> 字段。你在 config 文件中只要看到了 <code>type='CLASS_NAME'</code> 那么就一定可以在项目代码中找到对应的类的实现，而 <code>type</code> 之后填写的其他关键字，正是这些类需要的初始化参数。所以大可以把 registry 看作是一个高级的字典</p><p>使用 registry 管理类需要3个步骤（一般只要2个）：</p><ol><li>创建 build function (一般不用自己创建，Registry 有自带 build_from_cfg 函数)</li><li>创建 registry 类</li><li>把待管理的类注册到 registry 中，即可使用 registry 管理模块</li></ol><h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><p>假设要管理一个 <code>Converter class</code>，准备在 <code>Converters</code> 文件夹中实现。先尝试用一个 python 文件： <code>builder.py</code> 实现 registry 的管理功能，并通过 registry 实例化 Converter</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Converters/builder.py</span><span class="token keyword">from</span> mmcv<span class="token punctuation">.</span>utils <span class="token keyword">import</span> Registry<span class="token comment"># 1. create a build function</span><span class="token keyword">def</span> <span class="token function">build_converter</span><span class="token punctuation">(</span>cfg<span class="token punctuation">,</span> registry<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>    cfg_ <span class="token operator">=</span> cfg<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>    converter_type <span class="token operator">=</span> cfg_<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token string">'type'</span><span class="token punctuation">)</span>    <span class="token keyword">if</span> converter_type <span class="token keyword">not</span> <span class="token keyword">in</span> registry<span class="token punctuation">:</span>        <span class="token keyword">raise</span> KeyError<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Unrecognized converter type </span><span class="token interpolation"><span class="token punctuation">{</span>converter_type<span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        converter_cls <span class="token operator">=</span> registry<span class="token punctuation">.</span>get<span class="token punctuation">(</span>converter_type<span class="token punctuation">)</span>    converter <span class="token operator">=</span> converter_cls<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">,</span> <span class="token operator">**</span>cfg_<span class="token punctuation">)</span>    <span class="token keyword">return</span> converter<span class="token comment"># 2. create a registry for converters</span>CONVERTERS <span class="token operator">=</span> Registry<span class="token punctuation">(</span><span class="token string">'Converter'</span><span class="token punctuation">,</span> build_func<span class="token operator">=</span>build_converter<span class="token punctuation">)</span><span class="token comment"># if use default build_func: CONVERTERS = Registry('Converter')</span><span class="token comment"># 3. use the registry to manage the module</span><span class="token decorator annotation punctuation">@CONVERTERS<span class="token punctuation">.</span>register_module</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">Converter1</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> a<span class="token punctuation">,</span> b<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>a <span class="token operator">=</span> a        self<span class="token punctuation">.</span>b <span class="token operator">=</span> b <span class="token comment"># use this converter through configs</span>converter_cfg <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'Converter1'</span><span class="token punctuation">,</span> a<span class="token operator">=</span><span class="token string">'a_value'</span><span class="token punctuation">,</span> b<span class="token operator">=</span><span class="token string">'b_value'</span><span class="token punctuation">)</span>converter <span class="token operator">=</span> CONVERTERS<span class="token punctuation">.</span>build<span class="token punctuation">(</span>converter_cfg<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'converter attribute:'</span><span class="token punctuation">,</span> converter<span class="token punctuation">.</span>a<span class="token punctuation">,</span> converter<span class="token punctuation">.</span>b<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>上面就是 registry 的工作逻辑：先建造 registry 类，再将待管理的类通过装饰器注册到 registry 类中，最后使用 cfg 建造实例</p><p>如果去看 mmdetection 的代码会发现，其 <code>builder.py</code> 是写得非常简单的，并没有包含 <code>build_func</code> 以及具体管理的类。是因为其使用的是默认的 <code>build_func=build_from_cfg</code> 并且将其他类用单独文件保存，之后通过 <code>__init__.py</code> ，将所有的类注册到 builder 中的 registry 类中</p><h3 id="层级注册-Hierarchy-Registry"><a href="#层级注册-Hierarchy-Registry" class="headerlink" title="层级注册 Hierarchy Registry"></a>层级注册 Hierarchy Registry</h3><p>这里我更想叫它继承注册。在 registry 类中提供了 parent 参数，parent 必须也是 registry 类。这样子 registry 就能够继承 parent registry 的 build_func 来进行实例化，并且每一个类既能够使用注册在自己名下的类，通过指定”族谱“也能够也使用其他 registry 管理的类。但这个”族谱“是按照 OpenMMLab 项目划分的，不是我们能修改的，所以个这继承注册的意义是在于 OpenMMLab 不同项目之间的模型都可以调用，例如 mmdetection 可以调用 mmclassification 中的模型。请前往文档参考 <a href="https://mmcv.readthedocs.io/en/latest/understand_mmcv/registry.html#hierarchy-registry">更多</a></p><h2 id="Runner"><a href="#Runner" class="headerlink" title="Runner"></a>Runner</h2><p>Runner 是管理训练过程的类，有两个子类 <code>EpochBasedRunner</code> and <code>IterBasedRunner</code>。Runner 也能够在 train 和 val 两种模式中切换，和 hook 结合可以在训练过程中有更多拓展功能</p><h3 id="EpochBasedRunner"><a href="#EpochBasedRunner" class="headerlink" title="EpochBasedRunner"></a>EpochBasedRunner</h3><p>该 runner 的工作流是基于 epoch 的，每一个 epoch 将包含多个 iterations。比如当 <code>workflow = [('train', 2), ('val', 1)]</code> 该 runner 就会运行2次训练集1次验证集。下面看看其运行的基本逻辑</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># the condition to stop training</span><span class="token keyword">while</span> curr_epoch <span class="token operator">&lt;</span> max_epochs<span class="token punctuation">:</span>    <span class="token comment"># traverse the workflow.</span>    <span class="token comment"># e.g. workflow = [('train', 2), ('val', 1)]</span>    <span class="token keyword">for</span> i<span class="token punctuation">,</span> flow <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>workflow<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># mode(e.g. train) determines which function to run</span>        mode<span class="token punctuation">,</span> epochs <span class="token operator">=</span> flow        <span class="token comment"># epoch_runner will be either self.train() or self.val()</span>        epoch_runner <span class="token operator">=</span> <span class="token builtin">getattr</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> mode<span class="token punctuation">)</span>        <span class="token comment"># execute the corresponding function</span>        <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>            epoch_runner<span class="token punctuation">(</span>data_loaders<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>如果是 train 模式，那么将调用类似如下函数</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Currently, epoch_runner could be either train or val</span><span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data_loader<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># traverse the dataset and get batch data for 1 epoch</span>    <span class="token keyword">for</span> i<span class="token punctuation">,</span> data_batch <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>data_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># it will execute all before_train_iter function in the hooks registered. You may want to watch out for the order.</span>        self<span class="token punctuation">.</span>call_hook<span class="token punctuation">(</span><span class="token string">'before_train_iter'</span><span class="token punctuation">)</span>        <span class="token comment"># set train_mode as False in val function</span>        self<span class="token punctuation">.</span>run_iter<span class="token punctuation">(</span>data_batch<span class="token punctuation">,</span> train_mode<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>call_hook<span class="token punctuation">(</span><span class="token string">'after_train_iter'</span><span class="token punctuation">)</span>   self<span class="token punctuation">.</span>call_hook<span class="token punctuation">(</span><span class="token string">'after_train_epoch'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>以上两段代码就展示了 runner 的基本逻辑：遍历整个训练集，并在每次遍历前后运行 hook 进行拓展操作</p><h3 id="IterBasedRunner"><a href="#IterBasedRunner" class="headerlink" title="IterBasedRunner"></a>IterBasedRunner</h3><p>与 <code>EpochBasedRunner</code> 类似，但是是基于 iteration 的 runner 实现，一个 iteration 将包含一个 batchsize。如果定义了 <code>workflow = [('train', 2), ('val', 1)]</code> 那么将会循环运行2个训练集 iterations 和1个验证机 iteration。下面也看看其运行逻辑</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Although we set workflow by iters here, we might also need info on the epochs in some using cases. That can be provided by IterLoader.</span>iter_loaders <span class="token operator">=</span> <span class="token punctuation">[</span>IterLoader<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> data_loaders<span class="token punctuation">]</span><span class="token comment"># the condition to stop training</span><span class="token keyword">while</span> curr_iter <span class="token operator">&lt;</span> max_iters<span class="token punctuation">:</span>    <span class="token comment"># traverse the workflow.</span>    <span class="token comment"># e.g. workflow = [('train', 2), ('val', 1)]</span>    <span class="token keyword">for</span> i<span class="token punctuation">,</span> flow <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>workflow<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># mode(e.g. train) determines which function to run</span>        mode<span class="token punctuation">,</span> iters <span class="token operator">=</span> flow        <span class="token comment"># iter_runner will be either self.train() or self.val()</span>        iter_runner <span class="token operator">=</span> <span class="token builtin">getattr</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> mode<span class="token punctuation">)</span>        <span class="token comment"># execute the corresponding function</span>        <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>iters<span class="token punctuation">)</span><span class="token punctuation">:</span>            iter_runner<span class="token punctuation">(</span>iter_loaders<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="使用-Runner"><a href="#使用-Runner" class="headerlink" title="使用 Runner"></a>使用 Runner</h3><p>一般来讲使用 runner 来进行训练有4个基本步骤：</p><ol><li>初始化 dataloader, model, optimizer, etc.</li><li>初始化 runner：将 config, model, optimizer, etc. 传入 Runner 中进行实例化</li><li>注册 training hooks &amp; customized hooks</li><li>开始训练：<code>runner.run(data_loaders, cfg.workflow)</code></li></ol><p>具体示例代码请移步 <a href="https://mmcv.readthedocs.io/en/latest/understand_mmcv/runner.html#a-simple-example">MMCV Runner</a></p><h2 id="File-IO"><a href="#File-IO" class="headerlink" title="File IO"></a>File IO</h2><p>mmcv 给导入和输入文档设有 API，可以导入不同格式的文档，例如 json, yaml, pkl。下面来看看如何导入一个 json 文件为字典</p><pre class="line-numbers language-json" data-language="json"><code class="language-json"><span class="token comment">// file.json</span><span class="token punctuation">{</span>    <span class="token property">"version"</span><span class="token operator">:</span> <span class="token string">"0.2.0"</span><span class="token punctuation">,</span>    <span class="token property">"configurations"</span><span class="token operator">:</span> <span class="token punctuation">[</span>        <span class="token punctuation">{</span>            <span class="token property">"name"</span><span class="token operator">:</span> <span class="token string">"Python: Current File"</span><span class="token punctuation">,</span>            <span class="token property">"type"</span><span class="token operator">:</span> <span class="token string">"python"</span><span class="token punctuation">,</span>            <span class="token property">"request"</span><span class="token operator">:</span> <span class="token string">"launch"</span><span class="token punctuation">,</span>            <span class="token property">"program"</span><span class="token operator">:</span> <span class="token string">"${file}"</span><span class="token punctuation">,</span>            <span class="token property">"console"</span><span class="token operator">:</span> <span class="token string">"integratedTerminal"</span><span class="token punctuation">,</span>            <span class="token property">"justMyCode"</span><span class="token operator">:</span> <span class="token boolean">false</span>        <span class="token punctuation">}</span>    <span class="token punctuation">]</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> mmcv<span class="token builtin">file</span> <span class="token operator">=</span> mmcv<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'file.json'</span><span class="token punctuation">)</span><span class="token comment"># load data from a file-like object</span><span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'file.json'</span><span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>    data <span class="token operator">=</span> mmcv<span class="token punctuation">.</span>load<span class="token punctuation">(</span>f<span class="token punctuation">,</span> file_format<span class="token operator">=</span><span class="token string">'json'</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token punctuation">(</span><span class="token builtin">file</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">file</span><span class="token punctuation">)</span><span class="token comment"># &lt;class 'dict'&gt;</span><span class="token comment"># {'version': '0.2.0', 'configurations': [{'name': 'Python: Current File', 'type': 'python', 'request': 'launch', 'program': '${file}', 'console': 'integratedTerminal', 'justMyCode': False}]}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>也可以使用 <code>mmcv.dump</code> 来转化文件或者输出文件</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> mmcv<span class="token comment"># 将字典转化为字符串</span>info <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">'Declan'</span><span class="token punctuation">,</span> age<span class="token operator">=</span><span class="token number">23</span><span class="token punctuation">)</span>dump_info <span class="token operator">=</span> mmcv<span class="token punctuation">.</span>dump<span class="token punctuation">(</span>info<span class="token punctuation">,</span> file_format<span class="token operator">=</span><span class="token string">'yaml'</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>dump_info<span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token punctuation">(</span>dump_info<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># age: 23</span><span class="token comment"># name: Declan</span><span class="token comment"># &lt;class 'str'&gt;</span><span class="token comment"># 将文件保存为 info.yaml</span>mmcv<span class="token punctuation">.</span>dump<span class="token punctuation">(</span>info<span class="token punctuation">,</span> <span class="token string">'info.yaml'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>但是以上的 API 不能导入 txt 格式文件，需要使用 <code>mmcv.list_from_txt</code> or <code>mmcv.dict_from_txt</code> 将 txt 文件导入为列表或者字典</p><pre class="line-numbers language-a.txt" data-language="a.txt"><code class="language-a.txt">1 cat2 dog cow3 panda<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><pre class="line-numbers language-python" data-language="python"><code class="language-python">mmcv<span class="token punctuation">.</span>dict_from_file<span class="token punctuation">(</span><span class="token string">'a.txt'</span><span class="token punctuation">)</span><span class="token comment"># {'1': 'cat', '2': ['dog', 'cow'], '3': 'panda'}</span>mmcv<span class="token punctuation">.</span>list_from_file<span class="token punctuation">(</span><span class="token string">'a.txt'</span><span class="token punctuation">)</span><span class="token comment"># ['1 cat', '2 dog cow', '3 panda']</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h2 id="Data-Process"><a href="#Data-Process" class="headerlink" title="Data Process"></a>Data Process</h2><blockquote><p>This module provides some image processing methods, which requires <code>opencv</code> to be installed.</p></blockquote><h3 id="Image"><a href="#Image" class="headerlink" title="Image"></a>Image</h3><h4 id="Read-Write-Show"><a href="#Read-Write-Show" class="headerlink" title="Read/Write/Show"></a>Read/Write/Show</h4><p>对于图片的基本操作：读、写、展示，分别使用 <code>imread</code>，<code>imwrite</code>，<code>imshow</code> 三个 API</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> mmcv<span class="token comment"># Read &amp; Write</span>img <span class="token operator">=</span> mmcv<span class="token punctuation">.</span>imread<span class="token punctuation">(</span><span class="token string">'test.jpg'</span><span class="token punctuation">)</span>mmcv<span class="token punctuation">.</span>imwrite<span class="token punctuation">(</span>img<span class="token punctuation">,</span> <span class="token string">'out.jpg'</span><span class="token punctuation">)</span><span class="token comment"># Show</span>mmcv<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span><span class="token string">'tests/data/color.jpg'</span><span class="token punctuation">)</span><span class="token comment"># Show with bboxes</span>bboxes <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">50</span><span class="token punctuation">,</span> <span class="token number">50</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">60</span><span class="token punctuation">,</span> <span class="token number">60</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>mmcv<span class="token punctuation">.</span>imshow_bboxes<span class="token punctuation">(</span>img<span class="token punctuation">,</span> bboxes<span class="token punctuation">)</span><span class="token comment"># Show with ndarray</span><span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    img <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>uint8<span class="token punctuation">)</span>    mmcv<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>img<span class="token punctuation">,</span> win_name<span class="token operator">=</span><span class="token string">'test image'</span><span class="token punctuation">,</span> wait_time<span class="token operator">=</span><span class="token number">200</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="More"><a href="#More" class="headerlink" title="More"></a>More</h4><p>对于图片还有更多的操作就不在这里列举了，例如色域转换、剪裁、旋转等，参考 <a href="https://mmcv.readthedocs.io/en/latest/understand_mmcv/data_process.html#data-process">MMCV 文档</a></p><h3 id="Video"><a href="#Video" class="headerlink" title="Video"></a>Video</h3><p>关于视频模块主要实现3个功能：</p><ol><li>读取视频</li><li>编辑视频</li><li>处理光流文件</li></ol><h4 id="VideoReader"><a href="#VideoReader" class="headerlink" title="VideoReader"></a>VideoReader</h4><p>该 API 能够过得视频的一些基本信息，并能够视频中的每一帧进行索引或遍历</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">video <span class="token operator">=</span> mmcv<span class="token punctuation">.</span>VideoReader<span class="token punctuation">(</span><span class="token string">'test.mp4'</span><span class="token punctuation">)</span><span class="token comment"># obtain basic information</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>video<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>video<span class="token punctuation">.</span>width<span class="token punctuation">,</span> video<span class="token punctuation">.</span>height<span class="token punctuation">,</span> video<span class="token punctuation">.</span>resolution<span class="token punctuation">,</span> video<span class="token punctuation">.</span>fps<span class="token punctuation">)</span><span class="token comment"># iterate over all frames</span><span class="token keyword">for</span> frame <span class="token keyword">in</span> video<span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>frame<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token comment"># read the next frame</span>img <span class="token operator">=</span> video<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># read a frame by index</span>img <span class="token operator">=</span> video<span class="token punctuation">[</span><span class="token number">100</span><span class="token punctuation">]</span><span class="token comment"># read some frames</span>img <span class="token operator">=</span> video<span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">:</span><span class="token number">10</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>该模块内置方法 <code>cvt2frames</code> 可以将 video 转化为 images，同时 <code>mmcv.frames2video</code> 也可以将 images 转化为 video</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># split a video into frames and save to a folder</span>video <span class="token operator">=</span> mmcv<span class="token punctuation">.</span>VideoReader<span class="token punctuation">(</span><span class="token string">'test.mp4'</span><span class="token punctuation">)</span><span class="token comment"># convert a video to frame images</span>video<span class="token punctuation">.</span>cvt2frames<span class="token punctuation">(</span><span class="token string">'out_dir'</span><span class="token punctuation">)</span><span class="token comment"># generate video from frames</span>mmcv<span class="token punctuation">.</span>frames2video<span class="token punctuation">(</span><span class="token string">'out_dir'</span><span class="token punctuation">,</span> <span class="token string">'test.avi'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>如果熟悉 ffmpeg 的话，通过 ffmpeg 能够实现更多格式的转化，可以使用 python 中的 <code>os.system</code> 执行命令行</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> osos<span class="token punctuation">.</span>system<span class="token punctuation">(</span><span class="token string">'ffmpeg -version'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>mmcv 中也有一些接口借用了 ffmpeg 以实现对视频的更多操作</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># cut a video clip</span>mmcv<span class="token punctuation">.</span>cut_video<span class="token punctuation">(</span><span class="token string">'test.mp4'</span><span class="token punctuation">,</span> <span class="token string">'clip1.mp4'</span><span class="token punctuation">,</span> start<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> end<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> vcodec<span class="token operator">=</span><span class="token string">'h264'</span><span class="token punctuation">)</span><span class="token comment"># join a list of video clips</span>mmcv<span class="token punctuation">.</span>concat_video<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'clip1.mp4'</span><span class="token punctuation">,</span> <span class="token string">'clip2.mp4'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'joined.mp4'</span><span class="token punctuation">,</span> log_level<span class="token operator">=</span><span class="token string">'quiet'</span><span class="token punctuation">)</span><span class="token comment"># resize a video with the specified size</span>mmcv<span class="token punctuation">.</span>resize_video<span class="token punctuation">(</span><span class="token string">'test.mp4'</span><span class="token punctuation">,</span> <span class="token string">'resized1.mp4'</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">360</span><span class="token punctuation">,</span> <span class="token number">240</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># resize a video with a scaling ratio of 2</span>mmcv<span class="token punctuation">.</span>resize_video<span class="token punctuation">(</span><span class="token string">'test.mp4'</span><span class="token punctuation">,</span> <span class="token string">'resized2.mp4'</span><span class="token punctuation">,</span> ratio<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="Optical-flow"><a href="#Optical-flow" class="headerlink" title="Optical flow"></a>Optical flow</h4><p>mmcv 也对光流文件的处理提供支持，但我对于其了解不多，暂时不作整理。这里贴一个链接 <a href="https://mmcv.readthedocs.io/en/latest/understand_mmcv/data_process.html#optical-flow">MMCV Optical flow</a></p><h2 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h2><h3 id="KITTI-数据集"><a href="#KITTI-数据集" class="headerlink" title="KITTI 数据集"></a>KITTI 数据集</h3><p>KITTI数据集有40多个G，相比起来是一个比较小的数据集</p><p>对于数据集的讲解可以参考 <a href="https://blog.csdn.net/u013086672/article/details/103913361">CSDN</a></p><p>下载数据集可以在 <a href="https://gas.graviti.cn/dataset/data-decorators/KITTIObject">GRAVITI</a> 下载，需要注册一个账户，但是速度很快</p>]]></content>
      
      
      <categories>
          
          <category> 编程 </category>
          
          <category> OpenMMLab </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MMCV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MMDetection tutorial note</title>
      <link href="/archives/71f4e62.html"/>
      <url>/archives/71f4e62.html</url>
      
        <content type="html"><![CDATA[<h1 id="MMDetection-tutorial-note"><a href="#MMDetection-tutorial-note" class="headerlink" title="MMDetection tutorial note"></a>MMDetection tutorial note</h1><h2 id="Config"><a href="#Config" class="headerlink" title="Config"></a>Config</h2><p>由于 config 是有继承机制的，所以想要查看完整的 config，可以用官方提供的 <code>print_config.py</code> 函数来查看</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">python tools/misc/print_config.py /<span class="token environment constant">PATH</span>/TO/CONFIG<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="修改-config"><a href="#修改-config" class="headerlink" title="修改 config"></a>修改 config</h3><p>在使用 <code>tools/train.py</code> or <code>tools/test.py</code> 时，可以通过 <code>--cfg-options</code> 来修改此次运行的 config 而不修改 config 文件</p><p>更改字典，列表，元组都可以，只需要按照规范传入参数即可，下面给几个例子</p><ol><li><p>更改字典 <code>--cfg-options model.backbone.norm_eval=False</code></p></li><li><p>更改列表中的字典 <code>[dict(type='LoadImageFromFile'), ...]</code> </p><p><code>--cfg-options data.train.pipeline.0.type=LoadImageFromWebcam</code></p></li><li><p>更改列表，元组 <code>workflow=[('train', 1)]</code></p><p><code>--cfg-options workflow="[(train,1),(val,1)]"</code> 注意必须要加引号，且内部不能有空格</p></li></ol><h3 id="config-结构"><a href="#config-结构" class="headerlink" title="config 结构"></a>config 结构</h3><p>在 <code>config/_base_</code> 中有4个基本的组成部分</p><ol><li>dataset</li><li>models: backbone, neck 是必须有的</li><li>schedule</li><li>default_runtime</li></ol><p>更详细的要求和例子请直接查看 <a href="https://mmdetection.readthedocs.io/en/latest/tutorials/config.html#config-name-style">文档</a></p><p>config 的结构其实就给学习 MMDetection 有一个明确的指导，重点就是这四个部分，怎么建立数据集、模型，训练过程中的策略是什么，在训练过程中需不需要做些其他记录和处理…</p><h2 id="Customize-Datasets"><a href="#Customize-Datasets" class="headerlink" title="Customize Datasets"></a>Customize Datasets</h2><p>数据可以分为两个部分处理，一个是数据本身，另一个是数据的标签信息 <code>annotation_file</code>，所以想要建立个性化的数据集，处理好这两个部分即可</p><p>对于数据本身，比如图片数据、点云数据…其实能够做的处理是比较少的，更多的是做预处理比如 data augmentation，但这些操作就不在这一部分进行，而是到下一节 Data Piplines 中进行</p><h3 id="规范-annotation-file"><a href="#规范-annotation-file" class="headerlink" title="规范 annotation_file"></a>规范 annotation_file</h3><p>现在重心放在处理数据的标签信息上，核心就是把标签信息处理成为一种规范的格式就可以使用了，在 MMDetection 中 COCO format 是一种推荐的格式。COCO format 是一个 json 文件，文件中包含了整个数据集每一个样本的标签信息，其中有3个大的关键字：</p><ul><li><code>images</code>: contains a list of images with their informations like <code>file_name</code>, <code>height</code>, <code>width</code>, and <code>id</code>.</li><li><code>annotations</code>: contains the list of instance annotations.</li><li><code>categories</code>: contains the list of categories names and their ID.</li></ul><p>形如下面的内容</p><pre class="line-numbers language-json" data-language="json"><code class="language-json">'images'<span class="token operator">:</span> <span class="token punctuation">[</span>    <span class="token punctuation">{</span>        'file_name'<span class="token operator">:</span> 'COCO_val2014_000000001268.jpg'<span class="token punctuation">,</span>        'height'<span class="token operator">:</span> <span class="token number">427</span><span class="token punctuation">,</span>        'width'<span class="token operator">:</span> <span class="token number">640</span><span class="token punctuation">,</span>        'id'<span class="token operator">:</span> <span class="token number">1268</span>    <span class="token punctuation">}</span><span class="token punctuation">,</span>    ...<span class="token punctuation">]</span><span class="token punctuation">,</span>'annotations'<span class="token operator">:</span> <span class="token punctuation">[</span>    <span class="token punctuation">{</span>        'segmentation'<span class="token operator">:</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">192.81</span><span class="token punctuation">,</span>            <span class="token number">247.09</span><span class="token punctuation">,</span>            ...            <span class="token number">219.03</span><span class="token punctuation">,</span>            <span class="token number">249.06</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>  # if you have mask labels        'area'<span class="token operator">:</span> <span class="token number">1035.749</span><span class="token punctuation">,</span>        'iscrowd'<span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span>        'image_id'<span class="token operator">:</span> <span class="token number">1268</span><span class="token punctuation">,</span>        'bbox'<span class="token operator">:</span> <span class="token punctuation">[</span><span class="token number">192.81</span><span class="token punctuation">,</span> <span class="token number">224.8</span><span class="token punctuation">,</span> <span class="token number">74.73</span><span class="token punctuation">,</span> <span class="token number">33.43</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        'category_id'<span class="token operator">:</span> <span class="token number">16</span><span class="token punctuation">,</span>        'id'<span class="token operator">:</span> <span class="token number">42986</span>    <span class="token punctuation">}</span><span class="token punctuation">,</span>    ...<span class="token punctuation">]</span><span class="token punctuation">,</span>'categories'<span class="token operator">:</span> <span class="token punctuation">[</span>    <span class="token punctuation">{</span>'id'<span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span> 'name'<span class="token operator">:</span> 'car'<span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="更改-config-file-以匹配"><a href="#更改-config-file-以匹配" class="headerlink" title="更改 config file 以匹配"></a>更改 config file 以匹配</h3><p>更改 config file 中的 dataset/data 配置来匹配 <code>annotation_file</code>，需要明确的是三个部分：</p><ol><li><code>annotation_file_path</code> &amp; <code>image_path</code></li><li><code>classes</code> 数据集有哪些类别</li><li><code>num_classes</code> 数据集类别有多少</li></ol><p>这三个部分在 config 中的 train, val, test 字段中均有出现，具体更改哪些部分，参考下面的代码，假设新数据集有5个类别，用字母 a~e 来表示</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># the new config inherits the base configs to highlight the necessary modification</span>_base_ <span class="token operator">=</span> <span class="token string">'./cascade_mask_rcnn_r50_fpn_1x_coco.py'</span><span class="token comment"># 1. dataset settings</span>dataset_type <span class="token operator">=</span> <span class="token string">'CocoDataset'</span>classes <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token string">'a'</span><span class="token punctuation">,</span> <span class="token string">'b'</span><span class="token punctuation">,</span> <span class="token string">'c'</span><span class="token punctuation">,</span> <span class="token string">'d'</span><span class="token punctuation">,</span> <span class="token string">'e'</span><span class="token punctuation">)</span>data <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>    samples_per_gpu<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>    workers_per_gpu<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>    train<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>        <span class="token builtin">type</span><span class="token operator">=</span>dataset_type<span class="token punctuation">,</span>        <span class="token comment"># explicitly add your class names to the field `classes`</span>        classes<span class="token operator">=</span>classes<span class="token punctuation">,</span>        ann_file<span class="token operator">=</span><span class="token string">'path/to/your/train/annotation_data'</span><span class="token punctuation">,</span>        img_prefix<span class="token operator">=</span><span class="token string">'path/to/your/train/image_data'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    val<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>        <span class="token builtin">type</span><span class="token operator">=</span>dataset_type<span class="token punctuation">,</span>        <span class="token comment"># explicitly add your class names to the field `classes`</span>        classes<span class="token operator">=</span>classes<span class="token punctuation">,</span>        ann_file<span class="token operator">=</span><span class="token string">'path/to/your/val/annotation_data'</span><span class="token punctuation">,</span>        img_prefix<span class="token operator">=</span><span class="token string">'path/to/your/val/image_data'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    test<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>        <span class="token builtin">type</span><span class="token operator">=</span>dataset_type<span class="token punctuation">,</span>        <span class="token comment"># explicitly add your class names to the field `classes`</span>        classes<span class="token operator">=</span>classes<span class="token punctuation">,</span>        ann_file<span class="token operator">=</span><span class="token string">'path/to/your/test/annotation_data'</span><span class="token punctuation">,</span>        img_prefix<span class="token operator">=</span><span class="token string">'path/to/your/test/image_data'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># 2. model settings</span><span class="token comment"># explicitly over-write all the `num_classes` field from default 80 to 5.</span>model <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>    roi_head<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>        bbox_head<span class="token operator">=</span><span class="token punctuation">[</span>            <span class="token builtin">dict</span><span class="token punctuation">(</span>                <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'Shared2FCBBoxHead'</span><span class="token punctuation">,</span>                <span class="token comment"># explicitly over-write all the `num_classes` field from default 80 to 5.</span>                num_classes<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token builtin">dict</span><span class="token punctuation">(</span>                <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'Shared2FCBBoxHead'</span><span class="token punctuation">,</span>                <span class="token comment"># explicitly over-write all the `num_classes` field from default 80 to 5.</span>                num_classes<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token builtin">dict</span><span class="token punctuation">(</span>                <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'Shared2FCBBoxHead'</span><span class="token punctuation">,</span>                <span class="token comment"># explicitly over-write all the `num_classes` field from default 80 to 5.</span>                num_classes<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    <span class="token comment"># explicitly over-write all the `num_classes` field from default 80 to 5.</span>    mask_head<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>num_classes<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这里推荐 <a href="https://www.bilibili.com/video/BV1Jb4y1r7ir?p=1">bilibili 教程</a>，有实例讲解了如何处理个性化数据集</p><p>文档中还提到了可以<a href="https://mmdetection.readthedocs.io/en/latest/tutorials/customize_dataset.html#reorganize-new-data-format-to-middle-format"> 建立自己的 Dataset 类</a>，来完成原本的 <code>CocoDataset</code> 类的功能。只需要继承 <code>CustomDataset</code> 基类然后重写 <code>load_annotations(self, ann_file)</code> and <code>get_ann_info(self, idx)</code> 两个方法</p><h2 id="Customize-Data-Pipelines"><a href="#Customize-Data-Pipelines" class="headerlink" title="Customize Data Pipelines"></a>Customize Data Pipelines</h2><p>接下来就要具体地对数据集进行处理了，需要深入到 <code>mmdet/datasets</code> 当中看看，从 <code>builder.py</code> 大致可以看出，类似于 pytorch，mmdetection 也将数据处理分为 <code>Dataset</code> 和 <code>Dataloader</code> 两个类来创建和加载数据集。这一节的重点是在 <code>Dataset</code> 类中，上一节提到的 <code>CocoDataset</code>  类就是其中一个。在上一节，处理了数据集的 annotation 规范问题，这一节需要使用 <code>Dataset</code> 类建立一个 piplines 对数据集进行一系列变换操作</p><h3 id="变换操作"><a href="#变换操作" class="headerlink" title="变换操作"></a>变换操作</h3><p>在 <code>mmdet/datasets/piplines</code> 中有许多的方法，用于对数据的处理。如果想要创建自己的类，步骤也是类似的：</p><ol><li>创建 <code>MyTransform</code> 类</li><li>导入这个类</li><li>将该类加入到 config 中，文档中的 <a href="https://mmdetection.readthedocs.io/en/latest/tutorials/data_pipeline.html#extend-and-use-custom-pipelines">示例代码</a></li></ol><p>下面是 Faster R-CNN config 文件中 pipeline 部分的一个例子</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">img_norm_cfg <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>    mean<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">123.675</span><span class="token punctuation">,</span> <span class="token number">116.28</span><span class="token punctuation">,</span> <span class="token number">103.53</span><span class="token punctuation">]</span><span class="token punctuation">,</span> std<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">58.395</span><span class="token punctuation">,</span> <span class="token number">57.12</span><span class="token punctuation">,</span> <span class="token number">57.375</span><span class="token punctuation">]</span><span class="token punctuation">,</span> to_rgb<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>train_pipeline <span class="token operator">=</span> <span class="token punctuation">[</span>    <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'LoadImageFromFile'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'LoadAnnotations'</span><span class="token punctuation">,</span> with_bbox<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'Resize'</span><span class="token punctuation">,</span> img_scale<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1333</span><span class="token punctuation">,</span> <span class="token number">800</span><span class="token punctuation">)</span><span class="token punctuation">,</span> keep_ratio<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'RandomFlip'</span><span class="token punctuation">,</span> flip_ratio<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'Normalize'</span><span class="token punctuation">,</span> <span class="token operator">**</span>img_norm_cfg<span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'Pad'</span><span class="token punctuation">,</span> size_divisor<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'DefaultFormatBundle'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'Collect'</span><span class="token punctuation">,</span> keys<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'img'</span><span class="token punctuation">,</span> <span class="token string">'gt_bboxes'</span><span class="token punctuation">,</span> <span class="token string">'gt_labels'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">]</span>test_pipeline <span class="token operator">=</span> <span class="token punctuation">[</span>    <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'LoadImageFromFile'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token builtin">dict</span><span class="token punctuation">(</span>        <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'MultiScaleFlipAug'</span><span class="token punctuation">,</span>        img_scale<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1333</span><span class="token punctuation">,</span> <span class="token number">800</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        flip<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>        transforms<span class="token operator">=</span><span class="token punctuation">[</span>            <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'Resize'</span><span class="token punctuation">,</span> keep_ratio<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'RandomFlip'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'Normalize'</span><span class="token punctuation">,</span> <span class="token operator">**</span>img_norm_cfg<span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'Pad'</span><span class="token punctuation">,</span> size_divisor<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'ImageToTensor'</span><span class="token punctuation">,</span> keys<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'img'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'Collect'</span><span class="token punctuation">,</span> keys<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'img'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Dataset-实现变换操作"><a href="#Dataset-实现变换操作" class="headerlink" title="Dataset 实现变换操作"></a>Dataset 实现变换操作</h3><p>以 <code>CocoDataset</code> 为例，查看该类的代码，并没有发现在 <code>mmdet/datasets/coco.py</code> 中有实现 pipelines。实际上，<code>CocoDataset</code> 负责实现的是对 <code>annotation_file</code> 的处理，而对于 pipelines 的实现，在其继承的 <code>CustomDataset</code> 中实现的，具体实现逻辑如下：</p><ol><li>使用 <code>Compose</code> 类将 config 文件中的所有变换操作类实例化，并将所有的类存储到一个列表中</li><li>对需要处理的 data 依次使用列表中的变化操作，具体参考代码 <a href="https://github.com/open-mmlab/mmdetection/blob/master/mmdet/datasets/custom.py">CustomDataset</a> <a href="https://github.com/open-mmlab/mmdetection/blob/master/mmdet/datasets/pipelines/compose.py">Compose</a></li></ol><h2 id="Customize-Models"><a href="#Customize-Models" class="headerlink" title="Customize Models"></a>Customize Models</h2><p>在 mmdetection 中是通过 registry 来管理各种模块的，当然也包括模型中的模块。而如果想要通过 registry 添加模块的逻辑都是一样的，以添加一个新的 backbone, <code>MobileNet</code> 为例</p><ol><li><p>定义一个新的 backbone, <code>mmdet/models/backbones/mobilenet.py</code></p></li><li><p>导入这个模块，有两种方法</p><ul><li><p>在 <code>__init__.py</code> 中 import 这个模块，<code>from .mobilenet import MobileNet</code></p></li><li><p>在 config 中添加 <code>custom_imports</code> 字典</p></li></ul><pre class="line-numbers language-python" data-language="python"><code class="language-python">custom_imports <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>    imports<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'mmdet.models.backbones.mobilenet'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    allow_failed_imports<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li><li><p>在 config 中使用这个模块</p></li></ol><p>在 <code>mmdet/tools/train.py</code> 中可以看到，通过 <code>build_detector()</code> 将 config 中模型的具体参数实例化 registry 中的类。下面看一个简化的 <code>build_detector()</code></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> mmcv<span class="token punctuation">.</span>cnn <span class="token keyword">import</span> MODELS <span class="token keyword">as</span> MMCV_MODELS<span class="token keyword">from</span> mmcv<span class="token punctuation">.</span>utils <span class="token keyword">import</span> RegistryMODELS <span class="token operator">=</span> Registry<span class="token punctuation">(</span><span class="token string">'models'</span><span class="token punctuation">,</span> parent<span class="token operator">=</span>MMCV_MODELS<span class="token punctuation">)</span>DETECTORS <span class="token operator">=</span> MODELS<span class="token keyword">def</span> <span class="token function">build_detector</span><span class="token punctuation">(</span>cfg<span class="token punctuation">,</span> train_cfg<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> test_cfg<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""Build detector."""</span><span class="token keyword">return</span> DETECTORS<span class="token punctuation">.</span>build<span class="token punctuation">(</span>        cfg<span class="token punctuation">,</span> default_args<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>train_cfg<span class="token operator">=</span>train_cfg<span class="token punctuation">,</span> test_cfg<span class="token operator">=</span>test_cfg<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="Customize-Runtime-Settings"><a href="#Customize-Runtime-Settings" class="headerlink" title="Customize Runtime Settings"></a>Customize Runtime Settings</h2><p>这一部分主要讲怎么配置 optimizer 以及训练流程</p><h3 id="Customize-optimization-settings"><a href="#Customize-optimization-settings" class="headerlink" title="Customize optimization settings"></a>Customize optimization settings</h3><p>mmdetection 适配了所有 pytorch 中的优化器，只需要修改 optimizer 的 <code>type</code> 关键字即可</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># use Adam optimizer</span>optimizer <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'Adam'</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.0003</span><span class="token punctuation">,</span> weight_decay<span class="token operator">=</span><span class="token number">0.0001</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>Optimizer 的实现不是在 mmdetection 项目中，而是在 mmcv 项目中，所以想要个性化的 optimizer 则需要自己新建文件夹进行实现。现在新建 <code>mmdet/core/optimizer</code> 文件夹，新建 <code>my_optimizer.py</code></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> mmcv<span class="token punctuation">.</span>runner<span class="token punctuation">.</span>optimizer <span class="token keyword">import</span> OPTIMIZERS<span class="token keyword">from</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">import</span> Optimizer<span class="token decorator annotation punctuation">@OPTIMIZERS<span class="token punctuation">.</span>register_module</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">MyOptimizer</span><span class="token punctuation">(</span>Optimizer<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> a<span class="token punctuation">,</span> b<span class="token punctuation">,</span> c<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p> 然后修改 config 文件，并 import 该模块</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">optimizer <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'MyOptimizer'</span><span class="token punctuation">,</span> a<span class="token operator">=</span>a_value<span class="token punctuation">,</span> b<span class="token operator">=</span>b_value<span class="token punctuation">,</span> c<span class="token operator">=</span>c_value<span class="token punctuation">)</span>custom_imports <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>imports<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'mmdet.core.optimizer.my_optimizer'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                       allow_failed_imports<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>如果想要对 optimizer 有更加精细化的操作，需要构建新的 OPTIMIZER_CONSTRUCTORS，构建逻辑都是差不多的。这里就不展开了，因为很多优化操作并不熟悉，不知道该怎么用，等有具体的例子再进一步了解</p><h3 id="Customize-training-schedules"><a href="#Customize-training-schedules" class="headerlink" title="Customize training schedules"></a>Customize training schedules</h3><p>在训练优化的过程当中，需要对训练过程进行一些微调，例如对 learning rate 进行衰减，mmdetection 也可以通过调用 hook 做到，所谓的 Hook 就是在每个 epoch or iteration 之前、之后进行的一些操作。具体更改 training schedule 的操作为：在 config 文件中配置 <code>lr_config</code> 等字段。例如默认的阶梯策略 <code>StepLR</code> 可以在指定的 epoch 调整学习率</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">lr_config <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>    policy<span class="token operator">=</span><span class="token string">'step'</span><span class="token punctuation">,</span>    warmup<span class="token operator">=</span><span class="token string">'linear'</span><span class="token punctuation">,</span>    warmup_iters<span class="token operator">=</span><span class="token number">500</span><span class="token punctuation">,</span>    warmup_ratio<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">,</span>    step<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Customize-workflow"><a href="#Customize-workflow" class="headerlink" title="Customize workflow"></a>Customize workflow</h3><p>这部分基本上就使用默认的 workflow 就好，即 <code>workflow = [('train',1)]</code> ，这将会一次一次地循环训练集，直到达到 <code>total_epochs/max_epochs</code> 如果想要训练多个 epoch 过后对模型进行 evaluation 则是调用 <code>EvalHook</code>，而这在 config 文件中对应的是 <code>evaluation</code> 字段</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">workflow <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">'train'</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token comment"># 每间隔一次进行评估</span>evaluation <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>interval<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> metric<span class="token operator">=</span><span class="token string">'bbox'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="Customize-hooks"><a href="#Customize-hooks" class="headerlink" title="Customize hooks"></a>Customize hooks</h3><p>在之前已经提到了 hooks 的作用，mmdetection 中已经实现了一些 hooks：</p><ul><li>og_config</li><li>checkpoint_config</li><li>evaluation</li><li>lr_config</li><li>optimizer_config</li><li>momentum_config</li></ul><p>这些 hooks 能够在训练过程中去提供微调、评估、记录等功能，下面简单介绍一下其中的2个</p><ol><li><p>Checkpoint config，用于保存训练过程中的模型</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">checkpoint_config <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>interval<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li><p>Log config，用于记录训练过程中的关键数据，可以同时使用多个 logger</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">log_config <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>    interval<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span>    hooks<span class="token operator">=</span><span class="token punctuation">[</span>        <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'TextLoggerHook'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'TensorboardLoggerHook'</span><span class="token punctuation">)</span>    <span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ol><p>如果想要使用个性化的 hook，准备过程也是老3步了</p><ol><li><p>定义新的 hook</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> mmcv<span class="token punctuation">.</span>runner <span class="token keyword">import</span> HOOKS<span class="token punctuation">,</span> Hook<span class="token decorator annotation punctuation">@HOOKS<span class="token punctuation">.</span>register_module</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">MyHook</span><span class="token punctuation">(</span>Hook<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> a<span class="token punctuation">,</span> b<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">pass</span>    <span class="token keyword">def</span> <span class="token function">before_run</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> runner<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">pass</span>    <span class="token keyword">def</span> <span class="token function">after_run</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> runner<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">pass</span>    <span class="token keyword">def</span> <span class="token function">before_epoch</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> runner<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">pass</span>    <span class="token keyword">def</span> <span class="token function">after_epoch</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> runner<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">pass</span>    <span class="token keyword">def</span> <span class="token function">before_iter</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> runner<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">pass</span>    <span class="token keyword">def</span> <span class="token function">after_iter</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> runner<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">pass</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>导入新的 hook</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">custom_imports <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>imports<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'mmdet.core.utils.my_hook'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> allow_failed_imports<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li><p>使用新的 hook</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">custom_hooks <span class="token operator">=</span> <span class="token punctuation">[</span>    <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'MyHook'</span><span class="token punctuation">,</span> a<span class="token operator">=</span>a_value<span class="token punctuation">,</span> b<span class="token operator">=</span>b_value<span class="token punctuation">)</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li></ol><p>对于 hook 的调用，还需要进一步了解 <code>Runner</code> 类。mmdetection 是将这些 hook config 传入到了 <code>runner</code> 实例中，并在其中创建 hook 实例。更多有关 <code>Runner</code> 的内容需要在 <a href="https://mmcv.readthedocs.io/en/latest/understand_mmcv/runner.html#">mmcv</a> 里去查看</p><h2 id="Customize-Losses"><a href="#Customize-Losses" class="headerlink" title="Customize Losses"></a>Customize Losses</h2><p>mmdetction 中损失函数是直接在模型中各个 prediction head 中使用，而不是在 forward pass 之后单独使用，所以其关键字是什么，取决于模型之中各个 prediction head 怎么接收损失函数。以 <code>loss_cls</code> 字段为例使用 <code>FocalLoss</code></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">loss_cls<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>    <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'FocalLoss'</span><span class="token punctuation">,</span>    use_sigmoid<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>    gamma<span class="token operator">=</span><span class="token number">2.0</span><span class="token punctuation">,</span>    alpha<span class="token operator">=</span><span class="token number">0.25</span><span class="token punctuation">,</span>    loss_weight<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="Finetuning-Models"><a href="#Finetuning-Models" class="headerlink" title="Finetuning Models"></a>Finetuning Models</h2><p>已经训练好的模型参数已经有较好的特征提取能力，所以将这些参数用于新的数据集只需要一些微调。除了要准备好自己数据集和 config 之外，需要注意的就是调整 training schedule。由于是仅对模型进行微调，所以学习率应该设置得相对小一些，并且 epoch 也应当少一些以避免过拟合。文档给出了一个参考的例子</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># optimizer</span><span class="token comment"># lr is set for a batch size of 8</span>optimizer <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'SGD'</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">,</span> weight_decay<span class="token operator">=</span><span class="token number">0.0001</span><span class="token punctuation">)</span>optimizer_config <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>grad_clip<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token comment"># learning policy</span>lr_config <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>    policy<span class="token operator">=</span><span class="token string">'step'</span><span class="token punctuation">,</span>    warmup<span class="token operator">=</span><span class="token string">'linear'</span><span class="token punctuation">,</span>    warmup_iters<span class="token operator">=</span><span class="token number">500</span><span class="token punctuation">,</span>    warmup_ratio<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">,</span>    step<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment"># the max_epochs and step in lr_config need specifically tuned for the customized dataset</span>runner <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>max_epochs<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">)</span>log_config <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>interval<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token comment"># We can use the pre-trained Mask RCNN model to obtain higher performance</span>load_from <span class="token operator">=</span> <span class="token string">'checkpoints/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth'</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>可以把 mmdetection 的使用分为两个大块来进行理解：</p><ol><li>模型的建立</li><li>模型的训练</li></ol><p>首先是模型的建立，其核心为 config &amp; registry，要理解这两个类的作用。通过 config 将模型的所有构造细节都以字典的形式包含进来了，将这些 config 传入到 registry 中注册好的模型类中从而实现模型的实例化。从中可以看到注册和使用任何新模块的三个主要步骤：定义模型、导入模型、修改 config 文件</p><p>接着是模型的训练，部分的核心为 optimizer &amp; runner。其中 runner 包含了不同的 hook 以在每一个 epoch/iter 之前/之后进行需要的操作，例如：调整学习率、保存模型、记录数据等等。当然这些功能也是通过 config &amp; registry 来进行管理的</p><p>下面是一个完整的 config 文件及其简要注释说明，为 ResNet50 和 FPN 的 Mask R-CNN 的配置文件。配合之前的 tutorial，可以具体看看每个字段在 config 文件中的什么位置、有什么功能，帮助整体把握。当然也可以直接在 mmdetection github 项目上进行搜索，查找源码也是很方便的</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">model <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>    <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'MaskRCNN'</span><span class="token punctuation">,</span>  <span class="token comment"># 检测器(detector)名称</span>    backbone<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>  <span class="token comment"># 主干网络的配置文件</span>        <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'ResNet'</span><span class="token punctuation">,</span>  <span class="token comment"># 主干网络的类别，可用选项请参考 https://github.com/open-mmlab/mmdetection/blob/master/mmdet/models/backbones/resnet.py#L308</span>        depth<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span>  <span class="token comment"># 主干网络的深度，对于 ResNet 和 ResNext 通常设置为 50 或 101。</span>        num_stages<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span>  <span class="token comment"># 主干网络状态(stages)的数目，这些状态产生的特征图作为后续的 head 的输入。</span>        out_indices<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 每个状态产生的特征图输出的索引。</span>        frozen_stages<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>  <span class="token comment"># 第一个状态的权重被冻结</span>        norm_cfg<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>  <span class="token comment"># 归一化层(norm layer)的配置项。</span>            <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'BN'</span><span class="token punctuation">,</span>  <span class="token comment"># 归一化层的类别，通常是 BN 或 GN。</span>            requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 是否训练归一化里的 gamma 和 beta。</span>        norm_eval<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>  <span class="token comment"># 是否冻结 BN 里的统计项。</span>        style<span class="token operator">=</span><span class="token string">'pytorch'</span><span class="token punctuation">,</span>  <span class="token comment"># 主干网络的风格，'pytorch' 意思是步长为2的层为 3x3 卷积， 'caffe' 意思是步长为2的层为 1x1 卷积。</span>       init_cfg<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'Pretrained'</span><span class="token punctuation">,</span> checkpoint<span class="token operator">=</span><span class="token string">'torchvision://resnet50'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 加载通过 ImageNet 与训练的模型</span>    neck<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>        <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'FPN'</span><span class="token punctuation">,</span>  <span class="token comment"># 检测器的 neck 是 FPN，我们同样支持 'NASFPN', 'PAFPN' 等，更多细节可以参考 https://github.com/open-mmlab/mmdetection/blob/master/mmdet/models/necks/fpn.py#L10。</span>        in_channels<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">,</span> <span class="token number">2048</span><span class="token punctuation">]</span><span class="token punctuation">,</span>  <span class="token comment"># 输入通道数，这与主干网络的输出通道一致</span>        out_channels<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span>  <span class="token comment"># 金字塔特征图每一层的输出通道</span>        num_outs<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 输出的范围(scales)</span>    rpn_head<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>        <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'RPNHead'</span><span class="token punctuation">,</span>  <span class="token comment"># RPN_head 的类型是 'RPNHead', 我们也支持 'GARPNHead' 等，更多细节可以参考 https://github.com/open-mmlab/mmdetection/blob/master/mmdet/models/dense_heads/rpn_head.py#L12。</span>        in_channels<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span>  <span class="token comment"># 每个输入特征图的输入通道，这与 neck 的输出通道一致。</span>        feat_channels<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span>  <span class="token comment"># head 卷积层的特征通道。</span>        anchor_generator<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>  <span class="token comment"># 锚点(Anchor)生成器的配置。</span>            <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'AnchorGenerator'</span><span class="token punctuation">,</span>  <span class="token comment"># 大多是方法使用 AnchorGenerator 作为锚点生成器, SSD 检测器使用 `SSDAnchorGenerator`。更多细节请参考 https://github.com/open-mmlab/mmdetection/blob/master/mmdet/core/anchor/anchor_generator.py#L10。</span>            scales<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">,</span>  <span class="token comment"># 锚点的基本比例，特征图某一位置的锚点面积为 scale * base_sizes</span>            ratios<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">2.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>  <span class="token comment"># 高度和宽度之间的比率。</span>            strides<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 锚生成器的步幅。这与 FPN 特征步幅一致。 如果未设置 base_sizes，则当前步幅值将被视为 base_sizes。</span>        bbox_coder<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>  <span class="token comment"># 在训练和测试期间对框进行编码和解码。</span>            <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'DeltaXYWHBBoxCoder'</span><span class="token punctuation">,</span>  <span class="token comment"># 框编码器的类别，'DeltaXYWHBBoxCoder' 是最常用的，更多细节请参考 https://github.com/open-mmlab/mmdetection/blob/master/mmdet/core/bbox/coder/delta_xywh_bbox_coder.py#L9。</span>            target_means<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>  <span class="token comment"># 用于编码和解码框的目标均值</span>            target_stds<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 用于编码和解码框的标准方差</span>        loss_cls<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>  <span class="token comment"># 分类分支的损失函数配置</span>            <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'CrossEntropyLoss'</span><span class="token punctuation">,</span>  <span class="token comment"># 分类分支的损失类型，我们也支持 FocalLoss 等。</span>            use_sigmoid<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>  <span class="token comment"># RPN通常进行二分类，所以通常使用sigmoid函数。</span>            los_weight<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 分类分支的损失权重。</span>        loss_bbox<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>  <span class="token comment"># 回归分支的损失函数配置。</span>            <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'L1Loss'</span><span class="token punctuation">,</span>  <span class="token comment"># 损失类型，我们还支持许多 IoU Losses 和 Smooth L1-loss 等，更多细节请参考 https://github.com/open-mmlab/mmdetection/blob/master/mmdet/models/losses/smooth_l1_loss.py#L56。</span>            loss_weight<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 回归分支的损失权重。</span>    roi_head<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>  <span class="token comment"># RoIHead 封装了两步(two-stage)/级联(cascade)检测器的第二步。</span>        <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'StandardRoIHead'</span><span class="token punctuation">,</span>  <span class="token comment"># RoI head 的类型，更多细节请参考 https://github.com/open-mmlab/mmdetection/blob/master/mmdet/models/roi_heads/standard_roi_head.py#L10。</span>        bbox_roi_extractor<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>  <span class="token comment"># 用于 bbox 回归的 RoI 特征提取器。</span>            <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'SingleRoIExtractor'</span><span class="token punctuation">,</span>  <span class="token comment"># RoI 特征提取器的类型，大多数方法使用  SingleRoIExtractor，更多细节请参考 https://github.com/open-mmlab/mmdetection/blob/master/mmdet/models/roi_heads/roi_extractors/single_level.py#L10。</span>            roi_layer<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>  <span class="token comment"># RoI 层的配置</span>                <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'RoIAlign'</span><span class="token punctuation">,</span>  <span class="token comment"># RoI 层的类别, 也支持 DeformRoIPoolingPack 和 ModulatedDeformRoIPoolingPack，更多细节请参考 https://github.com/open-mmlab/mmdetection/blob/master/mmdet/ops/roi_align/roi_align.py#L79。</span>                output_size<span class="token operator">=</span><span class="token number">7</span><span class="token punctuation">,</span>  <span class="token comment"># 特征图的输出大小。</span>                sampling_ratio<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 提取 RoI 特征时的采样率。0 表示自适应比率。</span>            out_channels<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span>  <span class="token comment"># 提取特征的输出通道。</span>            featmap_strides<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 多尺度特征图的步幅，应该与主干的架构保持一致。</span>        bbox_head<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>  <span class="token comment"># RoIHead 中 box head 的配置.</span>            <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'Shared2FCBBoxHead'</span><span class="token punctuation">,</span>  <span class="token comment"># bbox head 的类别，更多细节请参考 https://github.com/open-mmlab/mmdetection/blob/master/mmdet/models/roi_heads/bbox_heads/convfc_bbox_head.py#L177。</span>            in_channels<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span>  <span class="token comment"># bbox head 的输入通道。 这与 roi_extractor 中的 out_channels 一致。</span>            fc_out_channels<span class="token operator">=</span><span class="token number">1024</span><span class="token punctuation">,</span>  <span class="token comment"># FC 层的输出特征通道。</span>            roi_feat_size<span class="token operator">=</span><span class="token number">7</span><span class="token punctuation">,</span>  <span class="token comment"># 候选区域(Region of Interest)特征的大小。</span>            num_classes<span class="token operator">=</span><span class="token number">80</span><span class="token punctuation">,</span>  <span class="token comment"># 分类的类别数量。</span>            bbox_coder<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>  <span class="token comment"># 第二阶段使用的框编码器。</span>                <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'DeltaXYWHBBoxCoder'</span><span class="token punctuation">,</span>  <span class="token comment"># 框编码器的类别，大多数情况使用 'DeltaXYWHBBoxCoder'。</span>                target_means<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>  <span class="token comment"># 用于编码和解码框的均值</span>                target_stds<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 编码和解码的标准方差。因为框更准确，所以值更小，常规设置时 [0.1, 0.1, 0.2, 0.2]。</span>            reg_class_agnostic<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>  <span class="token comment"># 回归是否与类别无关。</span>            loss_cls<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>  <span class="token comment"># 分类分支的损失函数配置</span>                <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'CrossEntropyLoss'</span><span class="token punctuation">,</span>  <span class="token comment"># 分类分支的损失类型，我们也支持 FocalLoss 等。</span>                use_sigmoid<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>  <span class="token comment"># 是否使用 sigmoid。</span>                loss_weight<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 分类分支的损失权重。</span>            loss_bbox<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>  <span class="token comment"># 回归分支的损失函数配置。</span>                <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'L1Loss'</span><span class="token punctuation">,</span>  <span class="token comment"># 损失类型，我们还支持许多 IoU Losses 和 Smooth L1-loss 等。</span>                loss_weight<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 回归分支的损失权重。</span>        mask_roi_extractor<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>  <span class="token comment"># 用于 mask 生成的 RoI 特征提取器。</span>            <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'SingleRoIExtractor'</span><span class="token punctuation">,</span>  <span class="token comment"># RoI 特征提取器的类型，大多数方法使用 SingleRoIExtractor。</span>            roi_layer<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>  <span class="token comment"># 提取实例分割特征的 RoI 层配置</span>                <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'RoIAlign'</span><span class="token punctuation">,</span>  <span class="token comment"># RoI 层的类型，也支持 DeformRoIPoolingPack 和 ModulatedDeformRoIPoolingPack。</span>                output_size<span class="token operator">=</span><span class="token number">14</span><span class="token punctuation">,</span>  <span class="token comment"># 特征图的输出大小。</span>                sampling_ratio<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 提取 RoI 特征时的采样率。</span>            out_channels<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span>  <span class="token comment"># 提取特征的输出通道。</span>            featmap_strides<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 多尺度特征图的步幅。</span>        mask_head<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>  <span class="token comment"># mask 预测 head 模型</span>            <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'FCNMaskHead'</span><span class="token punctuation">,</span>  <span class="token comment"># mask head 的类型，更多细节请参考 https://github.com/open-mmlab/mmdetection/blob/master/mmdet/models/roi_heads/mask_heads/fcn_mask_head.py#L21。</span>            num_convs<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span>  <span class="token comment"># mask head 中的卷积层数</span>            in_channels<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span>  <span class="token comment"># 输入通道，应与 mask roi extractor 的输出通道一致。</span>            conv_out_channels<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span>  <span class="token comment"># 卷积层的输出通道。</span>            num_classes<span class="token operator">=</span><span class="token number">80</span><span class="token punctuation">,</span>  <span class="token comment"># 要分割的类别数。</span>            loss_mask<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>  <span class="token comment"># mask 分支的损失函数配置。</span>                <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'CrossEntropyLoss'</span><span class="token punctuation">,</span>  <span class="token comment"># 用于分割的损失类型。</span>                use_mask<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>  <span class="token comment"># 是否只在正确的类中训练 mask。</span>                loss_weight<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># mask 分支的损失权重.</span>    train_cfg <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>  <span class="token comment"># rpn 和 rcnn 训练超参数的配置</span>        rpn<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>  <span class="token comment"># rpn 的训练配置</span>            assigner<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>  <span class="token comment"># 分配器(assigner)的配置</span>                <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'MaxIoUAssigner'</span><span class="token punctuation">,</span>  <span class="token comment"># 分配器的类型，MaxIoUAssigner 用于许多常见的检测器，更多细节请参考 https://github.com/open-mmlab/mmdetection/blob/master/mmdet/core/bbox/assigners/max_iou_assigner.py#L10。</span>                pos_iou_thr<span class="token operator">=</span><span class="token number">0.7</span><span class="token punctuation">,</span>  <span class="token comment"># IoU &gt;= 0.7(阈值) 被视为正样本。</span>                neg_iou_thr<span class="token operator">=</span><span class="token number">0.3</span><span class="token punctuation">,</span>  <span class="token comment"># IoU &lt; 0.3(阈值) 被视为负样本。</span>                min_pos_iou<span class="token operator">=</span><span class="token number">0.3</span><span class="token punctuation">,</span>  <span class="token comment"># 将框作为正样本的最小 IoU 阈值。</span>                match_low_quality<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>  <span class="token comment"># 是否匹配低质量的框(更多细节见 API 文档).</span>                ignore_iof_thr<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 忽略 bbox 的 IoF 阈值。</span>            sampler<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>  <span class="token comment"># 正/负采样器(sampler)的配置</span>                <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'RandomSampler'</span><span class="token punctuation">,</span>  <span class="token comment"># 采样器类型，还支持 PseudoSampler 和其他采样器，更多细节请参考 https://github.com/open-mmlab/mmdetection/blob/master/mmdet/core/bbox/samplers/random_sampler.py#L8。</span>                num<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span>  <span class="token comment"># 样本数量。</span>                pos_fraction<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span>  <span class="token comment"># 正样本占总样本的比例。</span>                neg_pos_ub<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span>  <span class="token comment"># 基于正样本数量的负样本上限。</span>                add_gt_as_proposals<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 采样后是否添加 GT 作为 proposal。</span>            allowed_border<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span>  <span class="token comment"># 填充有效锚点后允许的边框。</span>            pos_weight<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span>  <span class="token comment"># 训练期间正样本的权重。</span>            debug<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 是否设置调试(debug)模式</span>        rpn_proposal<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>  <span class="token comment"># 在训练期间生成 proposals 的配置</span>            nms_across_levels<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>  <span class="token comment"># 是否对跨层的 box 做 NMS。仅适用于 `GARPNHead` ，naive rpn 不支持 nms cross levels。</span>            nms_pre<span class="token operator">=</span><span class="token number">2000</span><span class="token punctuation">,</span>  <span class="token comment"># NMS 前的 box 数</span>            nms_post<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">,</span>  <span class="token comment"># NMS 要保留的 box 的数量，只在 GARPNHHead 中起作用。</span>            max_per_img<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">,</span>  <span class="token comment"># NMS 后要保留的 box 数量。</span>            nms<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span> <span class="token comment"># NMS 的配置</span>                <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'nms'</span><span class="token punctuation">,</span>  <span class="token comment"># NMS 的类别</span>                iou_threshold<span class="token operator">=</span><span class="token number">0.7</span> <span class="token comment"># NMS 的阈值</span>                <span class="token punctuation">)</span><span class="token punctuation">,</span>            min_bbox_size<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 允许的最小 box 尺寸</span>        rcnn<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>  <span class="token comment"># roi head 的配置。</span>            assigner<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>  <span class="token comment"># 第二阶段分配器的配置，这与 rpn 中的不同</span>                <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'MaxIoUAssigner'</span><span class="token punctuation">,</span>  <span class="token comment"># 分配器的类型，MaxIoUAssigner 目前用于所有 roi_heads。更多细节请参考 https://github.com/open-mmlab/mmdetection/blob/master/mmdet/core/bbox/assigners/max_iou_assigner.py#L10。</span>                pos_iou_thr<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span>  <span class="token comment"># IoU &gt;= 0.5(阈值)被认为是正样本。</span>                neg_iou_thr<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span>  <span class="token comment"># IoU &lt; 0.5(阈值)被认为是负样本。</span>                min_pos_iou<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span>  <span class="token comment"># 将 box 作为正样本的最小 IoU 阈值</span>                match_low_quality<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>  <span class="token comment"># 是否匹配低质量下的 box(有关更多详细信息，请参阅 API 文档)。</span>                ignore_iof_thr<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 忽略 bbox 的 IoF 阈值</span>            sampler<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>                <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'RandomSampler'</span><span class="token punctuation">,</span>  <span class="token comment">#采样器的类型，还支持 PseudoSampler 和其他采样器，更多细节请参考 https://github.com/open-mmlab/mmdetection/blob/master/mmdet/core/bbox/samplers/random_sampler.py#L8。</span>                num<span class="token operator">=</span><span class="token number">512</span><span class="token punctuation">,</span>  <span class="token comment"># 样本数量</span>                pos_fraction<span class="token operator">=</span><span class="token number">0.25</span><span class="token punctuation">,</span>  <span class="token comment"># 正样本占总样本的比例。.</span>                neg_pos_ub<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span>  <span class="token comment"># 基于正样本数量的负样本上限。.</span>                add_gt_as_proposals<span class="token operator">=</span><span class="token boolean">True</span>            <span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 采样后是否添加 GT 作为 proposal。</span>            mask_size<span class="token operator">=</span><span class="token number">28</span><span class="token punctuation">,</span>  <span class="token comment"># mask 的大小</span>            pos_weight<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span>  <span class="token comment"># 训练期间正样本的权重。</span>            debug<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 是否设置调试模式。</span>    test_cfg <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>  <span class="token comment"># 用于测试 rnn 和 rnn 超参数的配置</span>        rpn<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>  <span class="token comment"># 测试阶段生成 proposals 的配置</span>            nms_across_levels<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>  <span class="token comment"># 是否对跨层的 box 做 NMS。仅适用于`GARPNHead`，naive rpn 不支持做 NMS cross levels。</span>            nms_pre<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">,</span>  <span class="token comment"># NMS 前的 box 数</span>            nms_post<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">,</span>  <span class="token comment"># NMS 要保留的 box 的数量，只在`GARPNHHead`中起作用。</span>            max_per_img<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">,</span>  <span class="token comment"># NMS 后要保留的 box 数量</span>            nms<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span> <span class="token comment"># NMS 的配置</span>                <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'nms'</span><span class="token punctuation">,</span>  <span class="token comment"># NMS 的类型</span>                iou_threshold<span class="token operator">=</span><span class="token number">0.7</span> <span class="token comment"># NMS 阈值</span>                <span class="token punctuation">)</span><span class="token punctuation">,</span>            min_bbox_size<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># box 允许的最小尺寸</span>        rcnn<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>  <span class="token comment"># roi heads 的配置</span>            score_thr<span class="token operator">=</span><span class="token number">0.05</span><span class="token punctuation">,</span>  <span class="token comment"># bbox 的分数阈值</span>            nms<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>  <span class="token comment"># 第二步的 NMS 配置</span>                <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'nms'</span><span class="token punctuation">,</span>  <span class="token comment"># NMS 的类型</span>                iou_thr<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># NMS 的阈值</span>            max_per_img<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span>  <span class="token comment"># 每张图像的最大检测次数</span>            mask_thr_binary<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># mask 预处的阈值</span>dataset_type <span class="token operator">=</span> <span class="token string">'CocoDataset'</span>  <span class="token comment"># 数据集类型，这将被用来定义数据集。</span>data_root <span class="token operator">=</span> <span class="token string">'data/coco/'</span>  <span class="token comment"># 数据的根路径。</span>img_norm_cfg <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>  <span class="token comment">#图像归一化配置，用来归一化输入的图像。</span>    mean<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">123.675</span><span class="token punctuation">,</span> <span class="token number">116.28</span><span class="token punctuation">,</span> <span class="token number">103.53</span><span class="token punctuation">]</span><span class="token punctuation">,</span>  <span class="token comment"># 预训练里用于预训练主干网络模型的平均值。</span>    std<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">58.395</span><span class="token punctuation">,</span> <span class="token number">57.12</span><span class="token punctuation">,</span> <span class="token number">57.375</span><span class="token punctuation">]</span><span class="token punctuation">,</span>  <span class="token comment"># 预训练里用于预训练主干网络模型的标准差。</span>    to_rgb<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment">#  预训练里用于预训练主干网络的图像的通道顺序。</span>train_pipeline <span class="token operator">=</span> <span class="token punctuation">[</span>  <span class="token comment"># 训练流程</span>    <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'LoadImageFromFile'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 第 1 个流程，从文件路径里加载图像。</span>    <span class="token builtin">dict</span><span class="token punctuation">(</span>        <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'LoadAnnotations'</span><span class="token punctuation">,</span>  <span class="token comment"># 第 2 个流程，对于当前图像，加载它的注释信息。</span>        with_bbox<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>  <span class="token comment"># 是否使用标注框(bounding box)， 目标检测需要设置为 True。</span>        with_mask<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>  <span class="token comment"># 是否使用 instance mask，实例分割需要设置为 True。</span>        poly2mask<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 是否将 polygon mask 转化为 instance mask, 设置为 False 以加速和节省内存。</span>    <span class="token builtin">dict</span><span class="token punctuation">(</span>        <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'Resize'</span><span class="token punctuation">,</span>  <span class="token comment"># 变化图像和其注释大小的数据增广的流程。</span>        img_scale<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1333</span><span class="token punctuation">,</span> <span class="token number">800</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 图像的最大规模。</span>        keep_ratio<span class="token operator">=</span><span class="token boolean">True</span>    <span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 是否保持图像的长宽比。</span>    <span class="token builtin">dict</span><span class="token punctuation">(</span>        <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'RandomFlip'</span><span class="token punctuation">,</span>  <span class="token comment">#  翻转图像和其注释大小的数据增广的流程。</span>        flip_ratio<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 翻转图像的概率。</span>    <span class="token builtin">dict</span><span class="token punctuation">(</span>        <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'Normalize'</span><span class="token punctuation">,</span>  <span class="token comment"># 归一化当前图像的数据增广的流程。</span>        mean<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">123.675</span><span class="token punctuation">,</span> <span class="token number">116.28</span><span class="token punctuation">,</span> <span class="token number">103.53</span><span class="token punctuation">]</span><span class="token punctuation">,</span>  <span class="token comment"># 这些键与 img_norm_cfg 一致，因为 img_norm_cfg 被</span>        std<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">58.395</span><span class="token punctuation">,</span> <span class="token number">57.12</span><span class="token punctuation">,</span> <span class="token number">57.375</span><span class="token punctuation">]</span><span class="token punctuation">,</span>     <span class="token comment"># 用作参数。</span>        to_rgb<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token builtin">dict</span><span class="token punctuation">(</span>        <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'Pad'</span><span class="token punctuation">,</span>  <span class="token comment"># 填充当前图像到指定大小的数据增广的流程。</span>        size_divisor<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 填充图像可以被当前值整除。</span>    <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'DefaultFormatBundle'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 流程里收集数据的默认格式捆。</span>    <span class="token builtin">dict</span><span class="token punctuation">(</span>        <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'Collect'</span><span class="token punctuation">,</span>  <span class="token comment"># 决定数据中哪些键应该传递给检测器的流程</span>        keys<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'img'</span><span class="token punctuation">,</span> <span class="token string">'gt_bboxes'</span><span class="token punctuation">,</span> <span class="token string">'gt_labels'</span><span class="token punctuation">,</span> <span class="token string">'gt_masks'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span>test_pipeline <span class="token operator">=</span> <span class="token punctuation">[</span>    <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'LoadImageFromFile'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 第 1 个流程，从文件路径里加载图像。</span>    <span class="token builtin">dict</span><span class="token punctuation">(</span>        <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'MultiScaleFlipAug'</span><span class="token punctuation">,</span>  <span class="token comment"># 封装测试时数据增广(test time augmentations)。</span>        img_scale<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1333</span><span class="token punctuation">,</span> <span class="token number">800</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 决定测试时可改变图像的最大规模。用于改变图像大小的流程。</span>        flip<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>  <span class="token comment"># 测试时是否翻转图像。</span>        transforms<span class="token operator">=</span><span class="token punctuation">[</span>            <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'Resize'</span><span class="token punctuation">,</span>  <span class="token comment"># 使用改变图像大小的数据增广。</span>                 keep_ratio<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 是否保持宽和高的比例，这里的图像比例设置将覆盖上面的图像规模大小的设置。</span>            <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'RandomFlip'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 考虑到 RandomFlip 已经被添加到流程里，当 flip=False 时它将不被使用。</span>            <span class="token builtin">dict</span><span class="token punctuation">(</span>                <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'Normalize'</span><span class="token punctuation">,</span>  <span class="token comment">#  归一化配置项，值来自 img_norm_cfg。</span>                mean<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">123.675</span><span class="token punctuation">,</span> <span class="token number">116.28</span><span class="token punctuation">,</span> <span class="token number">103.53</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                std<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">58.395</span><span class="token punctuation">,</span> <span class="token number">57.12</span><span class="token punctuation">,</span> <span class="token number">57.375</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                to_rgb<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token builtin">dict</span><span class="token punctuation">(</span>                <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'Pad'</span><span class="token punctuation">,</span>  <span class="token comment"># 将配置传递给可被 32 整除的图像。</span>                size_divisor<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token builtin">dict</span><span class="token punctuation">(</span>                <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'ImageToTensor'</span><span class="token punctuation">,</span>  <span class="token comment"># 将图像转为张量</span>                keys<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'img'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token builtin">dict</span><span class="token punctuation">(</span>                <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'Collect'</span><span class="token punctuation">,</span>  <span class="token comment"># 收集测试时必须的键的收集流程。</span>                keys<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'img'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span>data <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>    samples_per_gpu<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>  <span class="token comment"># 单个 GPU 的 Batch size</span>    workers_per_gpu<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>  <span class="token comment"># 单个 GPU 分配的数据加载线程数</span>    train<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>  <span class="token comment"># 训练数据集配置</span>        <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'CocoDataset'</span><span class="token punctuation">,</span>  <span class="token comment"># 数据集的类别, 更多细节请参考 https://github.com/open-mmlab/mmdetection/blob/master/mmdet/datasets/coco.py#L19。</span>        ann_file<span class="token operator">=</span><span class="token string">'data/coco/annotations/instances_train2017.json'</span><span class="token punctuation">,</span>  <span class="token comment"># 注释文件路径</span>        img_prefix<span class="token operator">=</span><span class="token string">'data/coco/train2017/'</span><span class="token punctuation">,</span>  <span class="token comment"># 图片路径前缀</span>        pipeline<span class="token operator">=</span><span class="token punctuation">[</span>  <span class="token comment"># 流程, 这是由之前创建的 train_pipeline 传递的。</span>            <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'LoadImageFromFile'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token builtin">dict</span><span class="token punctuation">(</span>                <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'LoadAnnotations'</span><span class="token punctuation">,</span>                with_bbox<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>                with_mask<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>                poly2mask<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'Resize'</span><span class="token punctuation">,</span> img_scale<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1333</span><span class="token punctuation">,</span> <span class="token number">800</span><span class="token punctuation">)</span><span class="token punctuation">,</span> keep_ratio<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'RandomFlip'</span><span class="token punctuation">,</span> flip_ratio<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token builtin">dict</span><span class="token punctuation">(</span>                <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'Normalize'</span><span class="token punctuation">,</span>                mean<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">123.675</span><span class="token punctuation">,</span> <span class="token number">116.28</span><span class="token punctuation">,</span> <span class="token number">103.53</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                std<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">58.395</span><span class="token punctuation">,</span> <span class="token number">57.12</span><span class="token punctuation">,</span> <span class="token number">57.375</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                to_rgb<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'Pad'</span><span class="token punctuation">,</span> size_divisor<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'DefaultFormatBundle'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token builtin">dict</span><span class="token punctuation">(</span>                <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'Collect'</span><span class="token punctuation">,</span>                keys<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'img'</span><span class="token punctuation">,</span> <span class="token string">'gt_bboxes'</span><span class="token punctuation">,</span> <span class="token string">'gt_labels'</span><span class="token punctuation">,</span> <span class="token string">'gt_masks'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    val<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>  <span class="token comment"># 验证数据集的配置</span>        <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'CocoDataset'</span><span class="token punctuation">,</span>        ann_file<span class="token operator">=</span><span class="token string">'data/coco/annotations/instances_val2017.json'</span><span class="token punctuation">,</span>        img_prefix<span class="token operator">=</span><span class="token string">'data/coco/val2017/'</span><span class="token punctuation">,</span>        pipeline<span class="token operator">=</span><span class="token punctuation">[</span>  <span class="token comment"># 由之前创建的 test_pipeline 传递的流程。</span>            <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'LoadImageFromFile'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token builtin">dict</span><span class="token punctuation">(</span>                <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'MultiScaleFlipAug'</span><span class="token punctuation">,</span>                img_scale<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1333</span><span class="token punctuation">,</span> <span class="token number">800</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                flip<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>                transforms<span class="token operator">=</span><span class="token punctuation">[</span>                    <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'Resize'</span><span class="token punctuation">,</span> keep_ratio<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                    <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'RandomFlip'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                    <span class="token builtin">dict</span><span class="token punctuation">(</span>                        <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'Normalize'</span><span class="token punctuation">,</span>                        mean<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">123.675</span><span class="token punctuation">,</span> <span class="token number">116.28</span><span class="token punctuation">,</span> <span class="token number">103.53</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                        std<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">58.395</span><span class="token punctuation">,</span> <span class="token number">57.12</span><span class="token punctuation">,</span> <span class="token number">57.375</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                        to_rgb<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                    <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'Pad'</span><span class="token punctuation">,</span> size_divisor<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                    <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'ImageToTensor'</span><span class="token punctuation">,</span> keys<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'img'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                    <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'Collect'</span><span class="token punctuation">,</span> keys<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'img'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>                <span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    test<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>  <span class="token comment"># 测试数据集配置，修改测试开发/测试(test-dev/test)提交的 ann_file</span>        <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'CocoDataset'</span><span class="token punctuation">,</span>        ann_file<span class="token operator">=</span><span class="token string">'data/coco/annotations/instances_val2017.json'</span><span class="token punctuation">,</span>        img_prefix<span class="token operator">=</span><span class="token string">'data/coco/val2017/'</span><span class="token punctuation">,</span>        pipeline<span class="token operator">=</span><span class="token punctuation">[</span>  <span class="token comment"># 由之前创建的 test_pipeline 传递的流程。</span>            <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'LoadImageFromFile'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            <span class="token builtin">dict</span><span class="token punctuation">(</span>                <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'MultiScaleFlipAug'</span><span class="token punctuation">,</span>                img_scale<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1333</span><span class="token punctuation">,</span> <span class="token number">800</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                flip<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>                transforms<span class="token operator">=</span><span class="token punctuation">[</span>                    <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'Resize'</span><span class="token punctuation">,</span> keep_ratio<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                    <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'RandomFlip'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                    <span class="token builtin">dict</span><span class="token punctuation">(</span>                        <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'Normalize'</span><span class="token punctuation">,</span>                        mean<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">123.675</span><span class="token punctuation">,</span> <span class="token number">116.28</span><span class="token punctuation">,</span> <span class="token number">103.53</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                        std<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">58.395</span><span class="token punctuation">,</span> <span class="token number">57.12</span><span class="token punctuation">,</span> <span class="token number">57.375</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                        to_rgb<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                    <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'Pad'</span><span class="token punctuation">,</span> size_divisor<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                    <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'ImageToTensor'</span><span class="token punctuation">,</span> keys<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'img'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                    <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'Collect'</span><span class="token punctuation">,</span> keys<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'img'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>                <span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token punctuation">]</span><span class="token punctuation">,</span>        samples_per_gpu<span class="token operator">=</span><span class="token number">2</span>  <span class="token comment"># 单个 GPU 测试时的 Batch size</span>        <span class="token punctuation">)</span><span class="token punctuation">)</span>evaluation <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>  <span class="token comment"># evaluation hook 的配置，更多细节请参考 https://github.com/open-mmlab/mmdetection/blob/master/mmdet/core/evaluation/eval_hooks.py#L7。</span>    interval<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>  <span class="token comment"># 验证的间隔。</span>    metric<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'bbox'</span><span class="token punctuation">,</span> <span class="token string">'segm'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># 验证期间使用的指标。</span>optimizer <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>  <span class="token comment"># 用于构建优化器的配置文件。支持 PyTorch 中的所有优化器，同时它们的参数与 PyTorch 里的优化器参数一致。</span>    <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'SGD'</span><span class="token punctuation">,</span>  <span class="token comment"># 优化器种类，更多细节可参考 https://github.com/open-mmlab/mmdetection/blob/master/mmdet/core/optimizer/default_constructor.py#L13。</span>    lr<span class="token operator">=</span><span class="token number">0.02</span><span class="token punctuation">,</span>  <span class="token comment"># 优化器的学习率，参数的使用细节请参照对应的 PyTorch 文档。</span>    momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">,</span>  <span class="token comment"># 动量(Momentum)</span>    weight_decay<span class="token operator">=</span><span class="token number">0.0001</span><span class="token punctuation">)</span>  <span class="token comment"># SGD 的衰减权重(weight decay)。</span>optimizer_config <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>  <span class="token comment"># optimizer hook 的配置文件，执行细节请参考 https://github.com/open-mmlab/mmcv/blob/master/mmcv/runner/hooks/optimizer.py#L8。</span>    grad_clip<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span>  <span class="token comment"># 大多数方法不使用梯度限制(grad_clip)。</span>lr_config <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>  <span class="token comment"># 学习率调整配置，用于注册 LrUpdater hook。</span>    policy<span class="token operator">=</span><span class="token string">'step'</span><span class="token punctuation">,</span>  <span class="token comment"># 调度流程(scheduler)的策略，也支持 CosineAnnealing, Cyclic, 等。请从 https://github.com/open-mmlab/mmcv/blob/master/mmcv/runner/hooks/lr_updater.py#L9 参考 LrUpdater 的细节。</span>    warmup<span class="token operator">=</span><span class="token string">'linear'</span><span class="token punctuation">,</span>  <span class="token comment"># 预热(warmup)策略，也支持 `exp` 和 `constant`。</span>    warmup_iters<span class="token operator">=</span><span class="token number">500</span><span class="token punctuation">,</span>  <span class="token comment"># 预热的迭代次数</span>    warmup_ratio<span class="token operator">=</span>    <span class="token number">0.001</span><span class="token punctuation">,</span>  <span class="token comment"># 用于热身的起始学习率的比率</span>    step<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># 衰减学习率的起止回合数</span>runner <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>    <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'EpochBasedRunner'</span><span class="token punctuation">,</span>  <span class="token comment"># 将使用的 runner 的类别 (例如 IterBasedRunner 或 EpochBasedRunner)。</span>    max_epochs<span class="token operator">=</span><span class="token number">12</span><span class="token punctuation">)</span> <span class="token comment"># runner 总回合数， 对于 IterBasedRunner 使用 `max_iters`</span>checkpoint_config <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>  <span class="token comment"># Checkpoint hook 的配置文件。执行时请参考 https://github.com/open-mmlab/mmcv/blob/master/mmcv/runner/hooks/checkpoint.py。</span>    interval<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># 保存的间隔是 1。</span>log_config <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>  <span class="token comment"># register logger hook 的配置文件。</span>    interval<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span>  <span class="token comment"># 打印日志的间隔</span>    hooks<span class="token operator">=</span><span class="token punctuation">[</span>        <span class="token comment"># dict(type='TensorboardLoggerHook')  # 同样支持 Tensorboard 日志</span>        <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'TextLoggerHook'</span><span class="token punctuation">)</span>    <span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># 用于记录训练过程的记录器(logger)。</span>dist_params <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>backend<span class="token operator">=</span><span class="token string">'nccl'</span><span class="token punctuation">)</span>  <span class="token comment"># 用于设置分布式训练的参数，端口也同样可被设置。</span>log_level <span class="token operator">=</span> <span class="token string">'INFO'</span>  <span class="token comment"># 日志的级别。</span>load_from <span class="token operator">=</span> <span class="token boolean">None</span>  <span class="token comment"># 从一个给定路径里加载模型作为预训练模型，它并不会消耗训练时间。</span>resume_from <span class="token operator">=</span> <span class="token boolean">None</span>  <span class="token comment"># 从给定路径里恢复检查点(checkpoints)，训练模式将从检查点保存的轮次开始恢复训练。</span>workflow <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">'train'</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span>  <span class="token comment"># runner 的工作流程，[('train', 1)] 表示只有一个工作流且工作流仅执行一次。根据 total_epochs 工作流训练 12个回合。</span>work_dir <span class="token operator">=</span> <span class="token string">'work_dir'</span>  <span class="token comment"># 用于保存当前实验的模型检查点和日志的目录文件地址。</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h2><ol><li>学习 mmdetection 工具箱</li><li>实现一个项目</li></ol>]]></content>
      
      
      <categories>
          
          <category> 编程 </category>
          
          <category> OpenMMLab </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MMDetection </tag>
            
            <tag> MMLab </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>FFMPEG note</title>
      <link href="/archives/97736837.html"/>
      <url>/archives/97736837.html</url>
      
        <content type="html"><![CDATA[<h1 id="FFMPEG"><a href="#FFMPEG" class="headerlink" title="FFMPEG"></a>FFMPEG</h1><h2 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h2><h3 id="01-下载，配置"><a href="#01-下载，配置" class="headerlink" title="01.下载，配置"></a>01.下载，配置</h3><p>用的系统是 Ubuntu 可以直接 apt-get</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> ffmpeg<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>windows 可以去官网下载 <a href="https://www.gyan.dev/ffmpeg/builds/">windows build</a></p><h3 id="02-简介，上手-FFmpeg-FFprobe-FFplay"><a href="#02-简介，上手-FFmpeg-FFprobe-FFplay" class="headerlink" title="02.简介，上手(FFmpeg FFprobe FFplay)"></a>02.简介，上手(FFmpeg FFprobe FFplay)</h3><p>(1) 查看 ffmpeg 的帮助说明，提供的指令。建议将其中的命令大致看看，在本笔记最后附有该帮助说明</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">ffmpeg -h<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(2) 播放媒体的指令</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">ffplay video.mp4ffplay music.mp3<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>(3) 常用快捷键</p><p>按键”Q”或”Esc”：退出媒体播放<br>键盘方向键：媒体播放的前进后退<br>点击鼠标右键：拖动到该播放位置<br>按键”F”：全屏<br>按键”P”或空格键：暂停<br>按键”W”:切换显示模式</p><p>(4) 查看媒体参数信息</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">ffprobe video.mp4<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>输出形如下面的内容</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">Stream <span class="token comment">#0:0[0x1](und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(tv, bt709), 1440x720, 163 kb/s, 30 fps, 30 tbr, 16k tbn (default)</span>    Metadata:      handler_name    <span class="token builtin class-name">:</span> VideoHandler      vendor_id       <span class="token builtin class-name">:</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>Stream <span class="token comment">#0:1[0x2](und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 128 kb/s (default)</span>    Metadata:      handler_name    <span class="token builtin class-name">:</span> SoundHandler      vendor_id       <span class="token builtin class-name">:</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以看到视频为 h264 编码，分辨率 1440x720、比特率(码率) 163 kb/s、帧率 30 fps。音频为 acc 编码，音频采样率 44100 Hz，比特率 128 kb/s</p><h3 id="03-转换格式-文件格式-封装格式"><a href="#03-转换格式-文件格式-封装格式" class="headerlink" title="03.转换格式(文件格式,封装格式)"></a>03.转换格式(文件格式,封装格式)</h3><p>(1) 文件名可以是中英文，但不能有空格</p><p>(2) <strong>转换格式</strong></p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">ffmpeg -i video.mp4 video_avi.avi<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>ffmpeg 使用 -i 参数来表示输入文件，也可以用 -f 参数指定输出格式，但为了省事儿好像也可以不用指定，ffmpeg 会根据输出文件名的后缀自动识别</p><h3 id="04-提取音视频"><a href="#04-提取音视频" class="headerlink" title="04.提取音视频"></a>04.提取音视频</h3><p>(1) 单独提取视频（不含音频流）</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">ffmpeg -i video.mp4 -vcodec copy -an video_silent.mp4<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(2) 单独提取音频（不含视频流）</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">ffmpeg -i video.mp4 -vn -acodec copy video_novideo.m4a<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>具备多个音频流的，如</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">Stream <span class="token comment">#0:2[0x81]:Audio:ac3,48000Hz,5.1,s16,384kb/s</span>Stream <span class="token comment">#0:3[0x82]:Audio:ac3,48000Hz,5.1,s16,384kb/s</span>Stream <span class="token comment">#0:4[0x80]:Audio:ac3,48000Hz,5.1,s16,448kb/s</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>针对性的单一的提取，例如提取第2条，用指令： -map 0:3</p><p>(3) 合并音视频</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">ffmpeg -i video_novideo.m4a -i video_silent.mp4 -c copy video_merge.mp4<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>-c 为 -codec 的缩写，传入参数 copy 即使用原视频/音频编码器，这样会大大加快处理时间而不用重新转码。一般在 codec 前/后有 a/v 即代表音频/视频</p><h3 id="05-截取，连接音视频"><a href="#05-截取，连接音视频" class="headerlink" title="05.截取，连接音视频"></a>05.截取，连接音视频</h3><p>(1) 截取</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">ffmpeg -i music.mp3 -ss 00:00:30 -to 00:02:00 -acodec copy music_cutout.mp3<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>输入时间可以是如上的 <code>时:分:秒</code>，也可以是 <code>分:秒</code>，也可以直接输入多少秒，秒可以是浮点数。还可以截取指定长度的音视频，如截取60秒</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">ffmpeg -i music.mp3 -ss 00:00:30 -t <span class="token number">60</span> -acodec copy music_cutout60s.mp3<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>-sseof time_offset: 开始时间从媒体末尾开始计算，传入参数为复数</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">ffmpeg -i in.mp4 -ss 00:01:00 -to 00:01:10 -c copy out.mp4ffmpeg -ss 00:01:00 -i in.mp4 -to 00:01:10 -c copy out.mp4ffmpeg -ss 00:01:00 -i in.mp4 -to 00:01:10 -c copy -copyts out.mp4<span class="token comment"># 从末尾往前 10s 截取 5s</span>ffmpeg -sseof -10 -t <span class="token number">5</span> -i in.mp4 -c copy out.mp4<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>把-ss放到-i之前，启用了关键帧技术，加速操作。但截取的时间段不一定准确。可用最后一条指令，保留时间戳，保证时间准确。</p><p>(2) 连接音视频</p><p>我推荐使用下面的方法</p><ol><li><p>新建一个 list.txt 文件，里面包含了需要连接的音视频。格式如下</p><pre class="line-numbers language-txt" data-language="txt"><code class="language-txt">file '/path/to/file1'file '/path/to/file2'file '/path/to/file3'<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li><li><p>可以使用 -f concat，来合并音视频</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">ffmpeg -f concat -i mylist.txt -c copy output.mp4<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li></ol><p>对于精细的音视频连接并不推荐使用 ffmeg</p><h3 id="06-v2img-amp-img2v，水印，gif"><a href="#06-v2img-amp-img2v，水印，gif" class="headerlink" title="06.v2img &amp; img2v，水印，gif"></a>06.v2img &amp; img2v，水印，gif</h3><p>(1) 截图.</p><p>截取第7秒第1帧的画面</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">ffmpeg -i video.mp4 -ss <span class="token number">7</span> -vframes <span class="token number">1</span> video_image.jpg<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>视频分离成图片</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">ffmpeg -i input_test.mp4 -r <span class="token number">1</span> -f image2 output_image-%03d.png<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>图片也能合成为视频</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">ffmpeg -f image2 -r <span class="token number">15</span> -i output_image-%03d.png output_test.mp4<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这里的 <code>-r</code> 代表 rate 可以理解为帧率。<code>output_image-%03d.png</code> 是图片的命名格式，这种形式在 python 格式化字符串中经常看到</p><p>注意，这里选择 png 格式而不是 jpg 格式是因为 png 为无损压缩图，这样在视频和图片的转换当中，就不会有损失</p><p>(2) 水印</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">ffmpeg -i video.mp4 -i qt.png -filter_complex <span class="token string">"overlay=20:80"</span> video_watermark.mp4<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(3) 截取动图</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">ffmpeg -i video.mp4 -ss <span class="token number">7.5</span> -to <span class="token number">8.5</span> -s 640x320 -r <span class="token number">15</span> video_gif.gif<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="补充：视频编码"><a href="#补充：视频编码" class="headerlink" title="补充：视频编码"></a>补充：视频编码</h2><h3 id="01-改变编码-上-编码-音频转码"><a href="#01-改变编码-上-编码-音频转码" class="headerlink" title="01.改变编码 上(编码,音频转码)"></a>01.改变编码 上(编码,音频转码)</h3><p>(1)查看编解码器</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">ffmpeg -codecs<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(2)<strong>网站常用编码</strong></p><p>MP4封装：H264视频编码+ACC音频编码<br>WebM封装：VP8视频编码+Vorbis音频编码<br>OGG封装：Theora视频编码+Vorbis音频编码</p><p>(3)<strong>无损编码格式.flac转换编码</strong></p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">ffmpeg -i music_flac.flac -acodec libmp3lame -ar <span class="token number">44100</span> -ab 320k -ac <span class="token number">2</span> music_flac_mp3.mp3<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>说明：</strong></p><ul><li>acodec:audio Coder Decoder 音频编码解码器</li><li>libmp3lame:mp3解码器</li><li>ar:audio rate：音频采样率</li><li><strong>44100:设置音频的采样率44100。若不输入，默认用原音频的采样率</strong></li><li>ab:audio bit rate 音频比特率</li><li><strong>320k：设置音频的比特率。若不输入，默认128K</strong></li><li>ac: aduio channels 音频声道</li><li>2:声道数。若不输入，默认采用源音频的声道数</li></ul><p>概括：设置格式的基本套路-先是指名属性，然后跟着新的属性值</p><p>(4)查看结果属性</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">ffprobe music_flac_mp3.mp3<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="02-改变编码-中-视频压制"><a href="#02-改变编码-中-视频压制" class="headerlink" title="02.改变编码 中(视频压制)"></a>02.改变编码 中(视频压制)</h3><p>(1)视频转码</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">ffmpeg -i video.mp4 -s 1920x1080 -pix_fmt yuv420p -vcodec libx264 -preset medium -profile:v high -level:v <span class="token number">4.1</span> -crf <span class="token number">23</span> -acodec aac -ar <span class="token number">44100</span> -ac <span class="token number">2</span> -b:a 128k video_avi.avi<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>说明:</strong></p><ul><li><strong>-s 1920x1080：缩放视频新尺寸(size)</strong></li><li>-pix_fmt yuv420p：pixel format,用来设置视频颜色空间。参数查询：ffmpeg -pix_fmts</li><li>-vcodec libx264：video Coder Decoder，视频编码解码器</li><li>-preset medium: 编码器预设。参数：ultrafast,superfast,veryfast,faster,fast,medium,slow,slower,veryslow,placebo</li><li>-profile:v high :编码器配置，与压缩比有关。实时通讯-baseline,流媒体-main,超清视频-high</li><li>-level:v 4.1 ：对编码器设置的具体规范和限制，权衡压缩比和画质。</li><li>-crf 23 ：设置码率控制模式。constant rate factor-恒定速率因子模式。范围0~51,默认23。数值越小，画质越高。一般在8~28做出选择。</li><li><strong>-r 30 :设置视频帧率</strong></li><li>-acodec aac :audio Coder Decoder-音频编码解码器</li><li>-b:a 128k :音频比特率.大多数网站限制音频比特率128k,129k<br>其他参考上一个教程</li></ul><h3 id="03-改变编码-下-码率控制模式"><a href="#03-改变编码-下-码率控制模式" class="headerlink" title="03.改变编码 下(码率控制模式)"></a>03.改变编码 下(码率控制模式)</h3><p>ffmpeg支持的码率控制模式：-qp -crf -b</p><p>(1)  -qp :constant quantizer,恒定量化器模式 </p><p>无损压缩的例子（快速编码）</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">ffmpeg -i input -vcodec libx264 -preset ultrafast -qp <span class="token number">0</span> output.mkv<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>无损压缩的例子（高压缩比）</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">ffmpeg -i input -vcodec libx264 -preset veryslow -qp <span class="token number">0</span> output.mkv<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(2) -crf :constant rate factor,恒定速率因子模式</p><p>(3) -b ：bitrate,固定目标码率模式。一般不建议使用</p><p>3种模式默认单遍编码</p><p>VBR(Variable Bit Rate/动态比特率) 例子</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">ffmpeg -i input -vcodec libx264 -preset veryslow output<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>ABR(Average Bit Rate/平均比特率) 例子</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">ffmpeg -i input -vcodec libx264 -preset veryslow -b:v 3000k output<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>CBR(Constant Bit Rate/恒定比特率) 例子</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token punctuation">..</span>. -b:v 4000k -minrate 4000k -maxrate 4000k -bufsize 1835k <span class="token punctuation">..</span>.<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p>笔记来源：<a href="https://www.bilibili.com/video/av40146374">https://www.bilibili.com/video/av40146374</a></p><p>官方教程： <a href="http://ffmpeg.org/ffmpeg-all.html">http://ffmpeg.org/ffmpeg-all.html</a></p><p>博客：<a href="https://www.jianshu.com/p/f07f0be088d0">https://www.jianshu.com/p/f07f0be088d0</a></p><h2 id="帮助文档，用于查询"><a href="#帮助文档，用于查询" class="headerlink" title="帮助文档，用于查询"></a>帮助文档，用于查询</h2><p>下面是 ffmpeg 的帮助文档，用于查询</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">ffmpeg version <span class="token number">2021</span>-09-08-git-5e7e2e5031-full_build-www.gyan.dev Copyright <span class="token punctuation">(</span>c<span class="token punctuation">)</span> <span class="token number">2000</span>-2021 the FFmpeg developers  built with gcc <span class="token number">10.3</span>.0 <span class="token punctuation">(</span>Rev5, Built by MSYS2 project<span class="token punctuation">)</span>  configuration: --enable-gpl --enable-version3 --enable-static --disable-w32threads --disable-autodetect --enable-fontconfig --enable-iconv --enable-gnutls --enable-libxml2 --enable-gmp --enable-lzma --enable-libsnappy --enable-zlib --enable-librist --enable-libsrt --enable-libssh --enable-libzmq --enable-avisynth --enable-libbluray --enable-libcaca --enable-sdl2 --enable-libdav1d --enable-libzvbi --enable-librav1e --enable-libsvtav1 --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxvid --enable-libaom --enable-libopenjpeg --enable-libvpx --enable-libass --enable-frei0r --enable-libfreetype --enable-libfribidi --enable-libvidstab --enable-libvmaf --enable-libzimg --enable-amf --enable-cuda-llvm --enable-cuvid --enable-ffnvcodec --enable-nvdec --enable-nvenc --enable-d3d11va --enable-dxva2 --enable-libmfx --enable-libglslang --enable-vulkan --enable-opencl --enable-libcdio --enable-libgme --enable-libmodplug --enable-libopenmpt --enable-libopencore-amrwb --enable-libmp3lame --enable-libshine --enable-libtheora --enable-libtwolame --enable-libvo-amrwbenc --enable-libilbc --enable-libgsm --enable-libopencore-amrnb --enable-libopus --enable-libspeex --enable-libvorbis --enable-ladspa --enable-libbs2b --enable-libflite --enable-libmysofa --enable-librubberband --enable-libsoxr --enable-chromaprint  libavutil      <span class="token number">57</span>.  <span class="token number">4.101</span> / <span class="token number">57</span>.  <span class="token number">4.101</span>  libavcodec     <span class="token number">59</span>.  <span class="token number">7.102</span> / <span class="token number">59</span>.  <span class="token number">7.102</span>  libavformat    <span class="token number">59</span>.  <span class="token number">5.100</span> / <span class="token number">59</span>.  <span class="token number">5.100</span>  libavdevice    <span class="token number">59</span>.  <span class="token number">0.101</span> / <span class="token number">59</span>.  <span class="token number">0.101</span>  libavfilter     <span class="token number">8</span>.  <span class="token number">7.101</span> /  <span class="token number">8</span>.  <span class="token number">7.101</span>  libswscale      <span class="token number">6</span>.  <span class="token number">1.100</span> /  <span class="token number">6</span>.  <span class="token number">1.100</span>  libswresample   <span class="token number">4</span>.  <span class="token number">0.100</span> /  <span class="token number">4</span>.  <span class="token number">0.100</span>  libpostproc    <span class="token number">56</span>.  <span class="token number">0.100</span> / <span class="token number">56</span>.  <span class="token number">0.100</span>Hyper fast Audio and Video encoderusage: ffmpeg <span class="token punctuation">[</span>options<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token punctuation">[</span>infile options<span class="token punctuation">]</span> -i infile<span class="token punctuation">]</span><span class="token punctuation">..</span>. <span class="token punctuation">{</span><span class="token punctuation">[</span>outfile options<span class="token punctuation">]</span> outfile<span class="token punctuation">}</span><span class="token punctuation">..</span>.Getting help:    -h      -- print basic options    -h long -- print <span class="token function">more</span> options    -h full -- print all options <span class="token punctuation">(</span>including all <span class="token function">format</span> and codec specific options, very long<span class="token punctuation">)</span>    -h <span class="token assign-left variable">type</span><span class="token operator">=</span>name -- print all options <span class="token keyword">for</span> the named decoder/encoder/demuxer/muxer/filter/bsf/protocol    See <span class="token function">man</span> ffmpeg <span class="token keyword">for</span> detailed description of the options.Print <span class="token builtin class-name">help</span> / information / capabilities:-L                  show license-h topic            show <span class="token builtin class-name">help</span>-? topic            show <span class="token builtin class-name">help</span>-help topic         show <span class="token builtin class-name">help</span>--help topic        show <span class="token builtin class-name">help</span>-version            show version-buildconf          show build configuration-formats            show available formats-muxers             show available muxers-demuxers           show available demuxers-devices            show available devices-codecs             show available codecs-decoders           show available decoders-encoders           show available encoders-bsfs               show available bit stream filters-protocols          show available protocols-filters            show available filters-pix_fmts           show available pixel formats-layouts            show standard channel layouts-sample_fmts        show available audio sample formats-colors             show available color names-sources device     list sources of the input device-sinks device       list sinks of the output device-hwaccels           show available HW acceleration methodsGlobal options <span class="token punctuation">(</span>affect whole program instead of just one <span class="token function">file</span><span class="token punctuation">)</span>:-loglevel loglevel  <span class="token builtin class-name">set</span> logging level-v loglevel         <span class="token builtin class-name">set</span> logging level-report             generate a report-max_alloc bytes    <span class="token builtin class-name">set</span> maximum size of a single allocated block-y                  overwrite output files-n                  never overwrite output files-ignore_unknown     Ignore unknown stream types-filter_threads     number of non-complex filter threads-filter_complex_threads  number of threads <span class="token keyword">for</span> -filter_complex-stats              print progress report during encoding-max_error_rate maximum error rate  ratio of decoding errors <span class="token punctuation">(</span><span class="token number">0.0</span>: no errors, <span class="token number">1.0</span>: <span class="token number">100</span>% errors<span class="token punctuation">)</span> above <span class="token function">which</span> ffmpeg returns an error instead of success.-bits_per_raw_sample number  <span class="token builtin class-name">set</span> the number of bits per raw sample-vol volume         change audio volume <span class="token punctuation">(</span><span class="token number">256</span><span class="token operator">=</span>normal<span class="token punctuation">)</span>Per-file main options:-f <span class="token function">fmt</span>              force <span class="token function">format</span>-c codec            codec name-codec codec        codec name-pre preset         preset name-map_metadata outfile<span class="token punctuation">[</span>,metadata<span class="token punctuation">]</span>:infile<span class="token punctuation">[</span>,metadata<span class="token punctuation">]</span>  <span class="token builtin class-name">set</span> metadata information of outfile from infile-t duration         record or transcode <span class="token string">"duration"</span> seconds of audio/video-to time_stop       record or transcode stop <span class="token function">time</span>-fs limit_size      <span class="token builtin class-name">set</span> the limit <span class="token function">file</span> size <span class="token keyword">in</span> bytes-ss time_off        <span class="token builtin class-name">set</span> the start <span class="token function">time</span> offset-sseof time_off     <span class="token builtin class-name">set</span> the start <span class="token function">time</span> offset relative to EOF-seek_timestamp     enable/disable seeking by timestamp with -ss-timestamp <span class="token function">time</span>     <span class="token builtin class-name">set</span> the recording timestamp <span class="token punctuation">(</span><span class="token string">'now'</span> to <span class="token builtin class-name">set</span> the current <span class="token function">time</span><span class="token punctuation">)</span>-metadata <span class="token assign-left variable">string</span><span class="token operator">=</span>string  <span class="token function">add</span> metadata-program <span class="token assign-left variable">title</span><span class="token operator">=</span>string:st<span class="token operator">=</span>number<span class="token punctuation">..</span>.  <span class="token function">add</span> program with specified streams-target <span class="token builtin class-name">type</span>        specify target <span class="token function">file</span> <span class="token builtin class-name">type</span> <span class="token punctuation">(</span><span class="token string">"vcd"</span>, <span class="token string">"svcd"</span>, <span class="token string">"dvd"</span>, <span class="token string">"dv"</span> or <span class="token string">"dv50"</span> with optional prefixes <span class="token string">"pal-"</span>, <span class="token string">"ntsc-"</span> or <span class="token string">"film-"</span><span class="token punctuation">)</span>-apad               audio pad-frames number      <span class="token builtin class-name">set</span> the number of frames to output-filter filter_graph  <span class="token builtin class-name">set</span> stream filtergraph-filter_script filename  <span class="token builtin class-name">read</span> stream filtergraph description from a <span class="token function">file</span>-reinit_filter      reinit filtergraph on input parameter changes-discard            discard-disposition        dispositionVideo options:-vframes number     <span class="token builtin class-name">set</span> the number of video frames to output-r rate             <span class="token builtin class-name">set</span> frame rate <span class="token punctuation">(</span>Hz value, fraction or abbreviation<span class="token punctuation">)</span>-fpsmax rate        <span class="token builtin class-name">set</span> max frame rate <span class="token punctuation">(</span>Hz value, fraction or abbreviation<span class="token punctuation">)</span>-s size             <span class="token builtin class-name">set</span> frame size <span class="token punctuation">(</span>WxH or abbreviation<span class="token punctuation">)</span>-aspect aspect      <span class="token builtin class-name">set</span> aspect ratio <span class="token punctuation">(</span><span class="token number">4</span>:3, <span class="token number">16</span>:9 or <span class="token number">1.3333</span>, <span class="token number">1.7777</span><span class="token punctuation">)</span>-bits_per_raw_sample number  <span class="token builtin class-name">set</span> the number of bits per raw sample-vn                 disable video-vcodec codec       force video codec <span class="token punctuation">(</span><span class="token string">'copy'</span> to copy stream<span class="token punctuation">)</span>-timecode hh:mm:ss<span class="token punctuation">[</span>:<span class="token punctuation">;</span>.<span class="token punctuation">]</span>ff  <span class="token builtin class-name">set</span> initial TimeCode value.-pass n             <span class="token keyword">select</span> the pass number <span class="token punctuation">(</span><span class="token number">1</span> to <span class="token number">3</span><span class="token punctuation">)</span>-vf filter_graph    <span class="token builtin class-name">set</span> video filters-ab bitrate         audio bitrate <span class="token punctuation">(</span>please use -b:a<span class="token punctuation">)</span>-b bitrate          video bitrate <span class="token punctuation">(</span>please use -b:v<span class="token punctuation">)</span>-dn                 disable dataAudio options:-aframes number     <span class="token builtin class-name">set</span> the number of audio frames to output-aq quality         <span class="token builtin class-name">set</span> audio quality <span class="token punctuation">(</span>codec-specific<span class="token punctuation">)</span>-ar rate            <span class="token builtin class-name">set</span> audio sampling rate <span class="token punctuation">(</span>in Hz<span class="token punctuation">)</span>-ac channels        <span class="token builtin class-name">set</span> number of audio channels-an                 disable audio-acodec codec       force audio codec <span class="token punctuation">(</span><span class="token string">'copy'</span> to copy stream<span class="token punctuation">)</span>-vol volume         change audio volume <span class="token punctuation">(</span><span class="token number">256</span><span class="token operator">=</span>normal<span class="token punctuation">)</span>-af filter_graph    <span class="token builtin class-name">set</span> audio filtersSubtitle options:-s size             <span class="token builtin class-name">set</span> frame size <span class="token punctuation">(</span>WxH or abbreviation<span class="token punctuation">)</span>-sn                 disable subtitle-scodec codec       force subtitle codec <span class="token punctuation">(</span><span class="token string">'copy'</span> to copy stream<span class="token punctuation">)</span>-stag fourcc/tag    force subtitle tag/fourcc-fix_sub_duration   fix subtitles duration-canvas_size size   <span class="token builtin class-name">set</span> canvas size <span class="token punctuation">(</span>WxH or abbreviation<span class="token punctuation">)</span>-spre preset        <span class="token builtin class-name">set</span> the subtitle options to the indicated preset<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 软件 </category>
          
          <category> FFMPEG </category>
          
      </categories>
      
      
        <tags>
            
            <tag> FFMPEG </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pr note</title>
      <link href="/archives/d76b900f.html"/>
      <url>/archives/d76b900f.html</url>
      
        <content type="html"><![CDATA[<h1 id="Premiere-note"><a href="#Premiere-note" class="headerlink" title="Premiere note"></a>Premiere note</h1><p>教程资源：<a href="https://www.bilibili.com/video/BV1K64y1r7pp?p=1">基础教程 bilibili</a> </p><h2 id="从界面开始"><a href="#从界面开始" class="headerlink" title="从界面开始"></a>从界面开始</h2><p>关于编码：H.264 编码就是对应 mp4 格式视频</p><h3 id="界面"><a href="#界面" class="headerlink" title="界面"></a>界面</h3><ol><li><strong>素材箱</strong></li><li>工具栏</li><li><strong>序列</strong></li><li>预览窗口</li><li>效果窗口</li><li><strong>参数窗口</strong></li><li><strong>面板</strong>：不同的面板专注处理视频的不同部分，例如：组件面板完成的是对视频的粗剪</li></ol><h2 id="过程中的小技巧"><a href="#过程中的小技巧" class="headerlink" title="过程中的小技巧"></a>过程中的小技巧</h2><ol><li>通过效果面板 -&gt; 特效参数可以进行缩放，或者右键选择缩放为帧大小</li><li>右键选择倍速</li><li>右键取消视频音频链接</li><li>右键波纹删除，或选中空隙直接删除</li><li>右键减少音频增益</li><li>shift + left/right arrow 能够以5帧移，不按 shift 移动1帧</li><li>按住 shift 再拉动时间轴会有吸附效果</li><li>ctrl + k 快速剪裁</li><li>使用嵌套，融合素材</li><li>按住 ctrl 拖动视频，能够不覆盖地移动视频片段</li><li>单击顶部序列菜单 -&gt; 封闭间隙</li><li>ctrl + D 或者 shift + D 进行快速视频过渡</li></ol><h3 id="快捷键"><a href="#快捷键" class="headerlink" title="快捷键"></a>快捷键</h3><p>cut </p><h2 id="标记出入点"><a href="#标记出入点" class="headerlink" title="标记出入点"></a>标记出入点</h2><ol><li>预览工具栏</li></ol><p><img src="/archives/d76b900f/image-20210713213300154.png"></p><ol><li><strong>出入点</strong>在 pr 中以 bracket {} 形式出现</li></ol><p>​    双击素材，对素材进行出入点标记，再将素材拖入序列就能得到剪裁后的    素材</p><ol><li>添加标记点，就是工具栏第一个标志。可以标记视频中的重要时刻</li></ol><h2 id="抽帧卡点"><a href="#抽帧卡点" class="headerlink" title="抽帧卡点"></a>抽帧卡点</h2><p>根据音频的节奏去卡点，可以看到音频上的节奏点上是明显的波峰，把这些点标记出来，对原视频剪裁卡这个点即可</p><p>可以使用插件 beat edit 来帮我们自动找到节奏点</p><h2 id="加载字幕"><a href="#加载字幕" class="headerlink" title="加载字幕"></a>加载字幕</h2><p>如果是想要加大量字幕，推荐使用软件 arctime pro</p><p>TODO: 如何自动识别对话，形成字幕</p><h2 id="鬼畜"><a href="#鬼畜" class="headerlink" title="鬼畜"></a>鬼畜</h2><ol><li><p>鬼畜素材，鬼畜素材，鬼畜素材！</p></li><li><p>按住 alt 拖拽视频就能够复制</p></li><li>右键选择帧速度更改速度，还可以倒放</li></ol><h2 id="转场"><a href="#转场" class="headerlink" title="转场"></a>转场</h2><ol><li>基础的转场，淡入淡出</li><li>使用特效的转场，将特效加在调整图层上，不用修改原图层</li><li>可以使用 preset 转场资源：<a href="https://www.bilibili.com/video/BV1ab411E7EA">预设 bilibili</a> (更多资源请移步 bilibili)</li></ol><h2 id="字体"><a href="#字体" class="headerlink" title="字体"></a>字体</h2><p>推荐的字体，推荐字体网站 <a href="https://www.fonts.net.cn/">字体天下</a></p><ol><li>思源黑体</li><li>台北黑体，适用于繁体字</li><li>花园明朝体</li><li>刻石录明体，令东齐伋复刻体</li><li>OPPO/HarmonyOS SANS</li><li>手书体中文简体</li><li>good hood, maria 以上字体均免费可商用</li><li>gloss and boom</li><li>againts 字体</li><li>Futura, Baskerville(正规),  Trajan(标题)</li></ol><h2 id="调色"><a href="#调色" class="headerlink" title="调色"></a>调色</h2><p>使用 LUT 调色，配合上侧轮进行微调</p><p>教程：<a href="https://www.bilibili.com/video/BV1qE411d7BS">调色 bilibili</a></p><h2 id="动画"><a href="#动画" class="headerlink" title="动画"></a>动画</h2><p><strong>最基础也最常用的就是使用关键帧实现动画，Pr 能够通过关键帧自动实现简单动画</strong></p><p>下面是一些懒人教程，能够通过模板或者预设完成动画</p><p><a href="https://www.bilibili.com/video/BV1JK4y1o712?from=search&amp;seid=15809921384211472980">文字出入动画预设</a>：推荐使用 glitch smooth</p><p><a href="https://www.bilibili.com/video/BV1QJ411578F?from=search&amp;seid=1184998685891370931">快速添加 emoji 表情</a></p><h2 id="常用效果，进阶实战"><a href="#常用效果，进阶实战" class="headerlink" title="常用效果，进阶实战"></a>常用效果，进阶实战</h2><p><a href="https://www.bilibili.com/video/BV1h7411M7pH?from=search&amp;seid=1594445263778267172">简单视频过渡</a></p><p><a href="https://www.bilibili.com/video/BV1tt411w75b?from=search&amp;seid=14224780402575780190">裁剪，旋转</a></p><p><a href="https://www.bilibili.com/video/BV1Kb411M7QD?from=search&amp;seid=14224780402575780190">轨道遮罩教程</a></p><p><a href="https://www.bilibili.com/video/BV1T441177Rz/">不透明度，蒙板遮罩转场</a></p><p><a href="https://www.bilibili.com/medialist/play/ml1093412053/BV1CX4y1373V">绿幕素材教程 超级键</a></p><p><a href="https://www.bilibili.com/video/BV1Kb411M7QD?from=search&amp;seid=14224780402575780190">基础图形变换，玻璃划过效果</a></p><p><a href="https://www.bilibili.com/video/BV1Vb411J7q3?from=search&amp;seid=11560949388583323453">文字书写</a></p><h2 id="vlog-素材库"><a href="#vlog-素材库" class="headerlink" title="vlog 素材库"></a>vlog 素材库</h2><ol><li><p><a href="https://dongmanhuayuan.myheartsite.com/">动漫花园镜像站</a></p></li><li><p><a href="https://mixkit.co/">mixkit</a></p><p>视频，音频，Pr模板资源</p></li><li><p><a href="https://pixabay.com/zh/">pixabay</a></p><p>视频，音频，图片资源</p></li><li><p><a href="https://www.iconfont.cn/">iconfont</a></p></li><li><p>vlog 音乐资源：参考 <a href="https://www.bilibili.com/video/BV1uX4y1G7M8?from=search&amp;seid=14857001846860959682">vlog bgm bilibili</a>，还可以学习一下如何处理 bgm 与人声混合</p><p><a href="https://soundcloud.com/lakeyinspired">sound cloud: lakey inspired</a></p><p>如果想要使用 off vocal music 只需要搜索 歌名 + instrumental 即可</p></li></ol><p>视频、音效素材希望自己要有目的地去寻找，不然资源再多也没用</p>]]></content>
      
      
      <categories>
          
          <category> 软件 </category>
          
          <category> Adobe </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Pr </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Manim Kindergarten 教程</title>
      <link href="/archives/84b26b6c.html"/>
      <url>/archives/84b26b6c.html</url>
      
        <content type="html"><![CDATA[<h1 id="Manim-拓展学习"><a href="#Manim-拓展学习" class="headerlink" title="Manim 拓展学习"></a>Manim 拓展学习</h1><p>由于 Manim-Kindergarten 的 <a href="https://www.bilibili.com/video/BV1p54y197cC?from=search&amp;seid=1264961070490764259">视频教程</a> 非常友好，所以根据他们的视频进行整理和学习。但是由于教程中使用的 manim 版本并不是社区版本，所有整理的内容和原教程有所出入</p><h2 id="第一讲-物体的位置与坐标变换"><a href="#第一讲-物体的位置与坐标变换" class="headerlink" title="第一讲 物体的位置与坐标变换"></a>第一讲 物体的位置与坐标变换</h2><p>怎样确定物体的坐标？首先要理解 manim 的坐标体系。</p><ol><li>在 manim 中，使用三维 ndarray 表示一个点的坐标 <code>np.array([x, y, z])</code>，二维场景中设 <code>z = 0</code></li><li>单位长度取决于 constants.py 中的 FRAME_HEIGHT，画面的宽度由高度和长宽比同时决定。FRAME_HEIGHT 默认值为8，y 的变化范围只能是 [-4, 4]</li><li>在 manim 中，二维画面以中心为坐标原点，向右为 x 轴正方向，向上为 y 轴正方向</li></ol><p>manim 中定义了一些常用的单位方向常量比如：</p><p>LEFT = <code>np.array([-1, 0, 0])</code></p><p>RIGHT = <code>np.array([1, 0, 0])</code> </p><p>UP = <code>np.array([0, 1, 0])</code></p><p>DOWN = <code>np.array([0, -1, 0])</code></p><h3 id="shift-move-to"><a href="#shift-move-to" class="headerlink" title="shift+move_to"></a>shift+move_to</h3><p>两个方法都可以根据传入的 vector 移动物体，shift 是相对移动，move_to 是移动到坐标系中的点</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># create a mobject 'mob' first</span>mob<span class="token punctuation">.</span>shift<span class="token punctuation">(</span><span class="token operator">*</span>vectors<span class="token punctuation">)</span>mob<span class="token punctuation">.</span>move_to<span class="token punctuation">(</span><span class="token operator">*</span>vectors<span class="token punctuation">,</span> aligned_egde<span class="token punctuation">,</span> coor_mask<span class="token punctuation">)</span><span class="token comment"># corr_mask 可以屏蔽指定方向的移动</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h3 id="scale-amp-stretch-amp-set-width-height"><a href="#scale-amp-stretch-amp-set-width-height" class="headerlink" title="scale &amp; stretch &amp; set_width/height"></a>scale &amp; stretch &amp; set_width/height</h3><p>对物体进行放大</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">mob<span class="token punctuation">.</span>scale<span class="token punctuation">(</span>factor<span class="token punctuation">,</span> about_egde<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> about_point<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>对物体进行拉伸</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">mob<span class="token punctuation">.</span>stretch<span class="token punctuation">(</span>factor<span class="token punctuation">,</span> dim<span class="token punctuation">)</span>mob<span class="token punctuation">.</span>set_width<span class="token punctuation">(</span>width<span class="token punctuation">,</span> stretch<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>mob<span class="token punctuation">.</span>set_height<span class="token punctuation">(</span>height<span class="token punctuation">,</span> stretch<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="rotate"><a href="#rotate" class="headerlink" title="rotate"></a>rotate</h3><p>根据右手定律进行旋转 </p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># angle 需要用 manim 中定义的 DEGREES or PI 进行计算</span>mob<span class="token punctuation">.</span>rotate<span class="token punctuation">(</span>angle<span class="token punctuation">,</span> axis<span class="token operator">=</span>OUT<span class="token punctuation">,</span> about_point<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="flip"><a href="#flip" class="headerlink" title="flip"></a>flip</h3><p>能够指定对称轴进行镜像翻转</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">mob<span class="token punctuation">.</span>flip<span class="token punctuation">(</span><span class="token punctuation">)</span>mob<span class="token punctuation">.</span>flip<span class="token punctuation">(</span>axis<span class="token operator">=</span>vector<span class="token punctuation">,</span> about_point<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="align-to-amp-next-to"><a href="#align-to-amp-next-to" class="headerlink" title="align_to &amp; next_to"></a>align_to &amp; next_to</h3><p>坐标和某个物体对齐，或者在某个物体的相邻位置</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># direction is a vector like LEFT, RIGHT, UL</span>mob<span class="token punctuation">.</span>align_to<span class="token punctuation">(</span>mob_or_point<span class="token punctuation">,</span> direction<span class="token punctuation">)</span>mob<span class="token punctuation">.</span>next_to<span class="token punctuation">(</span>mob_or_point<span class="token punctuation">,</span> direction<span class="token punctuation">,</span> aligned_edge<span class="token punctuation">,</span> buff<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h2 id="第二讲-manim常用几何类"><a href="#第二讲-manim常用几何类" class="headerlink" title="第二讲 manim常用几何类"></a>第二讲 manim常用几何类</h2><h3 id="line-amp-arrow"><a href="#line-amp-arrow" class="headerlink" title="line &amp; arrow"></a>line &amp; arrow</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python">line <span class="token operator">=</span> Line<span class="token punctuation">(</span>start_point<span class="token punctuation">,</span> end_point<span class="token punctuation">,</span> buff<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>arrow <span class="token operator">=</span> Aroow<span class="token punctuation">(</span>start_point<span class="token punctuation">,</span> end_point<span class="token punctuation">,</span> buff<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> tip_length<span class="token punctuation">)</span><span class="token comment"># buff 调整的是到目标点的距离</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>还有其他更多的变化，比如 Dashline Vector</p><h3 id="arc"><a href="#arc" class="headerlink" title="arc"></a>arc</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python">arc <span class="token operator">=</span> Arc<span class="token punctuation">(</span>arc_center<span class="token punctuation">,</span> radius<span class="token punctuation">,</span> start_angle<span class="token punctuation">,</span> angle<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="circle-amp-dot-amp-ellipse"><a href="#circle-amp-dot-amp-ellipse" class="headerlink" title="circle &amp; dot &amp; ellipse"></a>circle &amp; dot &amp; ellipse</h3><p>这三类几何图形都是继承于 arc 类，所有参数都有相似之处</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">circle <span class="token operator">=</span> Circle<span class="token punctuation">(</span>arc_center<span class="token punctuation">,</span> radius<span class="token punctuation">,</span> stroke_width<span class="token punctuation">)</span>dot <span class="token operator">=</span> Dot<span class="token punctuation">(</span>arc_center<span class="token punctuation">,</span> radius<span class="token punctuation">)</span>ellipse <span class="token operator">=</span> Ellipse<span class="token punctuation">(</span>arc_center<span class="token punctuation">,</span> width<span class="token punctuation">,</span> height<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="annulus-amp-sector"><a href="#annulus-amp-sector" class="headerlink" title="annulus &amp; sector"></a>annulus &amp; sector</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python">annulus <span class="token operator">=</span> Annulus<span class="token punctuation">(</span>outer_radis<span class="token punctuation">,</span> inner_radius<span class="token punctuation">)</span>sector <span class="token operator">=</span> Sector<span class="token punctuation">(</span>outer_radius<span class="token punctuation">,</span> inner_radius<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="polygon-amp-triangle"><a href="#polygon-amp-triangle" class="headerlink" title="polygon &amp; triangle"></a>polygon &amp; triangle</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python">triangle <span class="token operator">=</span> Polygon<span class="token punctuation">(</span>point_1<span class="token punctuation">,</span> point_2<span class="token punctuation">,</span> point_3<span class="token punctuation">)</span>triangle <span class="token operator">=</span> Triangle<span class="token punctuation">(</span><span class="token punctuation">)</span>Hexagon <span class="token operator">=</span> RegularPolygon<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>对于多边形还有一个特别的方法，将顶点变为圆弧</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># mob is a polygon mobject instance</span>mob<span class="token punctuation">.</span>round_corners<span class="token punctuation">(</span>radius<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="rectangle-amp-square"><a href="#rectangle-amp-square" class="headerlink" title="rectangle &amp; square"></a>rectangle &amp; square</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python">rectangle <span class="token operator">=</span> Rectangle<span class="token punctuation">(</span>height<span class="token punctuation">,</span> width<span class="token punctuation">)</span>square <span class="token operator">=</span> Square<span class="token punctuation">(</span>side_length<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="VGroup"><a href="#VGroup" class="headerlink" title="VGroup"></a>VGroup</h3><p>该方法能够将多个 mobject 放到一个组中，能够实现类似 list 的功能，例如管理成员、嵌套，同时还能使用 mobject 通用方法</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">vgroup <span class="token operator">=</span> VGroup<span class="token punctuation">(</span>mob0<span class="token punctuation">,</span> mob1<span class="token punctuation">,</span> mob2<span class="token punctuation">)</span>vgroup<span class="token punctuation">.</span>add<span class="token punctuation">(</span>mob3<span class="token punctuation">)</span>vgroup<span class="token punctuation">.</span>add_to_back<span class="token punctuation">(</span>mob4<span class="token punctuation">)</span>vgroup<span class="token punctuation">.</span>remove<span class="token punctuation">(</span>mob2<span class="token punctuation">)</span>vgroup<span class="token punctuation">.</span>shift<span class="token punctuation">(</span>UP<span class="token punctuation">)</span><span class="token comment"># 将成员按照某一方向对齐，本质上是实现了 next_to 方法</span>vg<span class="token punctuation">.</span>arrange<span class="token punctuation">(</span>DOWN<span class="token punctuation">,</span> aligned_edge<span class="token operator">=</span>LEFT<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="第三讲-颜色的表示、运算与设置"><a href="#第三讲-颜色的表示、运算与设置" class="headerlink" title="第三讲 颜色的表示、运算与设置"></a>第三讲 颜色的表示、运算与设置</h2><h3 id="颜色的表示"><a href="#颜色的表示" class="headerlink" title="颜色的表示"></a>颜色的表示</h3><p>有三种表示方法</p><ol><li><p>定义的常量，如下图</p></li><li><p>十六进制，形如 #66CCFF</p></li><li><p>RGB数组，形如 np.array([255, 104, 100])</p></li></ol><p><img src="/archives/84b26b6c/image-20210729201211734.png" style="zoom: 20%;"></p><p>但所有的表示方法，在 manim 中最终都会转化为 Color 类</p><p><strong>推荐使用常量或者十六进制来表示颜色</strong></p><h3 id="颜色的运算"><a href="#颜色的运算" class="headerlink" title="颜色的运算"></a>颜色的运算</h3><p>列几个常见的运算</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 反色</span>invert_color<span class="token punctuation">(</span>color<span class="token punctuation">)</span><span class="token comment"># 插值</span>interpolate_color<span class="token punctuation">(</span>color_1<span class="token punctuation">,</span> color_2<span class="token punctuation">,</span> ratio<span class="token punctuation">)</span><span class="token comment"># 平均</span>average_color<span class="token punctuation">(</span><span class="token operator">*</span>colors<span class="token punctuation">)</span><span class="token comment"># 梯度</span>color_gradient<span class="token punctuation">(</span><span class="token punctuation">[</span>color_1<span class="token punctuation">,</span> color_2<span class="token punctuation">,</span><span class="token punctuation">]</span><span class="token punctuation">,</span> length<span class="token punctuation">)</span><span class="token comment"># 随机</span>random_color<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/archives/84b26b6c/image-20210729203331953.png" alt="color_gradient" style="zoom:25%;"></p><h3 id="物体颜色设置"><a href="#物体颜色设置" class="headerlink" title="物体颜色设置"></a>物体颜色设置</h3><p>stroke 代表边框着色，fill 代表内部着色</p><div class="table-container"><table><thead><tr><th>stroke</th><th>fill</th></tr></thead><tbody><tr><td>stroke_color</td><td>fill_color</td></tr><tr><td>stroke_opacity</td><td>fill_opacity</td></tr></tbody></table></div><p>上面的属性都可以通过 set_stroke/fill 来更改</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">mob<span class="token punctuation">.</span>set_stroke<span class="token punctuation">(</span>color<span class="token punctuation">,</span> width<span class="token punctuation">)</span>mob<span class="token punctuation">.</span>set_fill<span class="token punctuation">(</span>color<span class="token punctuation">,</span> opacity<span class="token punctuation">)</span>mob<span class="token punctuation">.</span>set_fill<span class="token punctuation">(</span><span class="token punctuation">[</span>color_1<span class="token punctuation">,</span> color_2<span class="token punctuation">,</span><span class="token punctuation">]</span><span class="token punctuation">,</span> opacity<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="给-VGroup-子物体上色"><a href="#给-VGroup-子物体上色" class="headerlink" title="给 VGroup 子物体上色"></a>给 VGroup 子物体上色</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># vg is a VGroup instance</span>vg<span class="token punctuation">.</span>set_color<span class="token punctuation">(</span>color<span class="token punctuation">)</span>vg<span class="token punctuation">.</span>set_color_by_gradient<span class="token punctuation">(</span><span class="token operator">*</span>colors<span class="token punctuation">)</span>vg<span class="token punctuation">.</span>set_colors_by_radial_gradient<span class="token punctuation">(</span>radius<span class="token punctuation">,</span> inner_color<span class="token punctuation">,</span> outer_color<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>值得一提的是，这些操作都是 <code>VMobject</code> 的内置方法，是一种通用的方法，而且这些方法不仅仅可以设置 <code>stroke</code> 的颜色，也可以设置 <code>width, opacity...</code></p><h2 id="第四讲-插入SVG、图片与文字"><a href="#第四讲-插入SVG、图片与文字" class="headerlink" title="第四讲 插入SVG、图片与文字"></a>第四讲 插入SVG、图片与文字</h2><h3 id="图片"><a href="#图片" class="headerlink" title="图片"></a>图片</h3><p>在 manim 插入图片需要先将图片放在当前文件夹下，或者使用 <code>config.assets_dir</code> 指定素材文件夹。不同的图片类型则使用不同的对象进行存储</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># SVG</span>mob <span class="token operator">=</span> SVGMobject<span class="token punctuation">(</span><span class="token string">'file'</span><span class="token punctuation">)</span><span class="token comment"># image: jpg, png, gif</span>mob <span class="token operator">=</span> ImageMobject<span class="token punctuation">(</span><span class="token string">'file'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>SVGMobject</code> 是 <code>VMobject</code> 的子类，可以使用其所有动画，但 <code>ImageMobject</code> 仅能使用部分动画，如：FadeIn</p><h3 id="文字与公式"><a href="#文字与公式" class="headerlink" title="文字与公式"></a>文字与公式</h3><p>在 manim 中可以使用 <code>Text</code> 创建普通文字对象</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">text <span class="token operator">=</span> Text<span class="token punctuation">(</span><span class="token operator">*</span>strings<span class="token punctuation">,</span> color<span class="token punctuation">,</span> font<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>可以传入多个字符串，同样 <code>Text</code> 也可以使用所有动画。如果想要使用 LaTeX 语法书写文字和公式，则需要使用 <code>Tex, MathTex</code> 类</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">text <span class="token operator">=</span> Tex<span class="token punctuation">(</span><span class="token operator">*</span>raw_strings<span class="token punctuation">)</span>formula <span class="token operator">=</span> MathTex<span class="token punctuation">(</span><span class="token operator">*</span>raw_strings<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>所有的文字和公式都是一个 <code>VGroup</code>，可以通过索引来对每个字符单独操作</p><h2 id="第五讲-坐标系统与方程"><a href="#第五讲-坐标系统与方程" class="headerlink" title="第五讲 坐标系统与方程"></a>第五讲 坐标系统与方程</h2><h3 id="坐标轴"><a href="#坐标轴" class="headerlink" title="坐标轴"></a>坐标轴</h3><p>在 manim 中可以插入坐标轴</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># NumberLine</span><span class="token comment"># x_range 标明数周的范围以及步长</span>line <span class="token operator">=</span> NumberLine<span class="token punctuation">(</span>        numberline <span class="token operator">=</span> NumberLine<span class="token punctuation">(</span>            x_range<span class="token operator">=</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>            length<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>            include_numbers<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>            include_ticks<span class="token operator">=</span><span class="token boolean">False</span>        <span class="token punctuation">)</span><span class="token comment"># Axes</span><span class="token comment"># 分别设置 x, y 坐标轴，具体参数打包为字典，关键字同 NumberLine</span>axes <span class="token operator">=</span> Axes<span class="token punctuation">(</span>            x_range<span class="token operator">=</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>            y_range<span class="token operator">=</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>            axis_config<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>                include_numbers<span class="token operator">=</span><span class="token boolean">True</span>            <span class="token punctuation">)</span>        <span class="token punctuation">)</span><span class="token comment"># NumberPlane</span><span class="token comment"># 注意这里的步长是指数轴的数量</span>number_plane <span class="token operator">=</span> NumberPlane<span class="token punctuation">(</span>            x_range<span class="token operator">=</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>            y_range<span class="token operator">=</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>            background_line_style<span class="token operator">=</span><span class="token punctuation">{</span>                <span class="token string">"stroke_color"</span><span class="token punctuation">:</span> TEAL<span class="token punctuation">,</span>                <span class="token string">"stroke_width"</span><span class="token punctuation">:</span> <span class="token number">4</span><span class="token punctuation">,</span>                <span class="token string">"stroke_opacity"</span><span class="token punctuation">:</span> <span class="token number">0.6</span>            <span class="token punctuation">}</span>        <span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="方程"><a href="#方程" class="headerlink" title="方程"></a>方程</h3><p>使用 <code>ParametricFunction</code> 可以显示函数</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 单变量方程，返回三维 ndarray</span><span class="token keyword">def</span> <span class="token function">func</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> t<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token keyword">return</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>sin<span class="token punctuation">(</span><span class="token number">2</span> <span class="token operator">*</span> t<span class="token punctuation">)</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>sin<span class="token punctuation">(</span><span class="token number">3</span> <span class="token operator">*</span> t<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">construct</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>    func <span class="token operator">=</span> ParametricFunction<span class="token punctuation">(</span>self<span class="token punctuation">.</span>func<span class="token punctuation">,</span> t_range <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> TAU<span class="token punctuation">]</span><span class="token punctuation">.</span>set_color<span class="token punctuation">(</span>RED<span class="token punctuation">)</span>    self<span class="token punctuation">.</span>add<span class="token punctuation">(</span>func<span class="token punctuation">.</span>scale<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="More"><a href="#More" class="headerlink" title="More"></a>More</h2><p>ManimCE 文档有一个 <a href="https://docs.manim.community/en/stable/reference.html">reference manual</a>，官方描述这个手册的功能：</p><blockquote><p>This reference manual details modules, functions, and variables included in Manim, describing what they are and what they do. </p></blockquote><p>里面包含了各种模块和函数，更多的 <code>VMobject</code> 和更多的动画操作，文档中还有 <a href="https://docs.manim.community/en/stable/examples.html">Example Gallery</a> 提供参考</p>]]></content>
      
      
      <categories>
          
          <category> 编程 </category>
          
          <category> Python </category>
          
          <category> Package </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 教程 </tag>
            
            <tag> Manim </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Pytorch tutorial</title>
      <link href="/archives/6c437432.html"/>
      <url>/archives/6c437432.html</url>
      
        <content type="html"><![CDATA[<h1 id="Pytorch-Tutorial"><a href="#Pytorch-Tutorial" class="headerlink" title="Pytorch Tutorial"></a>Pytorch Tutorial</h1><p><a href="https://pytorch.org/tutorials/">官方 tutorial</a> <a href="https://pytorch.org/tutorials/beginner/ptcheat.html#">官方 Cheat Sheet</a></p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><p>这部分可以看到整个 pytorch 的 workflow</p><ol><li><p>Working with Data</p><p>pytorch 提供一些小的数据集用于训练和测试。对于计算机视觉领域的模块 <code>TorchVision</code> 包含了一些常用数据集、模型和转换函数等等。装载数据集则使用 dataset, dataloader 类</p></li><li><p>Creating Models</p><p>继承 nn.Module 类，初始化相关模块，写好向前方程</p></li><li><p>Optimizing</p><p>定义损失函数，再使用反向传播算法进行优化</p></li><li><p>Saving &amp; Loading Models</p><p>保存模型，以及训练好的参数，方便之后测试和加载</p></li></ol><h2 id="Tensor"><a href="#Tensor" class="headerlink" title="Tensor"></a>Tensor</h2><blockquote><p>Tensors are similar to <a href="https://numpy.org/">NumPy’s</a> ndarrays, except that tensors can run on GPUs or other hardware accelerators. In fact, tensors and NumPy arrays can often share the same underlying memory, eliminating the need to copy data (see <a href="https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#bridge-to-np-label">Bridge with NumPy</a>). Tensors are also optimized for automatic differentiation</p></blockquote><p>从以上的描述来看 Tensor 数据类型有两个特点：</p><ol><li>能够在 GPU 上进行计算</li><li>能够自动微分</li></ol><p>如果熟悉 Numpy 的话，学习 Tensor 将会变得更加轻松。计划分为三个部分学习 Tensor：</p><ol><li>创建 Tensor</li><li>Tensor 的属性</li><li>Tensor 内置方法</li></ol><h3 id="创建-Tensor"><a href="#创建-Tensor" class="headerlink" title="创建 Tensor"></a>创建 Tensor</h3><p>参考 Cheat Sheet </p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch <span class="token keyword">import</span> numpy <span class="token keyword">as</span> npx <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token operator">*</span>size<span class="token punctuation">)</span>              <span class="token comment"># tensor with independent N(0,1) entries</span>x <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token punctuation">[</span>ones<span class="token operator">|</span>zeros<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token operator">*</span>size<span class="token punctuation">)</span>       <span class="token comment"># tensor with all 1's [or 0's]</span>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>L<span class="token punctuation">)</span>                 <span class="token comment"># create tensor from [nested] list or ndarray L</span>y <span class="token operator">=</span> x<span class="token punctuation">.</span>clone<span class="token punctuation">(</span><span class="token punctuation">)</span>                       <span class="token comment"># clone of x</span><span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>               <span class="token comment"># code wrap that stops autograd from tracking tensor history</span>requires_grad<span class="token operator">=</span><span class="token boolean">True</span>                  <span class="token comment"># arg, when set to True, tracks computation</span>                                    <span class="token comment"># history for future derivative calculations</span><span class="token comment"># create from other tensor</span>y <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones_like<span class="token punctuation">(</span>x<span class="token punctuation">)</span>y <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros_like<span class="token punctuation">(</span>x<span class="token punctuation">)</span>y <span class="token operator">=</span> x<span class="token punctuation">.</span>new_zeros<span class="token punctuation">(</span><span class="token operator">*</span>shape<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>创建 tensor 和创建 ndarray 是相似的。既可以生成指定分布的 tensor，也可以从 ndarray 中创建。由于 tensor 和 ndarray 关系密切，它们之间的转换也是很方便的。同时 tensor 和 numpy 也是共用内存的</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># tensor 转化为 ndarray</span>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>n <span class="token operator">=</span> x<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>n<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1</span><span class="token comment"># 该操作会改变 x</span><span class="token comment"># ndarray 转化为 tensor</span>n <span class="token operator">=</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">12</span><span class="token punctuation">)</span>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>n<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Tensor-的属性"><a href="#Tensor-的属性" class="headerlink" title="Tensor 的属性"></a>Tensor 的属性</h3><p>主要用3个属性：shape, dtype, deviece</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token comment"># f"string" 代表格式化，类似 str.format()</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Shape of tensor: </span><span class="token interpolation"><span class="token punctuation">{</span>tensor<span class="token punctuation">.</span>shape<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Datatype of tensor: </span><span class="token interpolation"><span class="token punctuation">{</span>tensor<span class="token punctuation">.</span>dtype<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Device tensor is stored on: </span><span class="token interpolation"><span class="token punctuation">{</span>tensor<span class="token punctuation">.</span>device<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>进一步还有与梯度相关的属性 <code>grad, requires_grad, data</code></p><h3 id="Tensor-内置方法"><a href="#Tensor-内置方法" class="headerlink" title="Tensor 内置方法"></a>Tensor 内置方法</h3><blockquote><p>Over 100 tensor operations, including arithmetic, linear algebra, matrix manipulation (transposing, indexing, slicing), sampling and more are comprehensively described <a href="https://pytorch.org/docs/stable/torch.html">here</a>.</p></blockquote><p>还是分模块来接招这些内置方法</p><h4 id="Standard-numpy-like-indexing-and-slicing"><a href="#Standard-numpy-like-indexing-and-slicing" class="headerlink" title="Standard numpy-like indexing and slicing"></a>Standard numpy-like indexing and slicing</h4><p>tensor 的索引和 ndarray 的索引是相同的，包括多元索引、布尔索引、花式索引，参考整理的 numpy cheat sheet</p><h4 id="Move-tensors-to-GPU"><a href="#Move-tensors-to-GPU" class="headerlink" title="Move tensors to GPU"></a>Move tensors to GPU</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># We move our tensor to the GPU if available</span><span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    tensor <span class="token operator">=</span> tensor<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">'cuda'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h4 id="Dimensionality"><a href="#Dimensionality" class="headerlink" title="Dimensionality"></a>Dimensionality</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python">x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span>                                  <span class="token comment"># return tuple-like object of dimensions</span>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>tensor_seq<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>          <span class="token comment"># concatenates tensors along dim</span>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>stack<span class="token punctuation">(</span>tensor_seq<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>  <span class="token comment"># stack tensors of the same shape along dim</span>y <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>a<span class="token punctuation">,</span>b<span class="token punctuation">,</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>                       <span class="token comment"># reshapes x into size (a,b,...)</span>y <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span>a<span class="token punctuation">)</span>                          <span class="token comment"># reshapes x into size (b,a) for some b</span>y <span class="token operator">=</span> x<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span>a<span class="token punctuation">,</span>b<span class="token punctuation">)</span>                      <span class="token comment"># swaps dimensions a and b</span>y <span class="token operator">=</span> x<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token operator">*</span>dims<span class="token punctuation">)</span>                      <span class="token comment"># permutes dimensions</span>y <span class="token operator">=</span> x<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>dim<span class="token punctuation">)</span>                      <span class="token comment"># tensor with added axis</span>y <span class="token operator">=</span> x<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>                    <span class="token comment"># (a,b,c) tensor -&gt; (a,b,1,c) tensor</span>y <span class="token operator">=</span> x<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span>                           <span class="token comment"># removes all dimensions of size 1 (a,1,b,1) -&gt; (a,b)</span>y <span class="token operator">=</span> x<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>                      <span class="token comment"># removes specified dimension of size 1 (a,1,b,1) -&gt; (a,b,1)</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>y <span class="token operator">=</span> x<span class="token punctuation">.</span>repeat<span class="token punctuation">(</span><span class="token operator">*</span>sizes<span class="token punctuation">)</span>y <span class="token operator">=</span> x<span class="token punctuation">.</span>repeat_interleave<span class="token punctuation">(</span><span class="token punctuation">[</span>tensor<span class="token operator">|</span><span class="token builtin">int</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token punctuation">)</span><span class="token comment"># similar to numpy.repeat()</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="Algebra"><a href="#Algebra" class="headerlink" title="Algebra"></a>Algebra</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python">ret <span class="token operator">=</span> A<span class="token punctuation">.</span>mm<span class="token punctuation">(</span>B<span class="token punctuation">)</span>       <span class="token comment"># matrix multiplication</span>ret <span class="token operator">=</span> A<span class="token punctuation">.</span>mv<span class="token punctuation">(</span>x<span class="token punctuation">)</span>       <span class="token comment"># matrix-vector multiplication</span>ret <span class="token operator">=</span> y<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>x<span class="token punctuation">)</span>      <span class="token comment"># Computes the dot product of two 1D tensors</span>x <span class="token operator">=</span> x<span class="token punctuation">.</span>t<span class="token punctuation">(</span><span class="token punctuation">)</span>           <span class="token comment"># matrix transpose</span><span class="token comment"># This computes the element-wise product</span>z1 <span class="token operator">=</span> tensor_1 <span class="token operator">*</span> tensor_2<span class="token comment"># convert one element tensor to a Python numerical value</span>x<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="GPU-Usage"><a href="#GPU-Usage" class="headerlink" title="GPU Usage"></a>GPU Usage</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token comment"># check for cuda</span>torch<span class="token punctuation">.</span>version<span class="token punctuation">.</span>cuda<span class="token comment"># check version</span>torch<span class="token punctuation">.</span>__version__<span class="token comment"># check torch version</span>x <span class="token operator">=</span> x<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># move x's data from CPU to GPU and return new object</span>x <span class="token operator">=</span> x<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># move x's data from GPU to CPU and return new object</span><span class="token keyword">if</span> <span class="token keyword">not</span> args<span class="token punctuation">.</span>disable_cuda <span class="token keyword">and</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>     <span class="token comment"># device agnostic code and modularity</span>    args<span class="token punctuation">.</span>device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">'cuda'</span><span class="token punctuation">,</span> index<span class="token punctuation">)</span><span class="token keyword">else</span><span class="token punctuation">:</span>                                                           args<span class="token punctuation">.</span>device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">'cpu'</span><span class="token punctuation">)</span>                       net<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token comment"># recursively convert their parameters and buffers to device specific tensors</span>x <span class="token operator">=</span> x<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token comment"># copy your tensors to a device (gpu, cpu)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="Datasets-amp-DataLoader"><a href="#Datasets-amp-DataLoader" class="headerlink" title="Datasets &amp; DataLoader"></a>Datasets &amp; DataLoader</h2><blockquote><p>Code for processing data samples can get messy and hard to maintain; we ideally want our dataset code to be decoupled from our model training code for better readability and modularity. PyTorch provides two data primitives: <code>torch.utils.data.DataLoader</code> and <code>torch.utils.data.Dataset</code> that allow you to use pre-loaded datasets as well as your own data. </p></blockquote><p>Dataset 类存储了数据集的路径，并且定义了 <code>__getitem__</code> 方法来获取单个数据集及其对应标签。而 DataLoder 则将数据集打包形成一个可迭代对象，方便不同方式的遍历</p><h3 id="载入-torchvision-中的数据集"><a href="#载入-torchvision-中的数据集" class="headerlink" title="载入 torchvision 中的数据集"></a>载入 torchvision 中的数据集</h3><p>先介绍如何从 <code>torchvision</code> 中载入官方数据集 <code>Fashion-MNIST</code></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> torchvision <span class="token keyword">import</span> datasets<span class="token keyword">from</span> torchvision<span class="token punctuation">.</span>transforms <span class="token keyword">import</span> ToTensortraining_data <span class="token operator">=</span> datasets<span class="token punctuation">.</span>FashionMNIST<span class="token punctuation">(</span>    root<span class="token operator">=</span><span class="token string">"data"</span><span class="token punctuation">,</span>    train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>    download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>    transform<span class="token operator">=</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>test_data <span class="token operator">=</span> datasets<span class="token punctuation">.</span>FashionMNIST<span class="token punctuation">(</span>    root<span class="token operator">=</span><span class="token string">"data"</span><span class="token punctuation">,</span>    train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>    download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>    transform<span class="token operator">=</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>参数的说明如下：</p><ul><li><code>root</code> is the path where the train/test data is stored,</li><li><code>train</code> specifies training or test dataset,</li><li><code>download=True</code> downloads the data from the internet if it’s not available at <code>root</code>.</li><li><code>transform</code> and <code>target_transform</code> specify the feature and label transformations</li></ul><p>用 <code>matplotlib</code> 来展示数据集中的部分图像，看能不能正常工作</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> pltlabels_map <span class="token operator">=</span> <span class="token punctuation">{</span>    <span class="token number">0</span><span class="token punctuation">:</span> <span class="token string">"T-Shirt"</span><span class="token punctuation">,</span>    <span class="token number">1</span><span class="token punctuation">:</span> <span class="token string">"Trouser"</span><span class="token punctuation">,</span>    <span class="token number">2</span><span class="token punctuation">:</span> <span class="token string">"Pullover"</span><span class="token punctuation">,</span>    <span class="token number">3</span><span class="token punctuation">:</span> <span class="token string">"Dress"</span><span class="token punctuation">,</span>    <span class="token number">4</span><span class="token punctuation">:</span> <span class="token string">"Coat"</span><span class="token punctuation">,</span>    <span class="token number">5</span><span class="token punctuation">:</span> <span class="token string">"Sandal"</span><span class="token punctuation">,</span>    <span class="token number">6</span><span class="token punctuation">:</span> <span class="token string">"Shirt"</span><span class="token punctuation">,</span>    <span class="token number">7</span><span class="token punctuation">:</span> <span class="token string">"Sneaker"</span><span class="token punctuation">,</span>    <span class="token number">8</span><span class="token punctuation">:</span> <span class="token string">"Bag"</span><span class="token punctuation">,</span>    <span class="token number">9</span><span class="token punctuation">:</span> <span class="token string">"Ankle Boot"</span><span class="token punctuation">,</span><span class="token punctuation">}</span>figure <span class="token operator">=</span> plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span>cols<span class="token punctuation">,</span> rows <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> cols <span class="token operator">*</span> rows <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    sample_idx <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>training_data<span class="token punctuation">)</span><span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>    img<span class="token punctuation">,</span> label <span class="token operator">=</span> training_data<span class="token punctuation">[</span>sample_idx<span class="token punctuation">]</span>    figure<span class="token punctuation">.</span>add_subplot<span class="token punctuation">(</span>rows<span class="token punctuation">,</span> cols<span class="token punctuation">,</span> i<span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span>labels_map<span class="token punctuation">[</span>label<span class="token punctuation">]</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token string">"off"</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>img<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> cmap<span class="token operator">=</span><span class="token string">"gray"</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>结果形如下面的图片</p><p><img src="/archives/6c437432/sphx_glr_data_tutorial_001.png" style="zoom: 50%;"></p><h3 id="载入自定义数据集"><a href="#载入自定义数据集" class="headerlink" title="载入自定义数据集"></a>载入自定义数据集</h3><blockquote><p>A custom Dataset class must implement three functions: <code>__init__</code>, <code>__len__</code>, and <code>__getitem__</code>. </p></blockquote><ol><li><p><code>__init__</code></p><p>初始化包含图像、注释文件的目录，以及对数据集的 transform </p></li><li><p><code>__len__</code></p><p>返回数据集样本个数</p></li><li><p><code>__getitem__</code></p><p>该函数返回数据集中索引为 idx 的样本及其对应标签</p></li></ol><p>下面通过一段代码来具体看看这些函数的实现</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> os<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd<span class="token keyword">from</span> torchvision<span class="token punctuation">.</span>io <span class="token keyword">import</span> read_image<span class="token keyword">class</span> <span class="token class-name">CustomImageDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> annotations_file<span class="token punctuation">,</span> img_dir<span class="token punctuation">,</span> transform<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> target_transform<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>img_labels <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>annotations_file<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>img_dir <span class="token operator">=</span> img_dir        self<span class="token punctuation">.</span>transform <span class="token operator">=</span> transform        self<span class="token punctuation">.</span>target_transform <span class="token operator">=</span> target_transform    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>img_labels<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> idx<span class="token punctuation">)</span><span class="token punctuation">:</span>        img_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>self<span class="token punctuation">.</span>img_dir<span class="token punctuation">,</span> self<span class="token punctuation">.</span>img_labels<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span>idx<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        image <span class="token operator">=</span> read_image<span class="token punctuation">(</span>img_path<span class="token punctuation">)</span>        label <span class="token operator">=</span> self<span class="token punctuation">.</span>img_labels<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span>idx<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>transform<span class="token punctuation">:</span>            image <span class="token operator">=</span> self<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>image<span class="token punctuation">)</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>target_transform<span class="token punctuation">:</span>            label <span class="token operator">=</span> self<span class="token punctuation">.</span>target_transform<span class="token punctuation">(</span>label<span class="token punctuation">)</span>        <span class="token keyword">return</span> image<span class="token punctuation">,</span> label<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以看出主要思路就是继承原 <code>Dataset</code> 类，然后改写了上面提到的三个方法，这也体现了面向对象的多态性</p><h3 id="Transforms"><a href="#Transforms" class="headerlink" title="Transforms"></a>Transforms</h3><blockquote><p> We use <strong>transforms</strong> to perform some manipulation of the data and make it suitable for training. The <a href="https://pytorch.org/vision/stable/transforms.html">torchvision.transforms</a> module offers several commonly-used transforms out of the box.</p></blockquote><p>数据增强是提升表现的常用手段，可以通过对数据集进行 transform 完成。文档举了两个非常简单的 transform 例子，更多的应用还是需要结合具体论文具体实践：</p><ol><li><a href="https://pytorch.org/vision/stable/transforms.html#torchvision.transforms.ToTensor">ToTensor</a> converts a PIL image or NumPy <code>ndarray</code> into a <code>FloatTensor</code>. and scales the image’s pixel intensity values in the range [0., 1.]</li><li>Lambda transforms apply any user-defined lambda function. Here, we define a function to turn the integer into a one-hot encoded tensor. </li></ol><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> datasets<span class="token keyword">from</span> torchvision<span class="token punctuation">.</span>transforms <span class="token keyword">import</span> ToTensor<span class="token punctuation">,</span> Lambdads <span class="token operator">=</span> datasets<span class="token punctuation">.</span>FashionMNIST<span class="token punctuation">(</span>    root<span class="token operator">=</span><span class="token string">"data"</span><span class="token punctuation">,</span>    train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>    download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>    transform<span class="token operator">=</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    target_transform<span class="token operator">=</span>Lambda<span class="token punctuation">(</span><span class="token keyword">lambda</span> y<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">)</span><span class="token punctuation">.</span>scatter_<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">,</span> value<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="使用-DataLoader-进行迭代"><a href="#使用-DataLoader-进行迭代" class="headerlink" title="使用 DataLoader 进行迭代"></a>使用 DataLoader 进行迭代</h3><p>将 dataset 传入 DataLoader 当中，形成可迭代对象</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoadertrain_dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>training_data<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>如果需要更复杂的取样，则需要 <a href="https://pytorch.org/docs/stable/data.html#data-loading-order-and-sampler">Samplers</a>，下面举一个 sampler 的子类进行说明</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>sampler <span class="token keyword">import</span> SubsetRandomSamplerNUM_TRAIN <span class="token operator">=</span> <span class="token number">5000</span>sampler <span class="token operator">=</span> SubsetRandomSampler<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span>NUM_TRAIN<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># 仅采样前 5000 个样本作为训练集</span>train_dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>training_data<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> sampler<span class="token operator">=</span>sampler<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在创建好 dataloader 实例过后，由于其是迭代器对象，以通过循环进行迭代。迭代器返回对象为一个元组，元组成员为数据集列表和其对应的标签列表。下面用 <code>next &amp; iter</code> 查看迭代器返回的第一个对象</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">train_features<span class="token punctuation">,</span> train_labels <span class="token operator">=</span> <span class="token builtin">next</span><span class="token punctuation">(</span><span class="token builtin">iter</span><span class="token punctuation">(</span>train_dataloader<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Feature batch shape: </span><span class="token interpolation"><span class="token punctuation">{</span>train_features<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Labels batch shape: </span><span class="token interpolation"><span class="token punctuation">{</span>train_labels<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>img <span class="token operator">=</span> train_features<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span>label <span class="token operator">=</span> train_labels<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>img<span class="token punctuation">,</span> cmap<span class="token operator">=</span><span class="token string">"gray"</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Label: </span><span class="token interpolation"><span class="token punctuation">{</span>label<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span><span class="token comment"># Output</span><span class="token comment"># Feature batch shape: torch.Size([64, 1, 28, 28])</span><span class="token comment"># Labels batch shape: torch.Size([64])</span><span class="token comment"># Label: 9</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/archives/6c437432/sphx_glr_data_tutorial_002.png" style="zoom:72%;"></p><h2 id="Build-Models"><a href="#Build-Models" class="headerlink" title="Build Models"></a>Build Models</h2><blockquote><p>Neural networks comprise of layers/modules that perform operations on data. The <a href="https://pytorch.org/docs/stable/nn.html">torch.nn</a> namespace provides all the building blocks you need to build your own neural network. </p><p>Every module in PyTorch subclasses the <a href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html">nn.Module</a>. A neural network is a module itself that consists of other modules (layers). This nested structure allows for building and managing complex architectures easily.</p></blockquote><p>建造网络模型的逻辑主要为：</p><ol><li>继承 <code>nn.Module</code> 类，这是所有网络的基类。让自定义的模型能够使用基类的方法，便于管理模型框架，例如：执行向前路径、管理模型参数及梯度、打印模型模块、模型嵌套等等</li><li>重写 <code>__init__</code> 方法，在方法中定义需要的模块</li><li>重写 <code>forward</code> 方法，在方法中定义向前计算的路径</li></ol><p>下面举一个简单的神经网络为例，看看具体实现</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">from</span> torch <span class="token keyword">import</span> nndevice <span class="token operator">=</span> <span class="token string">'cuda'</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">'cpu'</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Using {} device'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># 定义网络模型</span><span class="token keyword">class</span> <span class="token class-name">NeuralNetwork</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>flatten <span class="token operator">=</span> nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>linear_relu_stack <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">28</span><span class="token operator">*</span><span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        <span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span>x<span class="token punctuation">)</span>         x <span class="token operator">=</span> self<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>        logits <span class="token operator">=</span> self<span class="token punctuation">.</span>linear_relu_stack<span class="token punctuation">(</span>x<span class="token punctuation">)</span>        <span class="token keyword">return</span> logits<span class="token comment"># 将模型放到 GPU 上 </span>model <span class="token operator">=</span> NeuralNetwork<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token comment"># 打印模型模块</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Model structure: "</span><span class="token punctuation">,</span> model<span class="token punctuation">,</span> <span class="token string">"\n\n"</span><span class="token punctuation">)</span><span class="token keyword">for</span> name<span class="token punctuation">,</span> param <span class="token keyword">in</span> model<span class="token punctuation">.</span>named_parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Layer: </span><span class="token interpolation"><span class="token punctuation">{</span>name<span class="token punctuation">}</span></span><span class="token string"> | Size: </span><span class="token interpolation"><span class="token punctuation">{</span>param<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string"> | Values : </span><span class="token interpolation"><span class="token punctuation">{</span>param<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token format-spec">2]</span><span class="token punctuation">}</span></span><span class="token string"> \n"</span></span><span class="token punctuation">)</span><span class="token comment"># 简单测试</span>X <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span>logits <span class="token operator">=</span> model<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'logits: </span><span class="token interpolation"><span class="token punctuation">{</span>logits<span class="token punctuation">.</span>shape<span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>pred_probab <span class="token operator">=</span> nn<span class="token punctuation">.</span>Softmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">(</span>logits<span class="token punctuation">)</span>y_pred <span class="token operator">=</span> pred_probab<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Predicted class: </span><span class="token interpolation"><span class="token punctuation">{</span>y_pred<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>其中一些模块的功能就不再这里里描述了，例如：<code>nn.Sequential, nn.Flatten</code>，请直接参考 <a href="https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html#build-the-neural-network">文档</a></p><h2 id="Automatic-Differentiation"><a href="#Automatic-Differentiation" class="headerlink" title="Automatic Differentiation"></a>Automatic Differentiation</h2><blockquote><p>To compute those gradients, PyTorch has a built-in differentiation engine called <code>torch.autograd</code>. It supports automatic computation of gradient for any computational graph.</p></blockquote><p>实际上在自己写代码时，并没有显式地调用 <code>torch.autograd</code>，这个模块更多地是做背后功臣。在了解自动微分之前，需要了解如何使用反向传播算法来系统地计算参数的梯度。反向传播算法的核心就在于：通过计算图和向前计算时存储的中间结果，从 root (根节点) 计算到 leaf (叶节点)，反向逐层得到各个节点的梯度。了解反向传播算法，官方文档也推荐了 <a href="https://www.bilibili.com/video/BV16x411V7Qg?from=search&amp;seid=15593528008565591695&amp;spm_id_from=333.337.0.0">3Blue1Brown 视频</a>，3b1b nb！</p><h3 id="自动微分"><a href="#自动微分" class="headerlink" title="自动微分"></a>自动微分</h3><p>下面举一个例子来实现简单的自动微分</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token comment"># 使用随机种子</span>torch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">1998</span><span class="token punctuation">)</span>x <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span>  <span class="token comment"># input tensor</span>y <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>  <span class="token comment"># expected output</span>w <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>b <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>z <span class="token operator">=</span> torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>x<span class="token punctuation">,</span> w<span class="token punctuation">)</span><span class="token operator">+</span>bloss <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional<span class="token punctuation">.</span>binary_cross_entropy_with_logits<span class="token punctuation">(</span>z<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>以上构建了一个简单的计算流程，将需要计算的梯度的参数设为 <code>requires_grad=True</code>，或者用 <code>x.requires_grad_(True)</code>，说明一下：方法名后缀带下划线 <code>_</code> 则代表该方法为 <code>in place</code> 方法，会直接修改变量 </p><p>用公式来表示以上的计算过程</p><script type="math/tex; mode=display">z = x * w + b \\loss = -\frac{1}{N}\sum{y_i*ln(\sigma(z_i)) + (1-y_i)*ln(1 - \sigma(z_i))}</script><p>用计算图表示以上的计算过程</p><p><img src="/archives/6c437432/comp-graph.png" style="zoom: 50%;"></p><p>可以看到 tensor 在计算过程中在不断生成计算图</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token comment"># tensor([1., 1., 1., 1., 1.])</span><span class="token keyword">print</span><span class="token punctuation">(</span>z<span class="token punctuation">)</span><span class="token comment"># tensor([-2.9086,  0.8690,  1.4758], grad_fn=&lt;AddBackward0&gt;)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>因为 z 是计算得到的 tensor，可以看到其中还包含一个 <code>grad_fn</code>，这是 pytorch 中 <code>Function</code> 类的一个对象，可以把其看作计算图的具体实现。接下来只需要一行代码，就可以计算计算图中所有需要的梯度</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>b<span class="token punctuation">.</span>grad<span class="token punctuation">)</span><span class="token comment"># tensor([0.0172, 0.2348, 0.2713])</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p><strong>注意事项：</strong></p><ol><li><p>每个计算图只能计算一次，之后所有的中间结果将会被清除，但可以使用 <code>loss.backward(retain_graph=True)</code> 保留中间结果，举个简单例子说明（以下例子均沿用之前自动微分例子中的变量）</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 第一次 loss 反向传播计算梯度</span>loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># 基于 loss 创建一个新的 loss_2</span>loss_2  <span class="token operator">=</span> loss <span class="token operator">**</span> <span class="token number">2</span>loss_2<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># 在第二次反向传播计算中，显然会重新进行第一次的反向传播的计算流程</span><span class="token comment"># RuntimeError: Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time.</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>一般只对标量进行 <code>backward</code> 操作。对矢量进行 <code>backward</code> 操作，即对矢量进行求导，会得到雅可比矩阵</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># w.shape=(5, 3) w.requires_grad=True</span>z <span class="token operator">=</span> w <span class="token operator">**</span> <span class="token number">2</span>z<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># RuntimeError: grad can be implicitly created only for scalar outputs</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>对于中间变量（即非叶节点变量），由于在反向传播时需要计算其梯度，在自动微分时会标记其 <code>requires_grad=True</code>，但一般在反向传播计算完成之后，不保留这些中间结果的梯度，如需要则要调用方法 <code>x.retain_grad()</code></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># z.retain_grad()</span>loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>z<span class="token punctuation">.</span>grad<span class="token punctuation">)</span><span class="token comment"># warnings.warn("The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad "</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li></ol><h3 id="禁用自动微分"><a href="#禁用自动微分" class="headerlink" title="禁用自动微分"></a>禁用自动微分</h3><p>禁用自动微分主要应用在两个场景：</p><ol><li>Freeze parameters，将参数从计算图中剔除，gradient flow 不会经过该参数</li><li>仅计算向前路径，不跟踪所有梯度，加快计算</li></ol><p>针对以上的场景，有两种方法能够禁用自动微分：</p><ol><li><code>x.detach_()</code>：将 x 变量 <code>requires_grad=False</code></li><li><code>with torch.no_grad()</code>：在该模块内的所有运算，都不会跟踪计算图，即所有变量 <code>requires_grad=False</code></li></ol><p>下面仅对 <code>detach</code> 方法进行重点说明</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># detach</span><span class="token keyword">import</span> torchmode <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'no_detach'</span><span class="token punctuation">,</span> <span class="token string">'detach'</span><span class="token punctuation">]</span><span class="token keyword">for</span> mode_ <span class="token keyword">in</span> mode<span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'MODE: </span><span class="token interpolation"><span class="token punctuation">{</span>mode_<span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>    x <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>    y <span class="token operator">=</span> x <span class="token operator">**</span> <span class="token number">2</span>    z <span class="token operator">=</span> x <span class="token operator">**</span> <span class="token number">3</span>    <span class="token keyword">if</span> mode_ <span class="token operator">==</span> <span class="token string">'detach'</span><span class="token punctuation">:</span>        z<span class="token punctuation">.</span>detach_<span class="token punctuation">(</span><span class="token punctuation">)</span>    loss <span class="token operator">=</span> <span class="token punctuation">(</span>y<span class="token operator">+</span>z<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'parameter z:\n</span><span class="token interpolation"><span class="token punctuation">{</span>z<span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'x_grad:\n</span><span class="token interpolation"><span class="token punctuation">{</span>x<span class="token punctuation">.</span>grad<span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">,</span><span class="token string">'\n'</span><span class="token punctuation">)</span><span class="token triple-quoted-string string">''' resultMODE: no_detachparameter z:tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], grad_fn=&lt;PowBackward0&gt;)x_grad:tensor([5., 5., 5., 5., 5., 5., 5., 5., 5., 5.]) MODE: detachparameter z:tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])x_grad:tensor([2., 2., 2., 2., 2., 2., 2., 2., 2., 2.])  '''</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以看到将 b 节点从计算图中剔除之后，x 的梯度减少了，因为 gradient flow 不从 b 节点流过，前后计算图如下</p><p><img src="/archives/6c437432/attached.png" alt="attached graph" style="zoom: 67%;"></p><p><img src="/archives/6c437432/detached.png" alt="detached graph" style="zoom:67%;"></p><p>值得注意的是在计算图建立之后，对变量进行 detach 并不会影响反向传播</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torchx <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>y <span class="token operator">=</span> x <span class="token operator">**</span> <span class="token number">2</span>z <span class="token operator">=</span> x <span class="token operator">**</span> <span class="token number">3</span>loss <span class="token operator">=</span> <span class="token punctuation">(</span>y<span class="token operator">+</span>z<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'parameter z:\n</span><span class="token interpolation"><span class="token punctuation">{</span>z<span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span><span class="token comment"># tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], grad_fn=&lt;PowBackward0&gt;)</span>z<span class="token punctuation">.</span>detach_<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'parameter z_detached:\n</span><span class="token interpolation"><span class="token punctuation">{</span>z<span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span><span class="token comment">#tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])</span>loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'x_grad:\n</span><span class="token interpolation"><span class="token punctuation">{</span>x<span class="token punctuation">.</span>grad<span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">,</span><span class="token string">'\n'</span><span class="token punctuation">)</span><span class="token comment"># tensor([5., 5., 5., 5., 5., 5., 5., 5., 5., 5.]) </span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这是为什么呢？我的理解是计算图在构建完成之后，仅进行 detach 不会对已经生成的计算图进行修改，且 tensor 本身的值没有发生改，计算图就可以使用该值进行梯度计算。而之前的 for 循环每一次循环都重新创建了计算图</p><h2 id="Optimization"><a href="#Optimization" class="headerlink" title="Optimization"></a>Optimization</h2><p>这里将是整个深度学习耗时最长的部分，需要将之前的数据集送入到模型之中，使用优化算法改进模型。这一部分沿用之前的 <code>Fashion-MNIST</code> 数据集和神经网络，完整代码参考 <a href="https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html#prerequisite-codehttps://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html#prerequisite-code">prerequisite code</a></p><h3 id="优化循环"><a href="#优化循环" class="headerlink" title="优化循环"></a>优化循环</h3><p>在整个循环过程中，除了之前提到的数据集和模型，还有两个重要元素：损失函数和优化器。Pytorch 中的损失函数在 <code>nn</code> 模块下，优化器在 <code>optim</code> 模块下</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optimloss_fn <span class="token operator">=</span> nn<span class="token punctuation">.</span>X<span class="token punctuation">(</span><span class="token punctuation">)</span>                            <span class="token comment"># where X is L1Loss, MSELoss, CrossEntropyLoss...</span>opt <span class="token operator">=</span> optim<span class="token punctuation">.</span>X<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>      <span class="token comment"># where X is SGD, Adadelta, Adagrad, Adam...</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>整体的优化逻辑分为两步，首先使用反向传播算法计算出参数的梯度，然后根据这些梯度采用不同的优化算法进行迭代优化 <code>opt.step()</code> 。下面的代码实现了 <code>train_loop</code> 和 <code>teat_loop</code> 分别实现训练和测试模型</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">train_loop</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> loss_fn<span class="token punctuation">,</span> optimizer<span class="token punctuation">)</span><span class="token punctuation">:</span>    size <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span>    <span class="token keyword">for</span> batch<span class="token punctuation">,</span> <span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># Compute prediction and loss</span>        pred <span class="token operator">=</span> model<span class="token punctuation">(</span>X<span class="token punctuation">)</span>        loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>pred<span class="token punctuation">,</span> y<span class="token punctuation">)</span>        <span class="token comment"># Backpropagation</span>        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> batch <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>            loss<span class="token punctuation">,</span> current <span class="token operator">=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> batch <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"loss: </span><span class="token interpolation"><span class="token punctuation">{</span>loss<span class="token punctuation">:</span><span class="token format-spec">&gt;7f</span><span class="token punctuation">}</span></span><span class="token string">  [</span><span class="token interpolation"><span class="token punctuation">{</span>current<span class="token punctuation">:</span><span class="token format-spec">&gt;5d</span><span class="token punctuation">}</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">{</span>size<span class="token punctuation">:</span><span class="token format-spec">&gt;5d</span><span class="token punctuation">}</span></span><span class="token string">]"</span></span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">test_loop</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> loss_fn<span class="token punctuation">)</span><span class="token punctuation">:</span>    size <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span>    num_batches <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span>    test_loss<span class="token punctuation">,</span> correct <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span>    <span class="token comment"># Will not build computational graph</span>    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">for</span> X<span class="token punctuation">,</span> y <span class="token keyword">in</span> dataloader<span class="token punctuation">:</span>            pred <span class="token operator">=</span> model<span class="token punctuation">(</span>X<span class="token punctuation">)</span>            test_loss <span class="token operator">+=</span> loss_fn<span class="token punctuation">(</span>pred<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>            correct <span class="token operator">+=</span> <span class="token punctuation">(</span>pred<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">==</span> y<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">type</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>    test_loss <span class="token operator">/=</span> num_batches    correct <span class="token operator">/=</span> size    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Test Error: \n Accuracy: </span><span class="token interpolation"><span class="token punctuation">{</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token operator">*</span>correct<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">&gt;0.1f</span><span class="token punctuation">}</span></span><span class="token string">%, Avg loss: </span><span class="token interpolation"><span class="token punctuation">{</span>test_loss<span class="token punctuation">:</span><span class="token format-spec">&gt;8f</span><span class="token punctuation">}</span></span><span class="token string"> \n"</span></span><span class="token punctuation">)</span>model <span class="token operator">=</span> NeuralNetwork<span class="token punctuation">(</span><span class="token punctuation">)</span>    loss_fn <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>learning_rate <span class="token operator">=</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">3</span>optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>learning_rate<span class="token punctuation">)</span>epochs <span class="token operator">=</span> <span class="token number">10</span><span class="token keyword">for</span> t <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Epoch </span><span class="token interpolation"><span class="token punctuation">{</span>t<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">}</span></span><span class="token string">\n-------------------------------"</span></span><span class="token punctuation">)</span>    train_loop<span class="token punctuation">(</span>train_dataloader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> loss_fn<span class="token punctuation">,</span> optimizer<span class="token punctuation">)</span>    test_loop<span class="token punctuation">(</span>test_dataloader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> loss_fn<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Done!"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>最终结果也请直接查看 <a href="https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html#optimization-loop">optimization loop</a></p><h2 id="Save-and-Load-the-Model"><a href="#Save-and-Load-the-Model" class="headerlink" title="Save and Load the Model"></a>Save and Load the Model</h2><h3 id="保存模型参数"><a href="#保存模型参数" class="headerlink" title="保存模型参数"></a>保存模型参数</h3><p>模型的参数存储在其内部的一个字典当中，使用 <code>model.state_dict()</code> 方法可以返回该字典。使用 <code>torch.save</code> 方法即可存储</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>models <span class="token keyword">as</span> modelsmodel <span class="token operator">=</span> models<span class="token punctuation">.</span>vgg16<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'model_weights.pth'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这样就将模型参数保存到当前文件夹下，如果需要加载模型参数，则必须要先创建一个模型实例</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">model <span class="token operator">=</span> models<span class="token punctuation">.</span>vgg16<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># we do not specify pretrained=True, i.e. do not load default weights</span>model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'model_weights.pth'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p><strong>注意：</strong>一定要在推理之前调用 <code>model.eval()</code> 方法，以将 dropout 和 batch_norm 层设置为评估模式。不这样做会产生不一致的推理结果</p><h3 id="保存模型参数及其结构"><a href="#保存模型参数及其结构" class="headerlink" title="保存模型参数及其结构"></a>保存模型参数及其结构</h3><p>如果想要同时保存其结构，则直接传入模型本身</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">,</span> <span class="token string">'model.pth'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>加载模型虽然不需要先实例化模型，但仍需要有模型的定义</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># Model class must be defined somewhere</span>model <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'model.pth'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="模型导出为-ONNX"><a href="#模型导出为-ONNX" class="headerlink" title="模型导出为 ONNX"></a>模型导出为 ONNX</h3><blockquote><p><strong>ONNX is an open format built to represent machine learning models.</strong> ONNX defines a common set of operators - the building blocks of machine learning and deep learning models - and a common file format to enable AI developers to use models with a variety of frameworks, tools, runtimes, and compilers.</p></blockquote><p>Pytorch 支持将模型转为 ONNX 格式，更多信息就不打算整理了 <a href="https://pytorch.org/tutorials/beginner/basics/saveloadrun_tutorial.html#exporting-model-to-onnx">Exporting Model to ONNX</a> <a href="https://github.com/onnx/tutorials">ONNX tutorial</a></p><h2 id="整体复习"><a href="#整体复习" class="headerlink" title="整体复习"></a>整体复习</h2><blockquote><p>Congratulations! You have completed the PyTorch beginner tutorial! Try <a href="https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html">revisting the first page</a> to see the tutorial in its entirety again. We hope this tutorial has helped you get started with deep learning on PyTorch. Good luck!</p></blockquote><h2 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h2><p>根据自己在实践中遇到的 torch 常用操作总结，torch 里面习惯使用 <code>dim=</code> 而不是 <code>axis=</code></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torchtorch<span class="token punctuation">.</span>eye<span class="token punctuation">(</span>n<span class="token punctuation">,</span> m<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token comment"># n rows, m col</span>torch<span class="token punctuation">.</span>nonzero<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span><span class="token comment"># return a 2D tensor (N, input.shape)</span>torch<span class="token punctuation">.</span>where<span class="token punctuation">(</span>condition<span class="token punctuation">,</span> x<span class="token punctuation">,</span> y<span class="token punctuation">)</span>torch<span class="token punctuation">.</span>clamp<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> <span class="token builtin">min</span><span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token builtin">max</span><span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> <span class="token builtin">sum</span><span class="token punctuation">)</span><span class="token comment"># return a tuple (tensor, LongTensor)</span>torch<span class="token punctuation">.</span>norm<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token comment"># x is a tensor</span>x<span class="token punctuation">.</span>repeat<span class="token punctuation">(</span><span class="token operator">*</span>sizes<span class="token punctuation">)</span><span class="token comment"># repeat times</span>x<span class="token punctuation">.</span>expand<span class="token punctuation">(</span><span class="token operator">*</span>sizes<span class="token punctuation">)</span><span class="token comment"># expand to sizes</span>x<span class="token punctuation">.</span>contigous<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># 连续空间</span>x<span class="token punctuation">.</span>repeat_interleave<span class="token punctuation">(</span>tensor<span class="token punctuation">)</span><span class="token comment"># numpy.repeat()</span><span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> FF<span class="token punctuation">.</span>interpolate<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> size<span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token punctuation">)</span>F<span class="token punctuation">.</span>one_hot<span class="token punctuation">(</span>LongTensor<span class="token punctuation">,</span> num_classes<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 编程 </category>
          
          <category> Python </category>
          
          <category> Pytorch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 教程 </tag>
            
            <tag> Pytorch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>这本书能让你睡好</title>
      <link href="/archives/dead6afd.html"/>
      <url>/archives/dead6afd.html</url>
      
        <content type="html"><![CDATA[<h1 id="这本书能让你睡好"><a href="#这本书能让你睡好" class="headerlink" title="这本书能让你睡好"></a>这本书能让你睡好</h1><p>总体来讲分为几个大方面：睡眠观念，睡眠和锻炼的时间，光线影响，饮食影响，温度影响，身心放松技巧</p><h2 id="第一章-了解睡眠的价值（观念）"><a href="#第一章-了解睡眠的价值（观念）" class="headerlink" title="第一章 了解睡眠的价值（观念）"></a>第一章 了解睡眠的价值（观念）</h2><p>永远记住失眠的价值。当获得必须的睡眠，你会表现得更出色，做出更明智的决定，拥有更健康的身体。睡眠不是我们需要逾越的障碍，它是一种身体所需的自然状态，可以增强激素作用，治愈肌肉、组织和器官，让身体免受疾病侵害，让理智达到最优水平。重新调配你的睡眠，不要把睡眠视为需要克服的障碍，把睡眠看成对自己的特殊款待！</p><h2 id="第二章-白天多晒太阳（光线）"><a href="#第二章-白天多晒太阳（光线）" class="headerlink" title="第二章 白天多晒太阳（光线）"></a>第二章 白天多晒太阳（光线）</h2><p>晨光是如何改善睡眠的呢？光纤其实是在发信号给下丘脑及所有相关器官和腺体，提醒它们该醒了。最近，一项研究考察了日班办公室人员的睡眠质量，相比直接靠窗的人员，不靠窗人员接收的自然光会少173%，并因此平均没晚少睡46分钟。想要获得完美的睡眠，褪黑素真实扮演者明星级的角色。褪黑素是由人体中的松果腺和其他组织生成的，当室外变暗时，身体就会自然分泌褪黑素。但是如果不能在正确的时间获得适当的光线，我们的身体就会出现问题。皮质醇和褪黑素算是呈你相关的一对激素。白天接收阳光照射之所以重要，还有一个原因是可以刺激皮质醇的生成。获得更多阳光照射，可以为正常的皮质醇节律和褪黑素节律控制节奏。阳光中含有许多影响身体的波长，我们最需要了解UVA和UVB，UV代表紫外线，对UVA的不健康接触也是不行的(例如太阳暴晒)，UVB对人体健康的价值最大，因为它是唯一会刺激人体生成维生素D的波长。</p><h2 id="第三章-睡前远离电子屏幕（光线）"><a href="#第三章-睡前远离电子屏幕（光线）" class="headerlink" title="第三章 睡前远离电子屏幕（光线）"></a>第三章 睡前远离电子屏幕（光线）</h2><p>想要立刻改善睡眠，第一步就是减少晚间看电子屏幕的时间。蓝光会严重影响睡眠，因为会刺激人体生成更多的白天激素，误导原本准备睡觉的人。我们使用电子设备的文化传统不过刚刚几十年，在几百万年的进化历程与几十年熬夜习惯的对抗中，我们的能力也没进化得快适应。如果你想根据身体需求，进入深度睡眠，在睡前90分钟，你要关闭所有屏幕，让褪黑素激素和皮质醇水平回复正常。</p><h2 id="第四章-建立咖啡因宵禁（饮食）"><a href="#第四章-建立咖啡因宵禁（饮食）" class="headerlink" title="第四章 建立咖啡因宵禁（饮食）"></a>第四章 建立咖啡因宵禁（饮食）</h2><p>咖啡因是一种强大的神经兴奋剂。由于咖啡因摄入导致睡眠不足，必然会让我们感觉更加疲惫，疲惫之后我们会期待更多的咖啡因，这会让我们的睡眠问题雪上加霜。咖啡因的半衰期为5~8小时，半衰期本质上是指，人体系统中的物质最高浓度降低一般所需的时间。设定一个必须遵守的咖啡因小金，确保在你睡觉前，可以排除体系中的大部分咖啡因，对于大部分人来说，那个时间通常是下午2：00前。</p><h2 id="第五章-让自己凉快点（温度）"><a href="#第五章-让自己凉快点（温度）" class="headerlink" title="第五章 让自己凉快点（温度）"></a>第五章 让自己凉快点（温度）</h2><p>当身体该休息时，人体核心温度会自动下降，帮助人们启动睡眠状态。如果外界温度过高，身体想进入理想的舒适睡眠，就会面临一点生理上的挑战。研究表明，最佳的睡眠温度是15°~20°。如果你有睡眠障碍，试着睡前花1.5~2小时，洗个热水澡。</p><h2 id="第六章-选择正确的入睡时间（时间）"><a href="#第六章-选择正确的入睡时间（时间）" class="headerlink" title="第六章 选择正确的入睡时间（时间）"></a>第六章 选择正确的入睡时间（时间）</h2><p>人类在晚10点到凌晨2点处于睡眠状态，可以获得最佳的激素分泌和恢复效果。如果有人熬到晚上10点或11点，进入精力恢复状态后，通常觉得想睡觉更难入睡。精力恢复状态跟锻炼的过程区别不大，做过耐力训练的人都直到，只要坚持一段时间，即便你感觉累了，身体也会进入恢复状态，再次感觉精力满满，继续坚持下去。</p><h2 id="第十章-调暗光线（时间）"><a href="#第十章-调暗光线（时间）" class="headerlink" title="第十章 调暗光线（时间）"></a>第十章 调暗光线（时间）</h2><p>卧室里任何的光源都会打乱睡眠模式，即使戴上眼罩也不是100%有效的。你知道皮肤上其实有光感器吗？如果卧室里有光源，你的身体会接收光线，向大脑和器官发送信息从而干扰睡眠。</p><h2 id="第十一章-讲究方法，好好锻炼（时间）"><a href="#第十一章-讲究方法，好好锻炼（时间）" class="headerlink" title="第十一章 讲究方法，好好锻炼（时间）"></a>第十一章 讲究方法，好好锻炼（时间）</h2><p>关键问题不在于锻炼本身，而在于锻炼的时间和方式。为了优化睡眠，你活动时需要遵循几个原则：1.晚上不适合锻炼，早晨锻炼的好处不能忽视；2.长跑不利于好的睡眠；3.为了获得最佳的激素反应，需要做些举重练习</p><h2 id="第十四章-喝酒悠着点（饮食）"><a href="#第十四章-喝酒悠着点（饮食）" class="headerlink" title="第十四章 喝酒悠着点（饮食）"></a>第十四章 喝酒悠着点（饮食）</h2><p>晚上喝酒有利于快速入睡，但是快速眼动睡眠会被身体中的酒精严重干扰，你将无法进入深度的、持续的快速眼动睡眠，大脑和身体也无法完全恢复。</p><h2 id="第十六章-让心里话停下来-（冥想-腹式呼吸-技巧）"><a href="#第十六章-让心里话停下来-（冥想-腹式呼吸-技巧）" class="headerlink" title="第十六章 让心里话停下来 （冥想 腹式呼吸 技巧）"></a>第十六章 让心里话停下来 （冥想 腹式呼吸 技巧）</h2><h2 id="第十八章-早点起床（时间）"><a href="#第十八章-早点起床（时间）" class="headerlink" title="第十八章 早点起床（时间）"></a>第十八章 早点起床（时间）</h2><h2 id="第十九章-选择合适的纤体方法-（渐进式肌肉放松-按摩-技巧）"><a href="#第十九章-选择合适的纤体方法-（渐进式肌肉放松-按摩-技巧）" class="headerlink" title="第十九章 选择合适的纤体方法 （渐进式肌肉放松 按摩 技巧）"></a>第十九章 选择合适的纤体方法 （渐进式肌肉放松 按摩 技巧）</h2>]]></content>
      
      
      <categories>
          
          <category> 生活 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 睡眠 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python 3 面向对象</title>
      <link href="/archives/59bf225c.html"/>
      <url>/archives/59bf225c.html</url>
      
        <content type="html"><![CDATA[<h1 id="python-面向对象"><a href="#python-面向对象" class="headerlink" title="python 面向对象"></a>python 面向对象</h1><h2 id="面向对象编程"><a href="#面向对象编程" class="headerlink" title="面向对象编程"></a>面向对象编程</h2><p>什么是面向对象编程？用一段话描述面向对象的思想：</p><blockquote><p>把一组数据结构和处理它们的方法组成对象（object），把相同行为的对象归纳为类（class），通过类的封装（encapsulation）隐藏内部细节，通过继承（inheritance）实现类的特化（specialization）和泛化（generalization），通过多态（polymorphism）实现基于对象类型的动态分派</p></blockquote><p>这一段话我在之前是看得云里雾里，这样高度的概括过于抽象。现在看过了一些代码过后，再回头看这段话才没那么迷惑</p><h2 id="类和对象"><a href="#类和对象" class="headerlink" title="类和对象"></a>类和对象</h2><p>类是对象的模板，对象是类的实例。在面向对象的世界中，一切皆为对象。下面来创建一个类</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Student</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> name<span class="token punctuation">,</span> age<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>name <span class="token operator">=</span> name        self<span class="token punctuation">.</span>age <span class="token operator">=</span> age        <span class="token keyword">def</span> <span class="token function">introduce</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"My name is %s. I'm %d."</span> <span class="token operator">%</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>name<span class="token punctuation">,</span> self<span class="token punctuation">.</span>age<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>之前提到过 <code>__init__()</code> 方法在类中属于特殊方法，会在创建对象的时候自动调用。通过这个方法可以给对象绑定 <code>name</code> &amp; <code>age</code> 两个属性，这样在其他方法里就能够随意调用这些属性，而不需要再次传入这些参数。下面来创建 <code>Student</code> 类的对象，并使用其内部函数</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">student_1 <span class="token operator">=</span> Student<span class="token punctuation">(</span><span class="token string">'Declan'</span><span class="token punctuation">,</span> <span class="token number">23</span><span class="token punctuation">)</span>student_1<span class="token punctuation">.</span>introduce<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># My name is Declan. I'm 23.</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>创建对象，就是将类实例化，具体一点来说：给类传入一些参数，让其从模板称为了一个具体的对象。可以看到在创建的对象的代码里，并没有显式使用，也不能显式使用特殊方法 <code>__init__()</code> </p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># try this</span>student_2 <span class="token operator">=</span> Student<span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token string">'Declan'</span><span class="token punctuation">,</span> <span class="token number">23</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>这样做一定是会报错的。所以正确的理解是，<code>Student(name, age)</code> 中的参数 <code>name</code> &amp; <code>age</code> 就是给 <code>__init__()</code> 的参数，并在创建对象的时候自动运行 <code>__init__()</code> 方法</p><h3 id="访问可见性问题"><a href="#访问可见性问题" class="headerlink" title="访问可见性问题"></a>访问可见性问题</h3><p>在很多面向对象编程语言中，我们通常会将对象的属性设置为私有的（private）或受保护的（protected），简单的说就是不允许外界访问，而对象的方法通常都是公开的（public），在 Python 中，属性和方法的访问权限只有两种，也就是公开的和私有的，如果希望属性是私有的，在给属性命名时可以用两个下划线作为开头</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Test</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>__private <span class="token operator">=</span> <span class="token string">'private'</span>        self<span class="token punctuation">.</span>__func<span class="token punctuation">(</span><span class="token punctuation">)</span>                    <span class="token keyword">def</span> <span class="token function">__func</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>__private<span class="token punctuation">)</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'this function is private'</span><span class="token punctuation">)</span>test <span class="token operator">=</span> Test<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># private</span><span class="token comment"># this function is private</span><span class="token keyword">print</span><span class="token punctuation">(</span>test<span class="token punctuation">.</span>__private<span class="token punctuation">)</span><span class="token comment"># AttributeError: 'Test' object has no attribute '__private'</span><span class="token comment"># 直接访问被阻拦，但拐个弯还是有方法能够访问</span><span class="token keyword">print</span><span class="token punctuation">(</span>test<span class="token punctuation">.</span>_Test__private<span class="token punctuation">)</span><span class="token comment"># private</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以看在类的内部调用这些私有变量和函数是没有问题的，但是想要在函数之外直接访问这些变量和函数是被禁止的。在实际开发中，我们并不建议将属性设置为私有的，因为这会导致子类无法访问（后面会讲到）。所以大多数 Python 程序员会遵循一种命名惯例就是让属性名以单下划线开头如 <code>_name</code>，来表示属性是受保护的，本类之外的代码在访问这样的属性时应该要保持慎重</p><h2 id="类的方法"><a href="#类的方法" class="headerlink" title="类的方法"></a>类的方法</h2><h3 id="self"><a href="#self" class="headerlink" title="self"></a>self</h3><p>类的方法与普通的函数只有一个特别的区别——它们必须有一个额外的<strong>第一个参数名称</strong>，按照惯例它的名称是 self，当然也可以叫其它名字，下面看看这个 self 到底代表了什么</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Test</span><span class="token punctuation">:</span><span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>SELF<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token keyword">print</span><span class="token punctuation">(</span>SELF<span class="token punctuation">.</span>__class__<span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">pointer_self</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token keyword">print</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span>test <span class="token operator">=</span> Test<span class="token punctuation">(</span><span class="token punctuation">)</span>test<span class="token punctuation">.</span>pointer_self<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># &lt;class '__main__.Test'&gt;</span><span class="token comment"># &lt;__main__.Test object at 0x000001B64F611040&gt;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>从执行结果可以很明显的看出，self 代表的是类的实例，代表当前对象的地址，而 self.class 则指向类</p><h2 id="继承"><a href="#继承" class="headerlink" title="继承"></a>继承</h2><p>如果一种语言不支持继承，类就没有什么意义。子类会继承父类（也叫基类）的属性和方法，而且还可以定义自己的属性和方法，所以子类比父类拥有更多的能力，下面看一个简短的代码，理解继承机制的逻辑</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 这是之前写的学生类</span><span class="token keyword">class</span> <span class="token class-name">Student</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> name<span class="token punctuation">,</span> age<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>name <span class="token operator">=</span> name        self<span class="token punctuation">.</span>age <span class="token operator">=</span> age        self<span class="token punctuation">.</span>log <span class="token operator">=</span> <span class="token string">'this is a student'</span>        <span class="token keyword">def</span> <span class="token function">introduce</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"My name is %s. I'm %d."</span> <span class="token operator">%</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>name<span class="token punctuation">,</span> self<span class="token punctuation">.</span>age<span class="token punctuation">)</span><span class="token punctuation">)</span>   <span class="token comment"># 现在建立一个本科生类</span><span class="token keyword">class</span> <span class="token class-name">Undergraduate</span><span class="token punctuation">(</span>Student<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> name<span class="token punctuation">,</span> age<span class="token punctuation">,</span> grade<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># 在子类中调用父类的方法</span>        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span>name<span class="token punctuation">,</span> age<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>grade <span class="token operator">=</span> grade    <span class="token keyword">def</span> <span class="token function">which_grade</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'My grade is %d.'</span> <span class="token operator">%</span> self<span class="token punctuation">.</span>grade<span class="token punctuation">)</span>        <span class="token comment"># 在多态的时候取消注释</span>    <span class="token comment"># def introduce(self):</span>    <span class="token comment">#     print("Hello! My name is %s. I'm %d." % (self.name, self.age))</span>student_1 <span class="token operator">=</span> Undergraduate<span class="token punctuation">(</span><span class="token string">'Declan'</span><span class="token punctuation">,</span> <span class="token number">18</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>student_1<span class="token punctuation">.</span>which_grade<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># My grade is 1.</span><span class="token comment"># 子类实例直接使用父类的属性和方法</span><span class="token keyword">print</span><span class="token punctuation">(</span>student_1<span class="token punctuation">.</span>log<span class="token punctuation">)</span>student_1<span class="token punctuation">.</span>introduce<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># this is a student</span><span class="token comment"># My name is Declan. I'm 18.</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>重点的几个逻辑：</p><ol><li>声明父类，在定义的类名后传入父类名即可，如 <code>class Undergraduate(Student)</code></li><li>调用父类，通过 <code>super()</code> 函数调用父类中的属性、方法，如果是 python 2.x 的话需要使用 <code>super(子类名, self)</code> 调用</li><li>实例使用父类，子类实例可以直接使用父类中的属性、方法</li></ol><h2 id="多态"><a href="#多态" class="headerlink" title="多态"></a>多态</h2><p>子类在继承了父类的方法后，可以对父类已有的方法给出新的实现版本，这个动作称之为方法重写（override），父类的方法可以被多个子类进行重写得到多个不同的实现版本，这个就是多态（poly-morphism）</p><p>把上一节中关于多态的代码取消注释，再调用 <code>introduce()</code> 方法</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">student_1<span class="token punctuation">.</span>introduce<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># Hello! My name is Declan. I'm 18.</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>发现比之前父类的 <code>introduce()</code> 多打印了 <code>Hello!</code> 重写成功！ </p><h2 id="补充：类的特殊方法"><a href="#补充：类的特殊方法" class="headerlink" title="补充：类的特殊方法"></a>补充：类的特殊方法</h2><p>这些类的特殊方法也叫魔术方法，在特殊条件下被调用，下面列举一些</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token operator">-</span> <span class="token operator">**</span>__init__ <span class="token punctuation">:</span><span class="token operator">**</span> 构造函数，在生成对象时调用<span class="token operator">-</span> <span class="token operator">**</span>__del__ <span class="token punctuation">:</span><span class="token operator">**</span> 析构函数，释放对象时使用<span class="token operator">-</span> <span class="token operator">**</span>__repr__ <span class="token punctuation">:</span><span class="token operator">**</span> 打印对象时调用<span class="token operator">-</span> <span class="token operator">**</span>__setitem__ <span class="token punctuation">:</span><span class="token operator">**</span> 按照索引赋值<span class="token operator">-</span> <span class="token operator">**</span>__getitem__<span class="token punctuation">:</span><span class="token operator">**</span> 按照索引获取值<span class="token operator">-</span> <span class="token operator">**</span>__len__<span class="token punctuation">:</span><span class="token operator">**</span> 获得长度<span class="token operator">-</span> <span class="token operator">**</span>__cmp__<span class="token punctuation">:</span><span class="token operator">**</span> 比较运算<span class="token operator">-</span> <span class="token operator">**</span>__call__<span class="token punctuation">:</span><span class="token operator">**</span> 让对象变为可调用对象<span class="token comment"># 下面的魔术方法可以进行算符重载</span><span class="token operator">-</span> <span class="token operator">**</span>__add__<span class="token punctuation">:</span><span class="token operator">**</span> 加运算<span class="token operator">-</span> <span class="token operator">**</span>__sub__<span class="token punctuation">:</span><span class="token operator">**</span> 减运算<span class="token operator">-</span> <span class="token operator">**</span>__mul__<span class="token punctuation">:</span><span class="token operator">**</span> 乘运算<span class="token operator">-</span> <span class="token operator">**</span>__truediv__<span class="token punctuation">:</span><span class="token operator">**</span> 除运算<span class="token operator">-</span> <span class="token operator">**</span>__mod__<span class="token punctuation">:</span><span class="token operator">**</span> 求余运算<span class="token operator">-</span> <span class="token operator">**</span>__pow__<span class="token punctuation">:</span><span class="token operator">**</span> 乘方<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>实验一下 <code>__repr__, __call__</code></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Student</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> name<span class="token punctuation">,</span> age<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token boolean">None</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>name <span class="token operator">=</span> name        self<span class="token punctuation">.</span>age <span class="token operator">=</span> age    <span class="token keyword">def</span> <span class="token function">__repr__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">str</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> <span class="token string">"My name is {}. I'm {}."</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>name<span class="token punctuation">,</span> self<span class="token punctuation">.</span>age<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">__call__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> grade<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">str</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> <span class="token string">'grade {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>grade<span class="token punctuation">)</span>name <span class="token operator">=</span> <span class="token string">'Declan'</span>age <span class="token operator">=</span> <span class="token number">23</span>stu <span class="token operator">=</span> Student<span class="token punctuation">(</span>name<span class="token punctuation">,</span> age<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>stu<span class="token punctuation">)</span><span class="token comment"># My name is Declan. I'm 23.</span><span class="token keyword">print</span><span class="token punctuation">(</span>stu<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># grade 2</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="补充：装饰器"><a href="#补充：装饰器" class="headerlink" title="补充：装饰器"></a>补充：装饰器</h2><p>参考 <a href="https://www.cnblogs.com/auguse/articles/9922257.html">博客</a> 进行整理。装饰器本质上是一个 Python 函数或类，它可以让其他函数或类在不需要做任何代码修改的前提下增加额外功能。由于在学习 mmdetection 中发现 <code>registry</code> 类的实现就需要装饰器的帮忙，所以接下来将“花费”一些篇幅来了解装饰器的内部逻辑</p><h3 id="装饰器基本原理"><a href="#装饰器基本原理" class="headerlink" title="装饰器基本原理"></a>装饰器基本原理</h3><p>下面先看看不用 python 装饰器，怎样实现其类似的功能</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 原函数</span><span class="token keyword">def</span> <span class="token function">test</span><span class="token punctuation">(</span>name<span class="token punctuation">,</span> age<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"My name is {}, and I'm {}."</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>name<span class="token punctuation">,</span> age<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># 定义一个装饰器来包装原函数</span><span class="token keyword">def</span> <span class="token function">decorate</span><span class="token punctuation">(</span>func<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">wrap</span><span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'This is my introduction.'</span><span class="token punctuation">)</span>        func<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>    <span class="token comment"># 返回新的函数名</span>    <span class="token keyword">return</span> wrap<span class="token comment"># 将原函数包装，并将原函数指向装饰后的函数</span>test  <span class="token operator">=</span> decorate<span class="token punctuation">(</span>test<span class="token punctuation">)</span>name <span class="token operator">=</span> <span class="token string">'Declan'</span>age <span class="token operator">=</span> <span class="token number">23</span>test<span class="token punctuation">(</span>name<span class="token punctuation">,</span> age<span class="token punctuation">)</span><span class="token comment"># This is my introduction.</span><span class="token comment"># My name is Declan, and I'm 23.</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这样就实现了一个简单的装饰器，该装饰器的功能就是在原函数之前打印一句话 <code>This is my introduction</code></p><p>python 使用 <code>@</code> 关键字来实现装饰器，具体来说 <code>@</code> 关键字实现的是上面代码中的注释“将原函数包装，并将原函数指向装饰后的函数”。将之前的装饰器，用 <code>@</code> 重新实现</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 定义一个装饰器来包装原函数</span><span class="token keyword">def</span> <span class="token function">decorate</span><span class="token punctuation">(</span>func<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">wrap</span><span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'This is my introduction.'</span><span class="token punctuation">)</span>        func<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>    <span class="token comment"># 返回新的函数名</span>    <span class="token keyword">return</span> wrap<span class="token comment"># 原函数+装饰器</span><span class="token decorator annotation punctuation">@decorate</span><span class="token keyword">def</span> <span class="token function">test</span><span class="token punctuation">(</span>name<span class="token punctuation">,</span> age<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"My name is {}, and I'm {}."</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>name<span class="token punctuation">,</span> age<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># test  = decortate(test)</span>name <span class="token operator">=</span> <span class="token string">'Declan'</span>age <span class="token operator">=</span> <span class="token number">23</span>test<span class="token punctuation">(</span>name<span class="token punctuation">,</span> age<span class="token punctuation">)</span><span class="token comment"># This is my introduction.</span><span class="token comment"># My name is Declan, and I'm 23</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token punctuation">(</span>test<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># &lt;class 'function'&gt;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以看到，就是在原函数之前加上 <code>@decorate</code> 就实现了对原函数的装饰，替代了 <code>test  = decorate(test)</code> 这一步，<strong>这就是装饰器的本质</strong>。换句话说 <code>@</code> 关键字将下一行的函数/类，作为参数传给了 <code>decorate</code> 函数，而 <code>decorate(test)</code> 通常将返回一个函数，此函数将能用 <code>test</code> 进行调用</p><p>之前的装饰器只接受了原函数 <code>test</code> 作为参数，那如果想要实现传入多个参数，例如 <code>@decorate(*args)</code> 应该怎么办呢？接下来实现一个带参数的装饰器，也就是装饰器的装饰器🤣，虽然这么说很绕哈哈</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">name <span class="token operator">=</span> <span class="token string">'Declan'</span>age <span class="token operator">=</span> <span class="token number">23</span><span class="token keyword">def</span> <span class="token function">param_decorate</span><span class="token punctuation">(</span>addtional<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"It's running before test(), and addtional is </span><span class="token interpolation"><span class="token punctuation">{</span>addtional<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">decorate</span><span class="token punctuation">(</span>func<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">def</span> <span class="token function">wrap</span><span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'This is a introduction.'</span><span class="token punctuation">)</span>            func<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>            <span class="token keyword">return</span> <span class="token boolean">None</span>        <span class="token keyword">return</span> wrap    <span class="token keyword">return</span> decorate<span class="token decorator annotation punctuation">@param_decorate</span><span class="token punctuation">(</span><span class="token number">3.14</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">test</span><span class="token punctuation">(</span>name<span class="token punctuation">,</span> age<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"My name is {}, and I'm {}."</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>name<span class="token punctuation">,</span> age<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># It's running before test(), and addtional is 3.14</span>test<span class="token punctuation">(</span>name<span class="token punctuation">,</span> age<span class="token punctuation">)</span><span class="token comment"># This is a introduction.</span><span class="token comment"># My name is Declan, and I'm 23</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>使用以上代码会发现，即使没有运行 <code>test</code> 函数也输出了内容。这是因为给装饰器添加参数过后，那么 <code>@</code> 后跟随的就是一个执行函数，python 就会真实地执行该函数的内容。执行 <code>param_decorate</code> 函数返回的是一个函数名 <code>decorate</code>，那么此时 <code>@param_decorate()</code> 相当于 <code>@decorate</code></p><p><strong>还有一个方法来学习装饰器的内部逻辑，就是直接对代码 debug，一步步看程序是如何运行的</strong></p><h3 id="python-内置装饰器"><a href="#python-内置装饰器" class="headerlink" title="python 内置装饰器"></a>python 内置装饰器</h3><p>内置的装饰器和普通的装饰器原理是一样的，只不过一般用于类的方法当中，让类变得更灵活</p><h4 id="property"><a href="#property" class="headerlink" title="@property"></a>@property</h4><p>参考 <a href="https://www.runoob.com/python/python-func-property.html">菜鸟教程</a> <a href="https://www.liaoxuefeng.com/wiki/897692888725344/923030547069856">廖雪峰教程 </a>进行整理。<code>@property</code> 能够用于管理类的私有属性，方便读取属性、修改属性。下面看看如何使用该装饰器</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Student</span><span class="token punctuation">:</span>    <span class="token decorator annotation punctuation">@property</span>    <span class="token keyword">def</span> <span class="token function">get_the_score</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token triple-quoted-string string">"""I'm the 'score' property."""</span>        <span class="token keyword">return</span> self<span class="token punctuation">.</span>_score     <span class="token decorator annotation punctuation">@get_the_score<span class="token punctuation">.</span>setter</span>    <span class="token keyword">def</span> <span class="token function">score</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> value<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>_score <span class="token operator">=</span> value     <span class="token decorator annotation punctuation">@get_the_score<span class="token punctuation">.</span>deleter</span>    <span class="token keyword">def</span> <span class="token function">score</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">del</span> self<span class="token punctuation">.</span>_scorestudent <span class="token operator">=</span> Student<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># setter不仅可以更改属性值，也可以创建该属性</span>student<span class="token punctuation">.</span>get_the_score <span class="token operator">=</span> <span class="token number">60</span><span class="token comment"># 查看属性</span><span class="token keyword">print</span><span class="token punctuation">(</span>student<span class="token punctuation">.</span>get_the_score<span class="token punctuation">)</span><span class="token comment"># 60</span><span class="token comment"># 也使用原属性名称更改和访问</span>student<span class="token punctuation">.</span>score <span class="token operator">=</span> <span class="token number">100</span><span class="token keyword">print</span><span class="token punctuation">(</span>student<span class="token punctuation">.</span>score<span class="token punctuation">)</span><span class="token comment"># 100</span><span class="token comment"># 删除属性</span><span class="token comment"># del student.score</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>@property</code> 的实现比较复杂，我感觉我是真没理解，这里直接引用一下廖雪峰教程中的话：</p><blockquote><p>把一个 <code>get_the_score</code> 方法变成属性，只需要加上 <code>@property</code> 就可以了。此时，<code>@property</code>本身又创建了另一个装饰器 <code>@get_the_score.setter</code>，负责把一个 setter 方法变成属性赋值，于是，我们就拥有一个可控的属性操作</p></blockquote><p>我自己理解，如果需要只读属性，则只使用 <code>@property</code> 装饰器就可以了，如果还需要对属性进行进一步操控则加上其他 <code>setter, deleter</code> 装饰器</p><p>而且，如果使用了 <code>property</code> 装饰器，必须要使用单下划线变量，不然会报错，具体原因参考 <a href="https://zhuanlan.zhihu.com/p/53469919">知乎链接</a></p><h4 id="classmethod"><a href="#classmethod" class="headerlink" title="@classmethod"></a>@classmethod</h4><p>参考 <a href="https://zhuanlan.zhihu.com/p/35643573">知乎链接</a> 进行整理，<code>classmethod</code> 又被叫做类方法。<code>__init__()</code> 作为类的构造函数，能够在生成对象时调用，但如果想要使用其他构造函数时，可以使用<code>@classmethod</code> 实现，下面看如何使用类方法创建一个对象（为方便，把静态方法 <code>staticmethod</code> 的代码也写在这儿）</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Date</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> year<span class="token punctuation">,</span> month<span class="token punctuation">,</span> day<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>year <span class="token operator">=</span> year        self<span class="token punctuation">.</span>month <span class="token operator">=</span> month        self<span class="token punctuation">.</span>day <span class="token operator">=</span> day        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'{}年{}月{}日'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>year<span class="token punctuation">,</span> self<span class="token punctuation">.</span>month<span class="token punctuation">,</span> self<span class="token punctuation">.</span>day<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token decorator annotation punctuation">@classmethod</span>    <span class="token keyword">def</span> <span class="token function">create_from_string</span><span class="token punctuation">(</span>cls<span class="token punctuation">,</span> string<span class="token punctuation">)</span><span class="token punctuation">:</span>        year<span class="token punctuation">,</span> month<span class="token punctuation">,</span> day <span class="token operator">=</span> <span class="token builtin">map</span><span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">,</span>string<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'-'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> cls<span class="token punctuation">(</span>year<span class="token punctuation">,</span> month<span class="token punctuation">,</span> day<span class="token punctuation">)</span>    <span class="token decorator annotation punctuation">@staticmethod</span>    <span class="token keyword">def</span> <span class="token function">is_leap</span><span class="token punctuation">(</span>year<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> year <span class="token operator">%</span> <span class="token number">4</span> <span class="token operator">==</span> <span class="token number">0</span> <span class="token keyword">and</span> year <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> <span class="token boolean">True</span>        <span class="token keyword">elif</span> year <span class="token operator">%</span> <span class="token number">400</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>            <span class="token keyword">return</span> <span class="token boolean">True</span>        <span class="token keyword">else</span><span class="token punctuation">:</span> <span class="token keyword">return</span> <span class="token boolean">False</span><span class="token comment"># 普通构造</span>date <span class="token operator">=</span> Date<span class="token punctuation">(</span><span class="token number">2020</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">31</span><span class="token punctuation">)</span><span class="token comment"># 2020年7月31日</span><span class="token comment"># 通过类方法构造</span>date <span class="token operator">=</span> Date<span class="token punctuation">.</span>create_from_string<span class="token punctuation">(</span><span class="token string">'2020-7-31'</span><span class="token punctuation">)</span><span class="token comment"># 2020年7月31日</span><span class="token comment"># 使用静态方法</span><span class="token keyword">print</span><span class="token punctuation">(</span>Date<span class="token punctuation">.</span>is_leap<span class="token punctuation">(</span><span class="token number">1900</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># True</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>重点需要注意的是类方法的第一个参数，其表示调用当前的类名，默认名称为 <code>cls</code>，有点类似于 <code>self</code> 表示类的实例。那么类方法最后的返回值 <code>return cls(year, month, day)</code> 也就不难理解了，相当于 <code>return Data(year, month, day)</code> 重新创建了对象</p><p>类方法能够在不改变原本构造函数的情况下，给类的构造方法增加一些额外功能，例如对于传入参数做一些不同的处理等等</p><h4 id="staticmethod"><a href="#staticmethod" class="headerlink" title="@staticmethod"></a>@staticmethod</h4><p>参考 <a href="https://www.cnblogs.com/Meanwey/p/9788713.html">博客</a> 的说法：<code>@staticmethod</code> 静态方法只是名义上归属类管理，但是不能使用类变量和实例变量，是类的工具包。因为该函数不传入self或者cls，所以不能访问类属性和实例属性。静态方法的一个好处是，不用创建类的实例也能够调用该方法，具体调用方法参考上面代码</p>]]></content>
      
      
      <categories>
          
          <category> 编程 </category>
          
          <category> Python </category>
          
          <category> Basic </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 教程 </tag>
            
            <tag> Python </tag>
            
            <tag> 面向对象 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python 4 拓展</title>
      <link href="/archives/c19cb72c.html"/>
      <url>/archives/c19cb72c.html</url>
      
        <content type="html"><![CDATA[<h1 id="python-拓展"><a href="#python-拓展" class="headerlink" title="python 拓展"></a>python 拓展</h1><h2 id="format输出"><a href="#format输出" class="headerlink" title="format输出"></a>format输出</h2><p>这里总结一下 format 输出的形式，主要以 <code>{position:format}</code> 形式对变量进行引用</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">name <span class="token operator">=</span> <span class="token string">'Declan'</span>age <span class="token operator">=</span> <span class="token number">23</span><span class="token comment"># 按照顺序引用</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"{0} {1} {0}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>name<span class="token punctuation">,</span> age<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># Declan 23 Declan</span><span class="token comment"># 按照关键字引用</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"{name} {age}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>name<span class="token operator">=</span>name<span class="token punctuation">,</span> age<span class="token operator">=</span>age<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># Declan 23</span><span class="token comment"># 数字格式化</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"{:.2f}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>age<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># 23.00</span><span class="token comment"># 输出左右对齐</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"{:0&gt;10d}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>age<span class="token punctuation">)</span><span class="token punctuation">)</span>   <span class="token comment"># 向右对齐，默认宽度为10，不够以0补位</span><span class="token comment"># 0000000023</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"{:x&lt;10b}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>age<span class="token punctuation">)</span><span class="token punctuation">)</span>   <span class="token comment"># 向左对齐，默认宽度为10，不够以x补位</span><span class="token comment"># 10111xxxxx</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="读写文件"><a href="#读写文件" class="headerlink" title="读写文件"></a>读写文件</h2><p>Python open() 方法用于打开一个文件，并返回文件对象，在对文件进行处理过程都需要使用到这个函数，如果该文件无法被打开，会抛出 OSError。<strong>注意：</strong>使用 open() 方法一定要保证关闭文件对象，即调用 close() 方法</p><p>open() 函数常用形式是接收两个参数：文件名(file)和模式(mode)，更多参数查询  <a href="https://www.runoob.com/python/file-methods.html">菜鸟教程</a>。现在介绍一下常用的 <code>mode</code> 参数：</p><ol><li><code>r</code>，只读模式，为默认设置</li><li><code>w</code>，写入模式，会擦除文件中之前的内容，重新写入。如果没有文件会自动创建</li><li><code>a</code>，附加模式，会在文件末尾加入新内容</li><li><code>r+</code>，读写模式，指针位于文件开头</li></ol><p>下面介绍操作文件的基本功能：读和写。我们先在 python 脚本所在文件夹新建一个文本文档 <code>test.txt</code> 内容为 <code>a, b, c</code></p><h3 id="读文件"><a href="#读文件" class="headerlink" title="读文件"></a>读文件</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python">f <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'test.txt'</span><span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'r'</span><span class="token punctuation">)</span><span class="token comment"># 使用 read(size) 输出</span><span class="token comment"># 如果不传入输出字符数量，则全部输出</span><span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># a, b, c</span><span class="token comment"># 读完文件过后需要移动指针到文件开头才能重新再读一遍</span><span class="token comment"># 使用 seek(offset)，默认0位置从文件开头算起</span>f<span class="token punctuation">.</span>seek<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token comment"># 使用 readlines() 逐行输出</span><span class="token comment"># 该方法返回值是由每一行内容组成的一个列表</span><span class="token keyword">for</span> i <span class="token keyword">in</span> f<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token comment"># a, b, c</span>f<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="写文件"><a href="#写文件" class="headerlink" title="写文件"></a>写文件</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python">f <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'test.txt'</span><span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'a'</span><span class="token punctuation">)</span><span class="token comment"># 使用 write(str) 在指针处写入内容</span>f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">'\nadd something'</span><span class="token punctuation">)</span><span class="token comment"># a, b, c</span><span class="token comment"># add something</span>f<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>如果需要写入中文，建议设置编码为 utf-8，<code>open(filename, mode, encoding='utf-8')</code></p><h3 id="with-关键字"><a href="#with-关键字" class="headerlink" title="with 关键字"></a>with 关键字</h3><p>一些对象定义了标准的清理行为，无论系统是否成功的使用了它，一旦不需要它了，那么这个标准的清理行为就会执行。只需要该对象定义了 <code>__enter__ &amp; __exit__</code> 魔术方法，关键字 with 就可以保证诸如文件之类的对象在使用完之后一定会正确的执行他的清理方法</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token builtin">file</span><span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>    <span class="token comment"># statement</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h2 id="os-amp-sys-模块"><a href="#os-amp-sys-模块" class="headerlink" title="os &amp; sys 模块"></a>os &amp; sys 模块</h2><h3 id="os"><a href="#os" class="headerlink" title="os"></a>os</h3><p><strong>os</strong> 模块提供了非常丰富的方法用来处理文件和目录。关于 os 模块更多操作可以查询 <a href="https://www.runoob.com/python3/python3-os-file-methods.html">菜鸟教程</a>，这里列举一些常用的部分。由于返回的这些路径多为字符串类型，所以字符串的操作在这里也会经常使用</p><h4 id="系统相关"><a href="#系统相关" class="headerlink" title="系统相关"></a>系统相关</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> os<span class="token keyword">print</span><span class="token punctuation">(</span>os<span class="token punctuation">.</span>name<span class="token punctuation">)</span>  <span class="token comment"># 操作系统名称</span><span class="token keyword">print</span><span class="token punctuation">(</span>os<span class="token punctuation">.</span>environ<span class="token punctuation">)</span>   <span class="token comment"># 环境变量，返回一个“字典”</span><span class="token keyword">print</span><span class="token punctuation">(</span>os<span class="token punctuation">.</span>sep<span class="token punctuation">,</span> os<span class="token punctuation">.</span>pathsep<span class="token punctuation">)</span>   <span class="token comment"># 路径分割符号，windows 为 \ ;</span><span class="token comment"># 查看一下 PATH 环境变量</span><span class="token comment"># PATH一般为系统指定可执行文件的搜索路径</span>PATH <span class="token operator">=</span> os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'PATH'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">';'</span><span class="token punctuation">)</span><span class="token keyword">for</span> path <span class="token keyword">in</span> PATH<span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>path<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="文件和目录"><a href="#文件和目录" class="headerlink" title="文件和目录"></a>文件和目录</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> ospath <span class="token operator">=</span> <span class="token string">'.'</span>  <span class="token comment"># 当前文件夹</span>os<span class="token punctuation">.</span>mkdir<span class="token punctuation">(</span><span class="token string">'folder'</span><span class="token punctuation">)</span>os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span><span class="token string">'folder\subfolder'</span><span class="token punctuation">)</span>os<span class="token punctuation">.</span>remove<span class="token punctuation">(</span>path<span class="token punctuation">)</span>   <span class="token comment"># 删除文件</span>os<span class="token punctuation">.</span>removedirs<span class="token punctuation">(</span>path<span class="token punctuation">)</span>   <span class="token comment"># 删除空文件夹</span>os<span class="token punctuation">.</span>listdir<span class="token punctuation">(</span>path<span class="token punctuation">)</span>    <span class="token comment"># 返回文件列表</span>os<span class="token punctuation">.</span>getcwd<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 返回当前路径</span><span class="token comment"># os.path 是一个常用模块，重点介绍</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>abspath<span class="token punctuation">(</span>path<span class="token punctuation">)</span>   <span class="token comment"># 返回绝对路径</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>dirname<span class="token punctuation">(</span>path<span class="token punctuation">)</span>   <span class="token comment"># 返回路径的 dirname</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>basename<span class="token punctuation">(</span>path<span class="token punctuation">)</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>split<span class="token punctuation">(</span>path<span class="token punctuation">)</span> <span class="token comment"># 把路径分割成 dirname 和 basename，返回一个元组</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>splittext<span class="token punctuation">(</span>path<span class="token punctuation">)</span><span class="token comment"># 将路径的扩展名分离出来</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>path<span class="token punctuation">)</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>isdir<span class="token punctuation">(</span>path<span class="token punctuation">)</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>path<span class="token punctuation">,</span> <span class="token operator">*</span>path<span class="token punctuation">)</span><span class="token comment"># 将多个名称合成为一个路径名</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="sys"><a href="#sys" class="headerlink" title="sys"></a>sys</h3><p>sys 即 system，该模块提供了一些接口，用于访问 Python 解释器自身使用和维护的变量。下面列举一些常用成员</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> syssys<span class="token punctuation">.</span>version <span class="token comment"># 版本号</span>sys<span class="token punctuation">.</span>path    <span class="token comment"># python 解释器搜索路径</span>sys<span class="token punctuation">.</span>argv    <span class="token comment"># 传入当前 python 文件的参数列表</span>sys<span class="token punctuation">.</span>exit<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token comment"># 退出状态码</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="错误和异常"><a href="#错误和异常" class="headerlink" title="错误和异常"></a>错误和异常</h2><p>当 Python 脚本发生异常时我们需要捕获处理它，否则程序会终止执行</p><h3 id="try相关"><a href="#try相关" class="headerlink" title="try相关"></a>try相关</h3><p>异常处理的方法</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">try</span><span class="token punctuation">:</span>    statement<span class="token keyword">except</span> Exception<span class="token punctuation">:</span>    <span class="token comment"># 发生异常时执行的代码</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Something Wrong!'</span><span class="token punctuation">)</span>    statement<span class="token comment"># 可以有多个 exception 表示面对不同异常的处理</span><span class="token keyword">except</span> Excepthion_2<span class="token punctuation">:</span>    <span class="token comment"># 发生异常时执行的代码</span>    statement<span class="token keyword">else</span><span class="token punctuation">:</span>    <span class="token comment"># 没有异常时执行的代码</span>    statement<span class="token keyword">finally</span><span class="token punctuation">:</span>    <span class="token comment"># 无论有没有异常都会执行的代码</span>    statement<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="raise"><a href="#raise" class="headerlink" title="raise"></a>raise</h3><p>Python 使用 raise 语句抛出一个指定的异常。更多 python 内置异常查看 <a href="https://www.runoob.com/python/python-exceptions.html">菜鸟教程</a></p><h3 id="assert"><a href="#assert" class="headerlink" title="assert"></a>assert</h3><p>Python assert（断言）用于判断一个表达式，在表达式条件为 false 的时候触发异常。其基本语法为</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">assert</span> expression <span class="token punctuation">[</span><span class="token punctuation">,</span> arguments<span class="token punctuation">]</span><span class="token comment"># 与以下代码等价</span><span class="token keyword">if</span> <span class="token keyword">not</span> expression<span class="token punctuation">:</span>    <span class="token keyword">raise</span> AssertionError<span class="token punctuation">(</span>arguments<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>之后的参数为抛出异常的补充信息，也可以不用加。下面举一个例子</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">assert</span> <span class="token number">1</span><span class="token operator">==</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token string">'Somenthing Wrong!'</span><span class="token comment"># 以下为异常</span>Traceback <span class="token punctuation">(</span>most recent call last<span class="token punctuation">)</span><span class="token punctuation">:</span>  File <span class="token string">"d:/..."</span><span class="token punctuation">,</span> line <span class="token number">1</span><span class="token punctuation">,</span> <span class="token keyword">in</span> <span class="token operator">&lt;</span>module<span class="token operator">&gt;</span>    <span class="token keyword">assert</span> <span class="token number">1</span><span class="token operator">==</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token string">'Somenthing Wrong!'</span>AssertionError<span class="token punctuation">:</span> Somenthing Wrong!<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="argparse-模块"><a href="#argparse-模块" class="headerlink" title="argparse 模块"></a>argparse 模块</h2><p>argsparse 是 python 的命令行解析的标准模块，内置于python，不需要安装。这个库可以让我们<strong>直接在命令行中就可以向程序中传入参数</strong>，同时argparse会自动生成帮助文档，传入参数 <code>-h</code> 显示。下面写一个 python 脚本</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># arg.py</span><span class="token keyword">import</span> argparse<span class="token comment"># 创建 parser 并添加描述，通常为该脚本的用途</span>parser <span class="token operator">=</span> argparse<span class="token punctuation">.</span>ArgumentParser<span class="token punctuation">(</span>description<span class="token operator">=</span><span class="token string">'this is a parser'</span><span class="token punctuation">)</span><span class="token comment"># 添加参数</span>parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'params'</span><span class="token punctuation">)</span><span class="token comment"># 解析参数</span>args <span class="token operator">=</span> parser<span class="token punctuation">.</span>parse_args<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'show the params:'</span><span class="token punctuation">,</span> args<span class="token punctuation">.</span>params<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>由于 argparse 模块是从命令行向文件传入参数，所以现在在 cmd 下给文件名后面传入参数 123 得到结果如下</p><pre class="line-numbers language-cmd" data-language="cmd"><code class="language-cmd">(base) D:\VScodeProjects\LearnManim&gt;python arg.py 123show the params: 123# 参数 123 传入到了文件中 parser 的位置参数 params 中<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>从 <code>arg.py</code> 中看出使用 argparse 模块的步骤：</p><ol><li>创建 <code>ArgumentParser</code> 对象</li><li>给对象中加入参数 <code>add_argument</code></li><li>解析对象，也即将命令行中的参数传给 <code>args</code>，之后能够像类的属性一样调用这些参数 <code>args.params</code></li></ol><p>下面来详细了解一下方法 <code>add_argument</code>，该方法能够方便我们从命令行输入参数。先来看看该函数自己的参数</p><ol><li><p>位置参数：不带 <code>-</code> 的参数。从命令行传入的参数会按照顺序传给 parser 添加的参数，比如上面的例子中，传入的第一个参数为 123，而 parser 中添加的第一个参数是 <code>params</code>，所以 123 传给了 <code>params</code>。正如 python 自身函数传参规则一样，位置参数是必须要传入的参数，如果不传入则会报错</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token punctuation">(</span>base<span class="token punctuation">)</span> D<span class="token punctuation">:</span>\VScodeProjects\LearnManim<span class="token operator">&gt;</span>python arg<span class="token punctuation">.</span>py         usage<span class="token punctuation">:</span> arg<span class="token punctuation">.</span>py <span class="token punctuation">[</span><span class="token operator">-</span>h<span class="token punctuation">]</span> paramsarg<span class="token punctuation">.</span>py<span class="token punctuation">:</span> error<span class="token punctuation">:</span> the following arguments are required<span class="token punctuation">:</span> params<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li><li><p>可选参数：带 <code>-</code> 的参数。可选参数有两种方式，</p><ul><li><code>-</code> 指定短参数，如 <code>-h</code></li><li><code>--</code> 指定长参数，如 <code>--help</code></li></ul><p>两种参数可以同时存在，可选参数就像 python 函数中使用关键字传参一样。修改一下上面的 python 脚本</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># arg.py</span><span class="token keyword">import</span> argparseparser <span class="token operator">=</span> argparse<span class="token punctuation">.</span>ArgumentParser<span class="token punctuation">(</span>description<span class="token operator">=</span><span class="token string">'this is a parser'</span><span class="token punctuation">)</span>parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--params'</span><span class="token punctuation">,</span> <span class="token string">'-p'</span><span class="token punctuation">)</span>args <span class="token operator">=</span> parser<span class="token punctuation">.</span>parse_args<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'show the params:'</span><span class="token punctuation">,</span> args<span class="token punctuation">.</span>params<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>使用短参数和长参数都可以，不传入参数也不会报错</p><pre class="line-numbers language-cmd" data-language="cmd"><code class="language-cmd">(base) D:\VScodeProjects\LearnManim&gt;python arg.py -p 1show the params: 1(base) D:\VScodeProjects\LearnManim&gt;python arg.py --params 1show the params: 1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>类型 <code>type</code>：指定输入参数的类型</p></li><li><p>默认值 <code>default</code>：指定默认值</p></li><li><p>帮助 <code>help</code>：描述该参数的功能</p></li><li><p>必须参数 <code>required</code>：该参数是否为必须传入的参数</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--params'</span><span class="token punctuation">,</span> <span class="token string">'-p'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">'optional number'</span><span class="token punctuation">,</span> required<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li><p>动作 <code>action</code>：不需要在命令行传入参数。常用值为 <code>action='store_true'</code> 也即当传入关键字时，该参数值为 <code>True</code> </p><pre class="line-numbers language-python" data-language="python"><code class="language-python">parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--params'</span><span class="token punctuation">,</span> <span class="token string">'-p'</span><span class="token punctuation">,</span> action<span class="token operator">=</span><span class="token string">'store_true'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><pre class="line-numbers language-cmd" data-language="cmd"><code class="language-cmd">(base) D:\VScodeProjects\LearnManim&gt;python arg.py -p  show the params: True<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li></ol><p>当然还有更多的参数，就不列举了，遇到了就去查文档</p><h2 id="re-模块"><a href="#re-模块" class="headerlink" title="re 模块"></a>re 模块</h2><p>re 为正则表达式的缩写，所以需要了解正则表达式的一些基础知识。正则表达式可以匹配某些特定模式的数据，在编辑文件、爬虫等方面有着广泛应用，以下内容参考 <a href="https://www.bilibili.com/video/BV19t4y1y7qP/">bilibili</a> &amp; <a href="https://www.runoob.com/regexp/regexp-syntax.html">菜鸟教程</a> 学习，这里记录一些基本的语法规则，仅供复习</p><h3 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h3><h4 id="字符组"><a href="#字符组" class="headerlink" title="字符组"></a>字符组</h4><p><code>[]</code>，字符组，匹配集合中的任意字符，如果想表示特殊字符则需要转义字符 <code>\</code></p><p> <code>^</code>，在字符组内表示取反，在字符组外表示匹配开头</p><p><code>$</code>，匹配字符串的末尾</p><h4 id="快捷表示"><a href="#快捷表示" class="headerlink" title="快捷表示"></a>快捷表示</h4><p><code>\d</code>，数字</p><p><code>\s</code>，空格</p><p><code>\w</code>，字符（字母、数字、下划线）</p><p>大写为其取反 <code>\D</code> <code>\S</code> <code>\W</code> 表示非数字、非空格、非字符</p><p><code>.</code>，为任意单个字符，换行符除外</p><h4 id="限定符（控制重复次数）"><a href="#限定符（控制重复次数）" class="headerlink" title="限定符（控制重复次数）"></a>限定符（控制重复次数）</h4><p><code>{n}</code>，<code>{n,}</code>，<code>{n, m}</code> n, m 为非负整数，表示匹配重复次数或者重复区间</p><p><code>+</code>，匹配前面的子表达式一次或多次，相当于 <code>{1,}</code></p><p><code>*</code>，匹配前面的子表达式零次或多次，相当于 <code>{0,}</code></p><p><code>?</code> 可选字符，匹配0次或1次。也可表示非贪婪模式（最小匹配），常用于 <code>+ or *</code> 之后。例如需要匹配 <code>&lt;mark&gt;.*&lt;mark&gt;</code> 这样的模式，如果遇到字符串 <code>&lt;mark&gt;1&lt;mark&gt; &lt;mark&gt;2&lt;mark&gt;</code> 将会匹配整个字符串，而不能分 <code>&lt;mark&gt;1&lt;mark&gt;</code> 和 <code>&lt;mark&gt;2&lt;mark&gt;</code>，这时使用最小匹配即可完成 <code>&lt;mark&gt;.*？&lt;mark&gt;</code></p><h4 id="定位符"><a href="#定位符" class="headerlink" title="定位符"></a>定位符</h4><p><code>$</code>，匹配字符串的末尾</p><p><code>^</code>，匹配字符串的开头，但当 <code>^</code> 和 <script type="math/tex">` 同时出现时不代表开头和末尾分别匹配，而是代表整个字符串必须匹配该表达式，例如 `^python</script> 仅能匹配 python 这个字符串，而不能匹配开头末尾为 python 的字符串，像 python … python 是不被匹配的</p><p><code>\b</code>，匹配单词边界，即字与空格的位置</p><h4 id="分组"><a href="#分组" class="headerlink" title="分组"></a>分组</h4><p><code>()</code>，表示捕获分组，<code>()</code> 会把每个分组里的匹配的值保存起来， 多个匹配值可以通过转义符+数字 n 来查看，举个例子 <code>(expression_1)(expression_2)\2\1</code></p><p><code>(?:)</code>，不捕获，只使用分组功能</p><p><code>(express_1|express_2|express_3)</code>，选择，满足任一表达式即匹配</p><p><code>(?=express)</code>，正向先行断言，顺序从左往右看，判断在该位置的字符是否匹配表达式，如满足表达式则匹配整个表达式，如 <code>re(?=gular)</code> 只匹配 regular 中的 re 而不匹配其他单词中的 re</p><p><code>(?&lt;=express)</code>，正向后行断言，顺序从右往左，如 <code>(?&lt;=re)open</code> 只匹配 reopen 中的 open，不匹配其他单词中的 open</p><p><code>(?!express)</code>，逆向先行断言，不满足表达式则匹配</p><p><code>(?&lt;!express)</code>，逆向后行断言</p><h3 id="模块方法"><a href="#模块方法" class="headerlink" title="模块方法"></a>模块方法</h3><ol><li><p><code>re.match(pattern, string, flags=0)</code>，尝试从字符串的起始位置匹配一个模式，如果不是起始位置匹配成功的话，match()就返回none，匹配成功则返回匹配对象 MatchObject</p><p><code>flags</code> 为标志位，用于控制正则表达式的匹配方式，如：是否区分大小写，多行匹配等等，参考 <a href="https://www.runoob.com/python/python-reg-expressions.html#flags">正则表达式修饰符 - 可选标志</a></p><p>使用 group(num) 或 groups() 匹配对象函数来获取匹配表达式中的分组，即表达式中要有括号</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> reline <span class="token operator">=</span> <span class="token string">"Cats are smarter than dogs"</span> a <span class="token operator">=</span> re<span class="token punctuation">.</span>match<span class="token punctuation">(</span> <span class="token string">r'(.*) are (.*?) .*'</span><span class="token punctuation">,</span> line<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>group<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> a<span class="token punctuation">.</span>group<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># Cats smarter</span><span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>groups<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># ('Cats', 'smarter')</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>group() 也可以一次输入多个组号，在这种情况下它将返回一个包含那些组所对应值的元组</p><p>如果没有分组，则直接使用 group() 调用，不用传参，默认传入0</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> reline <span class="token operator">=</span> <span class="token string">"Cats are smarter than dogs"</span> a <span class="token operator">=</span> re<span class="token punctuation">.</span>match<span class="token punctuation">(</span> <span class="token string">r'.* are .*? .*'</span><span class="token punctuation">,</span> line<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>group<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># print(a.group(0)) is the same</span><span class="token comment"># Cats are smarter than dogs</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li><li><p><code>re.search(pattern, string, flags=0)</code>，扫描整个字符串并返回第一个成功的匹配对象 MatchObject</p></li><li><p><code>re.findall(pattern, string, flags=0)</code>，在字符串中找到正则表达式所匹配的所有<strong>子串</strong>，并返回一个列表，如果没有找到匹配的，则返回空列表</p></li><li><p><code>re.sub(pattern, repl, string, count=0, flags=0)</code> 用于替换字符串中的匹配项</p></li><li><p><code>re.compile(pattern, flags=0)</code> ，根据一个模式字符串和可选的标志参数生成一个正则表达式对象，该对象能够调用一系列的方法用于正则表达式匹配和替换</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> reline <span class="token operator">=</span> <span class="token string">"re short for regular expression"</span> pattern <span class="token operator">=</span> re<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span> <span class="token string">r're'</span><span class="token punctuation">)</span>all_list <span class="token operator">=</span> pattern<span class="token punctuation">.</span>findall<span class="token punctuation">(</span>line<span class="token punctuation">)</span>sub <span class="token operator">=</span> pattern<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">'RE'</span><span class="token punctuation">,</span> line<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>all_list<span class="token punctuation">)</span><span class="token comment"># ['re', 're', 're']</span><span class="token keyword">print</span><span class="token punctuation">(</span>sub<span class="token punctuation">)</span><span class="token comment"># RE short for REgular expREssion</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ol><h2 id="发送邮件"><a href="#发送邮件" class="headerlink" title="发送邮件"></a>发送邮件</h2><p>参考链接：[廖雪峰][<a href="https://www.liaoxuefeng.com/wiki/1016959663602400/1017790702398272">https://www.liaoxuefeng.com/wiki/1016959663602400/1017790702398272</a>], <a href="https://blog.csdn.net/qq_24285815/article/details/98945385">CSDN</a></p><p>直接上代码</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> smtplib<span class="token keyword">from</span> email<span class="token punctuation">.</span>header <span class="token keyword">import</span> Header<span class="token keyword">from</span> email<span class="token punctuation">.</span>mime<span class="token punctuation">.</span>text <span class="token keyword">import</span> MIMEText<span class="token keyword">from</span> email<span class="token punctuation">.</span>utils <span class="token keyword">import</span> parseaddr<span class="token punctuation">,</span> formataddrmsg <span class="token operator">=</span> MIMEText<span class="token punctuation">(</span><span class="token string">'hello, send by Python...'</span><span class="token punctuation">,</span> <span class="token string">'plain'</span><span class="token punctuation">,</span> <span class="token string">'utf-8'</span><span class="token punctuation">)</span><span class="token comment"># 输入Email地址和口令:</span>from_addr <span class="token operator">=</span> <span class="token string">'hongkun20sme@smail.nju.edu.cn'</span>password <span class="token operator">=</span> <span class="token string">'your_passwd'</span><span class="token comment"># 输入收件人地址:</span>to_addr <span class="token operator">=</span> <span class="token string">'hongkun20sme@smail.nju.edu.cn'</span><span class="token comment"># 输入SMTP服务器地址: smtp.exmail.qq.com(使用SSL，端口号465)</span>smtp_server <span class="token operator">=</span> <span class="token string">'smtp.exmail.qq.com'</span>port <span class="token operator">=</span> <span class="token number">465</span><span class="token comment"># 编码名字和地址</span><span class="token keyword">def</span> <span class="token function">_format_addr</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token punctuation">:</span>    name<span class="token punctuation">,</span> addr <span class="token operator">=</span> parseaddr<span class="token punctuation">(</span>s<span class="token punctuation">)</span>    <span class="token keyword">return</span> formataddr<span class="token punctuation">(</span><span class="token punctuation">(</span>Header<span class="token punctuation">(</span>name<span class="token punctuation">,</span> <span class="token string">'utf-8'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>encode<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> addr<span class="token punctuation">)</span><span class="token punctuation">)</span>msg <span class="token operator">=</span> MIMEText<span class="token punctuation">(</span><span class="token string">'hello, send by Python...'</span><span class="token punctuation">,</span> <span class="token string">'plain'</span><span class="token punctuation">,</span> <span class="token string">'utf-8'</span><span class="token punctuation">)</span><span class="token comment"># 发件人（仅作内容，不实际参与 SMTP 服务）</span>msg<span class="token punctuation">[</span><span class="token string">'From'</span><span class="token punctuation">]</span> <span class="token operator">=</span> _format_addr<span class="token punctuation">(</span><span class="token string">'MailBot &lt;%s&gt;'</span> <span class="token operator">%</span> from_addr<span class="token punctuation">)</span><span class="token comment"># 收件人</span>msg<span class="token punctuation">[</span><span class="token string">'To'</span><span class="token punctuation">]</span> <span class="token operator">=</span> _format_addr<span class="token punctuation">(</span><span class="token string">'Declan Chen &lt;%s&gt;'</span> <span class="token operator">%</span> to_addr<span class="token punctuation">)</span><span class="token comment"># 主题</span>msg<span class="token punctuation">[</span><span class="token string">'Subject'</span><span class="token punctuation">]</span> <span class="token operator">=</span> Header<span class="token punctuation">(</span><span class="token string">'来自SMTP的问候……'</span><span class="token punctuation">,</span> <span class="token string">'utf-8'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>encode<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># 这里与原廖雪峰教程中使用的 SMTP() 方法不一样，使用了 SMTP_SSL() 方法</span>server <span class="token operator">=</span> smtplib<span class="token punctuation">.</span>SMTP_SSL<span class="token punctuation">(</span>smtp_server<span class="token punctuation">,</span> port<span class="token punctuation">)</span>server<span class="token punctuation">.</span>set_debuglevel<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>server<span class="token punctuation">.</span>login<span class="token punctuation">(</span>from_addr<span class="token punctuation">,</span> password<span class="token punctuation">)</span>server<span class="token punctuation">.</span>sendmail<span class="token punctuation">(</span>from_addr<span class="token punctuation">,</span> <span class="token punctuation">[</span>to_addr<span class="token punctuation">]</span><span class="token punctuation">,</span> msg<span class="token punctuation">.</span>as_string<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>server<span class="token punctuation">.</span>quit<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h2><h3 id="时间和日期"><a href="#时间和日期" class="headerlink" title="时间和日期"></a>时间和日期</h3><h3 id="进程、线程"><a href="#进程、线程" class="headerlink" title="进程、线程"></a>进程、线程</h3><h3 id="Python-爬虫"><a href="#Python-爬虫" class="headerlink" title="Python 爬虫"></a>Python 爬虫</h3>]]></content>
      
      
      <categories>
          
          <category> 编程 </category>
          
          <category> Python </category>
          
          <category> Basic </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 教程 </tag>
            
            <tag> Python </tag>
            
            <tag> 拓展 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python 2 数据结构</title>
      <link href="/archives/760ade0a.html"/>
      <url>/archives/760ade0a.html</url>
      
        <content type="html"><![CDATA[<h1 id="Python-String-amp-Data-Structure"><a href="#Python-String-amp-Data-Structure" class="headerlink" title="Python String &amp; Data Structure"></a>Python String &amp; Data Structure</h1><h2 id="String-字符串"><a href="#String-字符串" class="headerlink" title="String 字符串"></a>String 字符串</h2><p>python 用单引号 <code>''</code> 或者双引号 <code>""</code> 来表示字符串，三引号 <code>'''</code> 允许跨多行的字符串</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">s1 <span class="token operator">=</span> <span class="token string">'hello, world!'</span>s2 <span class="token operator">=</span> <span class="token string">"hello, world!"</span><span class="token comment"># 以三个双引号或单引号开头的字符串可以折行</span>s3 <span class="token operator">=</span> <span class="token triple-quoted-string string">"""hello, world!"""</span><span class="token keyword">print</span><span class="token punctuation">(</span>s1<span class="token punctuation">,</span> s2<span class="token punctuation">,</span> s3<span class="token punctuation">,</span> end<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>字符串中可以使用反斜杠 <code>\</code> 表示转义，如 <code>\n, \t</code> 等转义字符，如果希望输入原字符串可在引号前加 r 字母</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">s1 <span class="token operator">=</span> <span class="token string">'\n\\hello, world!\\\n'</span>s2 <span class="token operator">=</span> <span class="token string">r'\n\\hello, world!\\\n'</span><span class="token keyword">print</span><span class="token punctuation">(</span>s1<span class="token punctuation">,</span> s2<span class="token punctuation">,</span> end<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="字符串运算"><a href="#字符串运算" class="headerlink" title="字符串运算"></a>字符串运算</h3><p>字符串接受 <code>+, *, [:], in</code> 等运算，对字符串内容进行合并、重复、截取、成员运算</p><h3 id="字符串格式化"><a href="#字符串格式化" class="headerlink" title="字符串格式化"></a>字符串格式化</h3><p>当字符串中需要表示变量时，格式化表示将会非常有用，基本用法如下</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">num<span class="token punctuation">,</span> pai <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3.1415926</span>s <span class="token operator">=</span> <span class="token string">'here is a number %d, and pai is %.2f'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>num<span class="token punctuation">,</span> pai<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>基本逻辑就是，一个萝卜一个坑，想要在字符串中插入变量，就在需要插入的地方用相应的符号替代，然后在字符串后用 <code>%</code> 指明变量</p><p>这里列几个常用的替代符号：<code>%d, %f, %s, %e</code>，最后一个 <code>%e</code> 表示科学计数</p><h3 id="字符串内建函数"><a href="#字符串内建函数" class="headerlink" title="字符串内建函数"></a>字符串内建函数</h3><p>字符串自带了很多方便的方法，这里列举几个常用的，string 代表某个字符串</p><ol><li><code>sting.count(str)</code>，字符串中有多少个 str</li><li><code>string.find(str)</code>，str 在字符串中的哪个位置，如不存在返回-1</li><li><code>string.format(*args, **kwargs)</code>，<strong>增强版格式化方法，非常推荐使用该函数来格式化字符串</strong>，参考 <a href="https://www.runoob.com/python/att-string-format.html">菜鸟教程</a></li><li><code>string.split(str)</code>，<strong>按照 str 分隔字符串，返回一个列表</strong></li><li><code>string.join(Iterable)</code>，将多个字符串使用 string 连接起来</li><li><code>string.replace(str1, str2)</code>，将 str1 替换为 str2</li></ol><h2 id="List-列表"><a href="#List-列表" class="headerlink" title="List 列表"></a>List 列表</h2><p>列表是最基本的数据结构，可以顺序存储不同的对象。在 python 中创建列表：</p><ol><li>直接赋值 <code>LIST = []</code></li><li>类型转换 <code>list(tuple)</code></li></ol><h3 id="列表运算"><a href="#列表运算" class="headerlink" title="列表运算"></a>列表运算</h3><p>列表也接受：<code>+, *, [:], in</code> 等运算符</p><h3 id="python-内置函数操作列表"><a href="#python-内置函数操作列表" class="headerlink" title="python 内置函数操作列表"></a>python 内置函数操作列表</h3><ol><li><code>len(list)</code></li><li><code>max(list)</code> &amp; <code>min(list)</code></li><li><code>for i in list</code> &amp; <code>for index, value in enumerate(list)</code>，对列表进行循环遍历</li></ol><h3 id="列表内建函数"><a href="#列表内建函数" class="headerlink" title="列表内建函数"></a>列表内建函数</h3><ol><li><code>list.append(obj)</code> &amp; <code>list.insert(index, obj)</code></li><li><code>list.remove(obj)</code> &amp; <code>list.pop()</code></li><li><code>list.sort(reverse=False)</code>，将列表按照上升值排列，返回 None</li><li><code>list.copy()</code></li></ol><h2 id="Tuple-元组"><a href="#Tuple-元组" class="headerlink" title="Tuple 元组"></a>Tuple 元组</h2><p>元组和列表类似，也是线性表的一种，不过在元组建立过后，其成员是不能够被修改的，增加和删除成员也是不支持的，在 python 中创建元组：</p><ol><li>直接赋值 <code>TUPLE = (1,)</code></li><li>类型转换 <code>tuple(list)</code></li></ol><h3 id="元组运算"><a href="#元组运算" class="headerlink" title="元组运算"></a>元组运算</h3><p>元组支持 <code>+, *, [:], in</code> 等运算符，但注意，由于元组成员不能被修改的性质，所以不能够对索引值进行新的赋值。虽然不能增加成员，但是仍可以使用 <code>+</code> 运算，将两个元组合并</p><h3 id="python-内置函数操作元组"><a href="#python-内置函数操作元组" class="headerlink" title="python 内置函数操作元组"></a>python 内置函数操作元组</h3><p>在列表当中能用的操作也能用作元组，毕竟元组可以看作不可修改成员的列表</p><h3 id="元组内建函数"><a href="#元组内建函数" class="headerlink" title="元组内建函数"></a>元组内建函数</h3><p>元组的内建函数就不如列表的丰富了，可以说元组有的，列表都有。下面列举两个</p><ol><li><p><code>tuple.count(obj)</code></p></li><li><p><code>tuple.index(obj)</code>，返回 obj 在元组中的索引数，若元组中不存在 obj 则报错</p></li></ol><p>最后提一句，为什么有了列表还需要有元组这样的数据类型呢？部分原因是元组可以用于保护一些数据，让其不被修改，并且创建元组在时间和空间上的代价更小</p><h2 id="Dict-字典"><a href="#Dict-字典" class="headerlink" title="Dict 字典"></a>Dict 字典</h2><p>字典也是一种可变容器，其不是通过 index 索引获得容器内的对象，而是通过 key: value 对，将 key 映射到其对应的 value。换句话说就是通过 key 来获得容器内的对象。很明显这样的映射性质需要 key 是唯一的，同时 python 也要求 key 是不可变的，如数字，字符串，元组。创建字典的方式：</p><ol><li><p>直接赋值 <code>DICT = {key_1：value_1}</code></p></li><li><p>通过内置函数 <code>dict()</code> 创建：</p><ul><li><p><code>dict(**kwargs)</code>，传入 key=value 对，例如 <code>DICT = dict(a=1, b=2)</code>，注意这里 key 不用转化为字符串形式</p></li><li><p><code>dict(iterable, **kwargs)</code>，传入可迭代对象，其中可迭代对象中的成员必须为二元元组，同时也可任意传入 key=value 对，下面举一个例子</p></li></ul><pre class="line-numbers language-python" data-language="python"><code class="language-python">ITER <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">'a'</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'b'</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token comment"># ITER 也可以通过 python 内置函数 zip() 生成</span><span class="token comment"># ITER = zip(['a', 'b'], [1, 2])</span>DICT <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>ITER<span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><ul><li><code>dict.fromkeys(iterable, value)</code>，传入可迭代对象，比如列表、元组都可以，将这些顺序表的成员作为 key 创建字典，并且所有的 value 都统一初始化</li></ul></li></ol><h3 id="字典运算"><a href="#字典运算" class="headerlink" title="字典运算"></a>字典运算</h3><p>字典支持 <code>[], in</code> 运算，显然 <code>+, *</code> 运算对于字典是没有意义的。而 <code>[]</code> 运算区别于列表和元组，索引值不是数字而是 key</p><h3 id="python-内置函数操作字典"><a href="#python-内置函数操作字典" class="headerlink" title="python 内置函数操作字典"></a>python 内置函数操作字典</h3><ol><li><p><code>len(dict)</code></p></li><li><p><code>for i in dict</code>，注意这样形式的循环只会对字典中的 key 进行循环遍历。如果想要同时对 key 和 value 循环遍历则需要调用字典内建函数 <code>dict.items()</code> 返回可遍历的 (key, value) 元组数组</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">DICT <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>a<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> b<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token keyword">for</span> i <span class="token keyword">in</span> DICT<span class="token punctuation">:</span><span class="token keyword">print</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token comment"># result: a b</span><span class="token keyword">for</span> key<span class="token punctuation">,</span>value <span class="token keyword">in</span> DICT<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'%s:%d'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>key<span class="token punctuation">,</span> value<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># result: a:1 b:2</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ol><h3 id="字典内建函数"><a href="#字典内建函数" class="headerlink" title="字典内建函数"></a>字典内建函数</h3><ol><li><code>dict.get(key, default=None)</code>，返回指定键的值，如果 key 值不在字典中则返回 default 值。如果希望不存在 key 值时，不仅返回 default 值，还创建该 key 值，则使用 <code>dict.setdefault(key, default=None)</code>。比较类似的，如果字典中不存在某个 key，那么使用 <code>dict[key] = value</code> 也会自动在字典中创建 key, value 对</li><li><code>dict.items()</code> 返回可遍历的 (key, value) 元组组成的列表</li><li><p><code>dict.keys()</code> &amp; <code>dict.values()</code> 返回 key/value 列表</p></li><li><p><code>dict.pop(key, default)</code> &amp; <code>dict.clear()</code> 前者删除 key 值，并返回该 key 对应 value，若不存在该 key 则返回 default。后者清空字典所有内容</p></li><li><code>dict.update(dict_new)</code> 将新字典里的 (key, value) 更新到本字典中</li><li><code>dict.copy()</code></li></ol><h2 id="Set-集合"><a href="#Set-集合" class="headerlink" title="Set 集合"></a>Set 集合</h2><p>集合是一个无序的不重复元素序列，且元素性质是不可变的，如数字，字符串，元组。创建集合有如下方法：</p><ol><li><p>直接赋值 <code>SET = {1, 2, 3}</code> 这里必须有元素，如果没有则会创建一个字典</p></li><li><p>类型转换 <code>set(iterable)</code>，传入可迭代对象，可以是列表、元组，也可以不传参数以创建空集合</p></li></ol><h3 id="集合运算"><a href="#集合运算" class="headerlink" title="集合运算"></a>集合运算</h3><p>集合运算相比于前面的数据结构就要更多了，除了基础的 <code>[], in</code> 这样的索引和成员运算，还有 <code>&amp;, |, -, ^</code> 交集、并集、差集、异或（对称差集）</p><h3 id="python-内置函数操作集合"><a href="#python-内置函数操作集合" class="headerlink" title="python 内置函数操作集合"></a>python 内置函数操作集合</h3><p>在列表当中能用的操作也能用作集合，毕竟集合可以粗略看作要求元素唯一的列表</p><h3 id="集合内建函数"><a href="#集合内建函数" class="headerlink" title="集合内建函数"></a>集合内建函数</h3><ol><li><code>set.add()</code></li><li><code>set.remove(obj)</code> &amp; <code>set.clear()</code> 前者删除指定元素，后者清空所有</li><li><code>set.issubset(set_new)</code> &amp; <code>set.issuperset(set_new)</code> &amp; <code>set.isdisjoint(set_new)</code> 判断是否是集合的子集、超集，以及是否是不相交的</li></ol><h2 id="补充：迭代器，生成式，生成器"><a href="#补充：迭代器，生成式，生成器" class="headerlink" title="补充：迭代器，生成式，生成器"></a>补充：迭代器，生成式，生成器</h2><p>这一部分将会涉及到部分面向对象的内容，以及 python 的特殊方法。之前就是因为缺少这两部分的内容的了解，一直对迭代器、生成器不理解，现在进行整理。参考资料：<a href="https://www.runoob.com/python3/python3-iterator-generator.html">迭代器与生成器</a> <a href="https://www.runoob.com/w3cnote/python-yield-used-analysis.html">浅析 yield</a> </p><h3 id="iterator-迭代器"><a href="#iterator-迭代器" class="headerlink" title="iterator 迭代器"></a>iterator 迭代器</h3><p>其实在之前就已经见到了迭代器了，列表、元组、字典这些数据结构都能够在 for-in 循环的时候自动生成迭代器对象。在一个类中如何实现迭代器对象？python 提供了特殊方法 <code>__iter__()</code> 和 <code>__next__()</code> 实现创造迭代器对象，当类中有 <code>__iter__()</code> 方法时，就意味着这个类的实例不是一个普通的对象，而是一个迭代器对象</p><p>这里提一下 python 类中 <code>__function__()</code> 形式的函数被成为称为特殊函数，在特定条件发生时运行，而 <code>__iter__()</code> 和 <code>__next__()</code> 则会在 for-in 循环中被调用。下面通过迭代器实现一个简单 <code>ListDemo</code> 了解其内部逻辑</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">ListDemo</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>args <span class="token operator">=</span> args        self<span class="token punctuation">.</span>count <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>args<span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">__iter__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># 函数内可以做一些初始化操作</span>        self<span class="token punctuation">.</span>index <span class="token operator">=</span> <span class="token number">0</span>        <span class="token comment"># 最后必须返回迭代器对象本身</span>        <span class="token keyword">return</span> self    <span class="token keyword">def</span> <span class="token function">__next__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>index <span class="token operator">&lt;</span> self<span class="token punctuation">.</span>count<span class="token punctuation">:</span>            result <span class="token operator">=</span> self<span class="token punctuation">.</span>args<span class="token punctuation">[</span>self<span class="token punctuation">.</span>index<span class="token punctuation">]</span>            self<span class="token punctuation">.</span>index <span class="token operator">+=</span> <span class="token number">1</span>            <span class="token keyword">return</span> result        <span class="token keyword">else</span><span class="token punctuation">:</span>            <span class="token comment"># 循环结束的标志</span>            <span class="token keyword">raise</span> StopIteration<span class="token comment"># 运行一下</span>LIST <span class="token operator">=</span>  ListDemo<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span> <span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token keyword">for</span> i <span class="token keyword">in</span> LIST<span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>整个迭代器在循环中到底在怎么运行呢？首先 <code>ListDemo</code> 先运行了 <code>__iter__()</code> 进行了初始化，返回迭代器对象本身。在循环当中， <code>ListDemo</code> 类在重复调用 <code>__next__()</code> 函数，并返回结果给 <code>i</code>，最后遇到 <code>StopIteration</code> 结束循环</p><p>python 还有内置函数 <code>iter()</code>  &amp; <code>next()</code> 用于直接调用 <code>__iter__()</code> &amp; <code>__next__()</code> 而不需要遇到循环才触发</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">LIST <span class="token operator">=</span>  ListDemo<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span> <span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span>iterator <span class="token operator">=</span> <span class="token builtin">iter</span><span class="token punctuation">(</span>LIST<span class="token punctuation">)</span><span class="token keyword">while</span> <span class="token boolean">True</span><span class="token punctuation">:</span>    <span class="token keyword">try</span><span class="token punctuation">:</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">next</span><span class="token punctuation">(</span>iterator<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">except</span> StopIteration<span class="token punctuation">:</span>        <span class="token keyword">break</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="generator-生成器"><a href="#generator-生成器" class="headerlink" title="generator 生成器"></a>generator 生成器</h3><p>如果说迭代器是定义在类当中的，那么生成器就是可以直接定义在普通函数中的迭代器。通过 <code>yield</code> 关键字能够将普通函数变为生成器，它将实现之前的  <code>__iter__()</code> 和 <code>__next__()</code> 功能。每次遇到 yield 时函数会暂停并保存当前所有的运行信息，并返回一个 <code>yield</code> 的值, 并在下一次执行 next() 方法时从当前 <code>yield</code> 位置继续运行。下面实现一个斐波那契数列函数，来进一步理解其内部逻辑</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">fibonacci</span><span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">:</span>    a<span class="token punctuation">,</span> b <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span>    count <span class="token operator">=</span> <span class="token number">0</span>     <span class="token keyword">while</span> count <span class="token operator">&lt;</span> n<span class="token punctuation">:</span>        <span class="token keyword">yield</span> a        a_ <span class="token operator">=</span> a        a <span class="token operator">=</span> b        b <span class="token operator">=</span> a_ <span class="token operator">+</span> b        count <span class="token operator">+=</span> <span class="token number">1</span>iterator <span class="token operator">=</span> fibonacci<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token keyword">for</span> i <span class="token keyword">in</span> iterator<span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>类比一下类中的迭代器，能够更快速的理解。通过 <code>yield</code> 声明这是一个生成器，这样会在遇到 for-in 循环的时候不断地调用 next() 方法并返回 <code>yield</code> 值 <code>a</code> 赋给 <code>i</code>。区别于类中的 <code>__next__()</code>  方法是重复 <code>__next__()</code> 函数内的代码，生成器运行 <code>next()</code> 函数，则会从当前 <code>yield</code> 处继续运行，直到碰到下一个 <code>yield</code> </p><h3 id="生成式"><a href="#生成式" class="headerlink" title="生成式"></a>生成式</h3><p>生成式是生成器的一个简单应用，可以用于生成列表、字典</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 使用生成式创建列表和字典</span>f <span class="token operator">=</span> <span class="token punctuation">[</span>x<span class="token operator">**</span><span class="token number">2</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">]</span>f <span class="token operator">=</span> <span class="token punctuation">[</span>x <span class="token operator">+</span> y <span class="token keyword">for</span> x <span class="token keyword">in</span> <span class="token string">'ABCDE'</span> <span class="token keyword">for</span> y <span class="token keyword">in</span> <span class="token string">'1234567'</span><span class="token punctuation">]</span>f <span class="token operator">=</span> <span class="token punctuation">{</span>x<span class="token punctuation">:</span>x<span class="token operator">**</span><span class="token number">2</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token comment"># 生成式本质上是一个生成器</span>f <span class="token operator">=</span> x <span class="token keyword">for</span> x <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token keyword">for</span> i <span class="token keyword">in</span> f<span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 编程 </category>
          
          <category> Python </category>
          
          <category> Basic </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 教程 </tag>
            
            <tag> Python </tag>
            
            <tag> 数据结构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Python 1 基础</title>
      <link href="/archives/2bc936a0.html"/>
      <url>/archives/2bc936a0.html</url>
      
        <content type="html"><![CDATA[<h1 id="Python-Basic"><a href="#Python-Basic" class="headerlink" title="Python Basic"></a>Python Basic</h1><p>在进行深度学习的实践中，越发感觉到自己的 python 理论不足，想要重新快速整理一下 python，建立一个比较完整但不细致的框架供自己之后复习。整理资源来自于 <a href="https://github.com/jackfrued/Python-100-Days">python 100 days</a> 和 <a href="https://www.runoob.com/python3/python3-tutorial.html">菜鸟教程</a> </p><h2 id="什么是-python"><a href="#什么是-python" class="headerlink" title="什么是 python?"></a>什么是 python?</h2><p>一种编程语言，以缩进分块，有着活跃的社区和丰富的三方库，在人工智能、网络爬虫、自动运维、Web开发等领域都有广泛应用</p><p>在我的狭隘理解当中 python = python.exe。当我在使用 anaconda 时，会有不同的环境，一般每一个环境都有自己的 python.exe，如果我想要运行一个 python 脚本，那么需要选择一个 python.exe/解释器 /interpreter 来执行这个脚本</p><h2 id="安装-python"><a href="#安装-python" class="headerlink" title="安装 python"></a>安装 python</h2><p>强烈建议直接安装 anaconda，简称 conda。这是一个流行的包管理工具，其管理奥义就是创建”环境“。环境中可以下载包，管理包，且每个环境都可以安装自己的 python 解释器。这就意味着如果你想要使用不同版本 python 解释器，conda 可以做到，只需要创建多个 conda 环境，想用哪个版本就切到哪个版本的 conda 环境，同时不同的环境可以下载不同的包，实现不一样的功能</p><h2 id="python-开发工具"><a href="#python-开发工具" class="headerlink" title="python 开发工具"></a>python 开发工具</h2><ol><li>python.exe，直接双击打开就可以开始写 python 代码了，最原生的交互式开发工具，懂我意思？</li><li>ipython，比原生开发工具好一点</li><li>pycharm，专业软件，非常好用</li><li>vscode，宇宙第一开发工具，懂？</li></ol><h2 id="变量与类型"><a href="#变量与类型" class="headerlink" title="变量与类型"></a>变量与类型</h2><p>现在正式开始对 python 脚本进行了解</p><p>介绍几个基础数据类型：</p><ol><li>int </li><li>float</li><li>string</li><li>bool</li><li>complex，很少用</li></ol><h3 id="变量命名"><a href="#变量命名" class="headerlink" title="变量命名"></a>变量命名</h3><p>规则：以字母，下划线，数字构成，数字不能开头，字母大小写敏感</p><p>PEP 8要求：</p><ul><li>一般用小写字母拼写，多个单词用下划线连接</li><li>受保护的实例属性用单个下划线开头（后面会讲到）</li><li>私有的实例属性用两个下划线开头（后面会讲到）</li></ul><h3 id="变量的使用"><a href="#变量的使用" class="headerlink" title="变量的使用"></a>变量的使用</h3><p>python 中变量的创建不需要声明，直接赋值即创建。<strong>还可以使用内置函数，对变量类型进行转换：int(), float(), str()…使用 type() 查看变量类型</strong></p><p><strong>再介绍两个基础函数，print() &amp; input()，前者用于打印，后者用于接收键盘输入字符串</strong></p><h4 id="运算符"><a href="#运算符" class="headerlink" title="运算符"></a>运算符</h4><p>下表大致按照优先级从高到低的顺序列出了所有的运算符</p><p><img src="/archives/2bc936a0/image-20210828224442524.png" style="zoom: 67%;"></p><p>比较陌生的是位运算符，身份运算符，成员运算符，需要重点理解一下，参考 <a href="https://www.runoob.com/python/python-operators.html">菜鸟教程</a></p><h2 id="分支与循环"><a href="#分支与循环" class="headerlink" title="分支与循环"></a>分支与循环</h2><p>分支使用 if…elif…else 形式实现分支</p><p>循环有两种形式：for-in 和 while，重点提一下 for-in，用来对一个容器进行迭代非常方便，这个容器可以是列表，字典，元组等具有迭代功能的容器。使用 <code>break &amp; continue</code> 来跳出循环</p><h2 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h2><p>python 使用 def 关键字声明函数，以 return 结束，如果没有 return 默认返回 None。在 python 中，函数的参数可以有默认值，也支持使用可变参数 *args, **kwargs</p><h3 id="函数参数"><a href="#函数参数" class="headerlink" title="函数参数"></a>函数参数</h3><h4 id="可更改对象与不可更改对象"><a href="#可更改对象与不可更改对象" class="headerlink" title="可更改对象与不可更改对象"></a>可更改对象与不可更改对象</h4><p>由于 python 中的变量不像 C 语言一样需要声明，所以 python 函数参数是传值还是引用，也和 C 语言不一样。由于 python 的变量不需要声明，那么 python 的变量与 C 语言变量有着本质的区别，举个例子</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">a <span class="token operator">=</span> <span class="token number">1</span>b <span class="token operator">=</span> <span class="token number">1</span><span class="token keyword">print</span><span class="token punctuation">(</span>a <span class="token keyword">is</span> b<span class="token punctuation">)</span><span class="token comment"># True</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>可以看到 a 和 b 其实是来自同一个对象，更改了 a 的值，b 也一起被更改了，就好像 a 和 b 的“指针”都指向了1</p><p>参考这个 <a href="http://winterttr.me/2015/10/24/python-passing-arguments-as-value-or-reference/">博客</a>， “类型是属于对象的，而不是变量的”，python 中的变量更像是一个“指针”，是对对象的引用，一个变量可以指向任意的对象。1是属于 int 对象的，而不是属于 a, b 变量的</p><p>现在回到参数传递这个话题，我认为可以认为是“引用”传递，但情况分为两种：</p><ol><li>传递参数为可更改对象 (mutable)，例如 list, dict, np.array，在函数中<strong>修改</strong>参数值时，会改变原变量；<strong>赋值</strong>新值时，不会改变原变量</li><li>传递参数为不可更改对象 (immutable)，例如 strings, numbers, tuples，在函数中<strong>赋值</strong>新值时，不会改变原变量，即原变量所指对象不变</li></ol><p>举个例子来理解一下</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">a <span class="token operator">=</span> <span class="token number">1</span>b <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span>c <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'this is c'</span><span class="token punctuation">]</span><span class="token keyword">def</span> <span class="token function">test</span><span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">,</span> c<span class="token punctuation">)</span><span class="token punctuation">:</span>    a <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1</span>    b<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1</span>    c <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">,</span> c<span class="token punctuation">)</span><span class="token comment"># -1 [-1, 2, 3] 0</span>    test<span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">,</span> c<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">,</span> c<span class="token punctuation">)</span><span class="token comment"># 1 [-1, 2, 3] ['this is c']</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="参数类型"><a href="#参数类型" class="headerlink" title="参数类型"></a>参数类型</h4><p>这里参考 <a href="https://cloud.tencent.com/developer/article/1640717">python 参数，腾讯云</a> 进行整理。python 函数的形参分为四种：</p><ul><li>必需参数：平时最常用的，必传确定数量的参数</li><li>缺省参数：在调用函数时可以传也可以不传，如果不传将使用默认值</li><li>可变参数：可变长度参数，通常用 <code>*args</code> 表示</li><li>关键字参数：长度可变，但需要以 key=value 对形式传递，通常用 <code>**kwargs</code> 表示</li></ul><p>对于定义函数时，参数位置的强制要求有以下两点：</p><ol><li>缺省参数必须在必须参数之后</li><li>关键字参数必须在最后</li></ol><p>在给函数传入参数时，可以传入两种类型：</p><ul><li>位置参数：直接传入实参，传入位置与函数定义时的参数位置相同</li><li>关键字参数：以 <code>param=value</code> 形式出现，可以忽略函数定义时参数的位置</li></ul><p>python 强制要求位置参数必须在关键字参数之前</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">test</span><span class="token punctuation">(</span>a<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span> b<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">'c'</span><span class="token punctuation">,</span> d<span class="token operator">=</span><span class="token string">'d'</span><span class="token punctuation">,</span> <span class="token operator">*</span>args<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token boolean">None</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'必须参数: %s, %s'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'缺省参数: %s, %s'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>c<span class="token punctuation">,</span> d<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'可变参数:'</span><span class="token punctuation">,</span> args<span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'关键字参数:'</span><span class="token punctuation">,</span> kwargs<span class="token punctuation">)</span>    test<span class="token punctuation">(</span><span class="token string">'a'</span><span class="token punctuation">,</span> <span class="token string">'b'</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> e<span class="token operator">=</span><span class="token string">'e'</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'--------------------------'</span><span class="token punctuation">)</span>test<span class="token punctuation">(</span><span class="token string">'a'</span><span class="token punctuation">,</span> b<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">'C'</span><span class="token punctuation">,</span> e<span class="token operator">=</span><span class="token string">'e'</span><span class="token punctuation">)</span><span class="token comment"># 上面过早传入了关键字参数，导致无法传入可变参数 *args</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>上面冒号 <code>:</code> 之后表示的是作者建议的传入参数类型，箭头 <code>-&gt;</code> 之后为建议的函数返回类型</p><h3 id="解包"><a href="#解包" class="headerlink" title="解包"></a>解包</h3><p>当需要传入的多个参数被打包在了一个元组/字典中，可以通过解包的方式，直接把元组/字典作为可变参数/关键字参数，传入到函数当中</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">args <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>kwargs <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>b<span class="token operator">=</span><span class="token string">'b'</span><span class="token punctuation">,</span> a<span class="token operator">=</span><span class="token string">'a'</span><span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">'c'</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">test</span><span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">,</span> c<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">,</span> c<span class="token punctuation">)</span>test<span class="token punctuation">(</span><span class="token operator">*</span>args<span class="token punctuation">)</span><span class="token comment"># 1 2 3</span>test<span class="token punctuation">(</span><span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token comment"># a b c</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>从上面的代码中可以看到，解包元组用  <code>*</code>，解包字典用 <code>**</code></p><h3 id="lambda-匿名函数"><a href="#lambda-匿名函数" class="headerlink" title="lambda 匿名函数"></a>lambda 匿名函数</h3><p>lambda 只是一个表达式，函数体比 def 简单很多，所以只能封装有限的逻辑。lambda 函数的语法只有一句</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">lambda</span> <span class="token punctuation">[</span>args_list<span class="token punctuation">]</span><span class="token punctuation">:</span> expression<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><code>expression</code> 可以是表达式，也可以是一个函数。下面举一个例子来使用 lambda 函数</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">add <span class="token operator">=</span> <span class="token keyword">lambda</span> a<span class="token punctuation">,</span> b<span class="token punctuation">:</span> a <span class="token operator">+</span> b<span class="token keyword">print</span><span class="token punctuation">(</span>add<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">exp</span><span class="token punctuation">(</span>a<span class="token punctuation">,</span> b<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">return</span> a<span class="token operator">**</span>b<span class="token comment"># expression can be a function</span>exp_of_2 <span class="token operator">=</span> <span class="token keyword">lambda</span> x<span class="token punctuation">:</span> exp<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>exp_of_2<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>所谓匿名，意即不再使用 def 语句这样标准的形式定义一个函数，故没有函数名！</p><h3 id="模块化管理"><a href="#模块化管理" class="headerlink" title="模块化管理"></a>模块化管理</h3><p>通过模块管理 python 文件/函数将会变得非常方便，需要使用的函数，使用关键字 <code>import</code> 导入即可，导入方法有如下：</p><ol><li><code>import module</code>：导入模块，以 <code>module.func</code> 使用模块中的函数等内容</li><li><code>import module ad md</code>：导入模块，命名为 md，使用方法类似1</li><li><code>from module import func</code>：直接从模块中导入函数，可直接使用 func()</li></ol><p>当我们使用 import 语句的时候，Python解释器是怎样找到对应的文件的呢？这就涉及到 Python 的搜索路径，搜索路径是由一系列目录名组成的，Python 解释器就依次从这些目录中去寻找所引入的模块。搜索路径被存储在 sys 模块中的 path 变量，此变量为一个列表</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> sys<span class="token keyword">for</span> path <span class="token keyword">in</span> sys<span class="token punctuation">.</span>path<span class="token punctuation">:</span><span class="token keyword">print</span><span class="token punctuation">(</span>path<span class="token punctuation">)</span><span class="token comment"># d:\VScodeProjects\TestProj</span><span class="token comment"># D:\LenovoSoftstore\Anaconda\python38.zip</span><span class="token comment"># D:\LenovoSoftstore\Anaconda\lib\site-packages</span><span class="token comment"># ...MORE</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>一般 <code>sys.path</code> 列表的第一个即为当前文件所在文件夹</p><h4 id="if-name-‘-main-‘"><a href="#if-name-‘-main-‘" class="headerlink" title="if __name__ = ‘__main__‘"></a>if __name__ = ‘__main__‘</h4><p>需要说明的是，如果导入的模块中有可执行的代码，那么在导入模块时就会执行。但事实上，我们可能不希望执行这些代码，只想要导入这个函数，例如下面的模块</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># module.py</span><span class="token keyword">def</span> <span class="token function">module_func</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'this is a module'</span><span class="token punctuation">)</span>module_func<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>此时如果在另一个 python 文件中 <code>import module</code> 将会看到输出 <code>this is a module</code>。为了避免这种情况，需要在模块中限定这些可执行代码，仅在该模块直接运行的时候运行，而不在导入的时候运行。可采取如下形式</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># module.py</span><span class="token keyword">def</span> <span class="token function">module_func</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'this is a module'</span><span class="token punctuation">)</span><span class="token comment"># __name__是Python中一个隐含的变量它代表了模块的名字</span><span class="token comment"># 只有被Python解释器直接执行的模块的名字才是__main__</span><span class="token keyword">if</span> __name__ <span class="token operator">=</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>module_func<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这里提到了一个隐含变量 <code>__name__</code>，是由 python 自动生成的变量，不需要人为定义。在 python 中有其他的隐含变量，例如 <code>__doc__</code> 用于保存对象的说明性文档，通过关键字 <code>?</code> 就能调出文档，<a href="https://blog.csdn.net/u011699626/article/details/107981264">CSDN doc参考</a></p>]]></content>
      
      
      <categories>
          
          <category> 编程 </category>
          
          <category> Python </category>
          
          <category> Basic </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 教程 </tag>
            
            <tag> Python </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Windows 软件推荐</title>
      <link href="/archives/c92482f1.html"/>
      <url>/archives/c92482f1.html</url>
      
        <content type="html"><![CDATA[<h2 id="Windows-的软件"><a href="#Windows-的软件" class="headerlink" title="Windows 的软件"></a>Windows 的软件</h2><ol><li><p>Listary，搜索神器</p></li><li><p>potplayer + 简洁皮肤定制，该播放强比你想象中更强大，对各种格式都有很好的兼容性，还能实时翻译字幕以及录制视频</p></li><li><p>bandzip</p></li><li><p>bilibili 直播姬，OBS，对于 OBS 的简要教程放在后面</p></li><li><p>clash</p></li><li><p>滴答清单</p></li><li><p>chrome，油猴插件：Bilibili Evolved，zotero，google translate，youtube 双语字幕, translatesubtitles.co/</p></li><li><p>印象笔记</p></li><li><p>typora</p></li><li><p>latex</p></li><li><p>vscode</p></li><li><p>zotero</p><ul><li><p>推荐 plugin: zotero citation counts manager 用于爬取文献引用。想要将 zotero 的文献进行转移时，只需要转移 storage 及其 zotero.split 文件即可</p></li><li><p>zotero 也有很方便的 word 插件，在需要的文献后面 add/edit citation 就可进行插入，然后在文末 add/edit bibliography 即可</p></li><li>为了保障 zotero 云端的空间，我选择了在拉取数据时不下载 pdf，这样空间就完全够用了。将 pdf 文档单独存放到其他文件夹中，并使用自己的脚本进行重新命名，解决。脚本代码放在后面</li></ul></li><li><p>git，当 github 下载文件慢时请搜索 github 镜像资源</p></li><li><p>百度网盘 阿里云盘</p></li><li><p>ps pr</p></li><li><p>WinSCP，Xshell，MobaXterm（强烈推荐，可以替代 WinSCP &amp; XShell）</p></li><li><p>SpaceSniffer，查看存储空间</p></li><li><p>utorrent</p></li><li><p>LinuxReader，方便双系统在 Win 中获取 Linux 系统的文件</p></li><li><p>Snipaste，好用的截图工具，以后再也不用打开 QQ 再截图了😎</p></li><li><p>Drawio &amp; Excalidrao，用于画流程图/网络架构</p></li><li><p>Utools，介绍自己常用的功能：中键快速用 cmd/vscode 打开文件夹；剪切板查看历史剪切记录；网页快开能够实现迅速搜索；中键显示翻译；OCR 图片转文字；Linux 命令查询插件；图片压缩插件；</p></li></ol><h2 id="OBS-简要教程"><a href="#OBS-简要教程" class="headerlink" title="OBS 简要教程"></a>OBS 简要教程</h2><p>主要根据 <a href="https://www.bilibili.com/video/BV1wt4y1Q7rV?p=1">bilibili</a> 进行学习</p><h3 id="界面介绍"><a href="#界面介绍" class="headerlink" title="界面介绍"></a>界面介绍</h3><p><img src="/archives/c92482f1/image-20210916200411505.png" style="zoom:80%;"></p><ol><li><p>来源</p><p>首先 OBS 最基本的功能就是录制电脑屏幕/窗口。我们需要告诉 OBS 需要添加哪些信息源，这就是<strong>来源</strong>窗口的功能。比如上图中添加了<strong>显示器采集</strong>，这个来源就能够记录你的屏幕内所显示的内容</p></li><li><p>场景</p><p><strong>OBS 在一个场景中可以添加多个来源</strong>，并且调整这些来源如何显示各个来源，比如我们希望最终的画面左边为<strong>显示器采集</strong>内容，右边为<strong>游戏源</strong>。我们也可以创建多个场景，在直播的时候可以直接选择某个场景，或者在场景之间切换</p></li><li><p>混音器</p><p>用于采集电脑声音和麦克风声音</p></li></ol><h3 id="设置"><a href="#设置" class="headerlink" title="设置"></a>设置</h3><p>掌握以上逻辑就能很好地使用 OBS 了，当然进一步使用肯定要对<strong>设置</strong>进行调整，以下为我的设置</p><p><img src="/archives/c92482f1/image-20210916201726253.png" style="zoom: 67%;"></p><p>比较重要的就是输出设置，串流代表你直播时采集画面的质量，录像即代表录制画面的质量。下面看看这几个参数</p><ol><li>码率，越高视频质量越高，一般推荐 2k-8k 之间</li><li><p>编码器，一般有两个选项，x264 代表用 CPU 进行编码，其他硬件则多为 GPU</p></li><li><p>音频比特率，一般为160或320</p></li></ol><p>面板中的其他设置，例如：推流用于设置直播平台服务器，视频还可以进一步设置视频的分辨率、帧数</p><h2 id="Arxiv-pdf-rename-script"><a href="#Arxiv-pdf-rename-script" class="headerlink" title="Arxiv pdf rename script"></a>Arxiv pdf rename script</h2><p>我希望重命名 arxiv 下载的 pdf 文件，不然全是数字 id 命名很难进行管理，所以自己写了一个 python 脚本，该脚本是使用 pdf 文件名作为 id 查询 arxiv 上论文的标题、作者、发布时间，然后重命名原 pdf 文件。使用方法如下</p><ol><li><p>下载 <a href="https://github.com/lukasschwab/arxiv.py">arxiv</a> 三方库 <code>pip install arxiv</code></p></li><li><p>将你的 pdf 放在一个文件夹中，例如 <code>archive</code></p></li><li><p>将脚本 <code>rename.py</code> 放在与 <code>archive</code> 同级的目录，如下</p><pre class="line-numbers language-none"><code class="language-none">- archive- xxxx.xxxx.pdf- xxxx.xxxx.pdf- rename.py<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>运行 <code>python rename.py</code></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> arxiv<span class="token keyword">from</span> pathlib <span class="token keyword">import</span> Path<span class="token comment"># PDF dir</span><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>    archive <span class="token operator">=</span> Path<span class="token punctuation">(</span><span class="token string">'./archive'</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> pdf <span class="token keyword">in</span> archive<span class="token punctuation">.</span>glob<span class="token punctuation">(</span><span class="token string">'*.pdf'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token builtin">id</span> <span class="token operator">=</span> pdf<span class="token punctuation">.</span>stem        <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span><span class="token builtin">id</span><span class="token punctuation">)</span> <span class="token operator">&gt;</span> <span class="token number">20</span><span class="token punctuation">:</span> <span class="token keyword">continue</span>  <span class="token comment"># ignore processed pdf</span>        search <span class="token operator">=</span> arxiv<span class="token punctuation">.</span>Search<span class="token punctuation">(</span>id_list<span class="token operator">=</span><span class="token punctuation">[</span><span class="token builtin">id</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        result <span class="token operator">=</span> <span class="token builtin">next</span><span class="token punctuation">(</span>search<span class="token punctuation">.</span>results<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>                <span class="token comment"># process title</span>        title <span class="token operator">=</span> result<span class="token punctuation">.</span>title<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">':'</span><span class="token punctuation">,</span> <span class="token string">' -'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">'?'</span><span class="token punctuation">,</span> <span class="token string">''</span><span class="token punctuation">)</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">'*'</span><span class="token punctuation">,</span> <span class="token string">''</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">220</span><span class="token punctuation">]</span>        <span class="token comment"># process time and author</span>        time <span class="token operator">=</span> result<span class="token punctuation">.</span>published<span class="token punctuation">.</span>year        author <span class="token operator">=</span> result<span class="token punctuation">.</span>authors<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>name        <span class="token comment"># rename path</span>        rename <span class="token operator">=</span> archive <span class="token operator">/</span> <span class="token string-interpolation"><span class="token string">f'</span><span class="token interpolation"><span class="token punctuation">{</span>time<span class="token punctuation">}</span></span><span class="token string">_</span><span class="token interpolation"><span class="token punctuation">{</span>title<span class="token punctuation">}</span></span><span class="token string">_</span><span class="token interpolation"><span class="token punctuation">{</span>author<span class="token punctuation">}</span></span><span class="token string">.pdf'</span></span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'</span><span class="token interpolation"><span class="token punctuation">{</span><span class="token builtin">id</span><span class="token punctuation">}</span></span><span class="token string"> -&gt; </span><span class="token interpolation"><span class="token punctuation">{</span>rename<span class="token punctuation">.</span>name<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token format-spec">30]</span><span class="token punctuation">}</span></span><span class="token string">...'</span></span><span class="token punctuation">)</span>        pdf<span class="token punctuation">.</span>replace<span class="token punctuation">(</span>rename<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ol>]]></content>
      
      
      <categories>
          
          <category> 生活 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 推荐 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MMDetection Quick Run</title>
      <link href="/archives/6f4f5bd8.html"/>
      <url>/archives/6f4f5bd8.html</url>
      
        <content type="html"><![CDATA[<h1 id="MMDetection-Quick-Run"><a href="#MMDetection-Quick-Run" class="headerlink" title="MMDetection Quick Run"></a>MMDetection Quick Run</h1><p>整理自 <a href="https://mmdetection.readthedocs.io/en/latest/index.html">MMDetection 官方文档</a></p><h2 id="Part-1-Inference-and-train-with-existing-models-and-standard-datasets"><a href="#Part-1-Inference-and-train-with-existing-models-and-standard-datasets" class="headerlink" title="Part 1, Inference and train with existing models and standard datasets"></a>Part 1, Inference and train with existing models and standard datasets</h2><blockquote><p>MMDetection provides hundreds of existing and existing detection models in <a href="https://mmdetection.readthedocs.io/en/latest/model_zoo.html">Model Zoo</a>, and supports multiple standard datasets, including Pascal VOC, COCO, CityScapes, LVIS, etc.</p></blockquote><p>这一部分将简要介绍，如何使用 MMDetection 对 Model zoo 中的模型进行测试和训练</p><h3 id="Inference-with-existing-models"><a href="#Inference-with-existing-models" class="headerlink" title="Inference with existing models"></a>Inference with existing models</h3><blockquote><p>By inference, we mean using trained models to detect objects on images. In MMDetection, a model is defined by a configuration file and existing model parameters are save in a checkpoint file.</p></blockquote><p>这里介绍了 MMDetection 模型表示的基本逻辑：<code>configuration file</code>+ <code>checkpoint file</code> </p><p>文档以 Faster R-CNN 为例子，如何进行目标检测推理</p><blockquote><p>To start with, we recommend <a href="https://github.com/open-mmlab/mmdetection/tree/master/configs/faster_rcnn">Faster RCNN</a> with this <a href="https://github.com/open-mmlab/mmdetection/blob/master/configs/faster_rcnn/faster_rcnn_r50_fpn_1x_coco.py">configuration file</a> and this <a href="https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth">checkpoint file</a>. It is recommended to download the checkpoint file to <code>checkpoints</code> directory.</p></blockquote><p>Q: config files 名字的意义是什么？在 config 对应的文件夹中有 markdown 文档进行说明，例如 <a href="https://github.com/open-mmlab/mmdetection/tree/master/configs/faster_rcnn">faster rcnn</a> </p><h4 id="High-level-APIs-for-inference"><a href="#High-level-APIs-for-inference" class="headerlink" title="High-level APIs for inference"></a>High-level APIs for inference</h4><p>在之前也见到过这个代码，现在再来看一看</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> mmdet<span class="token punctuation">.</span>apis <span class="token keyword">import</span> init_detector<span class="token punctuation">,</span> inference_detector<span class="token keyword">import</span> mmcv<span class="token comment"># Specify the path to model config and checkpoint file</span>config_file <span class="token operator">=</span> <span class="token string">'configs/faster_rcnn/faster_rcnn_r50_fpn_1x_coco.py'</span>checkpoint_file <span class="token operator">=</span> <span class="token string">'checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth'</span><span class="token comment"># build the model from a config file and a checkpoint file</span>model <span class="token operator">=</span> init_detector<span class="token punctuation">(</span>config_file<span class="token punctuation">,</span> checkpoint_file<span class="token punctuation">,</span> device<span class="token operator">=</span><span class="token string">'cuda:0'</span><span class="token punctuation">)</span><span class="token comment"># test a single image and show the results</span>img <span class="token operator">=</span> <span class="token string">'test.jpg'</span>  <span class="token comment"># or img = mmcv.imread(img), which will only load it once</span>result <span class="token operator">=</span> inference_detector<span class="token punctuation">(</span>model<span class="token punctuation">,</span> img<span class="token punctuation">)</span><span class="token comment"># visualize the results in a new window</span>model<span class="token punctuation">.</span>show_result<span class="token punctuation">(</span>img<span class="token punctuation">,</span> result<span class="token punctuation">)</span><span class="token comment"># or save the visualization results to image files</span>model<span class="token punctuation">.</span>show_result<span class="token punctuation">(</span>img<span class="token punctuation">,</span> result<span class="token punctuation">,</span> out_file<span class="token operator">=</span><span class="token string">'result.jpg'</span><span class="token punctuation">)</span><span class="token comment"># test a video and show the results</span>video <span class="token operator">=</span> mmcv<span class="token punctuation">.</span>VideoReader<span class="token punctuation">(</span><span class="token string">'video.mp4'</span><span class="token punctuation">)</span><span class="token keyword">for</span> frame <span class="token keyword">in</span> video<span class="token punctuation">:</span>    result <span class="token operator">=</span> inference_detector<span class="token punctuation">(</span>model<span class="token punctuation">,</span> frame<span class="token punctuation">)</span>    model<span class="token punctuation">.</span>show_result<span class="token punctuation">(</span>frame<span class="token punctuation">,</span> result<span class="token punctuation">,</span> wait_time<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>上面的代码中用到了是这三个 API:</p><ol><li>异步推理 <code>async_inference_detector</code></li><li>绘制 <code>show_result</code></li><li>推理 <code>inference_detector</code></li></ol><p>这里 <code>show_result</code> 的参数请查看 <a href="https://github.com/open-mmlab/mmdetection/blob/a1cecf63c713c53941b8dcf8a9d762baf8511f2c/mmdet/models/detectors/base.py">原代码</a>，如果需要显示的话要添加参数 <code>show=True</code>。但在用 vscode 连接远程服务器的情况下，即使设置了 <code>show=True</code> 也不会展示结果，可能因为服务器不支持 GUI，替代的方法就是在 Jupyter notebook 或者 interactive window 中运行</p><h4 id="Asynchronous-interface-supported-for-Python-3-7"><a href="#Asynchronous-interface-supported-for-Python-3-7" class="headerlink" title="Asynchronous interface - supported for Python 3.7+"></a>Asynchronous interface - supported for Python 3.7+</h4><p>这一节没有理解清楚，只稍微留了点印象：使用异步接口理论上能够加速推理/训练过程</p><h5 id="异步"><a href="#异步" class="headerlink" title="异步"></a>异步</h5><p>首先什么是 <a href="https://blog.csdn.net/lemon4869/article/details/107145903">异步思维</a>，在链接中的理解来说：异步就是不必等待推理结束才开始下一张图像的预处理。但看原代码说的异步到底是什么意思，我也不太理解，以后再回来整理 asyncio 相关知识吧</p><h5 id="async-amp-await"><a href="#async-amp-await" class="headerlink" title="async &amp; await"></a>async &amp; await</h5><p>什么是 Asynchronous interface <a href="https://zhuanlan.zhihu.com/p/353857526">知乎链接</a></p><p>什么是 asyncio <a href="https://blog.csdn.net/permike/article/details/110821246">知乎链接</a></p><p>Q: 这里需要更多的 python 知识，我得回去补充，比如 with 关键字什么意思？整个异步的过程是怎么样的，能否把整个时间与事件弄清楚？</p><h4 id="Demo"><a href="#Demo" class="headerlink" title="Demo"></a>Demo</h4><p>文档给了3个demo：</p><ol><li>Image Demo</li><li>Webcam Demo</li><li>Video Demo</li></ol><p>简单看了一下代码，看来还需要补充总结 OpenCV 的一些基础知识</p><h3 id="Test-existing-models-on-standard-datasets"><a href="#Test-existing-models-on-standard-datasets" class="headerlink" title="Test existing models on standard datasets"></a>Test existing models on standard datasets</h3><blockquote><p>MMDetection supports multiple public datasets including COCO, Pascal VOC, CityScapes, and <a href="https://github.com/open-mmlab/mmdetection/tree/master/configs/_base_/datasets">more</a>. This section will show how to test existing models on supported datasets.</p></blockquote><h4 id="Prepare-datasets"><a href="#Prepare-datasets" class="headerlink" title="Prepare datasets"></a>Prepare datasets</h4><p>推荐在项目之外建立数据集，然后以软链接的形式放到项目中，且目录结构要根据 config files 规放置（或者你自己修改 config files），举个几个例子</p><pre class="line-numbers language-none"><code class="language-none">mmdetection├── mmdet├── tools├── configs├── data│   ├── coco│   │   ├── annotations│   │   ├── train2017│   │   ├── val2017│   │   ├── test2017│   ├── cityscapes│   │   ├── annotations│   │   ├── leftImg8bit│   │   │   ├── train│   │   │   ├── val│   │   ├── gtFine│   │   │   ├── train│   │   │   ├── val│   ├── VOCdevkit│   │   ├── VOC2007│   │   ├── VOC2012<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="Test-existing-models"><a href="#Test-existing-models" class="headerlink" title="Test existing models"></a>Test existing models</h4><blockquote><p>We provide testing scripts for evaluating an existing model on the whole dataset (COCO, PASCAL VOC, Cityscapes, etc.). </p></blockquote><p>可以在单个 GPU 上测试，也可以在多个 GPU 上进行分布测试</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token comment"># single-gpu testing</span>python tools/test.py <span class="token punctuation">\</span>    <span class="token variable">${CONFIG_FILE}</span> <span class="token punctuation">\</span>    <span class="token variable">${CHECKPOINT_FILE}</span> <span class="token punctuation">\</span>    <span class="token punctuation">[</span>--out <span class="token variable">${RESULT_FILE}</span><span class="token punctuation">]</span> <span class="token punctuation">\</span>    <span class="token punctuation">[</span>--eval <span class="token variable">${EVAL_METRICS}</span><span class="token punctuation">]</span> <span class="token punctuation">\</span>    <span class="token punctuation">[</span>--show<span class="token punctuation">]</span><span class="token comment"># multi-gpu testing</span><span class="token function">bash</span> tools/dist_test.sh <span class="token punctuation">\</span>    <span class="token variable">${CONFIG_FILE}</span> <span class="token punctuation">\</span>    <span class="token variable">${CHECKPOINT_FILE}</span> <span class="token punctuation">\</span>    <span class="token variable">${GPU_NUM}</span> <span class="token punctuation">\</span>    <span class="token punctuation">[</span>--out <span class="token variable">${RESULT_FILE}</span><span class="token punctuation">]</span> <span class="token punctuation">\</span>    <span class="token punctuation">[</span>--eval <span class="token variable">${EVAL_METRICS}</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>mmdetection 提供对无标记数据集进行测试，但数据集需要符合 COCO format，如果不是 COCO format 例如 VOC 数据集，需要使用 <a href="https://github.com/open-mmlab/mmdetection/tree/master/tools/dataset_converters/pascal_voc.py">script in tools</a> 转化</p><p>mmdetection 提供 batch inference，能够一次推理多个样本，在 config files 中修改 <code>sample_per_gpu</code> 即可，或者使用 <code>--cfg-options data.test.samples_per_gpu=2</code></p><p>还有很多参数可以调整，具体请看源代码，文档也给出了很多 <a href="https://mmdetection.readthedocs.io/en/latest/1_exist_data_model.html#examples">例子</a></p><h3 id="Train-predefined-models-on-standard-datasets"><a href="#Train-predefined-models-on-standard-datasets" class="headerlink" title="Train predefined models on standard datasets"></a>Train predefined models on standard datasets</h3><blockquote><p>This section will show how to train <em>predefined</em> models (under <a href="https://github.com/open-mmlab/mmdetection/tree/master/configs">configs</a>) on standard datasets i.e. COCO.</p><p><strong>Important</strong>: 训练的默认学习率的配置为 8个 GPU 和 2 img/gpu，也就是 batch size 为16，如果使用不同的 batch size 那么就要按照线性缩放原则更改学习率 e.g., <code>lr=0.01</code> for 4 GPUs <em> 2 imgs/gpu and <code>lr=0.08</code> for 16 GPUs </em> 4 imgs/gpu.</p></blockquote><h4 id="Prepare-datasets-1"><a href="#Prepare-datasets-1" class="headerlink" title="Prepare datasets"></a>Prepare datasets</h4><p>准备过程和上一节 Test 部分是一致的。建议先将模型下载好，以防网不好导致报错</p><h4 id="Training-on-a-single-GPU"><a href="#Training-on-a-single-GPU" class="headerlink" title="Training on a single GPU"></a>Training on a single GPU</h4><p>在单个 GPU 上训练，基本使用方法</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">python tools/train.py <span class="token punctuation">\</span>    <span class="token variable">${CONFIG_FILE}</span> <span class="token punctuation">\</span>    <span class="token punctuation">[</span>optional arguments<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>训练过程中的 log 和 checkpoints 都会被存放到 <code>work_dir</code> 当中，也可以用 <code>--work-dir</code> 重新指定</p><p>默认每12个 epoch 使用验证集对模型进行一次评估 evaluation，train.py 还接受一些常用参数：</p><ul><li><code>--no-validate</code> (<strong>not suggested</strong>): Disable evaluation during training.</li><li><code>--work-dir ${WORK_DIR}</code>: Override the working directory.</li><li><code>--resume-from ${CHECKPOINT_FILE}</code>: Resume from a previous checkpoint file.</li><li><code>--options 'Key=value'</code>: Overrides other settings in the used config.</li></ul><p>文档提到两个参数的区别：<code>--resume-from &amp; --load-from</code> 前者不仅加载参数权重，也加载 optimizer 的状态，主要用于训练被突然打断后接着训练。后者只加载参数权重，主要用于 finetuning</p><h4 id="Training-on-multiple-GPUs"><a href="#Training-on-multiple-GPUs" class="headerlink" title="Training on multiple GPUs"></a>Training on multiple GPUs</h4><p>同样，基本用法</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">bash</span> ./tools/dist_train.sh <span class="token punctuation">\</span>    <span class="token variable">${CONFIG_FILE}</span> <span class="token punctuation">\</span>    <span class="token variable">${GPU_NUM}</span> <span class="token punctuation">\</span>    <span class="token punctuation">[</span>optional arguments<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>可选参数和上面训练单个 GPU 是一样的</p><h5 id="Launch-multiple-jobs-simultaneously"><a href="#Launch-multiple-jobs-simultaneously" class="headerlink" title="Launch multiple jobs simultaneously"></a>Launch multiple jobs simultaneously</h5><p>在训练当中，通常会有多任务的存在，mmdetection 也可以实现，但现在能力有限，实在不能理解具体的实现逻辑，留个 <a href="https://mmdetection.readthedocs.io/en/latest/1_exist_data_model.html#training-on-multiple-gpus">原文档链接</a></p><p>提到了很多新东西，nodes, port, slurm, pytorch launch utility…如果能够在实践中理解这些概念更好了</p><h2 id="Part-2-Train-with-customized-datasets"><a href="#Part-2-Train-with-customized-datasets" class="headerlink" title="Part 2, Train with customized datasets"></a>Part 2, Train with customized datasets</h2><blockquote><p> We use the <a href="https://github.com/matterport/Mask_RCNN/tree/master/samples/balloon">balloon dataset</a> as an example to describe the whole process.</p></blockquote><p>基本步骤为：</p><ol><li>Prepare the customized dataset</li><li>Prepare a config</li><li>Train, test, inference models on the customized dataset.</li></ol><h3 id="Prepare-the-customized-dataset"><a href="#Prepare-the-customized-dataset" class="headerlink" title="Prepare the customized dataset"></a>Prepare the customized dataset</h3><p>mmdetection 支持对 COCO format 数据集进行训练，将不同格式的数据集转化为 COCO format 即可。可能也可以对 config file 进行配置，来适配不同格式的数据集，但这一部分文档没有提及</p><h4 id="COCO-annotation-format"><a href="#COCO-annotation-format" class="headerlink" title="COCO annotation format"></a>COCO annotation format</h4><blockquote><p>The necessary keys of COCO format for instance segmentation is as below, for the complete details, please refer <a href="https://cocodataset.org/#format-data">here</a>.</p></blockquote><pre class="line-numbers language-json" data-language="json"><code class="language-json"><span class="token punctuation">{</span>    <span class="token property">"images"</span><span class="token operator">:</span> <span class="token punctuation">[</span>image<span class="token punctuation">]</span><span class="token punctuation">,</span>    <span class="token property">"annotations"</span><span class="token operator">:</span> <span class="token punctuation">[</span>annotation<span class="token punctuation">]</span><span class="token punctuation">,</span>    <span class="token property">"categories"</span><span class="token operator">:</span> <span class="token punctuation">[</span>category<span class="token punctuation">]</span><span class="token punctuation">}</span>image = <span class="token punctuation">{</span>    <span class="token property">"id"</span><span class="token operator">:</span> int<span class="token punctuation">,</span>    <span class="token property">"width"</span><span class="token operator">:</span> int<span class="token punctuation">,</span>    <span class="token property">"height"</span><span class="token operator">:</span> int<span class="token punctuation">,</span>    <span class="token property">"file_name"</span><span class="token operator">:</span> str<span class="token punctuation">,</span><span class="token punctuation">}</span>annotation = <span class="token punctuation">{</span>    <span class="token property">"id"</span><span class="token operator">:</span> int<span class="token punctuation">,</span>    <span class="token property">"image_id"</span><span class="token operator">:</span> int<span class="token punctuation">,</span>    <span class="token property">"category_id"</span><span class="token operator">:</span> int<span class="token punctuation">,</span>    <span class="token property">"segmentation"</span><span class="token operator">:</span> RLE or <span class="token punctuation">[</span>polygon<span class="token punctuation">]</span><span class="token punctuation">,</span>    <span class="token property">"area"</span><span class="token operator">:</span> float<span class="token punctuation">,</span>    <span class="token property">"bbox"</span><span class="token operator">:</span> <span class="token punctuation">[</span>x<span class="token punctuation">,</span>y<span class="token punctuation">,</span>width<span class="token punctuation">,</span>height<span class="token punctuation">]</span><span class="token punctuation">,</span>    <span class="token property">"iscrowd"</span><span class="token operator">:</span> <span class="token number">0</span> or <span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">}</span>categories = <span class="token punctuation">[</span><span class="token punctuation">{</span>    <span class="token property">"id"</span><span class="token operator">:</span> int<span class="token punctuation">,</span>    <span class="token property">"name"</span><span class="token operator">:</span> str<span class="token punctuation">,</span>    <span class="token property">"supercategory"</span><span class="token operator">:</span> str<span class="token punctuation">,</span><span class="token punctuation">}</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>balloon dataset format 形如下</p><pre class="line-numbers language-json" data-language="json"><code class="language-json"><span class="token punctuation">{</span>'base64_img_data'<span class="token operator">:</span> ''<span class="token punctuation">,</span> 'file_attributes'<span class="token operator">:</span> <span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">,</span> 'filename'<span class="token operator">:</span> '34020010494_e5cb88e1c4_k.jpg'<span class="token punctuation">,</span> 'fileref'<span class="token operator">:</span> ''<span class="token punctuation">,</span> 'regions'<span class="token operator">:</span> <span class="token punctuation">{</span>'<span class="token number">0</span>'<span class="token operator">:</span> <span class="token punctuation">{</span>'region_attributes'<span class="token operator">:</span> <span class="token punctuation">{</span><span class="token punctuation">}</span><span class="token punctuation">,</span>   'shape_attributes'<span class="token operator">:</span> <span class="token punctuation">{</span>'all_points_x'<span class="token operator">:</span> <span class="token punctuation">[</span>...<span class="token punctuation">,</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    'all_points_y'<span class="token operator">:</span> <span class="token punctuation">[</span>...<span class="token punctuation">,</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    'name'<span class="token operator">:</span> 'polygon'<span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">}</span><span class="token punctuation">,</span> 'size'<span class="token operator">:</span> <span class="token number">1115004</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>文档提供了函数将 balloon dataset JSON 格式转化为 COCO format，<a href="https://mmdetection.readthedocs.io/en/latest/2_new_data_model.html#coco-annotation-format">原文档</a></p><h3 id="Prepare-a-config"><a href="#Prepare-a-config" class="headerlink" title="Prepare a config"></a>Prepare a config</h3><blockquote><p>The second step is to prepare a config thus the dataset could be successfully loaded. </p></blockquote><p>假设以 balloon dataset 训练 Mask R-CNN with FPN，config 在 <code>configs/balloon</code> 命名为  <code>mask_rcnn_r50_caffe_fpn_mstrain-poly_1x_balloon.py</code></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># The new config inherits a base config to highlight the necessary modification</span>_base_ <span class="token operator">=</span> <span class="token string">'mask_rcnn/mask_rcnn_r50_caffe_fpn_mstrain-poly_1x_coco.py'</span><span class="token comment"># We also need to change the num_classes in head to match the dataset's annotation</span>model <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>    roi_head<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>        bbox_head<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>num_classes<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>        mask_head<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>num_classes<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># Modify dataset related settings</span>dataset_type <span class="token operator">=</span> <span class="token string">'COCODataset'</span>classes <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token string">'balloon'</span><span class="token punctuation">,</span><span class="token punctuation">)</span>data <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>    train<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>        img_prefix<span class="token operator">=</span><span class="token string">'balloon/train/'</span><span class="token punctuation">,</span>        classes<span class="token operator">=</span>classes<span class="token punctuation">,</span>        ann_file<span class="token operator">=</span><span class="token string">'balloon/train/annotation_coco.json'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    val<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>        img_prefix<span class="token operator">=</span><span class="token string">'balloon/val/'</span><span class="token punctuation">,</span>        classes<span class="token operator">=</span>classes<span class="token punctuation">,</span>        ann_file<span class="token operator">=</span><span class="token string">'balloon/val/annotation_coco.json'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    test<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>        img_prefix<span class="token operator">=</span><span class="token string">'balloon/val/'</span><span class="token punctuation">,</span>        classes<span class="token operator">=</span>classes<span class="token punctuation">,</span>        ann_file<span class="token operator">=</span><span class="token string">'balloon/val/annotation_coco.json'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment"># We can use the pre-trained Mask RCNN model to obtain higher performance</span>load_from <span class="token operator">=</span> <span class="token string">'checkpoints/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth'</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Train-amp-Test-Model"><a href="#Train-amp-Test-Model" class="headerlink" title="Train &amp; Test Model"></a>Train &amp; Test Model</h3><p>配置好了数据集过后，基本上就和 Part 1 中的训练和测试方法一样</p><p>To train a model with the new config, you can simply run</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">python tools/train.py configs/balloon/mask_rcnn_r50_caffe_fpn_mstrain-poly_1x_balloon.py<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>To test the trained model, you can simply run</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">python tools/test.py configs/balloon/mask_rcnn_r50_caffe_fpn_mstrain-poly_1x_balloon.py <span class="token punctuation">\</span>work_dirs/mask_rcnn_r50_caffe_fpn_mstrain-poly_1x_balloon.py/latest.pth <span class="token punctuation">\</span>--eval bbox segm<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h2 id="Part-3-Train-with-customized-models-and-standard-datasets"><a href="#Part-3-Train-with-customized-models-and-standard-datasets" class="headerlink" title="Part 3, Train with customized models and standard datasets"></a>Part 3, Train with customized models and standard datasets</h2><blockquote><p>In this note, you will know how to train, test and inference your own customized models under standard datasets.</p></blockquote><p>使用 cityscapes dataset 训练个性化 Cascade Mask R-CNN R50 model，使用 <a href="https://github.com/Gus-Guo/AugFPN"><code>AugFPN</code></a> 替代 <code>FPN</code> 作为 neck，并且加上 <code>Rotate</code> or <code>Translate</code> 作为数据增强</p><p>基本步骤比 Part 2 多一个准备 customized model:</p><ol><li>Prepare the standard dataset</li><li>Prepare your own customized model</li><li>Prepare a config</li><li>Train, test, and inference models on the standard dataset</li></ol><h3 id="Prepare-the-standard-dataset"><a href="#Prepare-the-standard-dataset" class="headerlink" title="Prepare the standard dataset"></a>Prepare the standard dataset</h3><p>基本流程，也是需要将 cityscapes dataset 转为 COCO format，mmdetection 也提供转化脚本 <code>tools/dataset_converters/cityscapes.py</code></p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">pip <span class="token function">install</span> cityscapesscriptspython tools/dataset_converters/cityscapes.py ./data/cityscapes --nproc <span class="token number">8</span> --out-dir ./data/cityscapes/annotations<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="Prepare-your-own-customized-model"><a href="#Prepare-your-own-customized-model" class="headerlink" title="Prepare your own customized model"></a>Prepare your own customized model</h3><h4 id="1-Define-a-new-neck-e-g-AugFPN"><a href="#1-Define-a-new-neck-e-g-AugFPN" class="headerlink" title="1. Define a new neck (e.g. AugFPN)"></a>1. Define a new neck (e.g. AugFPN)</h4><p>首先新建一个文件 <code>mmdet/models/necks/augfpn.py</code></p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> <span class="token punctuation">.</span><span class="token punctuation">.</span>builder <span class="token keyword">import</span> NECKS@NECKS<span class="token punctuation">.</span>register_module<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">AugFPN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>                in_channels<span class="token punctuation">,</span>                out_channels<span class="token punctuation">,</span>                num_outs<span class="token punctuation">,</span>                start_level<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>                end_level<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span>                add_extra_convs<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">pass</span>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment"># implementation is ignored        pass</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>注意这里用了一个装饰器，复习 python 的时候可以联系起来</p><h4 id="2-Import-the-module"><a href="#2-Import-the-module" class="headerlink" title="2. Import the module"></a>2. Import the module</h4><p>导入模块有两种方法：</p><ol><li><p>在  <code>mmdet/models/necks/__init__.py</code> 导入</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> <span class="token punctuation">.</span>augfpn <span class="token keyword">import</span> AugFPN<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li><p>在 config 文件中更改</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">custom_imports <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>    imports<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'mmdet.models.necks.augfpn.py'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    allow_failed_imports<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>这样就避免去更改原文件</p></li></ol><h4 id="3-Modify-the-config-file"><a href="#3-Modify-the-config-file" class="headerlink" title="3. Modify the config file"></a>3. Modify the config file</h4><p>将 neck 加入到 config file 中</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">neck<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>    <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'AugFPN'</span><span class="token punctuation">,</span>    in_channels<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">,</span> <span class="token number">2048</span><span class="token punctuation">]</span><span class="token punctuation">,</span>    out_channels<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span>    num_outs<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可以看出，如果想要更改别人的模型，mmdetection 都是以 config file 为核心，而不去更改原文件</p><p>如果要完成 AugFPN, Rotate, Translate 三个修改的话，在文档中给出了参考的 <a href="https://mmdetection.readthedocs.io/en/latest/3_exist_data_new_model.html#prepare-a-config">config file</a></p><h3 id="Train-amp-Test-Model-1"><a href="#Train-amp-Test-Model-1" class="headerlink" title="Train &amp; Test Model"></a>Train &amp; Test Model</h3><p>训练和测试基本使用方法在之前已经介绍过，这部分也一样</p><p>To train a model with the new config, you can simply run</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">python tools/train.py configs/cityscapes/cascade_mask_rcnn_r50_augfpn_autoaug_10e_cityscapes.py<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>To test the trained model, you can simply run</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">python tools/test.py configs/cityscapes/cascade_mask_rcnn_r50_augfpn_autoaug_10e_cityscapes.py <span class="token punctuation">\</span>work_dirs/cascade_mask_rcnn_r50_augfpn_autoaug_10e_cityscapes.py/latest.pth --eval bbox segm<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h2><h3 id="pth文件里有什么"><a href="#pth文件里有什么" class="headerlink" title=".pth文件里有什么"></a>.pth文件里有什么</h3><p>要回答一个问题，什么是 <a href="https://zhuanlan.zhihu.com/p/84797438">.pth 文件 知乎</a>，在 mmdetection 框架中可以看到 pth 文件包含了两个部分 <code>meta &amp; state_dict</code></p><p>其中 <code>meta</code> 保存了模型的配置信息，列出其 key：</p><ol><li>mmdet_version</li><li><strong>config</strong></li><li>CLASSES</li><li>epoch</li><li>iter</li><li>mmcv_version</li><li>time</li></ol><p>而 <code>state_dict</code> 保存了模型参数值，列出部分 key：</p><p>backbone.conv1.weight<br>backbone.bn1.weight<br>backbone.bn1.bias<br>backbone.bn1.running_mean<br>backbone.bn1.running_var<br>backbone.bn1.num_batches_tracked<br>backbone.layer1.0.conv1.weight<br>backbone.layer1.0.bn1.weight<br>backbone.layer1.0.bn1.bias<br>backbone.layer1.0.bn1.running_mean<br>backbone.layer1.0.bn1.running_var<br>backbone.layer1.0.bn1.num_batches_tracked</p><p>…….</p><h3 id="如何理解-Registry"><a href="#如何理解-Registry" class="headerlink" title="如何理解 Registry"></a>如何理解 Registry</h3><p>在学习 mmdetection 过程中一直又一个问题：如何使用 config + registry 返回一个 nn.Module 类的模型，这些模型是如何被注册到 Registry 类当中的？</p><p>阅读资源：</p><ol><li><p><a href="https://blog.csdn.net/sinat_29963957">mmdetection 源码阅读笔记</a></p></li><li><p><a href="https://zhuanlan.zhihu.com/p/337375549">mmdetection 整体构建流程</a></p></li><li><p><a href="https://blog.csdn.net/wulele2/article/details/114139512">mmdetection之model构建</a></p></li><li><p><a href="https://mmtracking.readthedocs.io/en/latest/">MMCV 官方文档</a>，这个文档相当有用，是 mmlab 的通用基础库，要好好学习一下</p></li><li><p><a href="https://www.cnblogs.com/hester/p/10546235.html#:~:text=Python%E4%B8%AD%E4%B8%80%E4%B8%AApy%E6%96%87%E4%BB%B6%E5%B0%B1%E6%98%AF%E4%B8%80%E4%B8%AA%E6%A8%A1%E5%9D%97%EF%BC%8C%E2%80%9C__all__%E2%80%9D%E5%8F%98%E9%87%8F%E6%98%AF%E4%B8%80%E4%B8%AA%E7%89%B9%E6%AE%8A%E7%9A%84%E5%8F%98%E9%87%8F%EF%BC%8C%E5%8F%AF%E4%BB%A5%E5%9C%A8py%E6%96%87%E4%BB%B6%E4%B8%AD%EF%BC%8C%E4%B9%9F%E5%8F%AF%E4%BB%A5%E5%9C%A8%E5%8C%85%E7%9A%84__init__.py%E4%B8%AD%E5%87%BA%E7%8E%B0%E3%80%82%20%E5%A6%82%EF%BC%9A%E5%85%A8%E5%B1%80%E5%8F%98%E9%87%8F%EF%BC%8C%E5%87%BD%E6%95%B0%EF%BC%8C%E7%B1%BB%E3%80%82%20%E5%A6%82%E4%B8%8B%EF%BC%8Ctest1.py%E5%92%8Cmain.py,%3F%20%3F%20%E4%B8%A4%E4%B8%AA%E6%96%87%E4%BB%B6%E5%9C%A8%E5%90%8C%E4%B8%80%E4%B8%AA%E7%9B%AE%E5%BD%95%E4%B8%8B%E3%80%82%20%E9%82%A3%E4%B9%88%E5%9C%A8%E6%A8%A1%E5%9D%97%E4%B8%AD%E7%9A%84__all__%E5%8F%98%E9%87%8F%E5%B0%B1%E6%98%AF%E4%B8%BA%E4%BA%86%E9%99%90%E5%88%B6%E6%88%96%E8%80%85%E6%8C%87%E5%AE%9A%E8%83%BD%E8%A2%AB%E5%AF%BC%E5%85%A5%E5%88%B0%E5%88%AB%E7%9A%84%E6%A8%A1%E5%9D%97%E7%9A%84%E5%87%BD%E6%95%B0%EF%BC%8C%E7%B1%BB%EF%BC%8C%E5%85%A8%E5%B1%80%E5%8F%98%E9%87%8F%E7%AD%89%EF%BC%8C%E5%A6%82%E6%9E%9C%E6%8C%87%E5%AE%9A%E4%BA%86%E9%82%A3%E4%B9%88%E5%8F%AA%E8%83%BD%E6%98%AF%E6%8C%87%E5%AE%9A%E7%9A%84%E9%82%A3%E4%BA%9B%E5%8F%AF%E4%BB%A5%E8%A2%AB%E5%AF%BC%E5%85%A5%EF%BC%8C%E6%B2%A1%E6%9C%89%E6%8C%87%E5%AE%9A%E9%BB%98%E8%AE%A4%E5%B0%B1%E6%98%AF%E5%85%A8%E9%83%A8%E5%8F%AF%E4%BB%A5%E5%AF%BC%E5%85%A5%EF%BC%8C%E5%BD%93%E7%84%B6%E7%A7%81%E6%9C%89%E5%B1%9E%E6%80%A7%E5%BA%94%E8%AF%A5%E9%99%A4%E5%A4%96%E3%80%82">python __all__变量</a></p></li><li>在 B 站上找到了一个官方 <a href="https://space.bilibili.com/630319191/channel/detail?cid=179690&amp;ctype=0">学习讲座系列</a>，这个讲座不太和我胃口，又在 B 站上找了一个西交的 <a href="https://www.bilibili.com/video/BV1Jb4y1r7ir?p=1">教学视频</a>，这个视频就比较友好，对我帮助更大</li></ol><p>我一直都很不理解这些类是怎么注册的，为什么有的代码似乎没有“明显”地运行，但是这些模块就已经被注册到 Registry 当中了？看完 MMCV 文档之后才大概明白了，重点就在于 <code>__init__.py</code> 文件以及 <code>__all__</code> 变量。可以看到在许多文件夹下都有 <code>__init__.py</code> 文件，例如 <code>mmdet/models/__init__.py</code>, <code>mmdet/models/backbones/__init__.py</code></p><p>如果 import 文件夹/模块下有 init.py 文件，那么就会在 import 该模块之前先运行 init.py 文件，就是在这个文件之中完成了各个模块的注册，其中 <code>__all__</code> 变量包含了需要导入的模块列表</p><p>具体看一下其中的内容</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> <span class="token punctuation">.</span>backbones <span class="token keyword">import</span> <span class="token operator">*</span>  <span class="token comment"># noqa: F401,F403</span><span class="token keyword">from</span> <span class="token punctuation">.</span>builder <span class="token keyword">import</span> <span class="token punctuation">(</span>BACKBONES<span class="token punctuation">,</span> DETECTORS<span class="token punctuation">,</span> HEADS<span class="token punctuation">,</span> LOSSES<span class="token punctuation">,</span> NECKS<span class="token punctuation">,</span>                      ROI_EXTRACTORS<span class="token punctuation">,</span> SHARED_HEADS<span class="token punctuation">,</span> build_backbone<span class="token punctuation">,</span>                      build_detector<span class="token punctuation">,</span> build_head<span class="token punctuation">,</span> build_loss<span class="token punctuation">,</span> build_neck<span class="token punctuation">,</span>                      build_roi_extractor<span class="token punctuation">,</span> build_shared_head<span class="token punctuation">)</span><span class="token keyword">from</span> <span class="token punctuation">.</span>dense_heads <span class="token keyword">import</span> <span class="token operator">*</span>  <span class="token comment"># noqa: F401,F403</span><span class="token keyword">from</span> <span class="token punctuation">.</span>detectors <span class="token keyword">import</span> <span class="token operator">*</span>  <span class="token comment"># noqa: F401,F403</span><span class="token keyword">from</span> <span class="token punctuation">.</span>losses <span class="token keyword">import</span> <span class="token operator">*</span>  <span class="token comment"># noqa: F401,F403</span><span class="token keyword">from</span> <span class="token punctuation">.</span>necks <span class="token keyword">import</span> <span class="token operator">*</span>  <span class="token comment"># noqa: F401,F403</span><span class="token keyword">from</span> <span class="token punctuation">.</span>plugins <span class="token keyword">import</span> <span class="token operator">*</span>  <span class="token comment"># noqa: F401,F403</span><span class="token keyword">from</span> <span class="token punctuation">.</span>roi_heads <span class="token keyword">import</span> <span class="token operator">*</span>  <span class="token comment"># noqa: F401,F403</span>__all__ <span class="token operator">=</span> <span class="token punctuation">[</span>    <span class="token string">'BACKBONES'</span><span class="token punctuation">,</span> <span class="token string">'NECKS'</span><span class="token punctuation">,</span> <span class="token string">'ROI_EXTRACTORS'</span><span class="token punctuation">,</span> <span class="token string">'SHARED_HEADS'</span><span class="token punctuation">,</span> <span class="token string">'HEADS'</span><span class="token punctuation">,</span> <span class="token string">'LOSSES'</span><span class="token punctuation">,</span>    <span class="token string">'DETECTORS'</span><span class="token punctuation">,</span> <span class="token string">'build_backbone'</span><span class="token punctuation">,</span> <span class="token string">'build_neck'</span><span class="token punctuation">,</span> <span class="token string">'build_roi_extractor'</span><span class="token punctuation">,</span>    <span class="token string">'build_shared_head'</span><span class="token punctuation">,</span> <span class="token string">'build_head'</span><span class="token punctuation">,</span> <span class="token string">'build_loss'</span><span class="token punctuation">,</span> <span class="token string">'build_detector'</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Bug-amp-vscode-debugger"><a href="#Bug-amp-vscode-debugger" class="headerlink" title="Bug  &amp; vscode debugger"></a>Bug  &amp; vscode debugger</h3><p>捣鼓了一天了在服务器，怎么都不能够搞好 xrdp，还差点把电脑弄出点毛病…最后用 <code>sudo dpkg --purge xrdp</code> 删除了没有下载完全的包才弄好了。我认为实验室的服务器需要一个大更新，一个是系统升级，另一个是清理内存，现在大概还有350G的空间剩余，最重要的是服务器的网络是个大问题！很多资源都无法直接下载，有些资源下载起来非常吃力</p><p>放一个 <a href="https://www.jianshu.com/p/ceb3c020e06b">nvidia-smi讲解链接</a>，理解一下各个指标是在说什么</p><h4 id="vscode-debugger"><a href="#vscode-debugger" class="headerlink" title="vscode debugger"></a>vscode debugger</h4><p>在使用 vscode debug 的时候发现有的代码并不会 step in，后来发现这些代码都是通过 pip/conda install 下载的库中的代码。而 vscode 的 debugger 会默认设定只在 ‘MyCode’ 中进行 debug，简单的说，如果不是“自己”写的代码，vscode debugger 是不会 step in 的</p><p>解决办法：在 debugger 的 json 文件中设置 <code>"justMyCode: false"</code></p><pre class="line-numbers language-json" data-language="json"><code class="language-json"><span class="token punctuation">{</span>    <span class="token comment">// Use IntelliSense to learn about possible attributes.</span>    <span class="token comment">// Hover to view descriptions of existing attributes.</span>    <span class="token comment">// For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387</span>    <span class="token property">"version"</span><span class="token operator">:</span> <span class="token string">"0.2.0"</span><span class="token punctuation">,</span>    <span class="token property">"configurations"</span><span class="token operator">:</span> <span class="token punctuation">[</span>        <span class="token punctuation">{</span>            <span class="token property">"name"</span><span class="token operator">:</span> <span class="token string">"Python: Current File"</span><span class="token punctuation">,</span>            <span class="token property">"type"</span><span class="token operator">:</span> <span class="token string">"python"</span><span class="token punctuation">,</span>            <span class="token property">"request"</span><span class="token operator">:</span> <span class="token string">"launch"</span><span class="token punctuation">,</span>            <span class="token property">"program"</span><span class="token operator">:</span> <span class="token string">"${file}"</span><span class="token punctuation">,</span>            <span class="token property">"console"</span><span class="token operator">:</span> <span class="token string">"integratedTerminal"</span><span class="token punctuation">,</span>            <span class="token comment">// add the next line into your .json file</span>            <span class="token property">"justMyCode"</span><span class="token operator">:</span> <span class="token boolean">false</span>        <span class="token punctuation">}</span>    <span class="token punctuation">]</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h2><ol><li><p>还需要整理 MMCV 以了解整个 OpenMMLab 的运行逻辑 </p></li><li><p>对于如何训练自己的网络还要继续看文档中的 Tutorial 部分</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 编程 </category>
          
          <category> OpenMMLab </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MMDetection </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>安装 MMDetection 笔记</title>
      <link href="/archives/54605061.html"/>
      <url>/archives/54605061.html</url>
      
        <content type="html"><![CDATA[<h1 id="安装-MMDetection-笔记"><a href="#安装-MMDetection-笔记" class="headerlink" title="安装 MMDetection 笔记"></a>安装 MMDetection 笔记</h1><p>想法：通过这种标准化的算法框架，来进行组合实验</p><p>但是目前 SE-SSD 没有支持，可以尝试组合一下</p><h2 id="OpenMMLab"><a href="#OpenMMLab" class="headerlink" title="OpenMMLab"></a>OpenMMLab</h2><p>官网：<a href="https://openmmlab.com/">https://openmmlab.com/</a></p><p>github: <a href="https://github.com/open-mmlab">https://github.com/open-mmlab</a></p><p>子项目官方文档：<a href="https://mmdetection.readthedocs.io/zh_CN/latest/">MMDetection</a> <a href="https://mmdetection3d.readthedocs.io/zh_CN/latest/index.html">MMDetection3D</a></p><p>什么是 OpenMMLab？什么是 MMDdetction？</p><blockquote><p>OpenMMLab 是一个计算机视觉开源算法体系和框架，涉及超过10种研究方向，开放超过100种算法、800种预训练模型</p><p>MMDetection is an open source object detection toolbox based on PyTorch. It is a part of the OpenMMLab project.</p></blockquote><h2 id="安装环境"><a href="#安装环境" class="headerlink" title="安装环境"></a>安装环境</h2><p>我打算先熟悉 MMDetection，因为这个项目在 github 上 star 是相对较多的，然后再进一步学习 mmdetection 3D，下面来安装 MMDetection 环境</p><p>首先看看依赖的要求</p><ul><li>Linux 和 macOS （Windows 理论上支持）</li><li>Python 3.6+</li><li>PyTorch 1.3+</li><li>CUDA 9.2+ （如果基于 PyTorch 源码安装，也能够支持 CUDA 9.0）</li><li>GCC 5+</li><li><a href="https://mmcv.readthedocs.io/en/latest/#installation">MMCV</a></li></ul><p>之后下载的依赖版本参考要求来</p><ol><li><p>创建 conda 环境 <code>conda create -n mmlab python=3.7</code></p></li><li><p>安装 pytorch</p><p>在 <a href="https://pytorch.org/get-started/previous-versions/">pytorch previous versions</a> 中查找你想要的版本，我选择如下</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">conda <span class="token function">install</span> <span class="token assign-left variable">pytorch</span><span class="token operator">==</span><span class="token number">1.5</span>.1 <span class="token assign-left variable">torchvision</span><span class="token operator">==</span><span class="token number">0.6</span>.1 <span class="token assign-left variable">cudatoolkit</span><span class="token operator">=</span><span class="token number">10.1</span> -c pytorch<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>此时查看我的电脑上安装的 CUDA 版本，使用命令 <code>nvcc -V</code></p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">nvcc: NVIDIA <span class="token punctuation">(</span>R<span class="token punctuation">)</span> Cuda compiler driverCopyright <span class="token punctuation">(</span>c<span class="token punctuation">)</span> <span class="token number">2005</span>-2018 NVIDIA CorporationBuilt on Sat_Aug_25_21:08:01_CDT_2018Cuda compilation tools, release <span class="token number">10.0</span>, V10.0.130<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>该版本为 10.0 和 cudatoolkit 的 10.1 版本并不一样，那么 pytorch 究竟是使用哪个版本呢？答案是使用 10.0 的版本，需要更改一下环境 CUDA_HOME 环境变量。更多的信息，请阅读补充笔记</p></li></ol><h2 id="安装-MMDetection"><a href="#安装-MMDetection" class="headerlink" title="安装 MMDetection"></a>安装 MMDetection</h2><p>官方推荐使用 <a href="https://github.com/open-mmlab/mim">MIM</a> 安装 MMDetection</p><blockquote><p>MIM provides a unified interface for launching and installing OpenMMLab projects and their extensions, and managing the OpenMMLab model zoo.</p></blockquote><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">pip <span class="token function">install</span> openmimmim <span class="token function">install</span> mmdet<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>MIM 自动下载了 mmdet 及其对应依赖</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token comment"># mim list</span>Package    Version    Source---------  ---------  -----------------------------------------mmcv-full  <span class="token number">1.3</span>.10     https://github.com/open-mmlab/mmcvmmdet      <span class="token number">2.15</span>.0     https://github.com/open-mmlab/mmdetection<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h2><p>将 MMDetection 仓库克隆到本地，运行如下代码</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> mmdet<span class="token punctuation">.</span>apis <span class="token keyword">import</span> inference_detector<span class="token punctuation">,</span> init_detectorconfig_file <span class="token operator">=</span> <span class="token string">'configs/faster_rcnn/faster_rcnn_r50_fpn_1x_coco.py'</span><span class="token comment"># 从 model zoo 下载 checkpoint 并放在 `checkpoints/` 文件下</span><span class="token comment"># 网址为: http://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth</span>checkpoint_file <span class="token operator">=</span> <span class="token string">'checkpoints/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth'</span>device <span class="token operator">=</span> <span class="token string">'cuda:0'</span><span class="token comment"># 初始化检测器</span>model <span class="token operator">=</span> init_detector<span class="token punctuation">(</span>config_file<span class="token punctuation">,</span> checkpoint_file<span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span><span class="token comment"># 推理演示图像</span>img <span class="token operator">=</span> <span class="token string">'demo/demo.jpg'</span>result <span class="token operator">=</span> inference_detector<span class="token punctuation">(</span>model<span class="token punctuation">,</span> img<span class="token punctuation">)</span><span class="token comment"># 绘制结果图</span>model<span class="token punctuation">.</span>show_result<span class="token punctuation">(</span>img<span class="token punctuation">,</span> result<span class="token punctuation">,</span> wait_time<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="补充：Pytorch-amp-CUDA"><a href="#补充：Pytorch-amp-CUDA" class="headerlink" title="补充：Pytorch &amp; CUDA"></a>补充：Pytorch &amp; CUDA</h2><h3 id="CUDA-amp-CUDA-toolkit-amp-pytorch-install-with-conda"><a href="#CUDA-amp-CUDA-toolkit-amp-pytorch-install-with-conda" class="headerlink" title="CUDA &amp; CUDA toolkit &amp; pytorch install with conda"></a>CUDA &amp; CUDA toolkit &amp; pytorch install with conda</h3><p>conda 在安装 Pytorch 等会使用到 CUDA 的框架时，会自动为用户安装 cudatoolkit，其主要包含应用程序在使用 CUDA 相关的功能时所依赖的动态链接库。在安装了 cudatoolkit 后，只要系统上存在与当前的 cudatoolkit 所兼容的 Nvidia 驱动，则已经编译好的 CUDA 相关的程序就可以直接运行，而不需要安装完整的 Nvidia 官方提供的 CUDA Toolkit </p><p>经过自己的实验，环境中的 CUDA_HOME 变量是清空的，而且也没有设置 /usr/local/cuda 软链接，但是 pytorch 依然能够调用 GPU，说明只需要你的 Nvidia Driver 和 conda install cudatoolkit 兼容，那么就不需要从 Nvidia 官网中下载完整的 CUDA Toolkit</p><p>综上 Pytorch 查找 cuda 路径顺序为：</p><ol><li><p>先查找环境变量中是否存在 CUDA_PATH / CUDA_HOME 如有则使用该路径指向的 CUDA 版本。其中 CUDA_PATH 为 windows 环境变量，CUDA_HOME 为 Linux 环境变量</p></li><li><p>若找不到 CUDA_HOME，则查看 usr/local/cuda 是否存在，若存在则使用该路径指向的 CUDA 版本</p></li><li><p>若两个路径都不存在，则使用 conda 下载的 cudatoolkit，也即下载 pytorch 时自动下载的 cudatoolkit</p></li></ol><p>推荐 <a href="https://www.cnblogs.com/yhjoker/p/10972795.html">参考链接</a> 进行深入了解</p>]]></content>
      
      
      <categories>
          
          <category> 编程 </category>
          
          <category> OpenMMLab </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MMDetection </tag>
            
            <tag> 安装教程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>猫头鹰先生催眠录音文本</title>
      <link href="/archives/11812369.html"/>
      <url>/archives/11812369.html</url>
      
        <content type="html"><![CDATA[<p><a href="https://www.bilibili.com/video/BV16f4y1S72h">bilibili link</a></p><p>my name is Mr. Owl</p><p>I will shortly lead you through a guided hypnosis</p><p>please don’t listen to this while driving or operating machinery</p><p>you may also want to have a glass of water nearby</p><p>it can help ground you after a recession</p><p>I would like you to start by simply lying down in a comfortable position </p><p>perhaps on some cushions</p><p>or on a couch</p><p>and just take a few moments to relax your mind</p><p>(a moment …)</p><p>in a moment</p><p>I’m going to ask you to imagine a place</p><p>a special place</p><p>you may see it</p><p>feel it</p><p>imagine it or experience it</p><p>in any way you want</p><p>and you might find your mind wondering quite a bit</p><p>but that doesn’t matter to you</p><p>the sound of my voice will continue to relax you</p><p>and it doesn’t matter if you don’t hear a word I say</p><p>because very soon now</p><p>you are going to be relaxed</p><p>more than you have ever known</p><p>imagine now that you are in that place</p><p>that place you know well</p><p>a hotel by a lake</p><p>and you are here </p><p>at the top of a gorgeous staircase</p><p>in a large open hallway</p><p>a really beautiful old hotel</p><p>it’s such a comfortable temperature here</p><p>daylight streams in through the window</p><p>slightly warm</p><p>such a peaceful place to be</p><p>and at the bottom of those stairs</p><p>an open doorway</p><p>leading to a garden</p><p>in a few moments</p><p>I will count</p><p>from 1 to 10</p><p>and count you down each step</p><p>let each number</p><p>represent a step</p><p>and each step takes you deeper and deeper</p><p>into relaxation</p><p>so that by the time I get to ten</p><p>you can allow yourself</p><p>to be as deeply relaxed</p><p>as you ever can be</p><p>and you’ll still hear</p><p>the sound of my voice</p><p>and as you look down</p><p>you can glimpse</p><p>through the open door</p><p>that intriguing garden</p><p>it’s so interesting to you</p><p>to explore and discover</p><p>this special place</p><p>the sunlight to the windows on your skin</p><p>there’s no one around</p><p>that needs anything from you</p><p>no one around</p><p>to bother you</p><p>1</p><p>when you are ready</p><p>take your first step now</p><p>relaxing letting go</p><p>2</p><p>take another step</p><p>feeling more at ease</p><p>and at peace with yourself</p><p>3</p><p>perhaps noticing</p><p>heavy</p><p>restful feeling</p><p>spreading down your legs</p><p>with every step</p><p>4</p><p>just drifting deeper</p><p>and deeper down</p><p>5</p><p>another step</p><p>becoming calmer</p><p>and even calmer still</p><p>continuing to relax</p><p>continuing to let go</p><p>and feeling so good</p><p>6</p><p>perhaps beginning to notice</p><p>any sounds becoming part of your experience of comfort</p><p>relaxation</p><p>and anything you notice</p><p>becoming part of your experience</p><p>7</p><p>sinking deeper and deeper</p><p>drifting</p><p>further</p><p>into this welcoming</p><p>relaxed state</p><p>8</p><p>enjoying those feelings</p><p>half awake</p><p>half asleep</p><p>9</p><p>noticing way of growing relaxation</p><p>and spreading comfort</p><p>10</p><p>an now</p><p>at the bottom of the stairs</p><p>and wandering through that open door</p><p>how into the gardon beyond</p><p>soak up those feelings of</p><p>tranquility</p><p>see</p><p>hear</p><p>feel sense or imagine this</p><p>beautiful garden</p><p>the greens</p><p>the flowers</p><p>the trees</p><p>the brown</p><p>the clear blue sky</p><p>feel the warmth of the sun</p><p>on your head and shoulders</p><p>enjoy a moment here</p><p>and peace</p><p>inhale the sense of the garden</p><p>there is no one around</p><p>wanting anything from you</p><p>needing anything from you</p><p>no one expecting anything</p><p>so enjoy this</p><p>peace</p><p>and quiet</p><p>for a few moments more</p><p>notice now</p><p>at the end of this garden</p><p>a set of steps</p><p>leading down to a sturdy pier</p><p>at the edge of lake</p><p>so now</p><p>take the steps now</p><p>sinking further and further into relaxation</p><p>as you do</p><p>more and more relaxed with each step</p><p>until you step onto the wooden pier</p><p>then stepping forward</p><p>towards that beautiful crystal blue water</p><p>the sun on your skin</p><p>and gentle breeze</p><p>and here</p><p>at the end of the pier</p><p>a fishing rod</p><p>You take it in your hand</p><p>feel a comforting weight of it</p><p>not too heavy to hold</p><p>but you know that it’s strong and sturdy</p><p>it will not struggle with the weight of today’s catch</p><p>slowly and deliberately</p><p>you unravel some of the line</p><p>you pull back the rod</p><p>and cast that line into that crystal</p><p>clear</p><p>blue water</p><p>it sits in that water for a moment</p><p>and soon you feel a gentle pull on the fishing rod</p><p>you’ve caught something</p><p>you gently crank back the handle</p><p>pulling your catch out of the water</p><p>what have you caught</p><p>it’s a white cube</p><p>so square and perfect on every side</p><p>a little water drips from it</p><p>as you gently swing it back onto the pier beside you</p><p>you lower the fishing rod to your side</p><p>and you take</p><p>the white cube from the line</p><p>what’s inside this cube</p><p>it’s a memory</p><p>a good memory</p><p>a memory from your life</p><p>a memory of a time when you were happy</p><p>and strong</p><p>and confident</p><p>you pick up the cube</p><p>you hold it close to your face</p><p>and now you can see this memory</p><p>you see it in a vivid wide screen</p><p>The colors are rich</p><p>the image is bright</p><p>the sound is clear and strong and vibrant</p><p>so strong and vibrant that you step into this memory</p><p>you are inside</p><p>let those feelings grow inside you</p><p>feeling happy and strong and confident and bright</p><p>take a moment to enjoy this</p><p>to live in it</p><p>to breathe</p><p>this beautiful positive memory from the white cube</p><p>feeling strong and confident</p><p>and bright and happy</p><p>now</p><p>slowly</p><p>and with care</p><p>you move out of the memory</p><p>and you lower the cube</p><p>from in front of your face</p><p>and se t it down gently on the pier beside you</p><p>take a moment now</p><p>look out</p><p>onto the lake</p><p>at the cool blue water</p><p>the peace</p><p>tranquility of it</p><p>you kneel down and lower the white cube</p><p>into the peaceful water</p><p>and as the ripples slow and stop</p><p>you catch sight of your own reflection</p><p>and you see how beautiful you are</p><p>how strong you are</p><p>you can see positivity in your eye</p><p>like jewels</p><p>you stand and look out at that lake</p><p>calm serene and full of power</p><p>breathe it in gently</p><p>and then breathe it out gently</p><p>all that power that’s within you</p><p>I let you enjoy those feelings for a few moments more</p><p>allow you time to bask in that life</p><p>but soon</p><p>soon I’ll start count from one up to five</p><p>when I reach five</p><p>you will be back in the room</p><p>1</p><p>starting to come back</p><p>become aware of your breathing</p><p>your body and the space around you</p><p>2</p><p>moving your legs start to wiggle your toes and feet</p><p>a lovely grounding energy, traveling up your legs</p><p>3</p><p>moving your arms starting to stretch, feel the energy moving through your body again</p><p>4 </p><p>your eyes starting to open</p><p>And on the next count your eyes fully open </p><p>5</p><p>eyes fully open, feeling refreshed and recharged and being fully aware of being in the space</p><p>welcome back</p>]]></content>
      
      
      <categories>
          
          <category> 生活 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 睡眠 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>校友访谈(纪录片)培训</title>
      <link href="/archives/c8ed5799.html"/>
      <url>/archives/c8ed5799.html</url>
      
        <content type="html"><![CDATA[<h1 id="校友访谈-纪录片-培训"><a href="#校友访谈-纪录片-培训" class="headerlink" title="校友访谈(纪录片)培训"></a>校友访谈(纪录片)培训</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><ol><li><p>认识纪录片和口述史</p><p>什么是真实，什么是好的纪录片</p></li><li><p>没有绝对的真实，让故事有逻辑，人物有发展，让观众感到真实，是一个好的纪录片的条件</p></li></ol><h2 id="前期调研"><a href="#前期调研" class="headerlink" title="前期调研"></a>前期调研</h2><ol><li>个人维度：生平，行业信息，突出成就，家庭情况</li><li>历史维度：经历过哪些重大的历史事件，与其他人物在历史上的交集</li><li>事件叙述：起因，过程，结果，历史意义</li><li>最终形成一个人物小传</li></ol><h3 id="案例分享《南大创业者的时代脉搏》"><a href="#案例分享《南大创业者的时代脉搏》" class="headerlink" title="案例分享《南大创业者的时代脉搏》"></a>案例分享《南大创业者的时代脉搏》</h3><h2 id="故事撰写"><a href="#故事撰写" class="headerlink" title="故事撰写"></a>故事撰写</h2><ol><li>一句话概括你的故事 logline</li><li>故事的介绍与结构，关于影片的故事结构，开头、过程、结尾、重要节点</li><li>人物的塑造需要有成长，有套路，从平凡到不平凡的循环过程</li></ol><h2 id="撰写采访问题"><a href="#撰写采访问题" class="headerlink" title="撰写采访问题"></a>撰写采访问题</h2><ol><li>撰写问题按照时间线的顺序，帮助被采访人回忆</li><li>有必须完成的固定动作：重要历程的回顾，重要时间点的讲述，关于主题的必然联系，所有人都希望被理解、被尊重</li><li><p>固定动作之外的惊喜问题：有一些尖锐深刻的话题，在心里拟定好，在现场找点切入</p></li><li><p>多人物采访时的问题思路：采访者之间的共性、特性问题，以及相应的惊喜问题</p></li></ol><h2 id="确定视觉与文字展现形式"><a href="#确定视觉与文字展现形式" class="headerlink" title="确定视觉与文字展现形式"></a>确定视觉与文字展现形式</h2><ol><li>阐述式：有旁白、有采访</li><li>观察式：观察人物</li><li>参与式：类似于 互动vlog</li><li>扮演式：找演员扮演</li><li>资料式：用资料和人物还原</li><li>动画纪录片</li></ol><p>阐述 + 资料为常见组合</p><h2 id="现场拍摄"><a href="#现场拍摄" class="headerlink" title="现场拍摄"></a>现场拍摄</h2><p>摄像机、三脚架、话筒、灯</p><p>注意事项：</p><ol><li>受访者知晓拍摄内容、用途、签文件</li><li>调整环境，让受访者感到舒适，但同时可能需要牺牲画质</li><li>开始前先聊聊家常，同时调整声音和构图，调整画面水平</li><li>采访时，一定不要打断受访者，始终保持眼神交流，不要使用语气词“嗯，啊”之类的</li><li>随即调整采访的顺序</li></ol><h2 id="跟拍"><a href="#跟拍" class="headerlink" title="跟拍"></a>跟拍</h2><ol><li>镜头稳定</li><li>镜头表现</li><li>素材保管，一定要双备份，甚至三备份！因为素材是很“贵”的，不要用剪切！</li><li>保持“记录感”，让镜头持续开机，有比没有强</li></ol><h2 id="Transcription-amp-paper-cut"><a href="#Transcription-amp-paper-cut" class="headerlink" title="Transcription &amp; paper cut"></a>Transcription &amp; paper cut</h2><ol><li>将视频中的文字对话导出</li><li>完成影片脚本，这个脚本是剪辑的根据与逻辑</li></ol><h2 id="剪辑与后期"><a href="#剪辑与后期" class="headerlink" title="剪辑与后期"></a>剪辑与后期</h2><ol><li>剪辑主要故事线</li><li>增加资料、素材、特效包装</li><li>声音制作、调色</li></ol>]]></content>
      
      
      <categories>
          
          <category> 生活 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 纪录片 </tag>
            
            <tag> 培训 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Conda 笔记</title>
      <link href="/archives/c8895fc.html"/>
      <url>/archives/c8895fc.html</url>
      
        <content type="html"><![CDATA[<h1 id="Conda-Cheat-Sheet"><a href="#Conda-Cheat-Sheet" class="headerlink" title="Conda Cheat Sheet"></a>Conda Cheat Sheet</h1><p>记录一些常用的 conda 命令帮助快速管理环境，整理自官方 <a href="https://docs.conda.io/projects/conda/en/4.6.0/_downloads/52a95608c49671267e40c689e0bc00ca/conda-cheatsheet.pdf">CONDA CHEAT SHEET</a></p><h2 id="Basic"><a href="#Basic" class="headerlink" title="Basic"></a>Basic</h2><h3 id="conda-info"><a href="#conda-info" class="headerlink" title="conda info"></a>conda info</h3><p>这个命令非常管用，基本上能够看到所有的 conda 配置信息</p><h3 id="conda-install"><a href="#conda-install" class="headerlink" title="conda install"></a>conda install</h3><p><code>conda install PACKAGENAME</code> 下载指定包</p><h3 id="conda-update"><a href="#conda-update" class="headerlink" title="conda update"></a>conda update</h3><p><code>conda update PACKAGENAME</code> 更新指定包 </p><h2 id="Environment"><a href="#Environment" class="headerlink" title="Environment"></a>Environment</h2><h3 id="conda-create-n"><a href="#conda-create-n" class="headerlink" title="conda create -n"></a>conda create -n</h3><p><code>conda create -n py36 python=3.6</code> 创造一个 python 3.6 的环境 py36</p><p>注意：一般都要加上 <code>python=x.x</code> 否则使用的是 base 环境的 python 解释器</p><h3 id="conda-env-list"><a href="#conda-env-list" class="headerlink" title="conda env list"></a>conda env list</h3><p>列出目前有的环境</p><h3 id="conda-env-remove"><a href="#conda-env-remove" class="headerlink" title="conda env remove"></a>conda env remove</h3><p><code>conda env remove -n env_name</code> 移除环境</p><h3 id="conda-activate-deactivate"><a href="#conda-activate-deactivate" class="headerlink" title="conda activate/deactivate"></a>conda activate/deactivate</h3><p><code>conda activate/deactivate env_name</code> 激活/退出环境</p><h2 id="Package"><a href="#Package" class="headerlink" title="Package"></a>Package</h2><h3 id="conda-install-1"><a href="#conda-install-1" class="headerlink" title="conda install"></a>conda install</h3><p><code>conda install PACKAGENAME</code> 下载包</p><p><code>conda install --file requirements.txt</code> 通过 requirements 文件下载包</p><h3 id="conda-remove"><a href="#conda-remove" class="headerlink" title="conda remove"></a>conda remove</h3><p><code>conda remove PACKAGENAME</code> 移除包</p><h3 id="conda-list"><a href="#conda-list" class="headerlink" title="conda list"></a>conda list</h3><p><code>conda list PACKAGENAME</code> 查看环境的某个包，如果不加 PACKAGENAME 则列出所有环境</p><h3 id="conda-clean"><a href="#conda-clean" class="headerlink" title="conda clean"></a>conda clean</h3><p>如果不清理的话，anaconda 还是很吃存储的，会逐渐积累很多下载包</p><p><code>conda clean --all</code>  Remove index cache, lock files, unused cache packages, and tarballs.</p><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><h3 id="禁用自动启动-base-环境"><a href="#禁用自动启动-base-环境" class="headerlink" title="禁用自动启动 base 环境"></a>禁用自动启动 base 环境</h3><p>每次打开新的 shell 都会自动进入 base 环境，用下面的命令行禁用</p><p><code>conda config --set auto_activate_base false</code></p><h3 id="镜像源设置"><a href="#镜像源设置" class="headerlink" title="镜像源设置"></a>镜像源设置</h3><p>编辑 <code>~/.condarc</code> 文件，设置镜像源，如没有该文件可使用 <code>conda config</code> 创建</p><p><a href="https://mirror.nju.edu.cn/help/anaconda">南京大学镜像源官方帮助文档</a></p><pre class="line-numbers language-.condarc" data-language=".condarc"><code class="language-.condarc">channels:  - defaultsshow_channel_urls: truedefault_channels:  - https://mirror.nju.edu.cn/anaconda/pkgs/main  - https://mirror.nju.edu.cn/anaconda/pkgs/r  - https://mirror.nju.edu.cn/anaconda/pkgs/msys2custom_channels:  conda-forge: https://mirror.nju.edu.cn/anaconda/cloud  msys2: https://mirror.nju.edu.cn/anaconda/cloud  bioconda: https://mirror.nju.edu.cn/anaconda/cloud  menpo: https://mirror.nju.edu.cn/anaconda/cloud  pytorch: https://mirror.nju.edu.cn/anaconda/cloud  simpleitk: https://mirror.nju.edu.cn/anaconda/cloud<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>当然也可以使用其他镜像源，例如：<a href="https://mirrors.bfsu.edu.cn/help/anaconda/">北京外国语大学镜像源</a> 速度也很快</p><p>同时也更新一下 pypi 源</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token comment"># 先更新 pip</span>pip <span class="token function">install</span> pip -U<span class="token comment"># Linux</span>pip <span class="token function">install</span> pip -U --user<span class="token comment"># Windows</span><span class="token comment"># 设置镜像</span>pip config <span class="token builtin class-name">set</span> global.index-url https://mirror.nju.edu.cn/pypi/web/simple<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>]]></content>
      
      
      <categories>
          
          <category> 编程 </category>
          
          <category> Tools </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Conda </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Manim 教程</title>
      <link href="/archives/5654e2fe.html"/>
      <url>/archives/5654e2fe.html</url>
      
        <content type="html"><![CDATA[<h1 id="Manim-note"><a href="#Manim-note" class="headerlink" title="Manim note"></a>Manim note</h1><p>官方 <a href="https://github.com/3b1b/manim">github 项目</a></p><blockquote><p>Note, there are two versions of manim. This repository began as a personal project by the author of <a href="https://www.3blue1brown.com/">3Blue1Brown</a> for the purpose of animating those videos, with video-specific code available <a href="https://github.com/3b1b/videos">here</a>. In 2020 a group of developers forked it into what is now the <a href="https://github.com/ManimCommunity/manim/">community edition</a>, with a goal of being more stable, better tested, quicker to respond to community contributions, and all around friendlier to get started with. See <a href="https://docs.manim.community/en/stable/installation/versions.html?highlight=OpenGL#which-version-to-use">this page</a> for more details.</p></blockquote><p>这里提到有两个版本的 manim，推荐使用 community edition，这个版本更稳定，更容易上手，下面是两个参考链接</p><ol><li><p><a href="https://github.com/ManimCommunity/manim/">ManimCE github</a></p></li><li><p><a href="https://www.manim.community/">ManimCE documentation</a></p></li></ol><p>强烈推荐根据官方文档进行学习，因为网上的很多资源都是过时的，包括我这篇笔记也会可能会很快过时。这篇笔记主要记录如何安装 ManimCE，以及其代码逻辑，更多实用的动画方法另外再做整理</p><h2 id="Install"><a href="#Install" class="headerlink" title="Install"></a>Install</h2><h3 id="Install-dependencies"><a href="#Install-dependencies" class="headerlink" title="Install dependencies"></a>Install dependencies</h3><p>官方给出了一个<a href="https://hub.gke2.mybinder.org/user/behackl-725d956-b7bf9b4aef40b78-cns6ckcq/notebooks/basic%20example%20scenes.ipynb"> jupyter notebook</a> 预先装载好了 manim 环境，如果你现在不想安装的话，可以在这个 notebook 里面进行小实验</p><p>ManimCE 需要预先下载两个软件 ffmpeg 和 LaTex。文档中建议使用 Scoop, Chocolatey 等包管理软件来下载 dependencies，但我太懒了，不想再下一个包管理软件，而且我自己的电脑上本来就安装了 LaTex 和 ffmpeg 所以只要确保 ManimCE  能够调用这些 dependencies 即可，具体来说就是让 ffmpeg 和 LaTex 命令加入环境变量</p><p>给两个参考链接：<a href="https://zhuanlan.zhihu.com/p/118362010">ffmpeg 知乎教程</a>  <a href="https://www.bilibili.com/video/BV11h41127FD?from=search&amp;seid=5330798070960440671">LaTex简介 bilibili</a></p><p>最后在命令行窗口输入 <code>ffmpeg -version</code> 和  <code>tex -version</code> 检查看看能否成功运行</p><h3 id="Install-ManimCE"><a href="#Install-ManimCE" class="headerlink" title="Install ManimCE"></a>Install ManimCE</h3><blockquote><p>Manim Community runs on Python 3.7+. If you’d like to just use the library, you can install it from PyPI via pip:</p></blockquote><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">pip <span class="token function">install</span> manim<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>因为习惯了用 conda，所以我选择在 conda 中创建一个 Manim 环境，然后再 pip install</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">conda create -n manim <span class="token assign-left variable">python</span><span class="token operator">=</span><span class="token number">3.8</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>(然而最终却稀里糊涂的安装在了 base 环境)</p><p>使用 <code>conda list manim</code> 检查是否安装成功，通过 <a href="https://docs.manim.community/en/stable/tutorials/quickstart.html">Quickstart</a> 简单运行一个程序，检查整个流程是否能够运行</p><h2 id="Tutorials"><a href="#Tutorials" class="headerlink" title="Tutorials"></a>Tutorials</h2><h3 id="Quickstart"><a href="#Quickstart" class="headerlink" title="Quickstart"></a>Quickstart</h3><p>下面是一段简单的代码，能够实现从矩形到圆形的变换</p><p><img src="/archives/5654e2fe/SquareToCircle_ManimCE_v0.8.0.gif" alt="SquareToCircle_ManimCE_v0.8.0" style="zoom: 25%;"></p><p>代码如下</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># scene.py</span><span class="token keyword">from</span> manim <span class="token keyword">import</span> <span class="token operator">*</span><span class="token keyword">class</span> <span class="token class-name">SquareToCircle</span><span class="token punctuation">(</span>Scene<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">construct</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        circle <span class="token operator">=</span> Circle<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># create a circle</span>        circle<span class="token punctuation">.</span>set_fill<span class="token punctuation">(</span>PINK<span class="token punctuation">,</span> opacity<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span>  <span class="token comment"># set color and transparency</span>        square <span class="token operator">=</span> Square<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># create a square</span>        square<span class="token punctuation">.</span>rotate<span class="token punctuation">(</span>PI <span class="token operator">/</span> <span class="token number">4</span><span class="token punctuation">)</span>  <span class="token comment"># rotate a certain amount</span>        self<span class="token punctuation">.</span>play<span class="token punctuation">(</span>Create<span class="token punctuation">(</span>square<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># animate the creation of the square</span>        self<span class="token punctuation">.</span>play<span class="token punctuation">(</span>Transform<span class="token punctuation">(</span>square<span class="token punctuation">,</span> circle<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># interpolate the square into the circle</span>        self<span class="token punctuation">.</span>play<span class="token punctuation">(</span>FadeOut<span class="token punctuation">(</span>square<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># fade out animation</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>在 terminal 中执行文件</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">manim -pql scene.py SquareToCircle<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>从上面的代码能够看出 Manim 的一些基本框架，首先要有 class 类别作为场景 Scene，在这个 class 中定义 construct() 函数来实现动画效果，然后通过命令行渲染出动画。文档中提到的 Tip:</p><blockquote><p>Every animation must be contained within the <a href="https://docs.manim.community/en/stable/reference/manim.scene.scene.Scene.html#manim.scene.scene.Scene.construct"><code>construct()</code></a> method of a class that derives from <a href="https://docs.manim.community/en/stable/reference/manim.scene.scene.Scene.html#manim.scene.scene.Scene"><code>Scene</code></a>. Other code, for example auxiliary or mathematical functions, may reside outside the class.</p></blockquote><h3 id="A-deeper-look"><a href="#A-deeper-look" class="headerlink" title="A deeper look"></a>A deeper look</h3><p>主要来分析一下上面的命令</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">manim -pql scene.py SquareToCircle<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>文档中解释</p><blockquote><p>First, this command executes manim on the file <code>scene.py</code>, which contains our animation code. Further, this command tells manim exactly which <code>Scene</code> is to be rendered, in this case, it is <code>SquareToCircle</code>. This is necessary because a single scene file may contain more than one scene. Next, the flag -p tells manim to play the scene once it’s rendered, and the -ql flag tells manim to render the scene in low quality.</p></blockquote><p>下面是几个常见的参数：</p><ol><li><code>-ql, -qm, -qh, -qk</code> 分别代表不同分辨率，从低到高，再到4k</li><li><code>-a</code> 渲染所有的 Scene</li><li><code>-i</code> 输出为 gif 格式</li><li><code>-f</code> 渲染完成后打开所在文件夹</li></ol><h3 id="Manim’s-building-blocks"><a href="#Manim’s-building-blocks" class="headerlink" title="Manim’s building blocks"></a>Manim’s building blocks</h3><p>Manim 中有3个重要概念</p><ol><li><strong>mathematical object</strong> (or <strong>mobject</strong> for short)</li><li><strong>animation</strong></li><li><strong>scene</strong>.</li></ol><blockquote><p>As we will see in the following sections, each of these three concepts is implemented in manim as a separate class: the <a href="https://docs.manim.community/en/stable/reference/manim.mobject.mobject.Mobject.html#manim.mobject.mobject.Mobject"><code>Mobject</code></a>, <a href="https://docs.manim.community/en/stable/reference/manim.animation.animation.Animation.html#manim.animation.animation.Animation"><code>Animation</code></a>, and <a href="https://docs.manim.community/en/stable/reference/manim.scene.scene.Scene.html#manim.scene.scene.Scene"><code>Scene</code></a> classes.</p></blockquote><h4 id="Mobject"><a href="#Mobject" class="headerlink" title="Mobject"></a>Mobject</h4><blockquote><p>Any object that can be displayed on the screen is a <code>mobject</code>, even if it is not necessarily <em>mathematical</em> in nature.</p></blockquote><p>通过 scene 类中的方法 add(), remove() 来在场景中加入 mobject</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> manim <span class="token keyword">import</span> <span class="token operator">*</span><span class="token keyword">class</span> <span class="token class-name">CreatingMobjects</span><span class="token punctuation">(</span>Scene<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">construct</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        circle <span class="token operator">=</span> Circle<span class="token punctuation">(</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>add<span class="token punctuation">(</span>circle<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>wait<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>remove<span class="token punctuation">(</span>circle<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>wait<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>对于 mobject 属性的调整，是通过调 mobject 类的方法来完成</p><ol><li><p>Placing mobject location. 选择在哪里加入物体</p><p>.shift()  .move_to()  .next_to()  .align_to()</p></li><li><p>Styling mobjects. 对物体进行风格渲染</p><p>.set_stroke()  .set_fill()</p></li><li><p>Mobject on-screen order. 添加入场景的 mobject 是有顺序的，后添加的物体会覆盖到图层的上方</p></li></ol><h4 id="Animation"><a href="#Animation" class="headerlink" title="Animation"></a>Animation</h4><blockquote><p>At the heart of manim is animation. Generally, you can add an animation to your scene by calling the <code>play()</code> method.</p></blockquote><p>一般来讲通过 play() 方法来加入动画</p><blockquote><p>Animations are procedures that interpolate between two mobjects.</p></blockquote><p>动画的基本原理可以理解为，使用不同的函数在两个关键帧之间进行插值，然后使用 play() 方法进行播放，比如在 Quickstart 中的动画</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">self<span class="token punctuation">.</span>play<span class="token punctuation">(</span>Create<span class="token punctuation">(</span>square<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># animate the creation of the square</span>self<span class="token punctuation">.</span>play<span class="token punctuation">(</span>Transform<span class="token punctuation">(</span>square<span class="token punctuation">,</span> circle<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># interpolate the square into the circle</span>self<span class="token punctuation">.</span>play<span class="token punctuation">(</span>FadeOut<span class="token punctuation">(</span>square<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># fade out animation</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>只要可变的属性，都可以使用动画，通过 <code>Mobject.aminate</code> 实现</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> manim <span class="token keyword">import</span> <span class="token operator">*</span><span class="token keyword">class</span> <span class="token class-name">ApplyMethodExample</span><span class="token punctuation">(</span>Scene<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">construct</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        square <span class="token operator">=</span> Square<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>set_fill<span class="token punctuation">(</span>RED<span class="token punctuation">,</span> opacity<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>add<span class="token punctuation">(</span>square<span class="token punctuation">)</span>        <span class="token comment"># animate the change of color</span>        self<span class="token punctuation">.</span>play<span class="token punctuation">(</span>square<span class="token punctuation">.</span>animate<span class="token punctuation">.</span>set_fill<span class="token punctuation">(</span>WHITE<span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>wait<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>        <span class="token comment"># animate the change of position</span>        self<span class="token punctuation">.</span>play<span class="token punctuation">(</span>square<span class="token punctuation">.</span>animate<span class="token punctuation">.</span>shift<span class="token punctuation">(</span>UP<span class="token punctuation">)</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>wait<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/archives/5654e2fe/ApplyMethodExample_ManimCE_v0.8.0.gif" alt="ApplyMethodExample_ManimCE_v0.8.0" style="zoom: 25%;"></p><h4 id="Scene"><a href="#Scene" class="headerlink" title="Scene"></a>Scene</h4><blockquote><p>The <a href="https://docs.manim.community/en/stable/reference/manim.scene.scene.Scene.html#manim.scene.scene.Scene"><code>Scene</code></a> class is the connective tissue of manim. </p></blockquote><p>所有的 mobject 和 animation 都必须加入到 scene 中才能被展现出来，并且 scene 中必须包含 construct() 方法</p><h3 id="Configuration"><a href="#Configuration" class="headerlink" title="Configuration"></a>Configuration</h3><blockquote><p>Manim provides an extensive configuration system that allows it to adapt to many different use cases. There are many configuration options that can be configured at different times during the scene rendering process. </p></blockquote><p>在渲染动画的过程中还可以设置更多的参数，比如视频渲染质量的高低 <code>-ql, -qh</code></p><p>能够设置 Configuration 的方法有几种</p><ol><li><p>The ManimConfig class</p><blockquote><p>The most direct way of configuring manim is via the global <code>config</code> object, which is an instance of <a href="https://docs.manim.community/en/stable/reference/manim._config.utils.ManimConfig.html#manim._config.utils.ManimConfig"><code>ManimConfig</code></a>.</p></blockquote><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> manim <span class="token keyword">import</span> <span class="token operator">*</span>config<span class="token punctuation">.</span>background_color <span class="token operator">=</span> WHITEconfig<span class="token punctuation">[</span><span class="token string">"background_color"</span><span class="token punctuation">]</span> <span class="token operator">=</span> WHITE<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li><li><p>Command-line arguments</p><blockquote><p>The following example specifies the output file name (with the <code>-o</code> flag), renders only the first ten animations (<code>-n</code> flag) with a white background (<code>-c</code> flag), and saves the animation as a .gif instead of as a .mp4 file (<code>-i</code> flag). It uses the default quality and does not try to open the file after it is rendered.</p></blockquote><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">manim -o myscene -i -n <span class="token number">0,10</span> -c WHITE <span class="token operator">&lt;</span>file.py<span class="token operator">&gt;</span> SceneName<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li><p>The config files</p><blockquote><p>Manim can also be configured using a configuration file. A configuration file is a file ending with the suffix <code>.cfg</code>. To use a configuration file when rendering your scene, you must create a file with name <code>manim.cfg</code> in the same directory as your scene code.</p></blockquote><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token punctuation">[</span>CLI<span class="token punctuation">]</span><span class="token comment"># my config file</span>output_file <span class="token operator">=</span> myscenesave_as_gif <span class="token operator">=</span> <span class="token boolean">True</span>background_color <span class="token operator">=</span> WHITE<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ol><h4 id="A-list-of-all-config-options"><a href="#A-list-of-all-config-options" class="headerlink" title="A list of all config options"></a>A list of all config options</h4><pre class="line-numbers language-config" data-language="config"><code class="language-config">     aspect_ratio              assets_dir        background_color       background_opacity           bottom          custom_folders         disable_caching                 dry_run  ffmpeg_loglevel             flush_cache            frame_height              frame_rate       frame_size             frame_width          frame_x_radius          frame_y_radiusfrom_animation_number          fullscreen              images_dir              input_file        left_side                 log_dir             log_to_file        max_files_cached        media_dir             media_width       movie_file_extension    notify_outdated_version      output_file       partial_movie_dir            pixel_height             pixel_width          plugins                 preview            progress_bar                 quality       right_side             save_as_gif         save_last_frame               save_pngs      scene_names       show_in_file_browser                sound                 tex_dir     tex_template       tex_template_file                text_dir                     top      transparent       upto_animation_number   use_opengl_renderer     use_webgl_renderer        verbosity               video_dir       webgl_renderer_path       window_position   window_monitor             window_size               write_all          write_to_movie<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Using-Text"><a href="#Using-Text" class="headerlink" title="Using Text"></a>Using Text</h3><p>There are two different ways by which you can render <strong>Text</strong> in videos:</p><ol><li>Using Pango (<a href="https://docs.manim.community/en/stable/reference/manim.mobject.svg.text_mobject.html#module-manim.mobject.svg.text_mobject"><code>text_mobject</code></a>)</li><li>Using LaTeX (<a href="https://docs.manim.community/en/stable/reference/manim.mobject.svg.tex_mobject.html#module-manim.mobject.svg.tex_mobject"><code>tex_mobject</code></a>)</li></ol><p>一般如果不用公式的话，直接使用 text_mobject 就可以了</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> manim <span class="token keyword">import</span> <span class="token operator">*</span><span class="token keyword">class</span> <span class="token class-name">HelloWorld</span><span class="token punctuation">(</span>Scene<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">construct</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        text <span class="token operator">=</span> Text<span class="token punctuation">(</span><span class="token string">'Hello world'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>scale<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>add<span class="token punctuation">(</span>text<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/archives/5654e2fe/image-20210729160507790.png" style="zoom:25%;"></p><p>使用 tex_mobject 的话，如下</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> manim <span class="token keyword">import</span> <span class="token operator">*</span><span class="token keyword">class</span> <span class="token class-name">HelloLaTeX</span><span class="token punctuation">(</span>Scene<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">construct</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        tex <span class="token operator">=</span> Tex<span class="token punctuation">(</span><span class="token string">r"\LaTeX"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>scale<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>        self<span class="token punctuation">.</span>add<span class="token punctuation">(</span>tex<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><img src="/archives/5654e2fe/image-20210729160532548.png" style="zoom: 33%;"></p><p>注意需要使用 raw string <code>r('...')</code> 因为 Latex 中很多特殊字符需要进行转义</p><p>还有不同的方法都能返回 text_mobject &amp; tex_mobject，比如 MarkupText, MathTex </p><p>这篇笔记就到这里了，还有好多好玩的功能就请自行探索吧 😎</p>]]></content>
      
      
      <categories>
          
          <category> 编程 </category>
          
          <category> Python </category>
          
          <category> Package </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 教程 </tag>
            
            <tag> Manim </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Faster RCNN</title>
      <link href="/archives/2ad8fafc.html"/>
      <url>/archives/2ad8fafc.html</url>
      
        <content type="html"><![CDATA[<h1 id="Faster-RCNN-note"><a href="#Faster-RCNN-note" class="headerlink" title="Faster RCNN note"></a>Faster RCNN note</h1><p>本文总结自知乎链接<a href="https://zhuanlan.zhihu.com/p/31426458">https://zhuanlan.zhihu.com/p/31426458</a></p><h2 id="整体思路"><a href="#整体思路" class="headerlink" title="整体思路"></a>整体思路</h2><p>Faster RCNN其实可以分为4个主要内容：</p><ol><li><p>Conv layers </p><p>Faster RCNN首先使用一组基础的conv+relu+pooling层提取image的feature maps。该feature maps被共享用于后续RPN层和全连接层。</p></li><li><p>Region Proposal Networks</p><p>该层通过softmax判断anchors属于positive或者negative，再利用bounding box regression修正anchors获得精确的proposals。</p></li><li><p>Roi Pooling</p><p>该层收集输入的feature maps和proposals，综合这些信息后提取proposal feature maps，送入后续全连接层判定目标类别。</p></li><li><p>Classification</p><p>利用proposal feature maps计算proposal的类别，同时再次bounding box regression获得检测框最终的精确位置。</p></li></ol><p><img src="/archives/2ad8fafc/image-20210614151135341.png" style="zoom: 67%;"></p><h2 id="Conv-Layers"><a href="#Conv-Layers" class="headerlink" title="Conv Layers"></a>Conv Layers</h2><p>Conv layers部分共有13个conv层，13个relu层，4个pooling层 </p><ol><li>所有的conv层都是：kernel_size=3，pad=1，stride=1</li><li>所有的pooling层都是：kernel_size=2，pad=0，stride=2</li></ol><p>那么，一个MxN大小的矩阵经过Conv layers固定变为(M/16)x(N/16)</p><h2 id="Region-Proposal-Networks"><a href="#Region-Proposal-Networks" class="headerlink" title="Region Proposal Networks"></a>Region Proposal Networks</h2><h3 id="Anchors"><a href="#Anchors" class="headerlink" title="Anchors"></a>Anchors</h3><p>提到RPN网络，就不能不说anchors。所谓anchors，实际上就是一组由程序生成的矩形。直接运行作者demo中的generate_anchors.py可以得到以下输出 (不要被这些数字吓到了，没有具体意义)</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token operator">-</span><span class="token number">84</span><span class="token punctuation">.</span>  <span class="token operator">-</span><span class="token number">40</span><span class="token punctuation">.</span>   <span class="token number">99</span><span class="token punctuation">.</span>   <span class="token number">55</span><span class="token punctuation">.</span><span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">176</span><span class="token punctuation">.</span>  <span class="token operator">-</span><span class="token number">88</span><span class="token punctuation">.</span>  <span class="token number">191</span><span class="token punctuation">.</span>  <span class="token number">103</span><span class="token punctuation">.</span><span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">360</span><span class="token punctuation">.</span> <span class="token operator">-</span><span class="token number">184</span><span class="token punctuation">.</span>  <span class="token number">375</span><span class="token punctuation">.</span>  <span class="token number">199</span><span class="token punctuation">.</span><span class="token punctuation">]</span> <span class="token punctuation">[</span> <span class="token operator">-</span><span class="token number">56</span><span class="token punctuation">.</span>  <span class="token operator">-</span><span class="token number">56</span><span class="token punctuation">.</span>   <span class="token number">71</span><span class="token punctuation">.</span>   <span class="token number">71</span><span class="token punctuation">.</span><span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">120</span><span class="token punctuation">.</span> <span class="token operator">-</span><span class="token number">120</span><span class="token punctuation">.</span>  <span class="token number">135</span><span class="token punctuation">.</span>  <span class="token number">135</span><span class="token punctuation">.</span><span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">248</span><span class="token punctuation">.</span> <span class="token operator">-</span><span class="token number">248</span><span class="token punctuation">.</span>  <span class="token number">263</span><span class="token punctuation">.</span>  <span class="token number">263</span><span class="token punctuation">.</span><span class="token punctuation">]</span> <span class="token punctuation">[</span> <span class="token operator">-</span><span class="token number">36</span><span class="token punctuation">.</span>  <span class="token operator">-</span><span class="token number">80</span><span class="token punctuation">.</span>   <span class="token number">51</span><span class="token punctuation">.</span>   <span class="token number">95</span><span class="token punctuation">.</span><span class="token punctuation">]</span> <span class="token punctuation">[</span> <span class="token operator">-</span><span class="token number">80</span><span class="token punctuation">.</span> <span class="token operator">-</span><span class="token number">168</span><span class="token punctuation">.</span>   <span class="token number">95</span><span class="token punctuation">.</span>  <span class="token number">183</span><span class="token punctuation">.</span><span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">168</span><span class="token punctuation">.</span> <span class="token operator">-</span><span class="token number">344</span><span class="token punctuation">.</span>  <span class="token number">183</span><span class="token punctuation">.</span>  <span class="token number">359</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>每行有4个值，代表了矩形左上角和右下角两个点$(x_1, y_1, x_2, y_2)$ </p><p>一共9个矩形，来组于不同长宽比和不同大小的组合：长宽比有3种，1:1, 1:2, 2:1</p><p><img src="/archives/2ad8fafc/image-20210614152512944.png" style="zoom:50%;"></p><p>那么这9个anchors是做什么的呢？借用Faster RCNN论文中的原图，如图7，遍历Conv layers计算获得的feature maps，为每一个点都配备这9种anchors作为初始的检测框</p><p><img src="/archives/2ad8fafc/v2-c93db71cc8f4f4fd8cfb4ef2e2cef4f4_720w.jpg" style="zoom:80%;"></p><p>简单解释一下上图：</p><ol><li><p>conv feature map中，每一个点都是256-dimensions</p></li><li><p>intermidiate layer为 3x3 卷积，out put dimension为256，得到新的conv feature map</p></li><li><p>在新的conv feature map上，我们对每一个点预先设定的k个anchor做bounding box regression和softmax分类(positive, nagetive两类)，分别对应4k coordinates，2k scores</p><p>换句话说，就是把某一anchor区域中的特征向量拿去做prediction，预测内容为该点的分类和该点/anchor对应的bounding box参数</p></li><li><p>由于anchor数量是巨大的，训练程序会在合适的anchors中<strong>随机</strong>选取128个postive anchors+128个negative anchors进行训练</p></li></ol><h3 id="Bounding-box-regression原理"><a href="#Bounding-box-regression原理" class="headerlink" title="Bounding box regression原理"></a>Bounding box regression原理</h3><p>怎样在anchor的基础上回归得到ground truth标签呢？</p><p>给定anchor $(A_x, A_y, A_w, A_h)$ ，给定ground truth $(G_x, G_y, G_w, G_h)$</p><p>我们只要去预测中心点的位置偏移，以及矩形长宽的缩放即可</p><p>个人觉得这样的回归方法有点麻烦，这样来看CenterNet中的bounding box回归是相当直接的</p><h3 id="Proposal"><a href="#Proposal" class="headerlink" title="Proposal"></a>Proposal</h3><ol><li>生成anchors，得到对应的confidence score &amp; bounding box regression，形成最初的proposal</li><li>对所有anchors，根据positive score进行排序，取前6000个anchor proposals</li><li>去除较小和超出边界的proposal</li><li>NMS</li></ol><h2 id="ROI-Pooling"><a href="#ROI-Pooling" class="headerlink" title="ROI Pooling"></a>ROI Pooling</h2><p>Rol pooling层有2个输入：</p><ol><li>原始feature maps</li><li>RPN输出的proposals</li></ol><p>这一个Pooling操作还要有一个功能，就是需要处理不同大小的proposal (kernel)。经典的pooing操作是使用相同大小的kernel，这里我们要预先对 proposal (region of interest) 进行统一的分割，使得pooling结果是相同的表示(如下图)</p><p><img src="/archives/2ad8fafc/image-20210614164103022.png" style="zoom: 67%;"></p><h2 id="Classification"><a href="#Classification" class="headerlink" title="Classification"></a>Classification</h2><p>Classification部分利用已经获得的proposal feature maps，通过full connect层与softmax计算每个proposal具体属于那个类别（如人，车，电视等），输出cls_prob概率向量；同时再次利用bounding box regression获得每个proposal的位置偏移量bbox_pred，用于回归更加精确的目标检测框</p><p><img src="/archives/2ad8fafc/image-20210614164211554.png" style="zoom:80%;"></p><h2 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h2><p>Faster R-CNN的训练，是在已经训练好的model（如VGG，ZF）的基础上继续进行训练，实际训练过程为以下：</p><ol><li>在已经训练好的model(e.g. VGG)，训练RPN</li><li>用步骤1中得到的RPN提出proposal</li><li>用提出的Proposal训练Fast RCNN</li><li>用步骤4中训练好的Fast RCNN继续训练RPN</li><li>重复2</li><li>重复3</li></ol><p>可以看出这是一种类似迭代的过程，但只循环了2次，文章提出更多的循环并不会带来相应的提升</p>]]></content>
      
      
      <categories>
          
          <category> papers </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Faster RCNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>VSCode 教程</title>
      <link href="/archives/ca50f614.html"/>
      <url>/archives/ca50f614.html</url>
      
        <content type="html"><![CDATA[<h1 id="VSCode-note"><a href="#VSCode-note" class="headerlink" title="VSCode note"></a>VSCode note</h1><p>学习视频 <a href="https://www.bilibili.com/video/BV1ty4y1S7mC?p=1">bilibili</a></p><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>直接在官网一键下载，宇宙第一开发工具，而且还是免费的<span class="github-emoji"><span>😆</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/1f606.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span> 使用最新版本的 vscode，有时出现一些莫名其妙的 bug<span class="github-emoji"><span>😢</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/1f622.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span>，可以使用前几个版本的，如果用熟了某一个版本那暂时不要更新了吧。如果想要完整卸载的话需要删除 <code>usr/.vscode</code> 和 <code>AppData/Code</code> 文件，感觉整体来看 vscode 依然是在发展当中的开发工具</p><h3 id="Getting-started"><a href="#Getting-started" class="headerlink" title="Getting started"></a>Getting started</h3><ol><li><p>vscode 支持更换主题皮肤</p></li><li><p>vscode 支持插件扩展，能够实现多种功能来提高编程效率，如下载不同语言，高亮代码等等，推荐的插件：Python, Gitlens, Remote SSH</p></li><li><p>通过快捷键 palette 查找文件 Ctrl + P，查找命令 Ctrl + Shift + P，折叠左侧工具栏 Ctrl + B</p><p>可以修改一些你常用命令的快捷键，我修改了如下命令：</p><ol><li>Run in python file: Ctrl + enter</li><li>Start debugging: Shift +enter</li><li>Close panels: Ctrl + Alt + P</li><li>Insert Line Above/Below: Ctrl + Shifg + \\ or Enter</li><li>Collapse folders: Ctrl + Shift + F</li></ol></li><li><p>设置面板快捷键 Ctrl + ,</p></li><li><p>新建一个文件 Ctrl + N</p></li></ol><h2 id="交互式演练场-Interactive-Playground"><a href="#交互式演练场-Interactive-Playground" class="headerlink" title="交互式演练场 Interactive Playground"></a>交互式演练场 Interactive Playground</h2><p>一些编辑的小技巧</p><ol><li><p>同时选中同名字段 Ctrl + Shift + L，但这个功能没有 Refactoring 智能</p></li><li><p>IntelliSense 自动补全 api 功能 Ctrl + space</p></li><li><p>行操作</p><ol><li>复制行，在没有任何东西选中的时候直接 Ctrl + C</li><li>上下移动行，Alt + 上下键</li><li>删除行 Ctrl + Shift + K</li></ol></li><li><p>Formatting 规范代码，需要自己定义 format</p></li></ol><h2 id="一些推荐的设置"><a href="#一些推荐的设置" class="headerlink" title="一些推荐的设置"></a>一些推荐的设置</h2><p>打开 settings</p><ol><li>在熟悉之后关闭 welcome/startup 界面</li><li>建议使用英文界面</li><li>设置字体 JetBrains Mono，还可以顺便设置一下字号。安装字体<a href="https://blog.csdn.net/HUSTHY/article/details/104023077">教程</a></li><li>设置是否显示缩略图 minimap</li><li><p>设置 restore windows 是否直接恢复上一次的项目</p></li><li><p>设置开启 Trims final newlines 自动消除文件末尾多余的空行</p></li></ol><h2 id="Python"><a href="#Python" class="headerlink" title="Python"></a>Python</h2><p>下载 Python 插件</p><h3 id="Get-Started"><a href="#Get-Started" class="headerlink" title="Get Started"></a>Get Started</h3><ol><li><p>在底部的 status bar 添加 python 解释器，也可以使用 palette 来添加 interpreter。会自动检测到电脑上的 python interpreter (包括 anaconda 中创建的环境)</p></li><li><p>建立 debug 环境 craete a launch.json file，直接使用默认值就好，详细说明在 <a href="https://zhuanlan.zhihu.com/p/142642410">知乎</a></p><p>补充：默认配置只 debug 当前 folder 下的代码（“自己”的代码），如果是 pip/conda install 安装的代码（“别人”的代码），是不会进行 debug 的。如果想要 debug 所有代码则配置文件需要加上 <code>"justMyCode": false</code> <a href="https://blog.csdn.net/g534441921/article/details/102743393">CSDN</a></p><p>补充：对于需要传参数的 python 脚本调试可以参考 <a href="https://www.zhihu.com/question/50700473">知乎</a></p></li><li><p>Jupyter notebook 是插件里自带的功能，直接打开 ipynb 文件就可以运行代码块！通过选择 notebook 中的 kernel (具体一点说就是选择 conda 中的环境) 就能在你想要的环境中运行了，非常方便</p></li></ol><h3 id="连接到远程服务器"><a href="#连接到远程服务器" class="headerlink" title="连接到远程服务器"></a>连接到远程服务器</h3><p>由于要跑一些模型，自己的电脑显卡根本跑不动，那就<del>白嫖</del>连接到实验室的服务器​</p><p>通过 vscode Extensions: <code>Remote-SSH</code> 完成，<a href="https://zhuanlan.zhihu.com/p/141205262">知乎</a></p><p>在 Remote Expolorer -&gt; SSH TARGETS -&gt; config 中添加配置</p><pre class="line-numbers language-config" data-language="config"><code class="language-config"># Read more about SSH config files: https://linux.die.net/man/5/ssh_configHost random_name    HostName host_ip    User user_name<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>遇到了报错 <code>Resolver error: Error: Running the contributed command: '_workbench.downloadResource' failed.</code> 无法连接到服务器。原因可能在于服务器是在内网，没有办法在服务器上自动下载好 vscode-server，于是只能本地下载，然后上传</p><p>参考 <a href="https://blog.csdn.net/ibless/article/details/118610776">CSDN</a> 解决问题</p>]]></content>
      
      
      <categories>
          
          <category> 编程 </category>
          
          <category> Tools </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 教程 </tag>
            
            <tag> VSCode </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CenterPoint 复现笔记</title>
      <link href="/archives/ba7995ee.html"/>
      <url>/archives/ba7995ee.html</url>
      
        <content type="html"><![CDATA[<h1 id="CenterPoint-复现笔记"><a href="#CenterPoint-复现笔记" class="headerlink" title="CenterPoint 复现笔记"></a>CenterPoint 复现笔记</h1><h2 id="Installation"><a href="#Installation" class="headerlink" title="Installation"></a>Installation</h2><ol><li><p>pytorch下载如果很慢，请采用镜像！</p></li><li><p>下载cmake使用apt，但要更新下载源为阿里云，这样版本才够新</p></li><li><p>安装spconv时报错</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">The following packages have unmet dependencies: gsettings-desktop-schemas <span class="token builtin class-name">:</span> Breaks: mutter <span class="token punctuation">(</span><span class="token operator">&lt;</span> <span class="token number">3.31</span>.4<span class="token punctuation">)</span> but <span class="token number">3.28</span>.4+git20200505-0ubuntu18.04.2 is to be installedE: Error, pkgProblemResolver::Resolve generated breaks, this may be caused by held packages.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>网络上一个解决方案是使用aptitude</p><pre class="line-numbers language-SHell" data-language="SHell"><code class="language-SHell"># download aptitudesudo apt install aptitudesudo aptitude install &lt;packagename&gt;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>血泪教训，不要轻易使用aptitude，系统很多东西都被改写了，经过一番折腾升级到了ubuntu 20.04，也不知道之前安装的东西有没有被动</p><p>印象中提到”held packages”，应该按照那种方式解决</p></li><li><p>在下载 spconv 报错</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">CMake Error at CMakeLists.txt:2 <span class="token punctuation">(</span>project<span class="token punctuation">)</span>:  No CMAKE_CUDA_COMPILER could be found.  raise CalledProcessError<span class="token punctuation">(</span>retcode, cmd<span class="token punctuation">)</span>subprocess.CalledProcessError: Command <span class="token string">'['</span>cmake<span class="token string">', '</span>/home/declan/CenterPoint/spconv<span class="token string">', '</span>-DCMAKE_PREFIX_PATH<span class="token operator">=</span>/home/declan/anaconda3/envs/centerpoint/lib/python3.6/site-packages/torch<span class="token string">', '</span>-DPYBIND11_PYTHON_VERSION<span class="token operator">=</span><span class="token number">3.6</span><span class="token string">', '</span>-DSPCONV_BuildTests<span class="token operator">=</span>OFF<span class="token string">', '</span>-DCMAKE_CUDA_FLAGS<span class="token operator">=</span><span class="token string">"--expt-relaxed-constexpr"</span><span class="token string">', '</span>-DCMAKE_LIBRARY_OUTPUT_DIRECTORY<span class="token operator">=</span>/home/declan/CenterPoint/spconv/build/lib.linux-x86_64-3.6/spconv<span class="token string">', '</span>-DCMAKE_BUILD_TYPE<span class="token operator">=</span>Release<span class="token string">']'</span> returned non-zero <span class="token builtin class-name">exit</span> status <span class="token number">1</span>.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>尝试设置 CUDA 路径</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token builtin class-name">export</span> <span class="token assign-left variable">PYTHONPATH</span><span class="token operator">=</span><span class="token string">"<span class="token variable">${PYTHONPATH}</span>:/home/declan/CenterPoint"</span><span class="token builtin class-name">export</span> <span class="token assign-left variable"><span class="token environment constant">PATH</span></span><span class="token operator">=</span>/usr/local/cuda-10.0/bin:<span class="token environment constant">$PATH</span><span class="token builtin class-name">export</span> <span class="token assign-left variable">CUDA_PATH</span><span class="token operator">=</span>/usr/local/cuda-10.0<span class="token builtin class-name">export</span> <span class="token assign-left variable">CUDA_HOME</span><span class="token operator">=</span>/usr/local/cuda-10.0<span class="token builtin class-name">export</span> <span class="token assign-left variable">LD_LIBRARY_PATH</span><span class="token operator">=</span>/usr/local/cuda-10.0/lib64:<span class="token variable">$LD_LIBRARY_PATH</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>没有效果。#241 issues和我问题一模一样 <a href="https://github.com/traveller59/spconv/issues/241">https://github.com/traveller59/spconv/issues/241</a></p><p>尝试增加路径 </p><p>try adding ‘-DCMAKE_CUDA_COMPILER=/usr/local/cuda-10.1/bin/nvcc’ in cmake_args</p><p>依旧失败</p><p>尝试使用不同版本的g++ sudo apt install g++-7，显示已经下载，我们需要切换版本</p><p>ls name* 可以列出所有name开头的包</p><p><a href="https://blog.csdn.net/FontThrone/article/details/104279224">https://blog.csdn.net/FontThrone/article/details/104279224</a></p><p>—slave 使得g++ gcc版本保持一致 70 90为重要权重priority</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">sudo</span> update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-7 <span class="token number">70</span> --slave /usr/bin/g++ g++ /usr/bin/g++-7<span class="token function">sudo</span> update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-9 <span class="token number">90</span> --slave /usr/bin/g++ g++ /usr/bin/g++-9<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>对g++和gcc进行管理</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">  Selection    Path            Priority   Status------------------------------------------------------------* <span class="token number">0</span>            /usr/bin/gcc-9   <span class="token number">90</span>        auto mode  <span class="token number">1</span>            /usr/bin/gcc-7   <span class="token number">70</span>        manual mode  <span class="token number">2</span>            /usr/bin/gcc-9   <span class="token number">90</span>        manual mode<span class="token function">sudo</span> update-alternatives --config gcc<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>成功</p></li><li><p>选择了 nuScenes mini 数据集</p></li><li><p>运行测试</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">python ./tools/dist_test.py infos_val_10sweeps_withvelo_filter_True.json  --work_dir work_dirs/CONFIG_NAME --checkpoint work_dirs/CONFIG_NAME/latest.pth --speed_test <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>报错</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">ModuleNotFoundError: No module named <span class="token string">'torchie'</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>尝试将torchie文档直接加入到PYTHONPATH当中</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token builtin class-name">export</span> <span class="token assign-left variable">PYTHONPATH</span><span class="token operator">=</span><span class="token variable">$PYTHONPATH</span>:/home/delcan/CenterPoint/det3d<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>新报错</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">Traceback <span class="token punctuation">(</span>most recent call last<span class="token punctuation">)</span>:  File <span class="token string">"./tools/dist_test.py"</span>, line <span class="token number">211</span>, <span class="token keyword">in</span> <span class="token operator">&lt;</span>module<span class="token operator">&gt;</span>    main<span class="token punctuation">(</span><span class="token punctuation">)</span>  File <span class="token string">"./tools/dist_test.py"</span>, line <span class="token number">102</span>, <span class="token keyword">in</span> main    logger <span class="token operator">=</span> get_root_logger<span class="token punctuation">(</span>cfg.log_level<span class="token punctuation">)</span>  File <span class="token string">"/home/declan/CenterPoint/det3d/torchie/utils/config.py"</span>, line <span class="token number">146</span>, <span class="token keyword">in</span> __getattr__    <span class="token builtin class-name">return</span> getattr<span class="token punctuation">(</span>self._cfg_dict, name<span class="token punctuation">)</span>  File <span class="token string">"/home/declan/CenterPoint/det3d/torchie/utils/config.py"</span>, line <span class="token number">29</span>, <span class="token keyword">in</span> __getattr__    raise exAttributeError: <span class="token string">'ConfigDict'</span> object has no attribute <span class="token string">'log_level'</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>可能是因为 nuscenes_mini 测试集原因</p><p><a href="https://github.com/tianweiy/CenterPoint/issues/106">https://github.com/tianweiy/CenterPoint/issues/106</a></p><p>我根据上面的内容对源码进行了修改，先尝试 train 一下</p><p>依旧报错，再检查可能是因为配置文件没有对的原因</p><p><a href="https://github.com/open-mmlab/mmdetection/issues/3093">https://github.com/open-mmlab/mmdetection/issues/3093</a></p><p>通过正确配置 <code>nusc_centerpoint_voxelnet_0075voxel_fix_bn_z.py</code> 文件解决上面报错</p><p><code>./configs/nusc/voxelnet/nusc_centerpoint_voxelnet_0075voxel_fix_bn_z.py</code></p><p>由于没有完整的 nuScenes 数据集，又有新的错误报错</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">FileNotFoundError: <span class="token punctuation">[</span>Errno <span class="token number">2</span><span class="token punctuation">]</span> No such <span class="token function">file</span> or directory: <span class="token string">'nuScenes/samples/LIDAR_TOP/n008-2018-08-27-11-48-51-0400__LIDAR_TOP__1535385105950634.pcd.bin'</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>跳过这里，尝试跑一个 demo</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">python ./tools/dist_test.py ./configs/nusc/voxelnet/nusc_centerpoint_voxelnet_0075voxel_fix_bn_z.py --work_dir work_dirs/nusc_centerpoint_voxelnet_0075voxel_fix_bn_z --checkpoint work_dirs/nusc_centerpoint_voxelnet_0075voxel_fix_bn_z/latest.pth --speed_test <span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>上面的报错</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">FileNotFoundError: <span class="token punctuation">[</span>Errno <span class="token number">2</span><span class="token punctuation">]</span> No such <span class="token function">file</span> or directory: <span class="token string">'nuScenes/samples/LIDAR_TOP/n015-2018-10-02-10-50-40+0800__LIDAR_TOP__1538448754047572.pcd.bin'</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>查找目录发现这个文件其实是存在的，说明路径没有对，在 CentePoint 目录下添加 nuScenes 的软链接就可以解决了</p></li><li><p>最终 RuntimeError: CUDA out of memory 即使 batch_size = 1 也直接炸了，放弃！</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> papers </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CenterPoint </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>阿里云服务器部署 Hexo 博客教程</title>
      <link href="/archives/d547a647.html"/>
      <url>/archives/d547a647.html</url>
      
        <content type="html"><![CDATA[<h1 id="阿里云服务器ECS"><a href="#阿里云服务器ECS" class="headerlink" title="阿里云服务器ECS"></a>阿里云服务器ECS</h1><p>参考链接：</p><p><a href="https://www.bilibili.com/video/BV177411K7bH">狂神说_bilibili</a></p><p>官方链接：</p><p><a href="https://developer.aliyun.com/plan/grow-up">阿里云开发者成长计划</a></p><p><a href="https://developer.aliyun.com/adc/student?spm=a2c6h.19776329.J_4403085560.4.658b3d804yW1UU#J_3120529270">ECS训练营</a></p><p><a href="https://www.aliyun.com/product/ecs?spm=5176.224200.J_8058803260.52.1401586cYUB7hI">云服务器ECS</a></p><h2 id="学生机"><a href="#学生机" class="headerlink" title="学生机"></a>学生机</h2><p>如果是学生/新用户，一定要去看看有哪些优惠，比如<a href="https://developer.aliyun.com/plan/grow-up">阿里云开发者成长计划</a>。此刻阿里云提供的学生优惠是免费使用2个月的服务器资源。如果购买的话，一个1核2G的服务器就足够了</p><p><img src="/archives/d547a647/image-20210717163630430-1627213118656.png" style="zoom: 25%;"></p><h2 id="设置安全组"><a href="#设置安全组" class="headerlink" title="设置安全组"></a>设置安全组</h2><p>进入控制台开启端口，否则外部无法访问。除了默认的三个端口，通过“快速添加”，我再添加了 http(80) &amp; https(443) 两个端口。由于现在我对计算机网络一窍不通，所以先就这样吧</p><p><img src="/archives/d547a647/image-20210717155930905-1627213118658.png" style="zoom: 33%;"></p><h2 id="重置实例密码"><a href="#重置实例密码" class="headerlink" title="重置实例密码"></a>重置实例密码</h2><p>修改密码之后实例就会自动重启</p><p>然后就可以通过 <code>ssh root@ip</code> 连接到服务器，其中 ip 是你服务器的公网 ip</p><p><img src="/archives/d547a647/image-20210717162311907-1627213118658.png" style="zoom: 33%;"></p><h2 id="Enjoy"><a href="#Enjoy" class="headerlink" title="Enjoy"></a>Enjoy</h2><p>之后就可以像操作 Linux 一样，操作自己的服务器啦！</p><h2 id="将博客部署到服务器上"><a href="#将博客部署到服务器上" class="headerlink" title="将博客部署到服务器上"></a>将博客部署到服务器上</h2><p>几个参考教程：<a href="https://developer.aliyun.com/article/775005">阿里云教程</a> <a href="https://blog.csdn.net/weixin_41154636/article/details/99685965">csdn 教程</a> <a href="https://cloud.tencent.com/developer/article/1632020">腾讯云教程</a> <a href="https://zhuanlan.zhihu.com/p/120743882">知乎教程</a></p><p>在开始之前，先根据之前的 Linux 安装教程简单设置一下自己的服务器：添加新用户，更改主机名</p><p>现在本地配置好 hexo 环境，具体配置过程在之前的博客有详细记录</p><h3 id="在服务器上安装-git"><a href="#在服务器上安装-git" class="headerlink" title="在服务器上安装 git"></a>在服务器上安装 git</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">sudo</span> yum <span class="token function">install</span> -y <span class="token function">git</span><span class="token comment"># 安装成功后查看 git version</span><span class="token function">git</span> --version <span class="token function">git</span> version <span class="token number">2.27</span>.0<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>因为之前在 Ubuntu 上使用的是 apt 包管理，在 CentOS 上则换为 yum 包管理。我试验了一下，如果不加 sudo 是不能下载成功的</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">Error: This <span class="token builtin class-name">command</span> has to be run under the root user.<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>所以我认为 yum 和 apt 一样需要 sudo 权限</p><h3 id="安装-nginx"><a href="#安装-nginx" class="headerlink" title="安装 nginx"></a>安装 nginx</h3><p>什么是 nginx？下面是官网描述</p><blockquote><p>NGINX is a high‑performance, highly scalable, highly available web server, reverse proxy server, and web accelerator (combining the features of an HTTP load balancer, content cache, and more).</p></blockquote><p>在我理解看来，部署网站的过程中 nginx 就是用来提供网页服务的服务器。这里就要更进一步理解什么是广义上的服务器</p><blockquote><p>从广义上讲，服务器是指网络中能对其它机器提供某些服务的计算机系统。从狭义上讲，服务器是专指某些高性能计算机，能通过网络，对外提供服务。</p></blockquote><p>使用以下命令安装</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">sudo</span> yum <span class="token function">install</span> -y nginx<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="建立-git-仓库"><a href="#建立-git-仓库" class="headerlink" title="建立 git 仓库"></a>建立 git 仓库</h3><p>Hexo 可以使用 git 来部署，这样每次写完之后就都可以使用git来一键部署了，比较方便。我们先为系统添加一个 git 用户</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">useradd</span> -m <span class="token function">git</span> <span class="token comment"># 添加一个新用户</span><span class="token function">passwd</span> <span class="token function">git</span> <span class="token comment"># 设置git用户密码</span><span class="token function">su</span> <span class="token function">git</span> <span class="token comment"># 切换用户进行后续操作</span><span class="token builtin class-name">cd</span> /home/git/<span class="token function">mkdir</span> -p projects/blog <span class="token comment"># 把项目目录建立起来</span><span class="token function">mkdir</span> repos <span class="token operator">&amp;&amp;</span> <span class="token builtin class-name">cd</span> repos<span class="token function">git</span> init --bare blog.git <span class="token comment"># 创建仓库</span><span class="token builtin class-name">cd</span> blog.git/hooks<span class="token function">vim</span> post-receive <span class="token comment"># 创建一个钩子</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>post-receive文件的内容如下：</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token shebang important">#!/bin/sh</span><span class="token function">git</span> --work-tree<span class="token operator">=</span>/home/git/projects/blog --git-dir<span class="token operator">=</span>/home/git/repos/blog.git checkout -f<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>给 post-receive 添加执行权限</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">chmod</span> +x post-receive<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>git init —bare 和 git init 有什么区别？ <a href="https://blog.csdn.net/sinat_34349564/article/details/52487860">csdn 链接</a></p><p>hooks有什么作用？ <a href="https://blog.csdn.net/weixin_41154636/article/details/99685965">csdn 链接</a></p><p>该钩子的意思是当本地有提交到服务器时，会将文件放在/home/hexo下</p><p><code>-f</code>这个参数如果在多人协作的博客中可能会引发不好的结果，因为他是强制更新的意思，会将本地版本覆盖掉远程服务器的版本，但是是个人的博客系统就无所谓了</p><h3 id="将公钥配置到服务器上"><a href="#将公钥配置到服务器上" class="headerlink" title="将公钥配置到服务器上"></a>将公钥配置到服务器上</h3><p>可以通过建立SSH信任关系，来免去登陆服务器时输入密码的步骤</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">ssh-copy-id -i ~/.ssh/id_rsa.pub git@server_ip<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>我尝试了一下自己手动复制 id_rsa.pub 到 authorized_keys 文件中，但是不能实现免密登陆，可能时复制时的字符串出现了问题，之前在 github 时也遇到了类似问题，直接复制公钥无法识别的情况</p><h3 id="更改-git-用户默认-shell"><a href="#更改-git-用户默认-shell" class="headerlink" title="更改 git 用户默认 shell"></a>更改 git 用户默认 shell</h3><p>为了安全，我们最好禁用 git 用户的 shell 登录权限。从而只能用 git clone，git push 等 git 操作访问服务器</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">cat</span> /etc/shells <span class="token comment"># 查看 git-shell 是否在登录方式里面</span><span class="token function">which</span> git-shell <span class="token comment"># 找到git-shell的路径，记下来</span><span class="token function">sudo</span> <span class="token function">vim</span> /etc/shells <span class="token comment"># 把 git-shell 路径添加到文件末尾</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>然后更改 git 用户 shell</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">sudo</span> <span class="token function">vim</span> /etc/passwd<span class="token comment"># 将原来的 /bin/bash 改为 /usr/bin/git-shell</span><span class="token comment"># git:x:1001:1001::/home/git:/usr/bin/git-shell</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p> 这样当你再次用 ssh 连接 git 用户时就会出现以下信息</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">fatal: Interactive <span class="token function">git</span> shell is not enabled.hint: ~/git-shell-commands should exist and have <span class="token builtin class-name">read</span> and execute access.Connection to your_ip closed.<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="部署上线"><a href="#部署上线" class="headerlink" title="部署上线"></a>部署上线</h3><p>我们修改<strong>本地</strong> hexo 配置文件 _config.yml</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">deploy</span><span class="token punctuation">:</span>  <span class="token key atrule">type</span><span class="token punctuation">:</span> git  <span class="token key atrule">repo</span><span class="token punctuation">:</span> git@your_ip<span class="token punctuation">:</span>/home/git/repos/blog.git<span class="token comment"># repo: git@github.com:name/name.github.io.git</span>  <span class="token key atrule">branch</span><span class="token punctuation">:</span> master<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>配置好后就是 hexo 三连一键部署：<code>hexo clean &amp;&amp; hexo g &amp;&amp; hexo d</code></p><h3 id="配置-nginx"><a href="#配置-nginx" class="headerlink" title="配置 nginx"></a>配置 nginx</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token builtin class-name">cd</span> /etc/nginx<span class="token function">cp</span> nginx.conf nginx_backup.conf <span class="token comment"># 备份配置文件</span><span class="token function">vim</span> nginx.conf<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>有两个需要修改的地方：</p><ol><li><p>开头的 <code>user nginx</code> 要改为 <code>user root</code> </p></li><li><p>server 部分</p><pre class="line-numbers language-nginx" data-language="nginx"><code class="language-nginx"><span class="token directive"><span class="token keyword">server</span></span><span class="token punctuation">{</span>        <span class="token directive"><span class="token keyword">listen</span>       <span class="token number">80</span></span><span class="token punctuation">;</span> <span class="token comment">#监听80端口</span>        <span class="token directive"><span class="token keyword">server_name</span> 139.159.245.212</span><span class="token punctuation">;</span> <span class="token comment">#你的服务器名，通常是域名，如果是域名，你就需要监听80端口</span>        <span class="token directive"><span class="token keyword">root</span>       /home/git/projects/blog</span><span class="token punctuation">;</span> <span class="token comment">#网站的根目录</span>        <span class="token directive"><span class="token keyword">location</span> /</span> <span class="token punctuation">{</span>        <span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li></ol><p>配置好后 <code>nginx -s reload</code> 重新加载配置信息，如果是第一次进行加载，则还需要先运行命令 <code>nginx -c /etc/nginx/nginx.conf</code></p><p>现在你就可以通过 ip 地址访问你的网页啦！</p><p>我发现由于我的网站封面太大(有6M)，打开时加载比较慢。所以我需要压缩一下封面图片的大小，推荐两个压缩图片网站</p><p><a href="https://compressjpeg.com/">https://compressjpeg.com/</a></p><p><a href="https://tinypng.com/">https://tinypng.com/</a></p><h2 id="域名"><a href="#域名" class="headerlink" title="域名"></a>域名</h2><p>什么是域名？参考链接：<a href="https://www.bilibili.com/video/BV1kE411i7Jo?from=search&amp;seid=2556702162224412196">CodeSheep bilibili</a></p><p>建议阅读官方文档：<a href="https://help.aliyun.com/product/35473.html?spm=a2c4g.11186623.6.540.5b09689epNroGg">阿里云域名服务</a> <a href="https://help.aliyun.com/document_detail/61257.html?spm=a2c4g.11174283.2.6.36904c070bCdBM">什么是阿里云域名服务</a></p><p>根据官方文档 <a href="https://help.aliyun.com/document_detail/54068.htm?spm=a2c4g.11186623.2.13.5ff0689efHL52u#task-1830383">注册通用域名</a>，花费79元巨资注册了3年域名 hongkun.space</p><p><img src="/archives/d547a647/image-20210717235130445-1627213118658.png" style="zoom:50%;"></p><p>完成购买过后还需要进行：</p><ol><li><a href="https://help.aliyun.com/document_detail/35881.htm?spm=a2c4g.11186623.2.14.275a689e1pnnCW#concept-uhk-w5v-12b">实名认证</a>：一般3天左右审核通过</li><li><a href="https://beian.aliyun.com/pcContainer/formpage?page=selfBa&amp;pageAction=init&amp;orderType=100">域名备案</a>：初审1-2天，完整备案审核过程大概十多天</li></ol><p>注意需要先进行实名认证，然后才能完成备案</p><p>这里我还遇到一个问题，我通过学生优惠免费领取的服务器不能进行域名备案，因为至少需要有3个月的服务器使用权才能备案。看来还是得自己购买一个服务器，我再次花费巨资96元（新用户优惠）购买了一年的轻量应用服务器</p><h3 id="轻量应用服务器"><a href="#轻量应用服务器" class="headerlink" title="轻量应用服务器"></a>轻量应用服务器</h3><p><a href="https://www.aliyun.com/product/swas?spm=5176.8789780.J_8058803260.52.578945b5xsNx3V">轻量应用服务器</a>有单独的<a href="https://account.aliyun.com/login/login.htm?spm=5176.161059.J_5253785160.3.2c9ea505nvWZQs&amp;oauth_callback=https%3A%2F%2Fswas.console.aliyun.com%2F%3Fspm%3D5176.161059.J_835498.2.3e9f7fdaKmYuj7&amp;lang=zh#/servers">控制台</a>，用来部署网站性价比非常不错，配置过程和上面的云服务器一样</p><p>在轻量应用服务器的控制台中，域名解析和备案就在概览页面当中，根据流程进行即可</p><p><img src="/archives/d547a647/image-20210725173426850.png" style="zoom: 33%;"></p><h2 id="部署-SSL-证书-https"><a href="#部署-SSL-证书-https" class="headerlink" title="部署 SSL 证书 (https)"></a>部署 SSL 证书 (https)</h2><p>网站现在可以访问了，但是如下图可见，登陆网站会提示 <strong>Not Secure!!!</strong></p><p><img src="/archives/d547a647/image-20210802105224250.png" style="zoom: 50%;"></p><p>这可不能忍，于是我根据 <a href="https://blog.csdn.net/qq_33505555/article/details/106046616">CSDN 教程</a> 给阿里云服务器配置 SSL 证书，使用的是 FreeSSL 一个提供免费 https 证书申请的网站</p><h3 id="使用-FreeSSL-申请证书"><a href="#使用-FreeSSL-申请证书" class="headerlink" title="使用 FreeSSL 申请证书"></a>使用 FreeSSL 申请证书</h3><p>老规矩，先看看 <a href="https://blog.freessl.cn/tag/ssl-apply/">官网教程</a></p><ol><li><p>生成 CSR <a href="https://cloud.tencent.com/document/product/400/5367">什么是 CSR ? 腾讯云文档</a></p><p>教程中推荐使用 Keymanager 生成</p></li><li><p>在阿里云服务器中配置 DNS 解析，并对配置进行检测和验证</p><p>验证成功后可以在 FreeSSL 控制台中查看证书</p><p><img src="/archives/d547a647/image-20210802141326078.png" style="zoom:33%;"></p><p>在“更多操作”中可以下载证书，一个 pem 文件，一个 private.key</p><p><img src="/archives/d547a647/image-20210802141919162.png" style="zoom:33%;"></p></li><li><p>然后将证书 .pem 文件导入到 keymanager 中</p><p><img src="/archives/d547a647/image-20210802170924734.png" style="zoom: 25%;"></p></li><li><p>进行一键部署。基于你自己的框架，选择不同的部署方法，我选择部署到 Nginx 上。这里的“一键部署”实质上就是上传你的证书到服务器上</p><p><img src="/archives/d547a647/image-20210802171457165.png" style="zoom: 33%;"></p><p>部署成功过后，使用 <a href="https://myssl.com/">myssl.com </a> 检查网站的安全性。但是如果你的 Nginx 配置不对的话，</p></li><li><p>配置 Nginx</p><p>现在我们希望通过 https 443 端口来打开网站，与之前监听 http 80 端口，我们监听 443 端口，然后将 80 端口重定向</p><pre class="line-numbers language-nginx" data-language="nginx"><code class="language-nginx"><span class="token directive"><span class="token keyword">server</span></span> <span class="token punctuation">{</span>      <span class="token comment">#listen 80;</span>      <span class="token directive"><span class="token keyword">listen</span> <span class="token number">443</span></span><span class="token punctuation">;</span>      <span class="token directive"><span class="token keyword">ssl</span> <span class="token boolean">on</span></span><span class="token punctuation">;</span>      <span class="token directive"><span class="token keyword">ssl_certificate</span> /etc/ssl/cert.pem</span><span class="token punctuation">;</span>      <span class="token directive"><span class="token keyword">ssl_certificate_key</span> /etc/ssl/key.pem</span><span class="token punctuation">;</span>      <span class="token directive"><span class="token keyword">server_name</span>  hongkun.space</span><span class="token punctuation">;</span>      <span class="token directive"><span class="token keyword">root</span>         /home/git/blog</span><span class="token punctuation">;</span>  ...  <span class="token punctuation">}</span>  <span class="token directive"><span class="token keyword">server</span></span> <span class="token punctuation">{</span>      <span class="token directive"><span class="token keyword">listen</span> <span class="token number">80</span></span><span class="token punctuation">;</span>      <span class="token directive"><span class="token keyword">server_name</span> hongkun.space      <span class="token comment"># permenant redirect to https</span>      return <span class="token number">301</span> https://hongkun.space<span class="token variable">$request_uri</span></span><span class="token punctuation">;</span>  <span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>配置好过后重启 <code>nginx -s reload</code></p></li><li><p>现在访问网站，旁边就有高贵的<span class="github-emoji"><span>🔒</span><img src="https://github.githubassets.com/images/icons/emoji/unicode/1f512.png?v8" aria-hidden="true" onerror="this.parent.classList.add('github-emoji-fallback')"></span></p><p><img src="/archives/d547a647/image-20210802173016910.png" style="zoom:50%;"></p><p>部署成功过后，还可以使用 <a href="https://myssl.com/">myssl.com </a> 检查网站的安全性</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 软件 </category>
          
          <category> Hexo </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo </tag>
            
            <tag> 阿里云 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CS231N Assignment2 笔记</title>
      <link href="/archives/407bb789.html"/>
      <url>/archives/407bb789.html</url>
      
        <content type="html"><![CDATA[<h1 id="cs231n-2021-Assignment-2-note"><a href="#cs231n-2021-Assignment-2-note" class="headerlink" title="cs231n 2021 Assignment 2 note"></a>cs231n 2021 Assignment 2 note</h1><h2 id="资源"><a href="#资源" class="headerlink" title="资源"></a>资源</h2><p>assignment 模板: <a href="https://github.com/cs231n/cs231n.github.io">github</a> </p><p>官方: <a href="https://cs231n.github.io/assignments2021/assignment2/">课程链接</a></p><p>assignment 参考链接: <a href="https://github.com/amanchadha/stanford-cs231n-assignments-2020">2020</a></p><p>发现了一种新的模式: pycharm + git + anaconda &amp; jupyter</p><p>上面的组合能够帮助写代码的效率提升，pycharm 能够帮助调试，git 用于版本管理，conda 用于环境管理。jupyter 在测试代码块上有很大的优势，并且很多 cs231n 的作业形式都是以 ipynb 的文件类型发布，更适合在 jupyter 上打开，而且 jupyter 能够直接使用创建好的 conda 环境，特别方便</p><p>经过一番折腾，最终决定使用 vs code 替换 pycharm，原因是 vs code 有 jupyter notebook 插件，可以直接显示在 editor 内，比 Pycharm 更方便而且以后想要学习其他语言 vs code 优势更大</p><h2 id="过程中的编程复习"><a href="#过程中的编程复习" class="headerlink" title="过程中的编程复习"></a>过程中的编程复习</h2><ol><li><p>重新复习了 numpy 的一些用法，一个重要思想就是尽量少考虑使用循环解决，要以 index 索引思想来解决数据的操作问题。</p><p>reshape已经存在的shape</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">a<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>b<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>当接受参数是元组而是可变参数 <em>args 的时候，可以用 </em>tuple 来将参数变为 *args</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token operator">*</span>a<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>要学会善用矩阵点乘 A * B，是将对应元素相乘，在计算模的时候，或者当其中一个是 indication function 时很有用</p></li><li><p>重新复习了字典的用法，核心是创造字典，dict(), dict.fromkeys()</p><p>字典的 key, val 迭代器，如果不用 items，则只有 key</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">for</span> key<span class="token punctuation">,</span> val <span class="token keyword">in</span> <span class="token builtin">dict</span><span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>pas<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li><li><p>对于格式化字符串有新的认知，下面例子</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">self<span class="token punctuation">.</span>params <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>self<span class="token punctuation">.</span>params<span class="token punctuation">[</span><span class="token string">'b%d'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> weight_scale <span class="token operator">*</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>hd<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>可以用这样的形式来调用 key</p></li></ol><h2 id="Fully-Connected-Networks"><a href="#Fully-Connected-Networks" class="headerlink" title="Fully Connected Networks"></a>Fully Connected Networks</h2><ol><li>对于网络的认知有了更新。要把层(layer, w)和点(node, x)分开来看，这样网络结构才更清晰。一般隐藏层不包含输出层</li><li><strong>反向传播熟悉 back propagation，尤其是矩阵相乘的反向传播，只需要记住结论就行了。对于广播过后的结果，需要将广播的矩阵作 sum 处理，得到广播前的对应元素梯度</strong></li><li>5 layers 和 3 layers 网络优化时比较，差异在哪里？5 layer 更难优化，对于初始值敏感</li><li><strong>对于优化算法进行了进一步了解，由三个核心点：AdaGrad, Momentum, EWA 最后自然推出 Adam 优化算法</strong></li><li><strong>在编写代码的时候重要的版本需要保存，这就需要使用 git</strong></li></ol><h2 id="Batch-normalization"><a href="#Batch-normalization" class="headerlink" title="Batch normalization"></a>Batch normalization</h2><p>进一步清晰了 bn 的过程与作用，可以回看自己的笔记了解详情</p><h3 id="Inline-Question-1"><a href="#Inline-Question-1" class="headerlink" title="Inline Question 1"></a>Inline Question 1</h3><p><strong>How does the scale of weight initialization affect models with/without batch normalization differently, and why?</strong></p><p>You should find that using batch normalization helps the network to converge much faster. </p><p>使用 batch normalization 会让网络在训练集上收敛更快。这和普通的 normalization 是一个道理，减少 zigzag 拐弯</p><p>还有几个需要知道和理解的点是：</p><ol><li>batch normalization 帮助缓解梯度消失/爆炸的问题，这将减缓因为 weight initialization 过大或过小而产生梯度消失/爆炸的问题</li><li>batch normalization 有一定的正则化效果，避免过拟合</li></ol><p><img src="/archives/407bb789/image-20210707160726541.png" style="zoom: 67%;"></p><h3 id="Inline-Question-2"><a href="#Inline-Question-2" class="headerlink" title="Inline Question 2"></a>Inline Question 2</h3><p><strong>hat does this imply about the relationship between batch normalization and batch size? Why is this relationship observed?</strong></p><p>一般规律是：batch size 越大训练集上收敛越快。当 batch size 比较小的时候，比 baseline 速度更慢，原因在于过少的样本带来的偏差太大，这样的噪音会影响训练和测试表现</p><p><img src="/archives/407bb789/image-20210707164225500.png" style="zoom: 67%;"></p><p>在训练和测试时均会用到 bn layer，测试时用的 $\mu,\sigma$  参数是训练过程中的指数加权平均 EWA</p><h3 id="Layer-Normalization"><a href="#Layer-Normalization" class="headerlink" title="Layer Normalization"></a>Layer Normalization</h3><p>用在 RNN 中更多，如果以后接触 NLP 领域的话再深入整理。简单的解释 <a href="https://zhuanlan.zhihu.com/p/74516930">知乎链接</a> </p><p>假设我们有 10行 3列 的数据，即我们的batchsize = 10，每一行数据有三个特征，这是一种“列缩放”。</p><p>而layer方向相反，它针对的是每一行进行缩放。即只看一笔数据，算出这笔所有特征的均值与方差再缩放。这是一种“行缩放”。</p><p>Q: 为什么 gamma 和 beta 还是原来的 (D, ) 形状？Layer normalization 在 RNN 中有什么作用？</p><p><img src="/archives/407bb789/image-20210707200112133.png" style="zoom: 67%;"></p><p>看得出 layer normalization 在训练上也是有一定作用的，但在图像方面相比于 batch normalization 效果差一点，另一个比较自然的结果是，对于 layer normalization 来说 hidden dimension 取较大值较好</p><h2 id="Drop-out"><a href="#Drop-out" class="headerlink" title="Drop out"></a>Drop out</h2><p>两行代码解决 (inverted) dropout layer 核心</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">mask <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token operator">*</span><span class="token builtin">input</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token operator">&lt;</span> poutput <span class="token operator">=</span> <span class="token builtin">input</span> <span class="token operator">*</span> mask <span class="token operator">/</span> p<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>vallina dropout 是在 test 时将输出乘以 p 使得输出是一个合理期望值。但如果我们在训练的时候已经除以 p 了，在测试时就不需要作任何操作。下图为正则化效果 regularization</p><p><img src="/archives/407bb789/image-20210708160433242.png" style="zoom:67%;"></p><h2 id="Convolutional-Neural-Networks"><a href="#Convolutional-Neural-Networks" class="headerlink" title="Convolutional Neural Networks"></a>Convolutional Neural Networks</h2><ol><li><p>用嵌套循环实现了最原始的卷积操作，使用 np.pad 函数能实现 padding 操作，感觉这个函数的参数不是那么灵活</p></li><li><p>返回最大值坐标 np.argmax，如果想要返回多元坐标还需要使用 np.unravel_index 转化</p><p><code>np.unravel(indices, shape)</code></p></li><li><p>assignment 提供了 fast_layers.py 来实现快速卷积操作，比我自己写的循环代码要快 1000 多倍，使用了 im2col 技巧以及 Cpython extension</p></li><li><p>为什么在正则化的时候正则项中不包括偏差 b? 个人理解认为 b 对于正则化的贡献并不大，而 w 参数则占据了绝大部分的参数。</p></li></ol><h3 id="Spatial-Batch-Normalization"><a href="#Spatial-Batch-Normalization" class="headerlink" title="Spatial Batch Normalization"></a>Spatial Batch Normalization</h3><p>这是卷积神经网络特有的 batch normalization。之前使用的 batch normalization 面对的是 (N, D) 形状的数据，但卷积过后得到的输出是类似 (N, C, H, W) 这样的多维数据。那我们应该怎样去计算这一批数据的统计量 $\mu, \sigma$ 呢？</p><p>如果沿着之前的思维，我们只沿着样本数据轴 N 去计算 $\mu, \sigma$ </p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># data.shape = (N, C, H, W)</span>mean <span class="token operator">=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>data<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>var  <span class="token operator">=</span> np<span class="token punctuation">.</span>var<span class="token punctuation">(</span>data<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>这将会得到 (C, H, W) 形状的统计量，其中每一个值 (c, h, w)，其样本来自于 N 个像素点（同一 channel，同一位置）。但我们希望样本的数量更广泛一些，具体一点来说，我们希望样本来自于 N 个 feature map (H, W)，用 numpy 表示为</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># data.shape = (N, C, H, W)</span>mean <span class="token operator">=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>data<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>var <span class="token operator">=</span> np<span class="token punctuation">.</span>var<span class="token punctuation">(</span>data<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>这将会得到 (C,) 形状的统计量，即：得到了对于某一个 channel 的统计量，这是合理的，因为同一个 channel 我们使用的是同一个 kernel。这样我们不仅得到了更广泛样本的统计量，还减少了参数数量</p><p>如果要使用之前写的 batch_norm 函数的话可以将数据转化为 (N <em> H </em> W, C) ，在 numpy 中使用 transpose + reshape 就可以完成</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">data<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> C<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="Spatial-Group-Normalization"><a href="#Spatial-Group-Normalization" class="headerlink" title="Spatial Group Normalization"></a>Spatial Group Normalization</h3><p>一张图展示Batch Norm， Layer Norm ，Group Norm的区别</p><p><img src="/archives/407bb789/image-20210710193505933.png" alt="image-20210710193505933"></p><p>Group Norm可以理解为在layer Norm的基础上，输入维度为 (N, C, H, W)，对C进行分组，即 (N, G, C//G, H, W)。为了完成这一部分，重新思考了如何基于系统计算 back propagation</p><p><strong>可以以重要的中间变量为节点，根据计算图逐步推导梯度。难点在于有矩阵参与的计算，经常伴随着矩阵形状的改变，在进行 back propagation 中一定要让梯度跟着这些计算进行升维和降维，可以想象为梯度会随着这些节点形状的变化进行复杂的流动，有分流(例如降维度)，也有汇合(例如 broadcast)</strong></p><p>例如，在 forward pass 中 broadcast 会将矩阵升维，sum 会将矩阵降维，如果在 backward pass 中遇到 broadcast 操作时，则需要将 upper_grad 根据对应维度求和，举个例子，如果我们要求下面 X 的梯度的话，代码应该时这样的</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># input: X, X.shape = (N, D)</span><span class="token comment"># f(X) = X - np.mean(X)</span><span class="token comment"># upper_grad = dout, dout.shape = (N, D)</span>dmean <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dout<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token comment"># sum broadcast dimension</span>dmean <span class="token operator">=</span> dmean <span class="token operator">/</span> N<span class="token comment"># mean operation back prop</span>dX <span class="token operator">=</span> dout <span class="token operator">-</span> dmean<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>如果想不使用计算图直接按照一般的矩阵梯度计算，遇到对矩阵/向量求导时，就会出现张量，也就是说维度会增加，需要熟悉张量的运算及其思维。还是借用上面的例子，但我们把平均值作为 (N, D) 形状来看待</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># input: X, X.shape = (N, D)</span><span class="token comment"># f(X) = X - np.mean(X) * np.ones(X.shape)</span><span class="token comment"># upper_grad = dout, dout.shape = (N, D)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><script type="math/tex; mode=display">\frac{\partial{loss}}{\partial{f(x)}} = dout，\ f(x)=x-\mu\\\frac{\partial{f(x)}}{\partial{\mu}} = a\ ((N\times D) \times (N\times D))\ shape\ tensor\\\frac{\partial{loss}}{\partial{\mu}}=\frac{\partial{loss}}{\partial{f(x)}} ·\frac{\partial{f(x)}}{\partial{\mu}}=dout\\\frac{\partial{\mu}}{\partial{x}} = a\ ((N\times D) \times (N\times D))\ shape\ tensor\\\frac{\partial{loss}}{\partial{x}}=\frac{\partial{loss}}{\partial{f(x)}}·\frac{\partial{f(x)}}{\partial{x}} - \frac{\partial{loss}}{\partial{f(x)}}·\frac{\partial{f(x)}}{\partial{\mu}}·\frac{\partial{\mu}}{\partial{x}}=dout -dout·\frac{\partial{\mu}}{\partial{x}}</script><p>这将是一种普适的方法，更加抽象化，能够处理任何的矩阵求导，但不推荐实际中使用。</p><p>不论使用哪种方法，最核心的还是要理解梯度流动的本质——某一个变量的变动能够引起输出多少变动</p><h2 id="BUG"><a href="#BUG" class="headerlink" title="BUG"></a>BUG</h2><h3 id="Fully-Connected-Layer"><a href="#Fully-Connected-Layer" class="headerlink" title="Fully Connected Layer"></a>Fully Connected Layer</h3><p>现在卡在了 solver 上</p><p>不能得到 overfitting 的结果</p><ol><li><p>尝试更换 solver 看能否得到不一样的结果</p><p>失败了</p></li><li><p>尝试使用2016的所有答案，看是否是自己的代码出问题了</p><p>失败了</p><p>小技巧 Ctrl+r 能够更换 pycharm 相同字段</p></li><li><p>尝试更改 colab 本身的文件，使用2016年的colab文件</p><p>成功，原因在于 learning rate 太小了，不能找到全局最优</p></li></ol><h3 id="Batch-normalization-1"><a href="#Batch-normalization-1" class="headerlink" title="Batch normalization"></a>Batch normalization</h3><ol><li><p>卡在了计算 back prop 上</p><p>最后出现的失误还是在于每一个公式必须要精确才行</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">norm_x <span class="token operator">=</span> <span class="token punctuation">(</span>x <span class="token operator">-</span> sample_mean<span class="token punctuation">)</span> <span class="token operator">/</span> np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>sample_var <span class="token operator">+</span> eps<span class="token punctuation">)</span>norm_x <span class="token operator">=</span> <span class="token punctuation">(</span>x <span class="token operator">-</span> sample_mean<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span>np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>sample_var<span class="token punctuation">)</span> <span class="token operator">+</span> eps<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>上面两个式子虽然在计算结果上相差不多，但是在网络的计算中，一点点的误差传播过后会变得越来越大</p></li><li><p>尝试使用 jupyter 进行编程，遇到问题：The kernel appears to have died. It will restart automatically</p><p>以为是 jupyter 的问题，但测试了不同的软件都出错了，最终发现是自己代码的问题！当找了一圈没有找到答案时，可能就要怀疑自己了，而不是怀疑软件出了问题！不过这也有好处，让我决定放弃使用 pycharm 转战 vs code</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 课程 </category>
          
          <category> CS231N </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CS231N </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux/Windows 安装笔记</title>
      <link href="/archives/53e3a160.html"/>
      <url>/archives/53e3a160.html</url>
      
        <content type="html"><![CDATA[<h1 id="安装Linux笔记"><a href="#安装Linux笔记" class="headerlink" title="安装Linux笔记"></a>安装Linux笔记</h1><h2 id="安装过程"><a href="#安装过程" class="headerlink" title="安装过程"></a>安装过程</h2><ol><li><p>如何安装双系统：移步 <a href="https://www.bilibili.com/video/BV18W41137XB">bilibili</a>（建议安装最新版，美观且体验更友好）或者阅读 <a href="https://ubuntu.com/tutorials/install-ubuntu-desktop#1-overview">ubuntu 官方教程</a></p></li><li><p>设置 root 密码。然后创建新用户，并设置新用户密码以及 sudo 权限</p></li><li><p>修改 /etc/hostname，reboot 后永久更改主机名</p></li><li><p>可能出现启动 windows 的时候有 bitlocker，禁用 bitlocker 安全协议</p></li><li><p>配置代理 clash，从 youtube 上学的（迷途小书童），要点就是将配置文件 config.yaml 和 Country.mmdb 移动到 ~/.config/clash 文件夹下面，配置文件通过 clash for windows 生成，文件目录为 User/.config/clash(/profiles) 。通过 clash dashboard 切换节点 <a href="http://clash.razord.top/">http://clash.razord.top/</a></p><p>让Terminal走代理的方法(desktop上的settings中设定会改写terminal端，使用export改写则不会影响desktop)，参考 <a href="https://zhuanlan.zhihu.com/p/46973701">知乎链接</a></p></li><li><p>官网下载git anaconda chrome typora chrome baiduyun vscode软件并安装</p><p>conda install, pip install 下载速度慢时，请使用国内镜像源，例如：</p><ol><li><a href="https://mirrors.bfsu.edu.cn/help/anaconda/">北京外国语大学镜像源</a>（截至2021/6/15下载速度很快）</li><li><a href="https://mirror.tuna.tsinghua.edu.cn/help/anaconda/">清华大学镜像源</a></li><li><a href="https://mirror.nju.edu.cn/help/anaconda">南京大学镜像源</a>（自家的镜像源，当然要推荐一下😎）</li></ol></li><li><p>配置 nvidia driver: 根据 <a href="https://zhuanlan.zhihu.com/p/59618999">知乎链接</a> ，在命令行里下载推荐的driver。如果在配置 nvidia driver 的过程中出现连接不上显卡，可能需要关闭 security boot。参考 <a href="https://zhuanlan.zhihu.com/p/336429888">稚晖君</a> 的教程，下载安装 CUDA，选择 runfile。</p><p>如果想移除所有 cuda, cudnn, nvidia driver</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">sudo</span> <span class="token function">apt-get</span> remove --purge nvidia*<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>设置 cuda path</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token builtin class-name">export</span> <span class="token assign-left variable">CUDA_HOME</span><span class="token operator">=</span>/usr/local/cuda<span class="token builtin class-name">export</span> <span class="token assign-left variable">LD_LIBRARY_PATH</span><span class="token operator">=</span><span class="token variable">${CUDA_HOME}</span>/lib64<span class="token builtin class-name">export</span> <span class="token assign-left variable"><span class="token environment constant">PATH</span></span><span class="token operator">=</span><span class="token variable">${CUDA_HOME}</span>/bin:<span class="token variable">${<span class="token environment constant">PATH</span>}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>(2022/1/31 更新) 尝试使用命令行在 ubuntu 16.04 上更新驱动，不太顺利，因为 ppa 中好像没有对这 16.04 进行支持，最新仅支持到 430，通过其他方法可能成功，但我就不进行过多尝试了。最终使用 <code>sudo apt install nvidia-418</code> 恢复了之前的驱动版本，其中遇到的报错 <code>NVIDIA NVML Driver/library version mismatch</code>，参考了 <a href="https://stackoverflow.com/questions/43022843/nvidia-nvml-driver-library-version-mismatch">StackOverflow </a> 中的第二个回答解决</p><p>教程里还教了如何更新 apt source 为阿里云镜像源，镜像中的软件会持续而且下载速度很快，这里我选择更换为 <a href="https://mirror.nju.edu.cn/help/ubuntu">南京大学镜像源</a> 如下所示。同时教程里也设置了 sudo，让每一次 sudo 都不需要输入密码</p>  <pre class="line-numbers language-source.list" data-language="source.list"><code class="language-source.list"># 默认注释了源码镜像以提高 apt update 速度，如有需要可自行取消注释deb https://mirror.nju.edu.cn/ubuntu/ {{release_name}} main restricted universe multiverse# deb-src https://mirror.nju.edu.cn/ubuntu/ {{release_name}} main restricted universe multiversedeb https://mirror.nju.edu.cn/ubuntu/ {{release_name}}-updates main restricted universe multiverse# deb-src https://mirror.nju.edu.cn/ubuntu/ {{release_name}}-updates main restricted universe multiversedeb https://mirror.nju.edu.cn/ubuntu/ {{release_name}}-backports main restricted universe multiverse# deb-src https://mirror.nju.edu.cn/ubuntu/ {{release_name}}-backports main restricted universe multiversedeb https://mirror.nju.edu.cn/ubuntu/ {{release_name}}-security main restricted universe multiverse# deb-src https://mirror.nju.edu.cn/ubuntu/ {{release_name}}-security main restricted universe multiverse# 预发布软件源，不建议启用# deb https://mirror.nju.edu.cn/ubuntu/ {{release_name}}-proposed main restricted universe multiverse# deb-src https://mirror.nju.edu.cn/ubuntu/ {{release_name}}-proposed main restricted universe multiverse<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>请根据 Ubuntu 版本自行替换 </p></li></ol><div class="table-container"><table><thead><tr><th>版本</th><th><code>{{release_name}}</code></th></tr></thead><tbody><tr><td>Ubuntu 14.04 LTS</td><td>trusty</td></tr><tr><td>Ubuntu 16.04 LTS</td><td>xenial</td></tr><tr><td>Ubuntu 18.04 LTS</td><td>bionic</td></tr><tr><td>Ubuntu 20.04 LTS</td><td>focal</td></tr><tr><td>Ubuntu 20.10</td><td>groovy</td></tr><tr><td>Ubuntu 21.04</td><td>hirsute</td></tr></tbody></table></div><ol><li><p>pip install 遇到问题 enter your password to unlock your login keyring</p><p>解决方法，直接cancel，或者在passwd and key中更改密码</p></li></ol><h1 id="安装-Windows-笔记"><a href="#安装-Windows-笔记" class="headerlink" title="安装 Windows 笔记"></a>安装 Windows 笔记</h1><p>实验室有一个空的主机，比较老，想要重新清理一下自己用。我并没有选择重装整个系统，而是选择重置，即恢复出厂设置</p><p>资源下载：<a href="https://msdn.itellyou.cn/">MSDN</a> <a href="https://rufus.ie/zh/">rufus</a> MSDN 提供了需要的各个 Windows 版本的 iso，使用 rufus 将 iso 烧入到U盘里</p><p>Win10 安装教程：<a href="https://www.bilibili.com/video/BV1DJ411D79y/?spm_id_from=333.788.recommend_more_video.-1">bilibili</a></p><p>Windows 激活：<a href="https://github.com/TGSAN/CMWTAT_Digital_Edition/releases">github</a></p><p>github 如果下载不够快，自行搜索 github 镜像，这里留一个参考 <a href="https://ghproxy.com/">link</a></p><p>磁盘管理：<a href="https://www.bilibili.com/video/BV1Uj411f7wj">bilibili</a></p><p>Office 下载：<a href="https://otp.landian.vip/zh-cn/">Office Tool plus</a></p><p>Office Tool plus <a href="https://www.coolhub.top/archives/11">使用方法</a>：</p><ol><li><p>卸载原有的 office wps，并清除旧版本激活信息（激活页面 -&gt; 许可证管理 -&gt; 清除激活状态）</p></li><li><p>推荐 Microsoft 365 企业应用版</p></li><li><p>使用一键安装代码</p><pre class="line-numbers language-none"><code class="language-none">deploy /addProduct O365ProPlusRetail_zh-cn_Access,Bing,Groove,Lync,OneDrive,OneNote,Outlook,Publisher,Teams /channel Current /downloadFirst<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li><p>在之后使用过程中可能遇到许可证问题，可以使用工具箱中的<strong>修复Office许可证问题</strong>。此时需要一个 <a href="https://www.coolhub.top/tech-articles/kms_list.html">KMS 地址</a>，填入即可</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 编程 </category>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 安装教程 </tag>
            
            <tag> Linux </tag>
            
            <tag> Windows </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Git 教程</title>
      <link href="/archives/2121b11b.html"/>
      <url>/archives/2121b11b.html</url>
      
        <content type="html"><![CDATA[<h1 id="Git-reorganiszed-note"><a href="#Git-reorganiszed-note" class="headerlink" title="Git reorganiszed note"></a>Git reorganiszed note</h1><p>重新整理了 git 的常用操作命令，能够覆盖大部分版本管理场景，适合作为提纲进行复习</p><p>整理来自：<a href="https://www.bilibili.com/video/BV1FE411P7B3?from=search&amp;seid=1905221215711628694">bilibili</a> <a href="https://www.liaoxuefeng.com/wiki/896043488029600">廖雪峰教程</a></p><h2 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h2><p>当遇到国外资源下载很慢的时候，可以考虑使用镜像资源</p><p>视频里使用了淘宝镜像安装 windows 版本 <a href="https://npm.taobao.org/mirrors/">https://npm.taobao.org/mirrors/</a></p><p>ubuntu 直接使用 <code>apt install git</code> 使用阿里云镜像</p><h2 id="Git-配置"><a href="#Git-配置" class="headerlink" title="Git 配置"></a>Git 配置</h2><p>首先要理解的是，在windows 中 git bash 的基本操作命令和 Linux  terminal 是一样的。在 Linux 中 git 是集成到 terminal 当中的</p><h3 id="git-config"><a href="#git-config" class="headerlink" title="git  config"></a>git  config</h3><p>配置用户名和邮箱</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">git</span> config --global user.name <span class="token string">'your_name'</span><span class="token function">git</span> config --global user.email <span class="token string">'***@qq.com'</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>之后的所有提交都会使用你的用户和邮箱</p><p>还可以根据需求配置代理</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token comment"># 设置代理</span><span class="token function">git</span> config --global http.proxy http://127.0.0.1:1080<span class="token comment"># 查看代理</span><span class="token function">git</span> config --global --get http.proxy<span class="token comment"># 取消代理</span><span class="token function">git</span> config --global --unset http.proxy<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="Git-基本理论"><a href="#Git-基本理论" class="headerlink" title="Git 基本理论"></a>Git 基本理论</h2><p>直接上图，重点关注左侧命令</p><p><img src="/archives/2121b11b/image-20210628141830141.png" style="zoom:80%;"></p><p>从工作区 -&gt; 暂存区：<code>git add</code></p><p>从暂存区 -&gt; 本地仓库：<code>git commit</code></p><p>从本地仓库 -&gt; 远程仓库：<code>git push</code></p><p>这三个命令就能够让你感受到 git 版本控制的基本流程</p><h2 id="Git-仓库搭建"><a href="#Git-仓库搭建" class="headerlink" title="Git 仓库搭建"></a>Git 仓库搭建</h2><h3 id="git-init-amp-git-clone"><a href="#git-init-amp-git-clone" class="headerlink" title="git init &amp; git clone"></a>git init &amp; git clone</h3><p>生成仓库(master 分支)的两种方法</p><ol><li><code>git init</code> 初始化，生成 .git 文件</li><li><code>git clone url</code> 克隆远程仓库</li><li><code>git clone -b branch_name url</code> 克隆指定分支</li></ol><p>删除仓库则只需要删除 .git 文件夹即可</p><h3 id="git-proxy-代理"><a href="#git-proxy-代理" class="headerlink" title="git proxy 代理"></a>git proxy 代理</h3><p>如果在 clone 项目的时候发现速度很慢，推荐使用国内的镜像源，如：<a href="https://gitclone.com/">gitclone</a> <a href="https://doc.fastgit.org/zh-cn/">fastgit</a></p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">git</span> config --global url.<span class="token string">"https://hub.fastgit.org/"</span>.insteadOf <span class="token string">"https://github.com/"</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="Git-文件基本操作"><a href="#Git-文件基本操作" class="headerlink" title="Git 文件基本操作"></a>Git 文件基本操作</h2><h3 id="git-status"><a href="#git-status" class="headerlink" title="git status"></a>git status</h3><p><code>git status</code> 查看 git 文件状态，<code>git status file_name</code> 可指定文件</p><p>文件的几种状态：</p><ol><li>untracked 文件在文件夹中，从没有 add 过</li><li>unmodify 文件已经 commit 且库中最新版本和当前文件是一致的，可以通过 <code>git rm</code> 将其移出版本库管理</li><li>modified 文件在 commit 或者 add 过后有过修改，可以使用 <code>git checkout</code> 丢弃修改</li><li>staged (文件在之前 commit 过后有过修改) 经过 add，没有 commit</li></ol><p>当存在文件为中文命名时 git status 会显示为转义数字串形如 \351\237… 这样的乱码解决方法如下</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">git</span> config --global core.quotepath <span class="token boolean">false</span><span class="token comment"># core.quotepath的作用是控制路径是否编码显示的选项, 当字符为中文时会转义输出</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h3 id="gitignore"><a href="#gitignore" class="headerlink" title=".gitignore"></a>.gitignore</h3><p>有些时候我们不想把某些文件纳入版本控制中，可在主目录下建立 .gitignore 文件，例如你不详把 txt 类型文件进行版本控制，则在 .gitignore 文件中写入 *.txt 即可，其他具体规则不作介绍，也比较简单。</p><h3 id="git-add"><a href="#git-add" class="headerlink" title="git add"></a>git add</h3><p><code>git add file_name</code> 将文件加入暂存区，文件成为 staged 状态</p><p><code>git add .</code> 将当前文件夹 add，比较方便快捷</p><h3 id="git-commit"><a href="#git-commit" class="headerlink" title="git commit"></a>git commit</h3><p><code>git commit -m 'message content'</code> 将暂存区所有文件加入到版本库中，并留下此次提交的 message</p><p><code>git commit -am 'message content'</code> 将同时完成 <code>git add all</code>（即将所有改动文件加入暂存区）和 <code>git commit</code> 操作</p><p><code>git commit --amend</code> 可以修改上一次提交的 commit message</p><h3 id="git-rm"><a href="#git-rm" class="headerlink" title="git rm"></a>git rm</h3><p><code>git rm --cached file_name</code> 将已经 commit 的文件从版本库中移除变为 untracked 文件</p><p><code>git rm file_name</code> 不使用参数则代表彻底删除该文件</p><h2 id="Git-版本回退"><a href="#Git-版本回退" class="headerlink" title="Git 版本回退"></a>Git 版本回退</h2><h3 id="git-log-amp-git-reflog"><a href="#git-log-amp-git-reflog" class="headerlink" title="git log &amp; git reflog"></a>git log &amp; git reflog</h3><p><code>git log</code> 查看 commit 历史记录，id，作者等信息</p><p><code>git reflog</code> 查看所有的操作</p><h3 id="git-reset"><a href="#git-reset" class="headerlink" title="git reset"></a>git reset</h3><p><code>git reset --hard commit_id</code> 将回退到某一个 commit 版本，id 只用写前几位，git 自动识别</p><p><code>git reset --hard HEAD^</code> 将回退到上一个 commit 版本，如果回退两个则是 HEAD^^</p><p><code>--hard</code> 参数其实代表回退到某个 commit 后，该 commit 之后的记录都会被丢弃。但 git 永远都有后悔药吃，如果回退到以前的版本想要再回来，使用 git reflog 查看所有命令</p><h3 id="git-checkout"><a href="#git-checkout" class="headerlink" title="git checkout"></a>git checkout</h3><p><code>git checkout filename</code> 能够让文件回到最近一次 add 或者 commit 时的状态</p><h2 id="分支与冲突"><a href="#分支与冲突" class="headerlink" title="分支与冲突"></a>分支与冲突</h2><h3 id="git-branch"><a href="#git-branch" class="headerlink" title="git branch"></a>git branch</h3><p>从这里我们可以更加深入理解 git 的工作形象，working tree</p><p>除了 master 分支，我们还可以创建其他分支，HEAD 所指的就是 working tree “生长”的地方，然后我们将分支合并，也即让 master “赶上来”，再删除 dev 分支。git 分支还有一个一般规则是，master 分支永远是最稳定的分支，开发都在 dev 或其他分支上进行</p><p><img src="/archives/2121b11b/branch_1.png" style="zoom: 50%;"></p><p><img src="/archives/2121b11b/branch_2.png" style="zoom: 50%;"></p><p><img src="/archives/2121b11b/branch_3.png" style="zoom:50%;"></p><p><code>git branch</code> 可以查看分支情况</p><p><code>git branch -d branch_name</code> 用于删除分支</p><h3 id="git-switch"><a href="#git-switch" class="headerlink" title="git switch"></a>git switch</h3><p><code>git switch -c branch_name</code> 使用 git swich 来创建分支</p><p><code>git switch branch_name</code> 使用 git swich 来切换分支</p><p><code>git switch -c branch_name origin/branch_name</code> 创建分支并复制远程的分支到本地</p><h3 id="git-merge"><a href="#git-merge" class="headerlink" title="git merge"></a>git merge</h3><p><code>git merge branch_name</code> 将某个分支合并到当前分支</p><p>如果发生了冲突：两个 branch 中在同一个文件中有不同的修改而无法合并，那么需要解决冲突。（判断文件是否有修改，是根据 commit id 之类的标记节点来判断的，但是否存在冲突则是根据文件的内容）</p><p><img src="/archives/2121b11b/branch_4.png" style="zoom:50%;"></p><p>先使用 <code>git status</code> 查看哪个文件发生冲突，然后使用 vim 编辑，git 会自动在文档中标明冲突的地方。怎样修改无所谓，只要你 add &amp; commit 过后，git 就会默认冲突解决，并将你的文件作为最新的版本加入版本库中，更新 working tree</p><p>如果对于 git 中 recursive 3-way merge 算法感兴趣，可以参看 <a href="https://en.wikipedia.org/wiki/Merge_(version_control">维基百科</a>)</p><h2 id="远程仓库"><a href="#远程仓库" class="headerlink" title="远程仓库"></a>远程仓库</h2><h3 id="添加远程仓库-github-or-gitee"><a href="#添加远程仓库-github-or-gitee" class="headerlink" title="添加远程仓库 github or gitee"></a>添加远程仓库 github or gitee</h3><p>gitee 为国内网站，传输速度更快。通过以下步骤将本机与远程连接（以 github 为例）：</p><ol><li><p>注册 github 账号</p></li><li><p>生成 ssh 公钥</p><ol><li><p>在本机 user 目录下找到 ssh 文件夹（安装 git 过后这个文件夹会自动生成）</p></li><li><p>在 shell 中运行以下命令生成 ssh 密钥，其中 rsa 是一种加密算法 </p><p><code>ssh-keygen -t rsa</code></p><p>之后你就能在 .ssh 文件中找到 id_rsa 和 id_rsa.pub 文件</p></li></ol></li><li><p>添加 id_rsa.pub 到 github 账户设置中</p></li></ol><p>这样就把本机和远程仓库连接起来了，具体的说是将本机与你的 github 账号通过 ssh 连接起来了</p><h3 id="git-remote"><a href="#git-remote" class="headerlink" title="git remote"></a>git remote</h3><p>你的账号里可以有很多的仓库，我们想要将本地仓库与某一个指定仓库链接使用以下命令即可</p><p><code>git remote add origin [url]</code></p><p>远程仓库的名字叫 origin，这是 git 的默认叫法，url 是仓库的 https 或者 ssh</p><p><code>git remote -v</code> 查看添加的远程仓库，<code>-v</code> 代表 verbose 模式，该不带参数仅返回远程仓库的名字 <code>origin</code> </p><p><code>git remote remove origin</code> 移除与远程仓库的链接</p><h3 id="git-push"><a href="#git-push" class="headerlink" title="git push"></a>git push</h3><p>把本地库的内容推送到远程仓库，使用下面命令</p><p><code>git push -u orgin master</code></p><p>这样就把本地 master 分支内容推送到了远程的 master 分支。-u 参数为 set upstream 的意思，在推送的同时将我们的本地 master 分支和远程 master 分支联系起来（相当于作了 <code>git branch -u origin/master</code> ），今后则可以直接输入 git push 来简化推送命令，强烈建议在第一次 push 的时候带上 -u 参数</p><p>其他本地分支与远程分支的 push 和连接也是一样的，把上面命令的 master 改为对应分支的名字（例如：dev 分支）即可，前提是本地要切换到那个分支，且远程存在同名的分支</p><p>个人认为 <code>git push</code> 一般是在同名的本地分支和远程分支之间进行</p><h3 id="git-pull"><a href="#git-pull" class="headerlink" title="git pull"></a>git pull</h3><p>文件冲突不仅出现在本地的 merge 当中，也存在在 push 操作当中。push 的本质也是将本地和远程这两个 branch 进行融合。当这个远程仓库只有你一个人在 push 时，是不会有冲突的，因为远程的 working tree 只会一直往前延伸；当有多个人都在对某一个文件进行修改，working tree 就相当于有了多个分支，在 push 的时候就会形成冲突。如果有远端的冲突形成，就需要使用 <code>git pull</code></p><p><code>git pull</code> 有两个作用，一个是拉取代码到本地，另一个是尝试与本地代码合并，如果不能使用 fast forward 合并，则需要自己来修改冲突部分，这部分和 <code>git merge</code> 是一样的</p><h3 id="搭建自己的远程仓库"><a href="#搭建自己的远程仓库" class="headerlink" title="搭建自己的远程仓库"></a>搭建自己的远程仓库</h3><blockquote><p>远程仓库实际上和本地仓库没啥不同，纯粹为了7x24小时开机并交换大家的修改。GitHub就是一个免费托管开源代码的远程仓库。但是对于某些视源代码如生命的商业公司来说，既不想公开源代码，又舍不得给GitHub交保护费，那就只能自己搭建一台Git服务器作为私有仓库使用。</p></blockquote><p>依旧是参考 <a href="https://www.liaoxuefeng.com/wiki/896043488029600/899998870925664">廖雪峰教程</a>，不过自己在实现时有一些区别。在进行 git clone 操作时，克隆的链接不应该使用绝对路径 <code>git clone git@server:/srv/sample.git</code> 应该去掉第一个斜杠 <code>git clone git@server:srv/sample.git</code></p><h2 id="Git-IDE"><a href="#Git-IDE" class="headerlink" title="Git + IDE"></a>Git + IDE</h2><p>现在 git 和很多 IDE 都有联动，可以直接在 IDE 中方便的操作 git，甚至将 git 可视化，可以直观看到你对文件的修改</p><p>以 pycharm 和 vscode 为例，只要在你的项目文件夹下有 .git 文件即可，如果没有则使用 git init 新建 </p>]]></content>
      
      
      <categories>
          
          <category> 编程 </category>
          
          <category> Tools </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 教程 </tag>
            
            <tag> Git </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hexo-theme-matery 教程</title>
      <link href="/archives/b129f5ae.html"/>
      <url>/archives/b129f5ae.html</url>
      
        <content type="html"><![CDATA[<h1 id="hexo-theme-matery-note"><a href="#hexo-theme-matery-note" class="headerlink" title="hexo-theme-matery note"></a>hexo-theme-matery note</h1><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>参考原 github 项目进行整理：<a href="https://github.com/blinkfox/hexo-theme-matery">https://github.com/blinkfox/hexo-theme-matery</a></p><h3 id="config-yml-的修改建议"><a href="#config-yml-的修改建议" class="headerlink" title="_config.yml 的修改建议"></a>_config.yml 的修改建议</h3><p>在 hexo 根目录下的 _config.yml 文件中：</p><ol><li><p>切换 theme 为 hexo-theme-matery</p></li><li><p>url 改为网站 url (如：<a href="http://xxx.github.io">http://xxx.github.io</a>)</p></li><li><p>per_page 数值改为6及6的倍数，这样文章列表在各个屏幕下都能较好显示</p></li><li><p>插入图片（有点复杂，可以先跳过）。根据 <a href="https://zhuanlan.zhihu.com/p/265077468">知乎链接</a> 配置好 post_asset_folder，里面提到的 typora 技巧也很实用，建议采用。且一般来讲链接中提到的 hexo-renderer-marked 插件都是已经内置好的，不然你的博客不会渲染成功。</p><p>但是这个方法不能控制图片大小，而且配置过 typora 后还要再改图片的路径。我再下载了 hexo-asset-image 插件过后，直接用 typora 中的 html 方法 <code>&lt;img src='post_name/img.jpg'&gt;</code>引用图片，不需要二次更改路径</p></li></ol><h3 id="新建分类-categories-页"><a href="#新建分类-categories-页" class="headerlink" title="新建分类 categories 页"></a>新建分类 categories 页</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">sudo</span> hexo new page <span class="token string">'categories'</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>categories 页是用来展示所有分类的页面</p><p>修改 <code>/source/categories/index.md</code> 文件的 front-matter (Front-matter 是文件最上方以 —- 分隔的区域，用于指定个别文件的变量)</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">---title: categoriesdate: <span class="token number">2018</span>-09-30 <span class="token number">17</span>:25:30type: <span class="token string">"categories"</span>layout: <span class="token string">"categories"</span>---<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>关于 page 和 post 的区别：两者其实很相似，你可以把 page 看作是特殊的 post，用来放置一些特殊内容：如分类、标签等等。</p><p>hexo 的分类是有等级关系的，我们以下面的 post front-matter 为例</p><pre class="line-numbers language-markdown" data-language="markdown"><code class="language-markdown">title: 我的博客搭建笔记date: 2021-06-29 15:26:41tags:<span class="token list punctuation">-</span> hexo<span class="token list punctuation">-</span> 博客搭建categories:<span class="token list punctuation">-</span> 软件基础<span class="token list punctuation">-</span> hexo<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>这个文件在分类时会被分配到所有提到的 categories 中，这些 categories 的路径是逐渐往下的 <code>/categories/软件基础/hexo/</code>，它们都有自己的 page 来收纳属于自己类别的文章。</p><h3 id="新建标签-tags-页"><a href="#新建标签-tags-页" class="headerlink" title="新建标签 tags 页"></a>新建标签 tags 页</h3><p>新建 page</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">hexo new page <span class="token string">"tags"</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>修改对应 index.md</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">---title: tagsdate: <span class="token number">2018</span>-09-30 <span class="token number">18</span>:23:38type: <span class="token string">"tags"</span>layout: <span class="token string">"tags"</span>---<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>给 post 指定 tags 只需要在 front-matter 中写好就行了，如上面 categories 的例子。</p><h3 id="新建关于我-about-页"><a href="#新建关于我-about-页" class="headerlink" title="新建关于我 about 页"></a>新建关于我 about 页</h3><h3 id="新建留言板-contact-页"><a href="#新建留言板-contact-页" class="headerlink" title="新建留言板 contact 页"></a>新建留言板 contact 页</h3><h3 id="新建友情链接-friends-页"><a href="#新建友情链接-friends-页" class="headerlink" title="新建友情链接 friends 页"></a>新建友情链接 friends 页</h3><p>新建方法都是和上面的方法一样的</p><h2 id="菜单导航配置与渲染"><a href="#菜单导航配置与渲染" class="headerlink" title="菜单导航配置与渲染"></a>菜单导航配置与渲染</h2><h3 id="名称、路径、图标"><a href="#名称、路径、图标" class="headerlink" title="名称、路径、图标"></a>名称、路径、图标</h3><p>配置菜单导航的名称、路径url、和图标icon，配置文件在 <code>themes/hexo-theme-matery/._config.yml</code></p><p>更改 menu 部分即可</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">menu:  <span class="token comment"># 把 Index 改为 Home</span>  Home:    url: /    icon: fas fa-home  Tags:    url: /tags    icon: fas fa-tags<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>可该的部分：</p><ol><li>名称可以是中文</li><li>图标可以在 <a href="https://fontawesome.com/icons">Font Awesome</a> 中查找</li><li>还可以使用二级菜单。二级菜单在实现上可以理解为创建了一个软链接，到你指定的 page 上。</li></ol><p>由于我对于这个导航还是比较满意，就不作过多修改</p><h3 id="修改页脚"><a href="#修改页脚" class="headerlink" title="修改页脚"></a>修改页脚</h3><p>页脚信息可能需要做定制化修改，修改的地方在主题文件的 <code>/layout/_partial/footer.ejs</code> 文件中，包括站点、使用的主题、访问量等。</p><p>由于代码看不明白，找到了一个比较详细的 <a href="https://sunhwee.com/posts/6e8839eb.html">教程</a>。根据教程修改了版权信息，增加了网站运行时间，访问人数的代码目前不需要修改</p><h3 id="代码高亮"><a href="#代码高亮" class="headerlink" title="代码高亮"></a>代码高亮</h3><p>修改 Hexo 根目录下 <code>_config.yml</code> 文件中 <code>highlight.enable</code> 的值为 <code>false</code>，并将 <code>prismjs.enable</code> 的值设置为 <code>true</code></p><p>以上的设置并不管用，没有高亮也没有行号</p><p>但是我下载了 hexo-prism-plugin 又卸载掉这个插件，就有高亮了，但依旧没有行号</p><p>考虑是 matery.css 文件中 pre 下 paddidng 不够大的问题，增加 padding 但依然没能解决</p><p>考虑是不是本身 prism 文件出了问题，重新到官网上下载了 prism.js 和 prism.css 替换原来系统中对应的文件，同时调整上面提到的 padding 参数，最后成功！</p><p>prism.js 文件位置在 <code>node_modules/prismjs</code></p><p>prism.css 文件位置在 <code>themes/hexo-theme-matery/source/libs/prism</code></p><p>现在想要去除隔离的那条竖线，尝试重复 <a href="https://github.com/blinkfox/hexo-theme-matery/issues/103">github issue</a> 的操作，操作过后竖线没有去除，不过稍微调整了一下代码位置，也挺好看</p><p>最终，我通过修改 prism.css 中 border-right 为 0px，去除了行号和代码之间的分隔线！</p><pre class="line-numbers language-css" data-language="css"><code class="language-css"><span class="token selector">.line-numbers .line-numbers-rows</span> <span class="token punctuation">{</span><span class="token property">position</span><span class="token punctuation">:</span> absolute<span class="token punctuation">;</span><span class="token property">pointer-events</span><span class="token punctuation">:</span> none<span class="token punctuation">;</span><span class="token property">top</span><span class="token punctuation">:</span> -0.2em<span class="token punctuation">;</span><span class="token property">font-size</span><span class="token punctuation">:</span> 100%<span class="token punctuation">;</span><span class="token property">left</span><span class="token punctuation">:</span> -3.8em<span class="token punctuation">;</span><span class="token property">width</span><span class="token punctuation">:</span> 3em<span class="token punctuation">;</span> <span class="token comment">/* works for line-numbers below 1000 lines */</span><span class="token property">letter-spacing</span><span class="token punctuation">:</span> -1px<span class="token punctuation">;</span><span class="token property">border-right</span><span class="token punctuation">:</span> 0px solid #999<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>现在解决标号和 code 没对齐的问题，修改 prism.css 文件中 <code>.line-numbers .line-numbers-rows</code> 下 top 参数为 -0.2em，微调成功！治好了强迫症！</p><h3 id="渲染表格"><a href="#渲染表格" class="headerlink" title="渲染表格"></a>渲染表格</h3><p>hexo 对表格的渲染与 typora 是不一样的，正文和表格需要间隔两行。而且 hexo 并不会显示双括号，建议使用代码格式引用双括号 <code>{{}}</code></p><h2 id="配置-theme-中的-config-yml"><a href="#配置-theme-中的-config-yml" class="headerlink" title="配置 theme 中的 _config.yml"></a>配置 theme 中的 _config.yml</h2><ol><li><p>根据配置文件中的注释，简单修改了下面的设置</p><p>dream, music, video, recommend, github &amp; social link, reward, clicklove, myProjects, mySkills, subtitle, banner</p></li><li><p>取消 rainbow 特效</p><pre class="line-numbers language-css" data-language="css"><code class="language-css"><span class="token selector">.bg-cover:after</span> <span class="token punctuation">{</span>    <span class="token property">-webkit-animation</span><span class="token punctuation">:</span> none<span class="token punctuation">;</span>    <span class="token property">animation</span><span class="token punctuation">:</span> none<span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre></li><li><p>在 hexo d 时遇到问题</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">err: Error: Spawn failed<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>第二天自动好了，根本原因是网络没有走通的问题，之后可能再次遇到，到时候再解决，建议在 github 上搜索</p><p>现在发现了，由于我使用的是 root 用户下的 git 配置，而我 root 用户下 git config 没有设置好参数所以部署失败。我在 root 目录的 .gitconfig 和 .ssh 下配置好了 user.name ssh 等必要 git 配置就成功了。这说明了在 linux 下不同的用户都需要自己去配置 git</p></li><li><p>修改博客 feature image 只选用1张简单图来代表。原来有 24 张图，我把24个路径全部改为同1张图。</p></li><li><p>因为之后需要写入数学公式，将 mathjax 改为 true。但发现显示公式渲染不正常，而且小括号显示不出来。根据 <a href="https://github.com/blinkfox/hexo-theme-matery/issues/119">github issue</a> 解决无法换行问题，将渲染器换为 hexo-renderer-kramed 而且代码高亮插件似乎并没受到影响。根据 <a href="https://adaning.github.io/posts/33457.html">MathJax常见问题</a> 解决小括号无法显示问题。根据 <a href="https://www.jianshu.com/p/7ab21c7f0674">博客</a> 再进一步配置 kramed 渲染，解决大括号的冲突问题。也遇到过本地 <code>hexo s</code> 能够渲染公式，但是 <code>hexo d</code> 部署后公式无法渲染的情况，根据 <a href="https://blog.csdn.net/qq_44846324/article/details/114582328">博客</a> 中解决语义冲突解决问题</p></li></ol><h2 id="配置-matery-css"><a href="#配置-matery-css" class="headerlink" title="配置 matery.css"></a>配置 matery.css</h2><p>为了进一步设置我们的网页，让其更具有个性化，就需要进一步调整 matery.css 文件。</p><ol><li><p>设置 导航颜色</p><pre class="line-numbers language-css" data-language="css"><code class="language-css"><span class="token selector">.bg-color</span> <span class="token punctuation">{</span>    <span class="token property">background-image</span><span class="token punctuation">:</span> <span class="token function">linear-gradient</span><span class="token punctuation">(</span>to right<span class="token punctuation">,</span> #BEBEBE 0%<span class="token punctuation">,</span> #708090 100%<span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>查询颜色代码网址：<a href="https://tool.oschina.net/commons?type=3">https://tool.oschina.net/commons?type=3</a></p></li><li><p>由于刚开始加载时 banner 图片没有迅速加载，会默认先加载橙色，我改成灰色</p><p>修改“\Hexo\themes\hexo-theme-matery\layout\ _partial\index-cover.ejs”文件中的第63行即可。</p><pre class="line-numbers language-ejs" data-language="ejs"><code class="language-ejs"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>div</span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>carousel-item red white-text bg-cover about-cover<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>把“red”修改为其他颜色即可。我改为 slate gray</p></li><li><p>改变 progress-bar 颜色</p></li><li><p>改变回到顶部按钮颜色 top-scroll</p></li><li><p>改变封面打字效果的文字大小、颜色 .bg-cover .description</p></li><li><p>修改了打字效果的颜色过后，我发现文章标题的颜色也跟着改了。解决方法是在下面的 .bg-cover .description 增加属性 color: #color_code，这样就能分别调整它们的颜色。</p></li><li><p>修改 about 页面链接颜色 aboutme</p></li><li><p>修改 archive 页面时间线颜色 cd-timeline</p></li></ol><h2 id="插件优化"><a href="#插件优化" class="headerlink" title="插件优化"></a>插件优化</h2><h3 id="文章-url-优化"><a href="#文章-url-优化" class="headerlink" title="文章 url 优化"></a>文章 url 优化</h3><p>我没有使用项目中主要介绍的转拼音方法，那样生成的链接太长了，而是使用 hexo-abbrlink 插件</p><pre class="line-numbers language-sehll" data-language="sehll"><code class="language-sehll">npm install hexo-abbrlink --save<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>在根目录 _config.yml 文件中修改</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">permalink</span><span class="token punctuation">:</span> archives/<span class="token punctuation">:</span>abbrlink.html<span class="token key atrule">abbrlink</span><span class="token punctuation">:</span>    <span class="token key atrule">alg</span><span class="token punctuation">:</span> crc32   <span class="token comment">#算法： crc16(default) and crc32</span>    <span class="token key atrule">rep</span><span class="token punctuation">:</span> hex     <span class="token comment">#进制： dec(default) and hex</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>在 hexo 三连时遇到报错</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">FATAL YAMLException: duplicated mapping key <span class="token punctuation">(</span><span class="token number">111</span>:1<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>说明有原配置文件中已经有 permalink 的定义，我们需要把里本身的 permalink 代码注释掉，完美运行！现在我们的文章 url 最后是特殊的数字id <code>/archives/48732.html</code></p><h3 id="文章字数统计插件"><a href="#文章字数统计插件" class="headerlink" title="文章字数统计插件"></a>文章字数统计插件</h3><h3 id="添加-emoji-表情支持"><a href="#添加-emoji-表情支持" class="headerlink" title="添加 emoji 表情支持"></a>添加 emoji 表情支持</h3><h3 id="搜索"><a href="#搜索" class="headerlink" title="搜索"></a>搜索</h3><p>上面三个部分都是按照 hexo-thme-matery github 项目配置的</p><h3 id="评论插件utterance"><a href="#评论插件utterance" class="headerlink" title="评论插件utterance"></a>评论插件utterance</h3><p>matery 在配置文件中告诉我们，有的评论软件有安全隐患，推荐使用 utterance</p><p>尝试 utterance，如果成功，则返回卸载 valine，注销 lean cloud</p><p>也尝试了 livere 安装也很不友好</p><p>成功在 contact 页面下展示了 utterance，方法是在 contact.ejs 文档下找了一个地方插入下面的代码（记得改为 r自己的 github repo，形式为 <owner>/<name> ），</name></owner></p><pre class="line-numbers language-ejs" data-language="ejs"><code class="language-ejs"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>script</span> <span class="token attr-name">src</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>https://utteranc.es/client.js<span class="token punctuation">"</span></span><span class="token attr-name">repo</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>[ENTER REPO HERE]<span class="token punctuation">"</span></span><span class="token attr-name">issue-term</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>pathname<span class="token punctuation">"</span></span><span class="token attr-name">theme</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>github-light<span class="token punctuation">"</span></span><span class="token attr-name">crossorigin</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>anonymous<span class="token punctuation">"</span></span><span class="token attr-name">async</span><span class="token punctuation">&gt;</span></span><span class="token script"><span class="token language-javascript"></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>script</span><span class="token punctuation">&gt;</span></span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>我插入在 <code>&lt;div class="card"&gt;</code> 后面，是管用的。因为原项目说，插入到你的 layout 需要出现的地方，我不懂前端的代码，只能胡乱插入了，管用就行！我猜测这是一个“卡片类”能够存放你的内容，以白色卡片在页面中展示出来。</p><p>用同样的方法在 post 下添加评论。找到 <code>/hexo-theme-matery/layout/_partial/post-detail.ejs</code> 文件，找到评论的布局之处（搜索主题自带的评论插件如 gittalk，就能找到）插入上面的代码即可。但是渲染过后背景是透明的，不太好看，我希望想 contact 一样有白色背景，那就复制一下 contact.ejs 中的“卡片类”评论区就行了。</p><h3 id="分类优化"><a href="#分类优化" class="headerlink" title="分类优化"></a>分类优化</h3><p>matery 主题的分类没有多层分类，在 categories 页面只有像 tag 一样标签，这样的分类又有什么用呢？根据 <a href="https://notes.zhangxiaocai.cn/posts/5a99eb4d.html#toc-heading-8">Hexo Matery 主题添加多级分类</a> 进行设置，可以得到更好的分类页，类别之间将有层次关系</p><p>具体来讲，采用了博客里最新更新的代码，又作了以下改动：</p><ol><li><p>给 category-item, category-count 等增加 color 属性，改为自己喜欢的颜色</p></li><li><p>给 category-title 增加 font-size 属性，修改标题大小</p></li><li><p>由于每次进入目录默认要展开一个类别，改动下方代码，让所有类别初始状态默认折叠</p><pre class="line-numbers language-js" data-language="js"><code class="language-js"><span class="token comment">/* origin code: &lt;li  class="&lt;%= subCats.length &gt; 0 ? 'active' : '' %&gt;" &gt; */</span><span class="token operator">&lt;</span>li  <span class="token keyword">class</span><span class="token operator">=</span><span class="token string">"&lt;%= subCats.length &gt; 10000 ? 'active' : '' %&gt;"</span> <span class="token operator">&gt;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li><li><p>删除箭头变化 <code>category-item-action col s11 m11</code></p></li></ol><h2 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h2><h3 id="网站SEO优化"><a href="#网站SEO优化" class="headerlink" title="网站SEO优化"></a>网站SEO优化</h3><p>Search Engine Optimization</p><p>将自己的网站提交给搜索引擎</p><h3 id="不断更新"><a href="#不断更新" class="headerlink" title="不断更新"></a>不断更新</h3><p>持续更新博客内容，完善分类</p>]]></content>
      
      
      <categories>
          
          <category> 软件 </category>
          
          <category> Hexo </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo </tag>
            
            <tag> 博客搭建 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>我的博客搭建笔记</title>
      <link href="/archives/4984.html"/>
      <url>/archives/4984.html</url>
      
        <content type="html"><![CDATA[<h1 id="个人博客搭建-hexo"><a href="#个人博客搭建-hexo" class="headerlink" title="个人博客搭建 hexo"></a>个人博客搭建 hexo</h1><p>整体参考过程为 CodeSheep 视频：<a href="https://www.bilibili.com/video/BV1Yb411a7ty">https://www.bilibili.com/video/BV1Yb411a7ty</a></p><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><h3 id="Node-js-amp-npm"><a href="#Node-js-amp-npm" class="headerlink" title="Node.js &amp; npm"></a>Node.js &amp; npm</h3><p>参考链接：<a href="https://developer.aliyun.com/article/760687">https://developer.aliyun.com/article/760687</a></p><p>我选择了 apt 安装</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">sudo</span> <span class="token function">apt</span> update<span class="token function">sudo</span> <span class="token function">apt</span> <span class="token function">install</span> nodejs <span class="token function">npm</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>版本信息</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">nodejs --versionv10.19.0<span class="token function">npm</span> --version<span class="token number">6.14</span>.4<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>版本还是有点老旧</p><h3 id="淘宝镜像-cnpm"><a href="#淘宝镜像-cnpm" class="headerlink" title="淘宝镜像 cnpm"></a>淘宝镜像 cnpm</h3><p>cnpm 的官方介绍是：cnpm是一个完整 npmjs.or 镜像，你可以用此代替官方版本(只读)，同步频率目前为 <strong>10分钟</strong> 一次以保证尽量与官方服务同步。</p><p>安装了 cnpm 就可以使用镜像资源下载包，如果不希望使用镜像资源则换回 npm 命令即可。使用如下命令安装</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">sudo</span> <span class="token function">npm</span> <span class="token function">install</span> -g cnpm --registry<span class="token operator">=</span>https://registry.npm.taobao.org<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="hexo"><a href="#hexo" class="headerlink" title="hexo"></a>hexo</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">sudo</span> cnpm <span class="token function">install</span> -g hexo-cli<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>版本信息</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">hexo -vhexo-cli: <span class="token number">4.3</span>.0os: linux <span class="token number">5.4</span>.0-77-generic Ubuntu <span class="token number">20.04</span>.2 LTS <span class="token punctuation">(</span>Focal Fossa<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h2 id="搭建博客"><a href="#搭建博客" class="headerlink" title="搭建博客"></a>搭建博客</h2><h3 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">mkdir</span> blog <span class="token operator">&amp;&amp;</span> <span class="token builtin class-name">cd</span> blog<span class="token function">sudo</span> hexo init<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>如果哪里出错了，想重来，直接删除 blog 文件夹即可</p><h3 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">sudo</span> hexo server<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>遇到报错</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">INFO  Validating configINFO  Start processingFATAL <span class="token punctuation">{</span> err:   TypeError: line.matchAll is not a <span class="token keyword">function</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>原因在于 nodejs 版本太低，尝试使用 n 升级 nodejs</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">sudo</span> <span class="token function">npm</span> <span class="token function">install</span> -g n<span class="token function">sudo</span> n latest<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>查看版本</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">node -vv16.4.0<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>成功启动 hexo server，你可以通过 <a href="http://localhost:4000">http://localhost:4000</a> 访问你的本地博客啦！</p><h3 id="写第一篇文章"><a href="#写第一篇文章" class="headerlink" title="写第一篇文章"></a>写第一篇文章</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">sudo</span> hexo new <span class="token string">'Fisrt Blog'</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>信息</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">INFO  Validating configINFO  Created: /home/declan/Documents/blog/source/_posts/First-Blog.md<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><p>你的文章位置在上面的路径中可以找到，可以通过 markdown 语法进行书写</p><h3 id="生成"><a href="#生成" class="headerlink" title="生成"></a>生成</h3><p>清理一些缓存，然后生成我们的页面，同样使用 hexo server 从本地查看效果</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell">hexo cleanhexo generatehexo server<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h2 id="布属到远端"><a href="#布属到远端" class="headerlink" title="布属到远端"></a>布属到远端</h2><h3 id="github"><a href="#github" class="headerlink" title="github"></a>github</h3><p>在 github 新建仓库 name.github.io name一定要是你的 github 用户名</p><p>在 blog 目录下，下载 git deployer</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">sudo</span> cnpm <span class="token function">install</span> --save hexo-deployer-git<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h3 id="设置-config-yml"><a href="#设置-config-yml" class="headerlink" title="设置 _config.yml"></a>设置 _config.yml</h3><p>在 blog 目录下打开 _config.yml 文件，在文件最后的 # Deployments 上修改</p><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token comment"># Deployment</span><span class="token comment">## Docs: https://hexo.io/docs/one-command-deployment</span>deploy:  type: <span class="token string">'git'</span>  repo: https://github.com/DeclK/declk.github.io.git  branch: master<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="Deploy"><a href="#Deploy" class="headerlink" title="Deploy"></a>Deploy</h3><pre class="line-numbers language-shell" data-language="shell"><code class="language-shell"><span class="token function">sudo</span> hexo deploy<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>现在你的仓库里多了一些文件</p><p>以后你就可以通过你的仓库名 <em>*</em>.github.io 来访问你的博客啦！</p><h2 id="更换主题"><a href="#更换主题" class="headerlink" title="更换主题"></a>更换主题</h2><p>在寻找了许久过后决定使用 <a href="https://github.com/blinkfox/hexo-theme-matery">hexo-theme-matery</a></p><h2 id="可移植性"><a href="#可移植性" class="headerlink" title="可移植性"></a>可移植性</h2><p>如果把 hexo 整个博客项目移到另一台电脑上，依然可以正常运行，可能会遇到一些小困难，但是根据 hexo 的提示命令，很快就能解决</p>]]></content>
      
      
      <categories>
          
          <category> 软件 </category>
          
          <category> Hexo </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo </tag>
            
            <tag> 博客搭建 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
